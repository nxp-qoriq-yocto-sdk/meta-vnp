From f23d1526ac3dd74a523bbfff212109042c216969 Mon Sep 17 00:00:00 2001
From: Bhanu Chander G <bhanu.gaddoju@nxp.com>
Date: Fri, 24 May 2019 15:55:55 +0530
Subject: [PATCH 01/16] ask kernel patch for 414

---
 Makefile                                      |    1 -
 arch/arm64/boot/dts/freescale/Makefile        |    4 +
 .../dts/freescale/fsl-ls1043a-dgw-sdk.dts     |   69 +
 .../dts/freescale/fsl-ls1043a-dgw-usdpaa.dts  |  108 +
 .../boot/dts/freescale/fsl-ls1043a-dgw.dts    |  292 ++
 .../boot/dts/freescale/fsl-ls1043a-rdb.dts    |   12 +
 .../dts/freescale/fsl-ls1043a-rgw-sdk.dts     |   70 +
 .../dts/freescale/fsl-ls1043a-rgw-usdpaa.dts  |  109 +
 .../boot/dts/freescale/fsl-ls1043a-rgw.dts    |  291 ++
 .../arm64/boot/dts/freescale/fsl-ls1043a.dtsi |  117 +-
 .../boot/dts/freescale/fsl-ls1046a-rdb.dts    |   15 +
 .../arm64/boot/dts/freescale/fsl-ls1046a.dtsi |  126 +-
 arch/arm64/mm/dma-mapping.c                   |   13 +
 drivers/crypto/caam/pdb.h                     |   12 +-
 drivers/gpio/gpio-mpc8xxx.c                   |    1 +
 drivers/gpio/gpio-pca953x.c                   |   23 +-
 drivers/mtd/nand/fsl_ifc_nand.c               |   14 +-
 .../ethernet/freescale/sdk_dpaa/dpaa_eth.c    |    9 +-
 .../ethernet/freescale/sdk_dpaa/dpaa_eth.h    |   11 +-
 .../freescale/sdk_dpaa/dpaa_eth_common.c      |   10 +
 .../freescale/sdk_dpaa/dpaa_eth_common.h      |   12 +
 .../ethernet/freescale/sdk_dpaa/dpaa_eth_sg.c |  316 +-
 .../net/ethernet/freescale/sdk_dpaa/mac-api.c |    3 +
 drivers/net/ethernet/freescale/sdk_dpaa/mac.h |    2 +
 .../freescale/sdk_dpaa/offline_port.c         |   51 +
 .../net/ethernet/freescale/sdk_fman/Kconfig   |   12 +
 .../freescale/sdk_fman/Peripherals/FM/HC/hc.c |  223 +-
 .../sdk_fman/Peripherals/FM/MAC/dtsec.c       |   13 +
 .../sdk_fman/Peripherals/FM/MAC/fm_mac.c      |   14 +
 .../sdk_fman/Peripherals/FM/MAC/fm_mac.h      |    1 +
 .../sdk_fman/Peripherals/FM/MAC/memac.c       |   58 +
 .../sdk_fman/Peripherals/FM/MAC/tgec.c        |    1 +
 .../sdk_fman/Peripherals/FM/Pcd/Makefile      |    6 +-
 .../sdk_fman/Peripherals/FM/Pcd/fm_cc.c       | 3298 +++++++++++++++--
 .../sdk_fman/Peripherals/FM/Pcd/fm_cc.h       |  130 +
 .../sdk_fman/Peripherals/FM/Pcd/fm_cc_dbg.h   | 1405 +++++++
 .../sdk_fman/Peripherals/FM/Pcd/fm_ehash.c    | 1797 +++++++++
 .../sdk_fman/Peripherals/FM/Pcd/fm_kg.c       |   21 +
 .../sdk_fman/Peripherals/FM/Pcd/fm_manip.c    |  126 +
 .../sdk_fman/Peripherals/FM/Pcd/fm_pcd.c      |  282 ++
 .../sdk_fman/Peripherals/FM/Pcd/fm_pcd.h      |   40 +
 .../sdk_fman/Peripherals/FM/Port/fm_port.c    |   99 +-
 .../sdk_fman/Peripherals/FM/Port/fm_port.h    |    3 +
 .../sdk_fman/Peripherals/FM/Port/fman_port.c  |    1 +
 .../freescale/sdk_fman/Peripherals/FM/fm.c    |   77 +-
 .../sdk_fman/Peripherals/FM/fm_muram.c        |   50 +-
 .../sdk_fman/Peripherals/FM/inc/fm_common.h   |  113 +-
 .../sdk_fman/Peripherals/FM/inc/fm_hc.h       |   16 +
 .../Peripherals/FM/inc/fm_sp_common.h         |    2 +-
 .../ethernet/freescale/sdk_fman/etc/memcpy.c  |   19 +
 .../sdk_fman/inc/Peripherals/fm_eh_types.h    |   52 +
 .../sdk_fman/inc/Peripherals/fm_ehash.h       | 1402 +++++++
 .../sdk_fman/inc/Peripherals/fm_ext.h         |   47 +
 .../sdk_fman/inc/Peripherals/fm_mac_ext.h     |    1 +
 .../sdk_fman/inc/Peripherals/fm_pcd_ext.h     |  158 +-
 .../freescale/sdk_fman/inc/flib/fsl_fman.h    |    1 +
 .../sdk_fman/src/inc/wrapper/lnxwrp_exp_sym.h |   11 +-
 .../src/inc/wrapper/lnxwrp_fsl_fman.h         |    2 +
 .../freescale/sdk_fman/src/system/sys_io.c    |    4 +
 .../sdk_fman/src/wrapper/lnxwrp_fm.c          |   16 +
 .../sdk_fman/src/wrapper/lnxwrp_fm_port.c     |    9 +-
 .../sdk_fman/src/wrapper/lnxwrp_ioctls_fm.c   |   43 +-
 .../src/wrapper/lnxwrp_ioctls_fm_compat.h     |    8 +
 .../sdk_fman/src/wrapper/lnxwrp_sysfs_fm.c    |  191 +-
 .../src/wrapper/lnxwrp_sysfs_fm_port.c        |    3 +
 .../freescale/sdk_fman/src/xx/xx_arm_linux.c  |    7 +
 drivers/net/ppp/ppp_generic.c                 |   57 +
 drivers/net/ppp/pppoe.c                       |   23 +
 drivers/net/usb/usbnet.c                      |   21 +
 drivers/nfc/Kconfig                           |    1 +
 drivers/nfc/Makefile                          |    1 +
 drivers/nfc/pn7150/Kconfig                    |   12 +
 drivers/nfc/pn7150/LICENSE                    |  339 ++
 drivers/nfc/pn7150/Makefile                   |    1 +
 drivers/nfc/pn7150/README.md                  |    2 +
 drivers/nfc/pn7150/pn5xx_i2c.c                |  869 +++++
 drivers/nfc/pn7150/pn5xx_i2c.h                |   50 +
 drivers/nfc/pn7150/sample_devicetree.txt      |   17 +
 drivers/staging/fsl_qbman/fsl_usdpaa.c        |    2 +-
 drivers/tty/serial/sc16is7xx.c                |    6 +-
 include/linux/fsl_oh_port.h                   |   28 +
 include/linux/fsl_qman.h                      |    5 +
 include/linux/if_bridge.h                     |   16 +
 include/linux/netdevice.h                     |   16 +
 include/linux/skbuff.h                        |   28 +
 include/net/ip.h                              |    3 +
 include/net/ip6_tunnel.h                      |    6 +
 include/net/netfilter/nf_conntrack.h          |   41 +
 include/net/netns/xfrm.h                      |    3 +
 include/net/tcp.h                             |    5 +
 include/net/udp.h                             |    5 +
 include/net/xfrm.h                            |   70 +
 .../uapi/linux/fmd/Peripherals/fm_ioctls.h    |   28 +
 .../linux/fmd/Peripherals/fm_pcd_ioctls.h     |   40 +
 include/uapi/linux/if.h                       |    6 +
 include/uapi/linux/if_arp.h                   |    4 +-
 include/uapi/linux/if_ether.h                 |    3 +
 include/uapi/linux/if_tunnel.h                |   28 +
 include/uapi/linux/in.h                       |    4 +
 include/uapi/linux/ip6_tunnel.h               |   48 +
 .../linux/netfilter/nf_conntrack_common.h     |   21 +-
 .../netfilter/nf_conntrack_tuple_common.h     |    3 +
 .../linux/netfilter/nfnetlink_conntrack.h     |   16 +
 include/uapi/linux/netlink.h                  |   10 +-
 include/uapi/linux/pfkeyv2.h                  |    3 +
 include/uapi/linux/ppp-ioctl.h                |    3 +
 include/uapi/linux/rtnetlink.h                |    8 +
 net/Kconfig                                   |    8 +
 net/bridge/br.c                               |   54 +
 net/bridge/br_fdb.c                           |   90 +
 net/bridge/br_forward.c                       |    6 +-
 net/bridge/br_input.c                         |   12 +
 net/bridge/br_private.h                       |    5 +
 net/bridge/br_stp_if.c                        |    4 +
 net/core/dev.c                                |   43 +-
 net/core/rtnetlink.c                          |   11 +
 net/core/skbuff.c                             |   66 +
 net/ipv4/Kconfig                              |   13 +
 net/ipv4/Makefile                             |    1 +
 net/ipv4/etherip.c                            |  626 ++++
 net/ipv4/ip_output.c                          |   14 +-
 net/ipv4/ip_tunnel.c                          |    3 +
 net/ipv4/xfrm4_policy.c                       |   19 +
 net/ipv6/Kconfig                              |   15 +
 net/ipv6/Makefile                             |    1 +
 net/ipv6/esp6.c                               |   56 +
 net/ipv6/ethipip6.c                           | 1614 ++++++++
 net/ipv6/ip6_tunnel.c                         |  800 +++-
 net/ipv6/netfilter/ip6t_NPT.c                 |   27 +
 net/ipv6/output_core.c                        |    8 +
 net/ipv6/udp.c                                |  114 +
 net/ipv6/xfrm6_input.c                        |  113 +
 net/ipv6/xfrm6_policy.c                       |   27 +
 net/key/af_key.c                              |  819 ++++
 net/netfilter/Makefile                        |    1 +
 net/netfilter/comcerto_fp_netfilter.c         |  332 ++
 net/netfilter/nf_conntrack_core.c             |   58 +-
 net/netfilter/nf_conntrack_netlink.c          |  119 +-
 net/netfilter/nf_conntrack_proto_tcp.c        |    4 +
 net/netfilter/nf_conntrack_standalone.c       |    7 +
 net/wireless/db.txt                           | 1230 +++++-
 net/xfrm/xfrm_output.c                        |   34 +
 net/xfrm/xfrm_policy.c                        |   70 +
 net/xfrm/xfrm_state.c                         |  162 +
 144 files changed, 19409 insertions(+), 482 deletions(-)
 create mode 100644 arch/arm64/boot/dts/freescale/fsl-ls1043a-dgw-sdk.dts
 create mode 100644 arch/arm64/boot/dts/freescale/fsl-ls1043a-dgw-usdpaa.dts
 create mode 100644 arch/arm64/boot/dts/freescale/fsl-ls1043a-dgw.dts
 create mode 100644 arch/arm64/boot/dts/freescale/fsl-ls1043a-rgw-sdk.dts
 create mode 100644 arch/arm64/boot/dts/freescale/fsl-ls1043a-rgw-usdpaa.dts
 create mode 100644 arch/arm64/boot/dts/freescale/fsl-ls1043a-rgw.dts
 create mode 100644 drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_cc_dbg.h
 create mode 100644 drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_ehash.c
 create mode 100644 drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_eh_types.h
 create mode 100644 drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_ehash.h
 create mode 100644 drivers/nfc/pn7150/Kconfig
 create mode 100644 drivers/nfc/pn7150/LICENSE
 create mode 100644 drivers/nfc/pn7150/Makefile
 create mode 100644 drivers/nfc/pn7150/README.md
 create mode 100644 drivers/nfc/pn7150/pn5xx_i2c.c
 create mode 100644 drivers/nfc/pn7150/pn5xx_i2c.h
 create mode 100644 drivers/nfc/pn7150/sample_devicetree.txt
 create mode 100644 include/linux/fsl_oh_port.h
 create mode 100644 net/ipv4/etherip.c
 create mode 100644 net/ipv6/ethipip6.c
 create mode 100644 net/netfilter/comcerto_fp_netfilter.c

diff --git a/Makefile b/Makefile
index 90a4bffa8446..41cae4c6e93b 100644
--- a/Makefile
+++ b/Makefile
@@ -394,7 +394,6 @@ LINUXINCLUDE    := \
 KBUILD_AFLAGS   := -D__ASSEMBLY__
 KBUILD_CFLAGS   := -Wall -Wundef -Wstrict-prototypes -Wno-trigraphs \
 		   -fno-strict-aliasing -fno-common -fshort-wchar \
-		   -Werror-implicit-function-declaration \
 		   -Wno-format-security \
 		   -std=gnu89
 KBUILD_CPPFLAGS := -D__KERNEL__
diff --git a/arch/arm64/boot/dts/freescale/Makefile b/arch/arm64/boot/dts/freescale/Makefile
index b158e3b0820f..1b144bdd971c 100644
--- a/arch/arm64/boot/dts/freescale/Makefile
+++ b/arch/arm64/boot/dts/freescale/Makefile
@@ -8,6 +8,10 @@ dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1043a-qds-sdk.dtb
 dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1043a-rdb.dtb
 dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1043a-rdb-sdk.dtb
 dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1043a-rdb-usdpaa.dtb
+dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1043a-dgw.dtb
+dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1043a-dgw-sdk.dtb
+dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1043a-rgw.dtb
+dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1043a-rgw-sdk.dtb
 dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1046a-qds.dtb
 dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1046a-qds-sdk.dtb
 dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1046a-rdb.dtb
diff --git a/arch/arm64/boot/dts/freescale/fsl-ls1043a-dgw-sdk.dts b/arch/arm64/boot/dts/freescale/fsl-ls1043a-dgw-sdk.dts
new file mode 100644
index 000000000000..c793fc271413
--- /dev/null
+++ b/arch/arm64/boot/dts/freescale/fsl-ls1043a-dgw-sdk.dts
@@ -0,0 +1,69 @@
+/*
+ * Device Tree Include file for Freescale Layerscape-1043A family SoC.
+ *
+ * Copyright 2014-2015 Freescale Semiconductor, Inc.
+ * Mingkai Hu <Mingkai.hu@freescale.com>
+ * Copyright 2018 NXP
+ *
+ * This file is dual-licensed: you can use it either under the terms
+ * of the GPLv2 or the X11 license, at your option. Note that this dual
+ * licensing only applies to this file, and not this project as a
+ * whole.
+ *
+ *  a) This library is free software; you can redistribute it and/or
+ *     modify it under the terms of the GNU General Public License as
+ *     published by the Free Software Foundation; either version 2 of the
+ *     License, or (at your option) any later version.
+ *
+ *     This library is distributed in the hope that it will be useful,
+ *     but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *     GNU General Public License for more details.
+ *
+ * Or, alternatively,
+ *
+ *  b) Permission is hereby granted, free of charge, to any person
+ *     obtaining a copy of this software and associated documentation
+ *     files (the "Software"), to deal in the Software without
+ *     restriction, including without limitation the rights to use,
+ *     copy, modify, merge, publish, distribute, sublicense, and/or
+ *     sell copies of the Software, and to permit persons to whom the
+ *     Software is furnished to do so, subject to the following
+ *     conditions:
+ *
+ *     The above copyright notice and this permission notice shall be
+ *     included in all copies or substantial portions of the Software.
+ *
+ *     THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ *     EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
+ *     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ *     NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ *     HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
+ *     WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ *     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ *     OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+#include "fsl-ls1043a-dgw.dts"
+
+&bman_fbpr {
+	compatible = "fsl,bman-fbpr";
+	alloc-ranges = <0 0 0x10000 0>;
+};
+&qman_fqd {
+	compatible = "fsl,qman-fqd";
+	alloc-ranges = <0 0 0x10000 0>;
+};
+&qman_pfdr {
+	compatible = "fsl,qman-pfdr";
+	alloc-ranges = <0 0 0x10000 0>;
+};
+
+&soc {
+#include "qoriq-dpaa-eth.dtsi"
+#include "qoriq-fman3-0-6oh.dtsi"
+};
+
+&fman0 {
+	compatible = "fsl,fman", "simple-bus";
+};
diff --git a/arch/arm64/boot/dts/freescale/fsl-ls1043a-dgw-usdpaa.dts b/arch/arm64/boot/dts/freescale/fsl-ls1043a-dgw-usdpaa.dts
new file mode 100644
index 000000000000..e76f80d68f1c
--- /dev/null
+++ b/arch/arm64/boot/dts/freescale/fsl-ls1043a-dgw-usdpaa.dts
@@ -0,0 +1,108 @@
+/*
+ * Device Tree Include file for Freescale Layerscape-1043A family SoC.
+ *
+ * Copyright (C) 2014-2015, Freescale Semiconductor
+ * Copyright 2018 NXP
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#include "fsl-ls1043a-dgw.dts"
+
+/ {
+	bp7: buffer-pool@7 {
+		compatible = "fsl,p4080-bpool", "fsl,bpool";
+		fsl,bpid = <7>;
+		fsl,bpool-ethernet-cfg = <0 0 0 192 0 0xdeadbeef>;
+		fsl,bpool-thresholds = <0x400 0xc00 0x0 0x0>;
+	};
+
+	bp8: buffer-pool@8 {
+		compatible = "fsl,p4080-bpool", "fsl,bpool";
+		fsl,bpid = <8>;
+		fsl,bpool-ethernet-cfg = <0 0 0 576 0 0xabbaf00d>;
+		fsl,bpool-thresholds = <0x100 0x300 0x0 0x0>;
+	};
+
+	bp9: buffer-pool@9 {
+		compatible = "fsl,p4080-bpool", "fsl,bpool";
+		fsl,bpid = <9>;
+		fsl,bpool-ethernet-cfg = <0 0 0 2048 0 0xfeedabba>;
+		fsl,bpool-thresholds = <0x100 0x300 0x0 0x0>;
+	};
+
+	fsl,dpaa {
+		compatible = "fsl,ls1043a", "fsl,dpaa", "simple-bus";
+
+		ethernet@0 {
+			compatible = "fsl,dpa-ethernet-init";
+			fsl,bman-buffer-pools = <&bp7 &bp8 &bp9>;
+			fsl,qman-frame-queues-rx = <0x50 1 0x51 1>;
+			fsl,qman-frame-queues-tx = <0x70 1 0x71 1>;
+		};
+
+		ethernet@1 {
+			compatible = "fsl,dpa-ethernet-init";
+			fsl,bman-buffer-pools = <&bp7 &bp8 &bp9>;
+			fsl,qman-frame-queues-rx = <0x52 1 0x53 1>;
+			fsl,qman-frame-queues-tx = <0x72 1 0x73 1>;
+		};
+
+		ethernet@2 {
+			compatible = "fsl,dpa-ethernet-init";
+			fsl,bman-buffer-pools = <&bp7 &bp8 &bp9>;
+			fsl,qman-frame-queues-rx = <0x54 1 0x55 1>;
+			fsl,qman-frame-queues-tx = <0x74 1 0x75 1>;
+		};
+
+		ethernet@3 {
+			compatible = "fsl,dpa-ethernet-init";
+			fsl,bman-buffer-pools = <&bp7 &bp8 &bp9>;
+			fsl,qman-frame-queues-rx = <0x56 1 0x57 1>;
+			fsl,qman-frame-queues-tx = <0x76 1 0x77 1>;
+		};
+
+		ethernet@4 {
+			compatible = "fsl,dpa-ethernet-init";
+			fsl,bman-buffer-pools = <&bp7 &bp8 &bp9>;
+			fsl,qman-frame-queues-rx = <0x58 1 0x59 1>;
+			fsl,qman-frame-queues-tx = <0x78 1 0x79 1>;
+		};
+
+		ethernet@5 {
+			compatible = "fsl,dpa-ethernet-init";
+			fsl,bman-buffer-pools = <&bp7 &bp8 &bp9>;
+			fsl,qman-frame-queues-rx = <0x60 1 0x61 1>;
+			fsl,qman-frame-queues-tx = <0x80 1 0x81 1>;
+		};
+
+		ethernet@8 {
+			compatible = "fsl,dpa-ethernet-init";
+			fsl,bman-buffer-pools = <&bp7 &bp8 &bp9>;
+			fsl,qman-frame-queues-rx = <0x5c 1 0x5d 1>;
+			fsl,qman-frame-queues-tx = <0x7c 1 0x7d 1>;
+
+		};
+		dpa-fman0-oh@2 {
+			compatible = "fsl,dpa-oh";
+			/* Define frame queues for the OH port*/
+			/* <OH Rx error, OH Rx default> */
+			fsl,qman-frame-queues-oh = <0x5a 1 0x5b 1>;
+			fsl,fman-oh-port = <&fman0_oh2>;
+		};
+	};
+	reserved-memory {
+		#address-cells = <2>;
+		#size-cells = <2>;
+		ranges;
+
+		usdpaa_mem: usdpaa_mem {
+			compatible = "fsl,usdpaa-mem";
+			alloc-ranges = <0 0 0x10000 0>;
+			size = <0 0x10000000>;
+			alignment = <0 0x10000000>;
+		};
+	};
+};
diff --git a/arch/arm64/boot/dts/freescale/fsl-ls1043a-dgw.dts b/arch/arm64/boot/dts/freescale/fsl-ls1043a-dgw.dts
new file mode 100644
index 000000000000..940bece8638d
--- /dev/null
+++ b/arch/arm64/boot/dts/freescale/fsl-ls1043a-dgw.dts
@@ -0,0 +1,292 @@
+/*
+ * Device Tree Include file for Freescale Layerscape-1043A family SoC.
+ *
+ * Copyright 2014-2015, Freescale Semiconductor
+ *
+ * Mingkai Hu <Mingkai.hu@freescale.com>
+ * Copyright 2018 NXP
+ *
+ * This file is dual-licensed: you can use it either under the terms
+ * of the GPLv2 or the X11 license, at your option. Note that this dual
+ * licensing only applies to this file, and not this project as a
+ * whole.
+ *
+ *  a) This library is free software; you can redistribute it and/or
+ *     modify it under the terms of the GNU General Public License as
+ *     published by the Free Software Foundation; either version 2 of the
+ *     License, or (at your option) any later version.
+ *
+ *     This library is distributed in the hope that it will be useful,
+ *     but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *     GNU General Public License for more details.
+ *
+ * Or, alternatively,
+ *
+ *  b) Permission is hereby granted, free of charge, to any person
+ *     obtaining a copy of this software and associated documentation
+ *     files (the "Software"), to deal in the Software without
+ *     restriction, including without limitation the rights to use,
+ *     copy, modify, merge, publish, distribute, sublicense, and/or
+ *     sell copies of the Software, and to permit persons to whom the
+ *     Software is furnished to do so, subject to the following
+ *     conditions:
+ *
+ *     The above copyright notice and this permission notice shall be
+ *     included in all copies or substantial portions of the Software.
+ *
+ *     THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ *     EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
+ *     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ *     NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ *     HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
+ *     WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ *     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ *     OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+/dts-v1/;
+#include "fsl-ls1043a.dtsi"
+
+/ {
+	model = "LS1043A DGW Board";
+	compatible = "fsl,ls1043a-dgw", "fsl,ls1043a";
+
+	aliases {
+		crypto = &crypto;
+	};
+};
+
+&i2c0 {
+	status = "okay";
+
+	pmic@08 {
+		compatible = "nxp,34vr500";
+		reg = <0x8>;
+	};
+	pca9546@21 {
+		compatible = "nxp,pca9546";
+		reg = <0x21>;
+	};
+	ina220@40 {
+		compatible = "ti,ina220";
+		reg = <0x40>;
+		shunt-resistor = <1000>;
+	};
+	adt7461a@4c {
+		compatible = "adi,adt7461";
+		reg = <0x4c>;
+	};
+	rtc@51 {
+		compatible = "nxp,pcf2127";
+		reg = <0x51>;
+	};
+	eeprom@52 {
+		compatible = "at24,24c04";
+		reg = <0x52>;
+	};
+	eeprom@53 {
+		compatible = "at24,24c04";
+		reg = <0x53>;
+	};
+	pca9554@77 {
+		compatible = "nxp,pca9554";
+		reg = <0x77>;
+        #address-cells = <1>;
+        #size-cells = <0>;
+
+	    i2c@3 {
+              #address-cells = <1>;
+              #size-cells = <0>;
+		      reg = <0x3>;
+
+			  eeprom@50 {
+				      compatible = "at24,24c04";
+				      reg = <0x50>;
+			   };
+		};
+
+	 };	
+};
+
+&ifc {
+	status = "okay";
+	#address-cells = <2>;
+	#size-cells = <1>;
+/* NAND Flash on board 128MB */
+	ranges = <0x0 0x0 0x0 0x7e800000 0x00010000>;
+
+
+		nand@0,0 {
+			compatible = "fsl,ifc-nand";
+			nand-ecc-mode = "none";
+			#address-cells = <1>;
+			#size-cells = <1>;
+            reg = <0x0 0x0 0x10000>;
+		
+/* this partitions nodes are not in previous current sdk may be moved to u-boot ,adding with reference to previos sdk */
+             partition@0 {
+				/* This location must not be altered  */
+				/* 1MB for u-boot Bootloader Image */
+				reg = <0x0 0x00100000>;
+				label = "NAND U-Boot Image";
+				read-only;
+			};
+
+			partition@100000 {
+				/* 128KB for u-boot environment */
+				reg = <0x00100000 0x00020000>;
+				label = "NAND U-Boot Env";
+				read-only;
+			};
+
+			partition@120000 {
+				/* 256KB for u-boot environment */
+				reg = <0x00120000 0x00040000>;
+				label = "FMAN / QE ucode";
+				read-only;
+			};
+
+			partition@160000 {
+				/* 48MB for FIT Image */
+				reg = <0x00160000 0x03000000>;
+				label = "NAND FIT Image";
+				read-only;
+			};
+
+			partition@3160000 {
+				/* 20MB for FIT Image */
+				reg = <0x03160000 0x04EA0000>;
+				label = "NAND User Space";
+			};
+		};
+};
+
+
+&dspi0 {
+	bus-num = <0>;
+	status = "okay";
+
+
+	slic@0 {
+		compatible = "microsemi,zl88801";
+		reg = <0>;
+		spi-max-frequency = <2000000>;
+	};
+
+
+};
+
+&duart0 {
+	status = "okay";
+};
+
+&duart1 {
+	status = "okay";
+};
+
+#include "fsl-ls1043-post.dtsi"
+
+&fman0 {
+	ethernet@e0000 {
+		phy-handle = <&qsgmii_phy1>;
+		phy-connection-type = "qsgmii";
+        status = "okay";
+	};
+
+	ethernet@e2000 {
+		phy-handle = <&qsgmii_phy2>;
+       	phy-connection-type = "qsgmii";
+        status = "okay";
+	};
+
+	ethernet@e4000 {
+		fixed-link = <1 1 1000 0 0>;
+		phy-connection-type = "rgmii";
+        status = "okay";
+	};
+
+	ethernet@e6000 {
+		phy-handle = <&rgmii_phy2>;
+		phy-connection-type = "rgmii";
+	};
+
+	ethernet@e8000 {
+		phy-handle = <&qsgmii_phy3>;
+		phy-connection-type = "qsgmii";
+        status = "okay";
+	};
+
+	ethernet@ea000 {
+		phy-handle = <&qsgmii_phy4>;
+  		phy-connection-type = "qsgmii";
+        status = "okay";
+	};
+
+    ethernet@f0000 { /* DTSEC9/10GEC1 */
+		fixed-link = <1 1 10000 0 0>;
+		phy-connection-type = "xgmii";
+		status = "okay";
+	};
+	dpa-fman0-oh@2 {
+                compatible = "fsl,dpa-oh";
+                /* <OH Rx error, OH Rx default> */
+                fsl,qman-frame-queues-oh = <0x60 1 0x61 1>;
+                fsl,fman-oh-port = <&fman0_oh_0x3>;
+        };
+	dpa-fman0-oh@3 {
+                compatible = "fsl,dpa-oh";
+                /* <OH Rx error, OH Rx default> */
+                fsl,qman-frame-queues-oh = <0x62 1 0x63 1>;
+                fsl,fman-oh-port = <&fman0_oh_0x4>;
+        };
+
+	mdio@fc000 {
+		rgmii_phy1: ethernet-phy@1 {
+			reg = <0x1>;
+		};
+		rgmii_phy2: ethernet-phy@2 {
+			reg = <0x2>;
+		};
+		qsgmii_phy1: ethernet-phy@3 {
+			reg = <0x4>;
+		};
+		qsgmii_phy2: ethernet-phy@4 {
+			reg = <0x5>;
+		};
+		qsgmii_phy3: ethernet-phy@5 {
+			reg = <0x6>;
+		};
+		qsgmii_phy4: ethernet-phy@6 {
+			reg = <0x7>;
+		};
+	};
+
+	mdio@fd000 {
+	};
+};
+
+&uqe {
+	ucc_hdlc: ucc@2000 {
+		compatible = "fsl,ucc_hdlc";
+		rx-clock-name = "clk8";
+		tx-clock-name = "clk9";
+		fsl,rx-sync-clock = "rsync_pin";
+		fsl,tx-sync-clock = "tsync_pin";
+		fsl,tx-timeslot = <0xfffffffe>;
+		fsl,rx-timeslot = <0xfffffffe>;
+		fsl,tdm-framer-type = "e1";
+		fsl,tdm-mode = "normal";
+		fsl,tdm-id = <0>;
+		fsl,siram-entry-id = <0>;
+		fsl,tdm-interface;
+	};
+
+	ucc_serial: ucc@2200 {
+		device_type = "serial";
+		compatible = "ucc_uart";
+		port-number = <0>;
+		rx-clock-name = "brg2";
+		tx-clock-name = "brg2";
+	};
+};
diff --git a/arch/arm64/boot/dts/freescale/fsl-ls1043a-rdb.dts b/arch/arm64/boot/dts/freescale/fsl-ls1043a-rdb.dts
index 1496579077c0..d34eda4521d7 100644
--- a/arch/arm64/boot/dts/freescale/fsl-ls1043a-rdb.dts
+++ b/arch/arm64/boot/dts/freescale/fsl-ls1043a-rdb.dts
@@ -213,6 +213,18 @@
 		phy-handle = <&aqr105_phy>;
 		phy-connection-type = "xgmii";
 	};
+	dpa-fman0-oh@2 {
+                compatible = "fsl,dpa-oh";
+                /* <OH Rx error, OH Rx default> */
+                fsl,qman-frame-queues-oh = <0x60 1 0x61 1>;
+                fsl,fman-oh-port = <&fman0_oh_0x3>;
+        };
+	dpa-fman0-oh@3 {
+                compatible = "fsl,dpa-oh";
+                /* <OH Rx error, OH Rx default> */
+                fsl,qman-frame-queues-oh = <0x62 1 0x63 1>;
+                fsl,fman-oh-port = <&fman0_oh_0x4>;
+        };
 
 	mdio@fc000 {
 		rgmii_phy1: ethernet-phy@1 {
diff --git a/arch/arm64/boot/dts/freescale/fsl-ls1043a-rgw-sdk.dts b/arch/arm64/boot/dts/freescale/fsl-ls1043a-rgw-sdk.dts
new file mode 100644
index 000000000000..d8c59246acbf
--- /dev/null
+++ b/arch/arm64/boot/dts/freescale/fsl-ls1043a-rgw-sdk.dts
@@ -0,0 +1,70 @@
+
+ /*
+ * Device Tree Include file for Freescale Layerscape-1043A family SoC.
+ *
+ * Copyright 2014-2015 Freescale Semiconductor, Inc.
+ * Mingkai Hu <Mingkai.hu@freescale.com>
+ * Copyright 2018 NXP
+ *
+ * This file is dual-licensed: you can use it either under the terms
+ * of the GPLv2 or the X11 license, at your option. Note that this dual
+ * licensing only applies to this file, and not this project as a
+ * whole.
+ *
+ *  a) This library is free software; you can redistribute it and/or
+ *     modify it under the terms of the GNU General Public License as
+ *     published by the Free Software Foundation; either version 2 of the
+ *     License, or (at your option) any later version.
+ *
+ *     This library is distributed in the hope that it will be useful,
+ *     but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *     GNU General Public License for more details.
+ *
+ * Or, alternatively,
+ *
+ *  b) Permission is hereby granted, free of charge, to any person
+ *     obtaining a copy of this software and associated documentation
+ *     files (the "Software"), to deal in the Software without
+ *     restriction, including without limitation the rights to use,
+ *     copy, modify, merge, publish, distribute, sublicense, and/or
+ *     sell copies of the Software, and to permit persons to whom the
+ *     Software is furnished to do so, subject to the following
+ *     conditions:
+ *
+ *     The above copyright notice and this permission notice shall be
+ *     included in all copies or substantial portions of the Software.
+ *
+ *     THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ *     EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
+ *     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ *     NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ *     HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
+ *     WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ *     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ *     OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+#include "fsl-ls1043a-rgw.dts"
+
+&bman_fbpr {
+	compatible = "fsl,bman-fbpr";
+	alloc-ranges = <0 0 0x10000 0>;
+};
+&qman_fqd {
+	compatible = "fsl,qman-fqd";
+	alloc-ranges = <0 0 0x10000 0>;
+};
+&qman_pfdr {
+	compatible = "fsl,qman-pfdr";
+	alloc-ranges = <0 0 0x10000 0>;
+};
+
+&soc {
+#include "qoriq-dpaa-eth.dtsi"
+#include "qoriq-fman3-0-6oh.dtsi"
+};
+
+&fman0 {
+	compatible = "fsl,fman", "simple-bus";
+};
diff --git a/arch/arm64/boot/dts/freescale/fsl-ls1043a-rgw-usdpaa.dts b/arch/arm64/boot/dts/freescale/fsl-ls1043a-rgw-usdpaa.dts
new file mode 100644
index 000000000000..e5bd3e056e4e
--- /dev/null
+++ b/arch/arm64/boot/dts/freescale/fsl-ls1043a-rgw-usdpaa.dts
@@ -0,0 +1,109 @@
+
+/*
+ * Device Tree Include file for Freescale Layerscape-1043A family SoC.
+ *
+ * Copyright (C) 2014-2015, Freescale Semiconductor
+ * Copyright 2018 NXP
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#include "fsl-ls1043a-rgw.dts"
+
+/ {
+	bp7: buffer-pool@7 {
+		compatible = "fsl,p4080-bpool", "fsl,bpool";
+		fsl,bpid = <7>;
+		fsl,bpool-ethernet-cfg = <0 0 0 192 0 0xdeadbeef>;
+		fsl,bpool-thresholds = <0x400 0xc00 0x0 0x0>;
+	};
+
+	bp8: buffer-pool@8 {
+		compatible = "fsl,p4080-bpool", "fsl,bpool";
+		fsl,bpid = <8>;
+		fsl,bpool-ethernet-cfg = <0 0 0 576 0 0xabbaf00d>;
+		fsl,bpool-thresholds = <0x100 0x300 0x0 0x0>;
+	};
+
+	bp9: buffer-pool@9 {
+		compatible = "fsl,p4080-bpool", "fsl,bpool";
+		fsl,bpid = <9>;
+		fsl,bpool-ethernet-cfg = <0 0 0 2048 0 0xfeedabba>;
+		fsl,bpool-thresholds = <0x100 0x300 0x0 0x0>;
+	};
+
+	fsl,dpaa {
+		compatible = "fsl,ls1043a", "fsl,dpaa", "simple-bus";
+
+		ethernet@0 {
+			compatible = "fsl,dpa-ethernet-init";
+			fsl,bman-buffer-pools = <&bp7 &bp8 &bp9>;
+			fsl,qman-frame-queues-rx = <0x50 1 0x51 1>;
+			fsl,qman-frame-queues-tx = <0x70 1 0x71 1>;
+		};
+
+		ethernet@1 {
+			compatible = "fsl,dpa-ethernet-init";
+			fsl,bman-buffer-pools = <&bp7 &bp8 &bp9>;
+			fsl,qman-frame-queues-rx = <0x52 1 0x53 1>;
+			fsl,qman-frame-queues-tx = <0x72 1 0x73 1>;
+		};
+
+		ethernet@2 {
+			compatible = "fsl,dpa-ethernet-init";
+			fsl,bman-buffer-pools = <&bp7 &bp8 &bp9>;
+			fsl,qman-frame-queues-rx = <0x54 1 0x55 1>;
+			fsl,qman-frame-queues-tx = <0x74 1 0x75 1>;
+		};
+
+		ethernet@3 {
+			compatible = "fsl,dpa-ethernet-init";
+			fsl,bman-buffer-pools = <&bp7 &bp8 &bp9>;
+			fsl,qman-frame-queues-rx = <0x56 1 0x57 1>;
+			fsl,qman-frame-queues-tx = <0x76 1 0x77 1>;
+		};
+
+		ethernet@4 {
+			compatible = "fsl,dpa-ethernet-init";
+			fsl,bman-buffer-pools = <&bp7 &bp8 &bp9>;
+			fsl,qman-frame-queues-rx = <0x58 1 0x59 1>;
+			fsl,qman-frame-queues-tx = <0x78 1 0x79 1>;
+		};
+
+		ethernet@5 {
+			compatible = "fsl,dpa-ethernet-init";
+			fsl,bman-buffer-pools = <&bp7 &bp8 &bp9>;
+			fsl,qman-frame-queues-rx = <0x60 1 0x61 1>;
+			fsl,qman-frame-queues-tx = <0x80 1 0x81 1>;
+		};
+
+		ethernet@8 {
+			compatible = "fsl,dpa-ethernet-init";
+			fsl,bman-buffer-pools = <&bp7 &bp8 &bp9>;
+			fsl,qman-frame-queues-rx = <0x5c 1 0x5d 1>;
+			fsl,qman-frame-queues-tx = <0x7c 1 0x7d 1>;
+
+		};
+		dpa-fman0-oh@2 {
+			compatible = "fsl,dpa-oh";
+			/* Define frame queues for the OH port*/
+			/* <OH Rx error, OH Rx default> */
+			fsl,qman-frame-queues-oh = <0x5a 1 0x5b 1>;
+			fsl,fman-oh-port = <&fman0_oh2>;
+		};
+	};
+	reserved-memory {
+		#address-cells = <2>;
+		#size-cells = <2>;
+		ranges;
+
+		usdpaa_mem: usdpaa_mem {
+			compatible = "fsl,usdpaa-mem";
+			alloc-ranges = <0 0 0x10000 0>;
+			size = <0 0x10000000>;
+			alignment = <0 0x10000000>;
+		};
+	};
+};
diff --git a/arch/arm64/boot/dts/freescale/fsl-ls1043a-rgw.dts b/arch/arm64/boot/dts/freescale/fsl-ls1043a-rgw.dts
new file mode 100644
index 000000000000..0c2c17387777
--- /dev/null
+++ b/arch/arm64/boot/dts/freescale/fsl-ls1043a-rgw.dts
@@ -0,0 +1,291 @@
+/*
+ * Device Tree Include file for Freescale Layerscape-1043A family SoC.
+ *
+ * Copyright 2014-2015, Freescale Semiconductor
+ *
+ * Mingkai Hu <Mingkai.hu@freescale.com>
+ * Copyright 2018 NXP
+ *
+ * This file is dual-licensed: you can use it either under the terms
+ * of the GPLv2 or the X11 license, at your option. Note that this dual
+ * licensing only applies to this file, and not this project as a
+ * whole.
+ *
+ *  a) This library is free software; you can redistribute it and/or
+ *     modify it under the terms of the GNU General Public License as
+ *     published by the Free Software Foundation; either version 2 of the
+ *     License, or (at your option) any later version.
+ *
+ *     This library is distributed in the hope that it will be useful,
+ *     but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *     GNU General Public License for more details.
+ *
+ * Or, alternatively,
+ *
+ *  b) Permission is hereby granted, free of charge, to any person
+ *     obtaining a copy of this software and associated documentation
+ *     files (the "Software"), to deal in the Software without
+ *     restriction, including without limitation the rights to use,
+ *     copy, modify, merge, publish, distribute, sublicense, and/or
+ *     sell copies of the Software, and to permit persons to whom the
+ *     Software is furnished to do so, subject to the following
+ *     conditions:
+ *
+ *     The above copyright notice and this permission notice shall be
+ *     included in all copies or substantial portions of the Software.
+ *
+ *     THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ *     EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
+ *     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ *     NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ *     HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
+ *     WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ *     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ *     OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+/dts-v1/;
+#include "fsl-ls1043a.dtsi"
+
+/ {
+	model = "LS1043A RGW Board";
+	compatible = "fsl,ls1043a-rgw", "fsl,ls1043a";
+
+	aliases {
+		crypto = &crypto;
+	};
+};
+
+&i2c0 {
+	status = "okay";
+
+	pmic@08 {
+		compatible = "nxp,34vr500";
+		reg = <0x8>;
+	};
+	pca9546@21 {
+		compatible = "nxp,pca9546";
+		reg = <0x21>;
+	};
+	ina220@40 {
+		compatible = "ti,ina220";
+		reg = <0x40>;
+		shunt-resistor = <1000>;
+	};
+	adt7461a@4c {
+		compatible = "adi,adt7461";
+		reg = <0x4c>;
+	};
+	rtc@51 {
+		compatible = "nxp,pcf2127";
+		reg = <0x51>;
+	};
+	eeprom@52 {
+		compatible = "at24,24c04";
+		reg = <0x52>;
+	};
+	eeprom@53 {
+		compatible = "at24,24c04";
+		reg = <0x53>;
+	};
+	pca9554@77 {
+		compatible = "nxp,pca9554";
+		reg = <0x77>;
+        #address-cells = <1>;
+        #size-cells = <0>;
+
+	    i2c@3 {
+              #address-cells = <1>;
+              #size-cells = <0>;
+		      reg = <0x3>;
+
+			  eeprom@50 {
+				      compatible = "at24,24c04";
+				      reg = <0x50>;
+			   };
+		};
+
+	 };	
+};
+
+&ifc {
+	status = "okay";
+	#address-cells = <2>;
+	#size-cells = <1>;
+/* NAND Flash on board 128MB */
+	ranges = <0x0 0x0 0x0 0x7e800000 0x00010000>;
+
+
+		nand@0,0 {
+			compatible = "fsl,ifc-nand";
+			#address-cells = <1>;
+			#size-cells = <1>;
+            reg = <0x0 0x0 0x10000>;
+		
+/* this partitions nodes are not in previous current sdk may be moved to u-boot ,adding with reference to previos sdk */
+             partition@0 {
+				/* This location must not be altered  */
+				/* 1MB for u-boot Bootloader Image */
+				reg = <0x0 0x00100000>;
+				label = "NAND U-Boot Image";
+				read-only;
+			};
+
+			partition@100000 {
+				/* 128KB for u-boot environment */
+				reg = <0x00100000 0x00020000>;
+				label = "NAND U-Boot Env";
+				read-only;
+			};
+
+			partition@120000 {
+				/* 256KB for u-boot environment */
+				reg = <0x00120000 0x00040000>;
+				label = "FMAN / QE ucode";
+				read-only;
+			};
+
+			partition@160000 {
+				/* 48MB for FIT Image */
+				reg = <0x00160000 0x03000000>;
+				label = "NAND FIT Image";
+				read-only;
+			};
+
+			partition@3160000 {
+				/* 20MB for FIT Image */
+				reg = <0x03160000 0x04EA0000>;
+				label = "NAND User Space";
+			};
+		};
+};
+
+
+&dspi0 {
+	bus-num = <0>;
+	status = "okay";
+
+
+	slic@0 {
+		compatible = "microsemi,zl88801";
+		reg = <0>;
+		spi-max-frequency = <2000000>;
+	};
+
+
+};
+
+&duart0 {
+	status = "okay";
+};
+
+&duart1 {
+	status = "okay";
+};
+
+#include "fsl-ls1043-post.dtsi"
+
+&fman0 {
+	ethernet@e0000 {
+		phy-handle = <&qsgmii_phy1>;
+		phy-connection-type = "qsgmii";
+        status = "okay";
+	};
+
+	ethernet@e2000 {
+		phy-handle = <&qsgmii_phy2>;
+       	phy-connection-type = "qsgmii";
+        status = "okay";
+	};
+
+	ethernet@e4000 {
+		phy-handle = <&rgmii_phy1>;
+		phy-connection-type = "rgmii";
+        status = "okay";
+	};
+
+	ethernet@e6000 {
+		phy-handle = <&rgmii_phy2>;
+		phy-connection-type = "rgmii";
+	};
+
+	ethernet@e8000 {
+		phy-handle = <&qsgmii_phy3>;
+		phy-connection-type = "qsgmii";
+        status = "okay";
+	};
+
+	ethernet@ea000 {
+		phy-handle = <&qsgmii_phy4>;
+  		phy-connection-type = "qsgmii";
+        status = "okay";
+	};
+
+    ethernet@f0000 { /* DTSEC9/10GEC1 */
+		fixed-link = <1 1 10000 0 0>;
+		phy-connection-type = "xgmii";
+		status = "okay";
+	};
+	dpa-fman0-oh@2 {
+                compatible = "fsl,dpa-oh";
+                /* <OH Rx error, OH Rx default> */
+                fsl,qman-frame-queues-oh = <0x60 1 0x61 1>;
+                fsl,fman-oh-port = <&fman0_oh_0x3>;
+        };
+	dpa-fman0-oh@3 {
+                compatible = "fsl,dpa-oh";
+                /* <OH Rx error, OH Rx default> */
+                fsl,qman-frame-queues-oh = <0x62 1 0x63 1>;
+                fsl,fman-oh-port = <&fman0_oh_0x4>;
+        };
+
+	mdio@fc000 {
+		rgmii_phy1: ethernet-phy@1 {
+			reg = <0x1>;
+		};
+		rgmii_phy2: ethernet-phy@2 {
+			reg = <0x2>;
+		};
+		qsgmii_phy1: ethernet-phy@3 {
+			reg = <0x4>;
+		};
+		qsgmii_phy2: ethernet-phy@4 {
+			reg = <0x5>;
+		};
+		qsgmii_phy3: ethernet-phy@5 {
+			reg = <0x6>;
+		};
+		qsgmii_phy4: ethernet-phy@6 {
+			reg = <0x7>;
+		};
+	};
+
+	mdio@fd000 {
+	};
+};
+
+&uqe {
+	ucc_hdlc: ucc@2000 {
+		compatible = "fsl,ucc_hdlc";
+		rx-clock-name = "clk8";
+		tx-clock-name = "clk9";
+		fsl,rx-sync-clock = "rsync_pin";
+		fsl,tx-sync-clock = "tsync_pin";
+		fsl,tx-timeslot = <0xfffffffe>;
+		fsl,rx-timeslot = <0xfffffffe>;
+		fsl,tdm-framer-type = "e1";
+		fsl,tdm-mode = "normal";
+		fsl,tdm-id = <0>;
+		fsl,siram-entry-id = <0>;
+		fsl,tdm-interface;
+	};
+
+	ucc_serial: ucc@2200 {
+		device_type = "serial";
+		compatible = "ucc_uart";
+		port-number = <0>;
+		rx-clock-name = "brg2";
+		tx-clock-name = "brg2";
+	};
+};
diff --git a/arch/arm64/boot/dts/freescale/fsl-ls1043a.dtsi b/arch/arm64/boot/dts/freescale/fsl-ls1043a.dtsi
index 98b9913e832e..1f2a88a30ff6 100644
--- a/arch/arm64/boot/dts/freescale/fsl-ls1043a.dtsi
+++ b/arch/arm64/boot/dts/freescale/fsl-ls1043a.dtsi
@@ -111,6 +111,119 @@
 			cpu-idle-states = <&CPU_PH20>;
 		};
 
+fman0-extended-args {
+                        cell-index = <0>;
+                        compatible = "fsl,fman-extended-args";
+                        total-fifo-size = <0x36500>;
+
+                        fman0_oh1-extended-args {
+                                cell-index = <1>;
+                                compatible = "fsl,fman-port-op-extended-args";
+                                fifo-size = <0x2000 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+
+			fman0_oh2-extended-args {
+                                cell-index = <2>;
+                                compatible = "fsl,fman-port-op-extended-args";
+                                fifo-size = <0x3200 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+			fman0_oh3-extended-args {
+                                cell-index = <3>;
+                                compatible = "fsl,fman-port-op-extended-args";
+                                fifo-size = <0x900 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+
+                        fman0_rx0-extended-args {
+                                cell-index = <0>;
+                                compatible = "fsl,fman-port-1g-rx-extended-args";
+                                fifo-size = <0x3200 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+                        fman0_tx0-extended-args {
+                                cell-index = <0>;
+                                compatible = "fsl,fman-port-1g-tx-extended-args";
+                                fifo-size = <0x3200 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+                        fman0_rx1-extended-args {
+                                cell-index = <1>;
+                                compatible = "fsl,fman-port-1g-rx-extended-args";
+                                fifo-size = <0x3200 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+			fman0_tx1-extended-args {
+                                cell-index = <1>;
+                                compatible = "fsl,fman-port-1g-tx-extended-args";
+                                fifo-size = <0x3200 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+                        fman0_rx2-extended-args {
+                                cell-index = <2>;
+                                compatible = "fsl,fman-port-1g-rx-extended-args";
+                                fifo-size = <0x3200 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+                        fman0_tx2-extended-args {
+                                cell-index = <2>;
+                                compatible = "fsl,fman-port-1g-tx-extended-args";
+                                fifo-size = <0x3200 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+                        fman0_rx3-extended-args {
+                                cell-index = <3>;
+                                compatible = "fsl,fman-port-1g-rx-extended-args";
+                                fifo-size = <0x3200 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+		    	fman0_tx3-extended-args {
+                                cell-index = <3>;
+                                compatible = "fsl,fman-port-1g-tx-extended-args";
+                                fifo-size = <0x3200 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+                        fman0_rx4-extended-args {
+                                cell-index = <4>;
+                                compatible = "fsl,fman-port-1g-rx-extended-args";
+                                fifo-size = <0x3200 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+                        fman0_tx4-extended-args {
+                                cell-index = <4>;
+                                compatible = "fsl,fman-port-1g-tx-extended-args";
+                                fifo-size = <0x3200 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+                        fman0_rx5-extended-args {
+                                cell-index = <5>;
+                                compatible = "fsl,fman-port-1g-rx-extended-args";
+                                fifo-size = <0x3200 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+                        fman0_tx5-extended-args {
+                                cell-index = <5>;
+                                compatible = "fsl,fman-port-1g-tx-extended-args";
+                                fifo-size = <0x3200 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+
+                        fman0_rx6-extended-args {
+                                cell-index = <0>;
+                                compatible = "fsl,fman-port-10g-rx-extended-args";
+                                fifo-size = <0x6000 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+                        fman0_tx6-extended-args {
+                                cell-index = <0>;
+                                compatible = "fsl,fman-port-10g-tx-extended-args";
+                                fifo-size = <0x4000 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+		};
+
+
 		l2: l2-cache {
 			compatible = "cache";
 		};
@@ -153,8 +266,8 @@
 
 		qman_fqd: qman-fqd {
 			compatible = "shared-dma-pool";
-			size = <0 0x400000>;
-			alignment = <0 0x400000>;
+			size = <0 0x800000>;
+			alignment = <0 0x800000>;
 			no-map;
 		};
 
diff --git a/arch/arm64/boot/dts/freescale/fsl-ls1046a-rdb.dts b/arch/arm64/boot/dts/freescale/fsl-ls1046a-rdb.dts
index f8a61a603690..df745354b9ba 100644
--- a/arch/arm64/boot/dts/freescale/fsl-ls1046a-rdb.dts
+++ b/arch/arm64/boot/dts/freescale/fsl-ls1046a-rdb.dts
@@ -146,6 +146,7 @@
 		#address-cells = <1>;
 		#size-cells = <1>;
 		spi-max-frequency = <20000000>;
+		m25p,fast-read;
 		reg = <0>;
 		spi-rx-bus-width = <4>;
 		spi-tx-bus-width = <4>;
@@ -156,6 +157,7 @@
 		#address-cells = <1>;
 		#size-cells = <1>;
 		spi-max-frequency = <20000000>;
+		m25p,fast-read;
 		reg = <1>;
 		spi-rx-bus-width = <4>;
 		spi-tx-bus-width = <4>;
@@ -195,6 +197,19 @@
 		phy-connection-type = "xgmii";
 	};
 
+	dpa-fman0-oh@2 {
+                compatible = "fsl,dpa-oh";
+                /* <OH Rx error, OH Rx default> */
+                fsl,qman-frame-queues-oh = <0x60 1 0x61 1>;
+                fsl,fman-oh-port = <&fman0_oh_0x3>;
+        };
+	dpa-fman0-oh@3 {
+                compatible = "fsl,dpa-oh";
+                /* <OH Rx error, OH Rx default> */
+                fsl,qman-frame-queues-oh = <0x62 1 0x63 1>;
+                fsl,fman-oh-port = <&fman0_oh_0x4>;
+        };
+
 	mdio@fc000 {
 		rgmii_phy1: ethernet-phy@1 {
 			reg = <0x1>;
diff --git a/arch/arm64/boot/dts/freescale/fsl-ls1046a.dtsi b/arch/arm64/boot/dts/freescale/fsl-ls1046a.dtsi
index 4cb03c14332d..c6494e6f8f19 100644
--- a/arch/arm64/boot/dts/freescale/fsl-ls1046a.dtsi
+++ b/arch/arm64/boot/dts/freescale/fsl-ls1046a.dtsi
@@ -110,6 +110,130 @@
 		l2: l2-cache {
 			compatible = "cache";
 		};
+		fman0-extended-args {
+                        cell-index = <0>;
+                        compatible = "fsl,fman-extended-args";
+                        total-fifo-size = <0x3D300>;
+
+                        fman0_oh1-extended-args {
+                                cell-index = <1>;
+                                compatible = "fsl,fman-port-op-extended-args";
+                                fifo-size = <0x2000 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+
+						fman0_oh2-extended-args {
+                                cell-index = <2>;
+                                compatible = "fsl,fman-port-op-extended-args";
+                                fifo-size = <0x3200 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+						fman0_oh3-extended-args {
+                                cell-index = <3>;
+                                compatible = "fsl,fman-port-op-extended-args";
+                                fifo-size = <0x900 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+
+                        fman0_rx0-extended-args {
+                                cell-index = <0>;
+                                compatible = "fsl,fman-port-1g-rx-extended-args";
+                                fifo-size = <0x3200 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+                        fman0_tx0-extended-args {
+                                cell-index = <0>;
+                                compatible = "fsl,fman-port-1g-tx-extended-args";
+                                fifo-size = <0x3200 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+                        fman0_rx1-extended-args {
+                                cell-index = <1>;
+                                compatible = "fsl,fman-port-1g-rx-extended-args";
+                                fifo-size = <0x3200 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+						fman0_tx1-extended-args {
+                                cell-index = <1>;
+                                compatible = "fsl,fman-port-1g-tx-extended-args";
+                                fifo-size = <0x3200 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+                        fman0_rx2-extended-args {
+                                cell-index = <2>;
+                                compatible = "fsl,fman-port-1g-rx-extended-args";
+                                fifo-size = <0x3200 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+                        fman0_tx2-extended-args {
+                                cell-index = <2>;
+                                compatible = "fsl,fman-port-1g-tx-extended-args";
+                                fifo-size = <0x3200 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+                        fman0_rx3-extended-args {
+                                cell-index = <3>;
+                                compatible = "fsl,fman-port-1g-rx-extended-args";
+                                fifo-size = <0x3200 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+		    			fman0_tx3-extended-args {
+                                cell-index = <3>;
+                                compatible = "fsl,fman-port-1g-tx-extended-args";
+                                fifo-size = <0x3200 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+                        fman0_rx4-extended-args {
+                                cell-index = <4>;
+                                compatible = "fsl,fman-port-1g-rx-extended-args";
+                                fifo-size = <0x3200 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+                        fman0_tx4-extended-args {
+                                cell-index = <4>;
+                                compatible = "fsl,fman-port-1g-tx-extended-args";
+                                fifo-size = <0x3200 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+						fman0_rx5-extended-args {
+                                cell-index = <5>;
+                                compatible = "fsl,fman-port-1g-rx-extended-args";
+                                fifo-size = <0x3200 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+                        fman0_tx5-extended-args {
+                                cell-index = <5>;
+                                compatible = "fsl,fman-port-1g-tx-extended-args";
+                                fifo-size = <0x3200 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+
+                        fman0_rx6-extended-args {
+                                cell-index = <0>;
+                                compatible = "fsl,fman-port-10g-rx-extended-args";
+                                fifo-size = <0x6000 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+                        fman0_tx6-extended-args {
+                                cell-index = <0>;
+                                compatible = "fsl,fman-port-10g-tx-extended-args";
+                                fifo-size = <0x4000 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+                        fman0_rx7-extended-args {
+                                cell-index = <1>;
+                                compatible = "fsl,fman-port-10g-rx-extended-args";
+                                fifo-size = <0x6000 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+                        fman0_tx7-extended-args {
+                                cell-index = <1>;
+                                compatible = "fsl,fman-port-10g-tx-extended-args";
+                                fifo-size = <0x4000 0x0>;
+                                buffer-layout = <128 64>;
+                        };
+
+		};
 	};
 
 	idle-states {
@@ -204,7 +328,7 @@
 		};
 
 		qspi: quadspi@1550000 {
-			compatible = "fsl,ls1021a-qspi";
+			compatible = "fsl,ls1021a-qspi","fsl,ls1-qspi";
 			#address-cells = <1>;
 			#size-cells = <0>;
 			reg = <0x0 0x1550000 0x0 0x10000>,
diff --git a/arch/arm64/mm/dma-mapping.c b/arch/arm64/mm/dma-mapping.c
index dae572f62e21..13de121bf8e6 100644
--- a/arch/arm64/mm/dma-mapping.c
+++ b/arch/arm64/mm/dma-mapping.c
@@ -44,7 +44,20 @@ static pgprot_t __get_dma_pgprot(unsigned long attrs, pgprot_t prot,
 
 static struct gen_pool *atomic_pool __ro_after_init;
 
+#ifdef CONFIG_CPE_FAST_PATH
+/*
+ * Here PFE_DMA_SIZE is calculated for 32K bidirectional flows.
+ * For each connection it allocates two times memory from 128 dma pool
+ * So, for 32k bidirectional connections = 32*1024*(128+128)=8M
+ * Adding some extra memory for other applications and for PFE also.
+ */
+#define PFE_DMA_SIZE			(12 * SZ_1M)
+
+#define DEFAULT_DMA_COHERENT_POOL_SIZE  PFE_DMA_SIZE
+#else
 #define DEFAULT_DMA_COHERENT_POOL_SIZE  SZ_256K
+#endif /* endif for ifdef CONFIG_CPE_FAST_PATH */
+
 static size_t atomic_pool_size __initdata = DEFAULT_DMA_COHERENT_POOL_SIZE;
 
 static int __init early_coherent_pool(char *p)
diff --git a/drivers/crypto/caam/pdb.h b/drivers/crypto/caam/pdb.h
index 810f0bef0652..7bef4a832ed4 100644
--- a/drivers/crypto/caam/pdb.h
+++ b/drivers/crypto/caam/pdb.h
@@ -145,7 +145,7 @@ struct ipsec_encap_pdb {
 	u32 spi;
 	u32 ip_hdr_len;
 	u32 ip_hdr[0];
-};
+}__attribute__((packed));
 
 /**
  * ipsec_decap_cbc - PDB part for IPsec CBC decapsulation
@@ -153,7 +153,7 @@ struct ipsec_encap_pdb {
  */
 struct ipsec_decap_cbc {
 	u32 rsvd[2];
-};
+}__attribute__((packed));
 
 /**
  * ipsec_decap_ctr - PDB part for IPsec CTR decapsulation
@@ -163,7 +163,7 @@ struct ipsec_decap_cbc {
 struct ipsec_decap_ctr {
 	u8 ctr_nonce[4];
 	u32 ctr_initial;
-};
+}__attribute__((packed));
 
 /**
  * ipsec_decap_ccm - PDB part for IPsec CCM decapsulation
@@ -177,7 +177,7 @@ struct ipsec_decap_ctr {
 struct ipsec_decap_ccm {
 	u8 salt[4];
 	u32 ccm_opt;
-};
+}__attribute__((packed));
 
 /**
  * ipsec_decap_gcm - PDB part for IPsec GCN decapsulation
@@ -187,7 +187,7 @@ struct ipsec_decap_ccm {
 struct ipsec_decap_gcm {
 	u8 salt[4];
 	u32 resvd;
-};
+}__attribute__((packed));
 
 /**
  * ipsec_decap_pdb - PDB for IPsec decapsulation
@@ -211,7 +211,7 @@ struct ipsec_decap_pdb {
 	u32 seq_num_ext_hi;
 	u32 seq_num;
 	__be32 anti_replay[4];
-};
+}__attribute__((packed));
 
 /*
  * IPSec ESP Datapath Protocol Override Register (DPOVRD)
diff --git a/drivers/gpio/gpio-mpc8xxx.c b/drivers/gpio/gpio-mpc8xxx.c
index 8c93dec498fa..a0646b58d4d0 100644
--- a/drivers/gpio/gpio-mpc8xxx.c
+++ b/drivers/gpio/gpio-mpc8xxx.c
@@ -157,6 +157,7 @@ static int mpc8xxx_irq_set_type(struct irq_data *d, unsigned int flow_type)
 
 	switch (flow_type) {
 	case IRQ_TYPE_EDGE_FALLING:
+	case IRQ_TYPE_LEVEL_LOW:
 		raw_spin_lock_irqsave(&mpc8xxx_gc->lock, flags);
 		gc->write_reg(mpc8xxx_gc->regs + GPIO_ICR,
 			gc->read_reg(mpc8xxx_gc->regs + GPIO_ICR)
diff --git a/drivers/gpio/gpio-pca953x.c b/drivers/gpio/gpio-pca953x.c
index 1b9dbf691ae7..8cfb99edb0ba 100644
--- a/drivers/gpio/gpio-pca953x.c
+++ b/drivers/gpio/gpio-pca953x.c
@@ -187,9 +187,11 @@ static int pca953x_write_regs_8(struct pca953x_chip *chip, int reg, u8 *val)
 
 static int pca953x_write_regs_16(struct pca953x_chip *chip, int reg, u8 *val)
 {
-	u16 word = get_unaligned((u16 *)val);
+//	__le16 word = cpu_to_le16(get_unaligned((u16 *)val));
 
-	return i2c_smbus_write_word_data(chip->client, reg << 1, word);
+	return i2c_smbus_write_word_data(chip->client,
+					reg << 1, (u16) *val);
+//					 reg << 1, (__force u16)word);
 }
 
 static int pca957x_write_regs_16(struct pca953x_chip *chip, int reg, u8 *val)
@@ -537,6 +539,7 @@ static bool pca953x_irq_pending(struct pca953x_chip *chip, u8 *pending)
 	bool pending_seen = false;
 	bool trigger_seen = false;
 	u8 trigger[MAX_BANK];
+	u8 pendings = 0;
 	int ret, i;
 
 	if (chip->driver_data & PCA_PCAL) {
@@ -552,14 +555,22 @@ static bool pca953x_irq_pending(struct pca953x_chip *chip, u8 *pending)
 
 		for (i = 0; i < NBANK(chip); i++) {
 			/* Apply filter for rising/falling edge selection */
+			/* assume this is level interrupt */
+#if 1
+			trigger[i] = (~cur_stat[i]) & chip->irq_mask[i];
+			pending[i] = trigger[i];
+			pendings += pending[i];
+#else
 			pending[i] = (~cur_stat[i] & chip->irq_trig_fall[i]) |
 				(cur_stat[i] & chip->irq_trig_raise[i]);
 			pending[i] &= trigger[i];
 			if (pending[i])
 				pending_seen = true;
+#endif
 		}
 
-		return pending_seen;
+		return pendings;
+//		return pending_seen;
 	}
 
 	ret = pca953x_read_regs(chip, chip->regs->input, cur_stat);
@@ -825,6 +836,9 @@ static int pca953x_probe(struct i2c_client *client,
 		}
 	}
 
+	/* assume it is PCAL9555a, as there is no device tree based matching
+	 * in this kernel version */
+	chip->driver_data |= PCA_PCAL;
 	mutex_init(&chip->i2c_lock);
 	/*
 	 * In case we have an i2c-mux controlled by a GPIO provided by an
@@ -857,8 +871,9 @@ static int pca953x_probe(struct i2c_client *client,
 		chip->write_regs = pca953x_write_regs_24;
 		chip->read_regs = pca953x_read_regs_24;
 	} else {
-		if (PCA_CHIP_TYPE(chip->driver_data) == PCA953X_TYPE)
+		if (PCA_CHIP_TYPE(chip->driver_data) == PCA953X_TYPE) {
 			chip->write_regs = pca953x_write_regs_16;
+		}
 		else
 			chip->write_regs = pca957x_write_regs_16;
 		chip->read_regs = pca953x_read_regs_16;
diff --git a/drivers/mtd/nand/fsl_ifc_nand.c b/drivers/mtd/nand/fsl_ifc_nand.c
index 3f5fd7668ee8..171674d04d66 100644
--- a/drivers/mtd/nand/fsl_ifc_nand.c
+++ b/drivers/mtd/nand/fsl_ifc_nand.c
@@ -825,6 +825,8 @@ static int fsl_ifc_chip_init(struct fsl_ifc_mtd *priv)
 	struct fsl_ifc_runtime __iomem *ifc_runtime = ctrl->rregs;
 	struct nand_chip *chip = &priv->chip;
 	struct mtd_info *mtd = nand_to_mtd(&priv->chip);
+	int ret;
+	const char *pm;
 	u32 csor;
 
 	/* Fill in fsl_ifc_mtd structure */
@@ -915,8 +917,16 @@ static int fsl_ifc_chip_init(struct fsl_ifc_mtd *priv)
 			chip->ecc.strength = 8;
 		}
 	} else {
-		chip->ecc.mode = NAND_ECC_SOFT;
-		chip->ecc.algo = NAND_ECC_HAMMING;
+		ret = of_property_read_string(priv->dev->of_node, "nand-ecc-mode", &pm);
+		if((ret >= 0) && (!strcasecmp(pm, "none")))
+		{
+		        chip->ecc.mode = NAND_ECC_NONE;
+		}
+		else 
+		{
+			chip->ecc.mode = NAND_ECC_SOFT;
+			chip->ecc.algo = NAND_ECC_HAMMING;
+		}
 	}
 
 	if (ctrl->version >= FSL_IFC_VERSION_1_1_0)
diff --git a/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth.c b/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth.c
index 296510911687..977f3f8e81f2 100644
--- a/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth.c
+++ b/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth.c
@@ -903,6 +903,7 @@ static int dpa_new_loop_id(void)
 }
 #endif
 
+#define EXTRA_ETHERNET_BUF_FOR_IPR	512
 static int
 dpaa_eth_priv_probe(struct platform_device *_of_dev)
 {
@@ -1004,9 +1005,13 @@ dpaa_eth_priv_probe(struct platform_device *_of_dev)
 
 	if (err < 0)
 		goto fq_probe_failed;
-
 	/* bp init */
-
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+	printk("%s::bpid %d, count %d ", __FUNCTION__,
+                dpa_bp->bpid, dpa_bp->config_count);
+        dpa_bp->config_count += EXTRA_ETHERNET_BUF_FOR_IPR;
+        printk("adj count %d\n", dpa_bp->config_count);
+#endif
 	err = dpa_priv_bp_create(net_dev, dpa_bp, count);
 
 	if (err < 0)
diff --git a/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth.h b/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth.h
index 57c9bef44a98..8f6e9672b538 100644
--- a/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth.h
+++ b/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth.h
@@ -91,7 +91,10 @@ struct dpa_buffer_layout_s {
 /* The raw buffer size must be cacheline aligned.
  * Normally we use 2K buffers.
  */
-#define DPA_BP_RAW_SIZE		2048
+/* As 1518 byte packets are received in scatter gather buffers from DPAA, 
+and these buffers are used by WIFI which requires contiguous buffers. So
+increased buffer size from 2048 to 2176, to accomodate them in contiguous fd */
+#define DPA_BP_RAW_SIZE		2176
 #else
 /* For jumbo frame optimizations, use buffers large enough to accommodate
  * 9.6K frames, FD maximum offset, skb sh_info overhead and some extra
@@ -678,10 +681,12 @@ static inline void _dpa_bp_free_pf(void *addr)
 
 #ifndef CONFIG_PPC
 extern bool dpaa_errata_a010022; /* SoC affected by A010022 errata */
+
 #define NONREC_MARK	0x01
 #define HAS_DMA_ISSUE(start, size) \
-	(((uintptr_t)(start) + (size)) > \
-	 (((uintptr_t)(start) + 0x1000) & ~0xFFF))
+	(((u64)(start) + (size)) > (((u64)(start) + 0x1000) & ~0xFFF))
+
+
 #endif  /* !CONFIG_PPC */
 
 #endif	/* __DPA_H */
diff --git a/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_common.c b/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_common.c
index eee1402c37c9..41d9ff5f937d 100644
--- a/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_common.c
+++ b/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_common.c
@@ -650,6 +650,16 @@ void dpa_set_rx_mode(struct net_device *net_dev)
 					   "mac_dev->set_promisc() = %d\n",
 					   _errno);
 	}
+	if (!!(net_dev->flags & IFF_ALLMULTI) != priv->mac_dev->allmulti) {
+		priv->mac_dev->allmulti = !priv->mac_dev->allmulti;
+		_errno = priv->mac_dev->set_allmulti(
+				priv->mac_dev->get_mac_handle(priv->mac_dev),
+				priv->mac_dev->allmulti);
+		if (unlikely(_errno < 0) && netif_msg_drv(priv))
+			netdev_err(net_dev,
+					   "mac_dev->set_allmulti() = %d\n",
+					   _errno);
+	}
 
 	_errno = priv->mac_dev->set_multi(net_dev, priv->mac_dev);
 	if (unlikely(_errno < 0) && netif_msg_drv(priv))
diff --git a/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_common.h b/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_common.h
index b2d31943064e..6f434e620ac9 100644
--- a/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_common.h
+++ b/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_common.h
@@ -95,6 +95,12 @@ typedef enum dpaa_eth_hook_result (*dpaa_eth_egress_hook_t)(
 typedef enum dpaa_eth_hook_result (*dpaa_eth_confirm_hook_t)(
 		struct net_device *net_dev, const struct qm_fd *fd, u32 fqid);
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+typedef struct qman_fq *(*cdx_ipsec_eth_hook_t)(
+		struct net_device *net_dev, struct sk_buff *skb, u32 handle);
+int dpa_register_eth_ipsec_hook(cdx_ipsec_eth_hook_t hookfn);
+#endif
+
 /* used in napi related functions */
 extern u16 qman_portal_max;
 
@@ -134,6 +140,12 @@ void fsl_dpaa_eth_set_hooks(struct dpaa_eth_hooks_s *hooks);
 extern struct dpaa_eth_hooks_s dpaa_eth_hooks;
 #endif
 
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+typedef int (*dpaa_eth_bpool_replenish_hook_t)(
+                        struct net_device *net_dev, u32 bpid);
+void register_dpaa_eth_bpool_replenish_hook(dpaa_eth_bpool_replenish_hook_t func);
+#endif
+
 int dpa_netdev_init(struct net_device *net_dev,
 		    const uint8_t *mac_addr,
 		    uint16_t tx_timeout);
diff --git a/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_sg.c b/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_sg.c
index 138919aad93d..841c320cfa4d 100644
--- a/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_sg.c
+++ b/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_sg.c
@@ -51,6 +51,32 @@
 #endif
 #ifdef CONFIG_FSL_DPAA_CEETM
 #include "dpaa_eth_ceetm.h"
+#endif
+#if defined(CONFIG_IP_NF_CONNTRACK_MARK) || defined(CONFIG_NF_CONNTRACK_MARK)
+#include "net/netfilter/nf_conntrack.h"
+#endif // CONFIG_IP_NF_CONNTRACK_MARK ||  CONFIG_NF_CONNTRACK_MARK
+#include <net/xfrm.h>
+
+
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+//added for IPR offload to FMAN
+static dpaa_eth_bpool_replenish_hook_t dpaa_eth_bpool_replenish_hook;
+#endif
+
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+static cdx_ipsec_eth_hook_t cdx_eth_ipsec_hook;
+
+int dpa_register_eth_ipsec_hook(cdx_ipsec_eth_hook_t hookfn)
+{
+       if (cdx_eth_ipsec_hook) {
+               printk("%s::hook already registered\n", __FUNCTION__);
+               return -1;
+       }
+       cdx_eth_ipsec_hook = hookfn;
+       return 0;
+}
+EXPORT_SYMBOL(dpa_register_eth_ipsec_hook);
+
 #endif
 
 /* DMA map and add a page frag back into the bpool.
@@ -100,6 +126,7 @@ static int _dpa_bp_add_8_bufs(const struct dpa_bp *dpa_bp)
 		 * We only need enough space to store a pointer, but allocate
 		 * an entire cacheline for performance reasons.
 		 */
+#if 0 //ndef CONFIG_PPC
 #ifndef CONFIG_PPC
 		if (unlikely(dpaa_errata_a010022)) {
 			struct page *new_page = alloc_page(GFP_ATOMIC);
@@ -114,7 +141,15 @@ static int _dpa_bp_add_8_bufs(const struct dpa_bp *dpa_bp)
 		if (unlikely(!new_buf))
 			goto netdev_alloc_failed;
 		new_buf = PTR_ALIGN(new_buf + SMP_CACHE_BYTES, SMP_CACHE_BYTES);
+#else
+#define DPA_ETH_BPOOL_ALIGN     2048
+#define DPA_BPOOL_SIZE          DPA_ETH_BPOOL_ALIGN
+                new_buf = netdev_alloc_frag(DPA_ETH_BPOOL_ALIGN + DPA_BPOOL_SIZE);
+		if (unlikely(!new_buf))
+			goto netdev_alloc_failed;
+                new_buf = PTR_ALIGN(new_buf + DPA_ETH_BPOOL_ALIGN, DPA_ETH_BPOOL_ALIGN);
 
+#endif //0
 		skb = build_skb(new_buf, DPA_SKB_SIZE(dpa_bp->size) +
 			SKB_DATA_ALIGN(sizeof(struct skb_shared_info)));
 		if (unlikely(!skb)) {
@@ -311,11 +346,17 @@ EXPORT_SYMBOL(_dpa_cleanup_tx_fd);
 #ifndef CONFIG_FSL_DPAA_TS
 bool dpa_skb_is_recyclable(struct sk_buff *skb)
 {
+#if 0 // copying from modified 4.1 kernel file.
 #ifndef CONFIG_PPC
 	/* Do no recycle skbs realigned by the errata workaround */
 	if (unlikely(dpaa_errata_a010022) && skb->mark == NONREC_MARK)
 		return false;
 #endif
+#else
+	/* the skb has been marked to avoid recycling */
+	if (skb->mark == NONREC_MARK)
+		return false;
+#endif //0
 
 	/* No recycling possible if skb buffer is kmalloc'ed  */
 	if (skb->head_frag == 0)
@@ -379,7 +420,7 @@ EXPORT_SYMBOL(dpa_buf_is_recyclable);
  * We are guaranteed there is enough room at the end of the data buffer to
  * accommodate the shared info area of the skb.
  */
-static struct sk_buff *__hot contig_fd_to_skb(const struct dpa_priv_s *priv,
+struct sk_buff *__hot contig_fd_to_skb(const struct dpa_priv_s *priv,
 	const struct qm_fd *fd, int *use_gro)
 {
 	dma_addr_t addr = qm_fd_addr(fd);
@@ -436,7 +477,7 @@ static struct sk_buff *__hot contig_fd_to_skb(const struct dpa_priv_s *priv,
 
 	return skb;
 }
-
+EXPORT_SYMBOL(contig_fd_to_skb);
 
 /* Build an skb with the data of the first S/G entry in the linear portion and
  * the rest of the frame as skb fragments.
@@ -572,6 +613,14 @@ static inline int dpa_skb_loop(const struct dpa_priv_s *priv,
 }
 #endif
 
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+void register_dpaa_eth_bpool_replenish_hook(dpaa_eth_bpool_replenish_hook_t func)
+{
+        dpaa_eth_bpool_replenish_hook = func;
+}
+EXPORT_SYMBOL(register_dpaa_eth_bpool_replenish_hook);
+#endif
+
 void __hot _dpa_rx(struct net_device *net_dev,
 		struct qman_portal *portal,
 		const struct dpa_priv_s *priv,
@@ -606,6 +655,32 @@ void __hot _dpa_rx(struct net_device *net_dev,
 
 	/* The only FD types that we may receive are contig and S/G */
 	DPA_BUG_ON((fd->format != qm_fd_contig) && (fd->format != qm_fd_sg));
+#if 0
+        {
+                char *ptr;
+                uint32_t ii;
+
+                ptr = ((char *)phys_to_virt(addr) + 0x0);
+                for (ii  = 0; ii < 0x70; ii++) {
+                        if ((ii % 16) == 0)
+                                printk("\n%02x ", *(ptr + ii));
+                        else
+                                printk("%02x ", *(ptr + ii));
+                }
+                printk("\n");
+        }
+	{
+		uint32_t ccbase;
+		uint64_t hashval;
+		//get ccbase 
+		ccbase  = *((uint32_t *)((char *)phys_to_virt(addr) + 0x18));
+                printk("%s::ccbase %08x, fqid 0x%x\n", __FUNCTION__, cpu_to_be32(ccbase), fqid);
+		hashval  = *((uint64_t *)((char *)phys_to_virt(addr) + 0x48));
+                printk("%s::hashval %lx\n", __FUNCTION__, cpu_to_be64(hashval));
+	 		
+	}
+#endif
+
 
 	if (likely(fd->format == qm_fd_contig)) {
 #ifdef CONFIG_FSL_DPAA_HOOKS
@@ -616,6 +691,15 @@ void __hot _dpa_rx(struct net_device *net_dev,
 			/* won't count the rx bytes in */
 			return;
 		}
+#endif
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+                if (dpaa_eth_bpool_replenish_hook) {
+                        if (dpaa_eth_bpool_replenish_hook(net_dev, fd->bpid)) {
+                                //could not replenish buffer, drop packet ??
+                                printk("%s::could not replenish buffer to pool\n",
+                                        __FUNCTION__);
+                        }
+                }
 #endif
 		skb = contig_fd_to_skb(priv, fd, &use_gro);
 	} else {
@@ -758,6 +842,100 @@ int __hot skb_to_contig_fd(struct dpa_priv_s *priv,
 EXPORT_SYMBOL(skb_to_contig_fd);
 
 #ifndef CONFIG_PPC
+bool check_skb_4k_boundaries(struct sk_buff *skb, struct dpa_priv_s *priv)
+{
+	int nr_frags, i = 0;
+	skb_frag_t *frag;
+
+	/* Check if the headroom crosses a boundary */
+	if (HAS_DMA_ISSUE(skb->head, skb_headroom(skb)))
+		return true;
+
+	/* Check if the non-paged data crosses a boundary */
+	if (HAS_DMA_ISSUE(skb->data, skb_headlen(skb)))
+		return true;
+
+	/* Check if the entire linear skb crosses a boundary */
+	if (HAS_DMA_ISSUE(skb->head, skb_end_offset(skb)))
+		return true;
+
+	nr_frags = skb_shinfo(skb)->nr_frags;
+
+	while (i < nr_frags) {
+		frag = &skb_shinfo(skb)->frags[i];
+
+		/* Check if a paged fragment crosses a boundary from its
+		 * offset to its end.
+		 */
+		if (HAS_DMA_ISSUE(frag->page_offset, frag->size))
+			return true;
+
+		i++;
+	}
+
+	/* Check if the headroom is aligned */
+	if (((u64)skb->data - priv->tx_headroom) %
+	    priv->buf_layout[TX].data_align != 0)
+		return true;
+
+	return false;
+}
+
+/* Realign the skb by copying its contents at the start of a newly allocated
+ * page. Build a new skb around the new buffer and release the old one.
+ * A performance drop should be expected.
+ */
+struct sk_buff *realign_skb(struct sk_buff *skb, struct dpa_priv_s *priv)
+{
+	int trans_offset = skb_transport_offset(skb);
+	int net_offset = skb_network_offset(skb);
+	struct sk_buff *nskb;
+	int nsize, headroom;
+	struct page *npage;
+	void *npage_addr;
+
+	headroom = priv->tx_headroom;
+
+	npage = alloc_page(GFP_ATOMIC);
+	if (unlikely(!npage)) {
+		WARN_ONCE(1, "Memory allocation failure\n");
+		return NULL;
+	}
+	npage_addr = page_address(npage);
+
+	/* For the new skb we only need the old one's headroom and data (both
+	 * non-paged and paged). We can skip its tailroom.
+	 */
+	nsize = headroom + skb->len +
+		SKB_DATA_ALIGN(sizeof(struct skb_shared_info));
+	WARN(nsize > 4096, "new skb size larger than page size %d\n", nsize);
+
+	nskb = build_skb(npage_addr, nsize);
+	if (unlikely(!nskb)) {
+		put_page(npage);
+		return NULL;
+	}
+
+	/* Code borrowed and adapted from skb_copy() */
+	skb_reserve(nskb, headroom);
+	skb_put(nskb, skb->len);
+	if (skb_copy_bits(skb, 0, nskb->data, skb->len))
+		BUG();
+	copy_skb_header(nskb, skb);
+
+	/* We increase the headroom when we align it so we have to reset the
+	 * network and transport header offsets relative to the new data
+	 * pointer. The checksum offload relies on these offsets.
+	 */
+	skb_set_network_header(nskb, net_offset);
+	skb_set_transport_header(nskb, trans_offset);
+
+	/* We don't want the buffer to be recycled so we mark it accordingly */
+	nskb->mark = NONREC_MARK;
+
+	dev_kfree_skb(skb);
+	return nskb;
+}
 /* Verify the conditions that trigger the A010022 errata: data unaligned to
  * 16 bytes and 4K memory address crossings.
  */
@@ -1022,12 +1200,88 @@ int __hot skb_to_sg_fd(struct dpa_priv_s *priv,
 }
 EXPORT_SYMBOL(skb_to_sg_fd);
 
+typedef struct qman_fq* (*FnHandler)(struct net_device *net_dev, int queue);
+FnHandler CEETM_Get_Queue = NULL;
+
+void RegisterCEETMHandler(FnHandler pCeetmGetQueue)
+{
+  CEETM_Get_Queue = pCeetmGetQueue;
+  return;
+}
+EXPORT_SYMBOL(RegisterCEETMHandler);
+#define EMAC_QUEUENUM_MASK 0xff
+
+static int pfe_eth_get_queuenum( struct sk_buff *skb )
+{
+        int queuenum = 0;
+
+        /* Get the Fast Path queue number */
+        /* Use conntrack mark (if conntrack exists), then packet mark (if any), then fallback to default */
+
+       #if defined(CONFIG_IP_NF_CONNTRACK_MARK) || defined(CONFIG_NF_CONNTRACK_MARK)
+        if (skb->_nfct) {
+                enum ip_conntrack_info cinfo;
+                struct nf_conn *ct;
+                ct = nf_ct_get(skb, &cinfo);
+
+                if (ct) {
+                        u_int32_t connmark;
+                        connmark = ct->mark;
+
+                        if ((connmark & 0x80000000) != 0)
+                                connmark >>= 16;
+
+                        queuenum = connmark & EMAC_QUEUENUM_MASK;
+                }
+                else
+                       queuenum = QOS_LEAST_PRIORITY_QUEUE;
+        }
+        else  /* continued after #endif ... */
+        #endif
+                if (skb->mark)
+                        queuenum = skb->mark & EMAC_QUEUENUM_MASK;
+                else 
+                {
+                    //These are packets through control path,
+                    // highest priority queue needs to be taken
+                    queuenum = QOS_DEFAULT_QUEUE; 
+                }
+
+        return queuenum;
+}
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+unsigned int ipsec_offload_pkt_cnt;
+void print_ipsec_offload_pkt_count(void)
+{
+	printk("%s:: Ipsec offload slow path packet count = %d\n",__func__,ipsec_offload_pkt_cnt);
+	ipsec_offload_pkt_cnt = 0;
+} 
+EXPORT_SYMBOL(print_ipsec_offload_pkt_count);
+#endif
 int __hot dpa_tx(struct sk_buff *skb, struct net_device *net_dev)
 {
 	struct dpa_priv_s	*priv;
 	const int queue_mapping = dpa_get_queue_mapping(skb);
-	struct qman_fq *egress_fq, *conf_fq;
+	struct qman_fq *egress_fq = NULL, *conf_fq = NULL,*lfq;
+        int queuenum = 0;
+#ifdef CONFIG_XFRM
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+        if(skb->ipsec_offload) {
+               if (skb->sp) {
+                       struct xfrm_state *x;
+                       if (cdx_eth_ipsec_hook) {
+                               if (skb->sp->len) {
+                                       x = skb->sp->xvec[0];
+                                       egress_fq = cdx_eth_ipsec_hook(net_dev, skb,
+                                               x->handle);
+                               }
+                       }
+               }
+		ipsec_offload_pkt_cnt++;
+       }
 
+#endif
+#endif
 #ifdef CONFIG_FSL_DPAA_HOOKS
 	/* If there is a Tx hook, run it. */
 	if (dpaa_eth_hooks.tx &&
@@ -1042,10 +1296,17 @@ int __hot dpa_tx(struct sk_buff *skb, struct net_device *net_dev)
 	if (priv->ceetm_en)
 		return ceetm_tx(skb, net_dev);
 #endif
-
-	egress_fq = priv->egress_fqs[queue_mapping];
-	conf_fq = priv->conf_fqs[queue_mapping];
-
+	if (!egress_fq) {
+               egress_fq = priv->egress_fqs[queue_mapping];
+        	queuenum = pfe_eth_get_queuenum(skb); 
+        	if(CEETM_Get_Queue)
+        	{	
+         		 lfq = CEETM_Get_Queue(net_dev,queuenum );
+         		 if(lfq)
+            			 egress_fq = lfq;
+        	}
+	}	
+        conf_fq = priv->conf_fqs[queue_mapping];
 	return dpa_tx_extended(skb, net_dev, egress_fq, conf_fq);
 }
 
@@ -1057,6 +1318,10 @@ int __hot dpa_tx_extended(struct sk_buff *skb, struct net_device *net_dev,
 	struct dpa_percpu_priv_s *percpu_priv;
 	struct rtnl_link_stats64 *percpu_stats;
 	int err = 0;
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	int ipsec_offload = 0;
+#endif
+	//const bool nonlinear = skb_is_nonlinear(skb);
 	bool nonlinear;
 	int *countptr, offset = 0;
 
@@ -1066,6 +1331,12 @@ int __hot dpa_tx_extended(struct sk_buff *skb, struct net_device *net_dev,
 	percpu_stats = &percpu_priv->stats;
 	countptr = raw_cpu_ptr(priv->dpa_bp->percpu_count);
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	if(skb->ipsec_offload) {
+		ipsec_offload =1; 
+	}
+#endif
+
 	clear_fd(&fd);
 
 #ifndef CONFIG_PPC
@@ -1089,6 +1360,18 @@ int __hot dpa_tx_extended(struct sk_buff *skb, struct net_device *net_dev,
 	skb_shinfo(skb)->tx_flags |= SKBTX_IN_PROGRESS;
 #endif /* CONFIG_FSL_DPAA_TS */
 
+#if 0 // this below code copied 4.1 kernel file, but similar is added above
+#ifndef CONFIG_PPC
+	if (unlikely(dpaa_errata_a010022) && check_skb_4k_boundaries(skb, priv)) {
+		skb = realign_skb(skb, priv);
+		if (!skb)
+			goto skb_to_fd_failed;
+	}
+#endif
+
+	nonlinear = skb_is_nonlinear(skb);
+#endif // 0
+
 	/* MAX_SKB_FRAGS is larger than our DPA_SGT_MAX_ENTRIES; make sure
 	 * we don't feed FMan with more fragments than it supports.
 	 * Btw, we're using the first sgt entry to store the linear part of
@@ -1134,6 +1417,16 @@ int __hot dpa_tx_extended(struct sk_buff *skb, struct net_device *net_dev,
 					goto skb_to_fd_failed;
 			}
 #endif
+#if 0 // this below code copied 4.1 kernel file, but similar is added above
+#ifndef CONFIG_PPC
+			if (unlikely(dpaa_errata_a010022) &&
+			    check_skb_4k_boundaries(skb, priv)) {
+				skb = realign_skb(skb, priv);
+				if (!skb)
+					goto skb_to_fd_failed;
+			}
+#endif
+#endif // 0
 			/* skb_copy() has now linearized the skbuff. */
 		} else if (unlikely(nonlinear)) {
 			/* We are here because the egress skb contains
@@ -1163,7 +1456,14 @@ int __hot dpa_tx_extended(struct sk_buff *skb, struct net_device *net_dev,
 		(*countptr)++;
 		percpu_priv->tx_returned++;
 	}
-
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+        /* IPSec offloaded packet will be queued to sec engine.
+	 * Sec engine treat fd.cmd differently and we need to ensure
+	 * no bit is set there.	
+	 */
+	if(ipsec_offload )
+		fd.cmd = 0;	
+#endif
 	if (unlikely(dpa_xmit(priv, percpu_stats, &fd, egress_fq, conf_fq) < 0))
 		goto xmit_failed;
 
diff --git a/drivers/net/ethernet/freescale/sdk_dpaa/mac-api.c b/drivers/net/ethernet/freescale/sdk_dpaa/mac-api.c
index 2c5652d99ddd..5770c773cd2a 100644
--- a/drivers/net/ethernet/freescale/sdk_dpaa/mac-api.c
+++ b/drivers/net/ethernet/freescale/sdk_dpaa/mac-api.c
@@ -837,6 +837,7 @@ static void __cold setup_dtsec(struct mac_device *mac_dev)
 	mac_dev->stop		= stop;
 	mac_dev->set_promisc	= fm_mac_set_promiscuous;
 	mac_dev->change_addr    = fm_mac_modify_mac_addr;
+	mac_dev->set_allmulti      = fm_mac_set_allmulti;
 	mac_dev->set_multi      = set_multi;
 	mac_dev->uninit		= uninit;
 	mac_dev->ptp_enable		= fm_mac_enable_1588_time_stamp;
@@ -864,6 +865,7 @@ static void __cold setup_xgmac(struct mac_device *mac_dev)
 	mac_dev->stop		= stop;
 	mac_dev->set_promisc	= fm_mac_set_promiscuous;
 	mac_dev->change_addr    = fm_mac_modify_mac_addr;
+	mac_dev->set_allmulti   = fm_mac_set_allmulti;
 	mac_dev->set_multi      = set_multi;
 	mac_dev->uninit		= uninit;
 	mac_dev->get_mac_handle	= get_mac_handle;
@@ -881,6 +883,7 @@ static void __cold setup_memac(struct mac_device *mac_dev)
 	mac_dev->stop		= stop;
 	mac_dev->set_promisc	= fm_mac_set_promiscuous;
 	mac_dev->change_addr    = fm_mac_modify_mac_addr;
+	mac_dev->set_allmulti   = fm_mac_set_allmulti;
 	mac_dev->set_multi      = set_multi;
 	mac_dev->uninit		= uninit;
 	mac_dev->get_mac_handle		= get_mac_handle;
diff --git a/drivers/net/ethernet/freescale/sdk_dpaa/mac.h b/drivers/net/ethernet/freescale/sdk_dpaa/mac.h
index b5288f2abc33..3799bc149838 100644
--- a/drivers/net/ethernet/freescale/sdk_dpaa/mac.h
+++ b/drivers/net/ethernet/freescale/sdk_dpaa/mac.h
@@ -49,6 +49,7 @@ struct mac_device {
 	void __iomem		*vaddr;
 	uint8_t			 addr[ETH_ALEN];
 	bool			 promisc;
+	bool			 allmulti;
 
 	struct fm		*fm_dev;
 	struct fm_port		*port_dev[2];
@@ -80,6 +81,7 @@ struct mac_device {
 	int (*start)(struct mac_device *mac_dev);
 	int (*stop)(struct mac_device *mac_dev);
 	int (*set_promisc)(struct fm_mac_dev *fm_mac_dev, bool enable);
+	int (*set_allmulti)(struct fm_mac_dev *fm_mac_dev, bool enable);
 	int (*change_addr)(struct fm_mac_dev *fm_mac_dev, uint8_t *addr);
 	int (*set_multi)(struct net_device *net_dev,
 			 struct mac_device *mac_dev);
diff --git a/drivers/net/ethernet/freescale/sdk_dpaa/offline_port.c b/drivers/net/ethernet/freescale/sdk_dpaa/offline_port.c
index fb084af5cc24..5fab9b162ff5 100644
--- a/drivers/net/ethernet/freescale/sdk_dpaa/offline_port.c
+++ b/drivers/net/ethernet/freescale/sdk_dpaa/offline_port.c
@@ -47,6 +47,7 @@
 #include <linux/module.h>
 #include <linux/of_platform.h>
 #include <linux/fsl_qman.h>
+#include <linux/fsl_oh_port.h>
 
 #include "offline_port.h"
 #include "dpaa_eth.h"
@@ -62,6 +63,7 @@ MODULE_LICENSE("Dual BSD/GPL");
 MODULE_AUTHOR("Bogdan Hamciuc <bogdan.hamciuc@freescale.com>");
 MODULE_DESCRIPTION(OH_MOD_DESCRIPTION);
 
+static struct fman_offline_port_info offline_port_info[MAX_FMANS][MAX_OFFLINE_PORTS];
 
 static const struct of_device_id oh_port_match_table[] = {
 	{
@@ -228,6 +230,33 @@ static int __cold oh_free_pcd_fqids(struct device *dev, uint32_t base_fqid)
 	return 0;
 }
 
+
+int oh_port_driver_get_port_info(struct fman_offline_port_info *info)
+{
+        uint32_t ii;
+        uint32_t fman_idx;
+        uint32_t port_idx;
+        struct fman_offline_port_info *port_info;
+
+        if (sscanf(info->port_name, "dpa-fman%d-oh@%d", &fman_idx, &port_idx) != 2) {
+                printk("%s::invalid name %s\n", __FUNCTION__, info->port_name);
+                return (-EINVAL);
+        }
+
+        port_info = &offline_port_info[fman_idx][0];
+        for (ii = 0; ii < MAX_OFFLINE_PORTS; ii++) {
+                if (strcmp(&info->port_name[0], &port_info->port_name[0]) == 0) {
+                        memcpy(info, port_info, sizeof(struct fman_offline_port_info));
+                        return 0;
+                }
+                port_info++;
+        }
+        return (-ENOENT);
+}
+
+EXPORT_SYMBOL(oh_port_driver_get_port_info);
+
+
 static void oh_set_buffer_layout(struct fm_port *port,
 				 struct dpa_buffer_layout_s *layout)
 {
@@ -733,6 +762,28 @@ oh_port_probe(struct platform_device *_of_dev)
 		goto return_kfree;
 
 	dev_info(dpa_oh_dev, "OH port %s enabled.\n", oh_node->full_name);
+	{
+                uint32_t fman_idx;
+                uint32_t port_idx;
+                struct fman_offline_port_info *info;
+                char *devname;
+
+                printk("devname %s\n", dev_name(dpa_oh_dev));
+                devname = strstr(dev_name(dpa_oh_dev), "dpa-fman");
+                if (devname) {
+                        if (sscanf(devname, "dpa-fman%d-oh@%d", &fman_idx, &port_idx) == 2) {
+                                info = &offline_port_info[fman_idx][port_idx - 1];
+                                strcpy(&info->port_name[0], devname);
+                                info->channel_id = channel_id;
+                                info->err_fqid = oh_config->default_fqid;
+                                info->default_fqid = oh_config->error_fqid;
+                                printk("%s::found OH port %s, fman %d, port %d\n", __FUNCTION__,
+                                                &info->port_name[0], fman_idx, port_idx);
+                        }
+                } else {
+                        printk("strstr failed on str %s\n", dev_name(dpa_oh_dev));
+                }
+        }
 
 	/* print of all referenced & created queues */
 	dump_oh_config(dpa_oh_dev, oh_config);
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Kconfig b/drivers/net/ethernet/freescale/sdk_fman/Kconfig
index d98c0989005a..ccfcd6a8fd1f 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Kconfig
+++ b/drivers/net/ethernet/freescale/sdk_fman/Kconfig
@@ -49,6 +49,18 @@ config FMAN_V3L
 endchoice
 endmenu
 
+config DBG_UCODE_INFRA
+	bool "debug infra support for microcode"
+	default n
+	---help---
+		enable/disable debug infra support for microcode
+
+config DMAR_TEST
+	bool "DMA read test in microcode"
+	default n
+	---help---
+		enable DMA read test in microcode
+
 config FMAN_MIB_CNT_OVF_IRQ_EN
 	bool "Enable the dTSEC MIB counters overflow interrupt"
 	default n
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/HC/hc.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/HC/hc.c
index 363c8f9532d5..c15ffb899210 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/HC/hc.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/HC/hc.c
@@ -66,6 +66,14 @@
 #define HC_HCOR_ACTION_REG_IP_FRAG_SCRATCH_POOL_CMD_SHIFT       24
 #define HC_HCOR_ACTION_REG_IP_FRAG_SCRATCH_POOL_BPID            16
 
+
+#ifdef CONFIG_DBG_UCODE_INFRA 
+#define HC_HCOR_OPCODE_DBG_UCODE_CMD  0x1e
+#ifdef CONFIG_DMAR_TEST
+#define HC_HCOR_OPCDOE_DMA_READ_TEST 0x1f
+#endif //CONFIG_DMAR_TEST
+#endif // CONFIG_DBG_UCODE_INFRA 
+
 #define HC_HCOR_GBL                         0x20000000
 
 #define HC_HCOR_KG_SCHEME_COUNTER           0x00000400
@@ -82,6 +90,9 @@
 #define SIZE_OF_HC_FRAME_PROFILE_CNT        (sizeof(t_HcFrame)-sizeof(t_FmPcdPlcrProfileRegs)+sizeof(uint32_t))
 #define SIZE_OF_HC_FRAME_READ_OR_CC_DYNAMIC 16
 
+
+#define SIZE_OF_HC_FRAME_READ_DBG_UCODE_CMD 64 //jyos
+
 #define HC_CMD_POOL_SIZE                    (INTG_MAX_NUM_OF_CORES)
 
 #define BUILD_FD(len)                     \
@@ -116,6 +127,11 @@ typedef struct t_HcFrame {
         volatile uint32_t                       clsPlanEntries[CLS_PLAN_NUM_PER_GRP];
         t_FmPcdCcCapwapReassmTimeoutParams      ccCapwapReassmTimeout;
         t_FmPcdCcReassmTimeoutParams            ccReassmTimeout;
+#ifdef CONFIG_DMAR_TEST
+	volatile uint8_t			data[64];
+#else
+	volatile uint8_t			data[48]; 
+#endif //CONFIG_DMAR_TEST
     } hcSpecificData;
 } t_HcFrame;
 
@@ -659,7 +675,7 @@ t_Error FmHcPcdKgSetClsPlan(t_Handle h_FmHc, t_FmPcdKgInterModuleClsPlanSet *p_S
 
         idx = (uint8_t)(i - p_Set->baseEntry);
         ASSERT_COND(idx < FM_PCD_MAX_NUM_OF_CLS_PLANS);
-        memcpy(&p_HcFrame->hcSpecificData.clsPlanEntries, &p_Set->vectors[idx], CLS_PLAN_NUM_PER_GRP*sizeof(uint32_t));
+        memcpy((void *)&p_HcFrame->hcSpecificData.clsPlanEntries, &p_Set->vectors[idx], CLS_PLAN_NUM_PER_GRP*sizeof(uint32_t));
         p_HcFrame->commandSequence = seqNum;
 
         BUILD_FD(sizeof(t_HcFrame));
@@ -1193,6 +1209,97 @@ t_Error FmHcPcdCcDoDynamicChange(t_Handle h_FmHc, uint32_t oldAdAddrOffset, uint
     return E_OK;
 }
 
+t_Error FmHcPcdCcDoDynamicChangeWithAging(t_Handle h_FmHc,
+                                          uint32_t oldAdAddrOffset,
+                                          uint32_t newAdAddrOffset,
+                                          e_ModifyState modifyState,
+                                          uint16_t keyIndex)
+{
+    t_FmHc                  *p_FmHc = (t_FmHc*)h_FmHc;
+    t_HcFrame               *p_HcFrame;
+    t_DpaaFD                fmFd;
+    t_Error                 err = E_OK;
+    uint32_t                seqNum;
+
+    SANITY_CHECK_RETURN_ERROR(p_FmHc, E_INVALID_HANDLE);
+
+    p_HcFrame = GetBuf(p_FmHc, &seqNum);
+    if (!p_HcFrame)
+        RETURN_ERROR(MINOR, E_NO_MEMORY, ("HC Frame object"));
+    memset(p_HcFrame, 0, sizeof(t_HcFrame));
+
+    p_HcFrame->opcode     = (uint32_t)(HC_HCOR_GBL | HC_HCOR_OPCODE_CC_UPDATE_WITH_AGING);
+    p_HcFrame->actionReg  = newAdAddrOffset;
+    p_HcFrame->actionReg |= 0xc0000000;
+    p_HcFrame->extraReg   = oldAdAddrOffset;
+
+    switch (modifyState)
+    {
+        case e_MODIFY_STATE_ADD:
+            p_HcFrame->extraReg |= HC_HCOR_EXTRA_REG_CC_AGING_ADD;
+            break;
+
+        case e_MODIFY_STATE_REMOVE:
+            p_HcFrame->extraReg |= HC_HCOR_EXTRA_REG_CC_AGING_REMOVE;
+            p_HcFrame->extraReg |= ((keyIndex << HC_HCOR_EXTRA_REG_CC_REMOVE_INDX_SHIFT) & HC_HCOR_EXTRA_REG_CC_REMOVE_INDX_MASK);
+            break;
+
+        case e_MODIFY_STATE_CHANGE:
+            p_HcFrame->extraReg &= ~HC_HCOR_EXTRA_REG_CC_AGING_CHANGE_MASK;
+            break;
+    }
+
+    p_HcFrame->commandSequence = seqNum;
+
+    BUILD_FD(SIZE_OF_HC_FRAME_READ_OR_CC_DYNAMIC);
+
+    err = EnQFrm(p_FmHc, &fmFd, seqNum);
+
+    PutBuf(p_FmHc, p_HcFrame, seqNum);
+
+    if (err != E_OK)
+        RETURN_ERROR(MAJOR, err, NO_MSG);
+
+    return E_OK;
+}
+
+t_Error FmHcPcdCcResetAgingMask(t_Handle h_FmHc, uint32_t adAddrOffset, uint32_t newAgeMask, uint32_t *p_OldAgeMask)
+{
+    t_FmHc                  *p_FmHc = (t_FmHc*)h_FmHc;
+    t_HcFrame               *p_HcFrame;
+    t_DpaaFD                fmFd;
+    t_Error                 err = E_OK;
+    uint32_t                seqNum;
+
+    SANITY_CHECK_RETURN_ERROR(p_FmHc, E_INVALID_HANDLE);
+
+    p_HcFrame = GetBuf(p_FmHc, &seqNum);
+    if (!p_HcFrame)
+        RETURN_ERROR(MINOR, E_NO_MEMORY, ("HC Frame object"));
+    memset(p_HcFrame, 0, sizeof(t_HcFrame));
+
+    p_HcFrame->opcode     = (uint32_t)(HC_HCOR_GBL | HC_HCOR_OPCODE_CC_AGE_MASK);
+    p_HcFrame->actionReg  = adAddrOffset;
+    p_HcFrame->extraReg   = newAgeMask;
+    p_HcFrame->commandSequence = seqNum;
+
+    BUILD_FD(SIZE_OF_HC_FRAME_READ_OR_CC_DYNAMIC);
+
+    err = EnQFrm(p_FmHc, &fmFd, seqNum);
+
+    /* On command completion the FMC writes to HCER the 'aging-mask' field
+       before it was updated by this command. This way the user may identify
+       which bits were cleared by FMC before setting them. */
+    *p_OldAgeMask = p_HcFrame->extraReg;
+
+    PutBuf(p_FmHc, p_HcFrame, seqNum);
+
+    if (err != E_OK)
+        RETURN_ERROR(MAJOR, err, NO_MSG);
+
+    return E_OK;
+}
+
 t_Error FmHcPcdSync(t_Handle h_FmHc)
 {
     t_FmHc                  *p_FmHc = (t_FmHc*)h_FmHc;
@@ -1230,3 +1337,117 @@ t_Handle    FmHcGetPort(t_Handle h_FmHc)
     t_FmHc *p_FmHc = (t_FmHc*)h_FmHc;
     return p_FmHc->h_HcPortDev;
 }
+
+#ifdef CONFIG_DBG_UCODE_INFRA 
+t_Error FmHcPcdDbgUcodeHCmd(t_Handle h_FmHc, 
+			   uint32_t muram_offset,
+			   uint8_t  *data,
+			   uint8_t	size)
+{
+    t_FmHc                  *p_FmHc = (t_FmHc*)h_FmHc;
+    t_HcFrame               *p_HcFrame;
+    t_DpaaFD                fmFd;
+    t_Error                 err = E_OK;
+    uint32_t                seqNum, ii;
+    uint8_t		   *hc_data;
+
+
+    SANITY_CHECK_RETURN_ERROR(p_FmHc, E_INVALID_HANDLE);
+
+    p_HcFrame = GetBuf(p_FmHc, &seqNum);
+    if (!p_HcFrame)
+        RETURN_ERROR(MINOR, E_NO_MEMORY, ("HC Frame object"));
+    memset(p_HcFrame, 0, sizeof(t_HcFrame));
+
+    p_HcFrame->opcode     = (uint32_t)(HC_HCOR_GBL | HC_HCOR_OPCODE_DBG_UCODE_CMD);
+    p_HcFrame->actionReg = muram_offset;
+    p_HcFrame->extraReg =  size;
+    hc_data = (uint8_t *)p_HcFrame->hcSpecificData.data;
+    for (ii=0; ii<size; ii++)
+	hc_data[ii] =  data[ii];
+
+    BUILD_FD(SIZE_OF_HC_FRAME_READ_DBG_UCODE_CMD);
+
+    err = EnQFrm(p_FmHc, &fmFd, seqNum);
+
+    PutBuf(p_FmHc, p_HcFrame, seqNum);
+    if (err != E_OK)
+        RETURN_ERROR(MAJOR, err, NO_MSG);
+
+    return E_OK;
+}
+
+t_Error FmHcPcdDbgUcodeTest(t_Handle h_FmHc,
+			uint32_t opcode,
+			uint32_t *data,
+			uint16_t data_size)
+{
+    t_FmHc                  *p_FmHc = (t_FmHc*)h_FmHc;
+    t_HcFrame               *p_HcFrame;
+    t_DpaaFD                fmFd;
+    t_Error                 err = E_OK;
+    uint32_t                seqNum;
+
+    SANITY_CHECK_RETURN_ERROR(p_FmHc, E_INVALID_HANDLE);
+	
+    p_HcFrame = GetBuf(p_FmHc, &seqNum);
+    if (!p_HcFrame)
+	RETURN_ERROR(MINOR, E_NO_MEMORY, ("HC Frame object"));
+    memset(p_HcFrame, 0, sizeof(t_HcFrame));
+	
+    p_HcFrame->opcode	  = opcode;
+    p_HcFrame->actionReg  = *data;
+    p_HcFrame->extraReg = data_size;
+	
+    BUILD_FD(SIZE_OF_HC_FRAME_READ_DBG_UCODE_CMD);
+	
+    err = EnQFrm(p_FmHc, &fmFd, seqNum);
+	
+    PutBuf(p_FmHc, p_HcFrame, seqNum);
+	
+    if (err != E_OK)
+	RETURN_ERROR(MAJOR, err, NO_MSG);
+	
+    return E_OK;
+}
+#ifdef CONFIG_DMAR_TEST
+
+t_Error FmHcPcdDMAreadTest(t_Handle h_FmHc, uint32_t muram_addr_offset,
+									 uint8_t *ptr, uint8_t size)
+{
+    t_FmHc                  *p_FmHc = (t_FmHc*)h_FmHc;
+    t_HcFrame               *p_HcFrame;
+    uint8_t					*data;
+    t_DpaaFD                fmFd;
+    t_Error                 err = E_OK;
+    uint32_t                seqNum, ii;
+
+    SANITY_CHECK_RETURN_ERROR(p_FmHc, E_INVALID_HANDLE);
+	
+    p_HcFrame = GetBuf(p_FmHc, &seqNum);
+    if (!p_HcFrame)
+	RETURN_ERROR(MINOR, E_NO_MEMORY, ("HC Frame object"));
+    memset(p_HcFrame, 0, sizeof(t_HcFrame));
+	
+    p_HcFrame->opcode	  = HC_HCOR_OPCDOE_DMA_READ_TEST;
+    p_HcFrame->actionReg  = muram_addr_offset;
+    p_HcFrame->extraReg = size;
+    data = p_HcFrame->hcSpecificData.data;
+    memcpy(data, ptr, size);
+	
+    BUILD_FD(SIZE_OF_HC_FRAME_READ_DBG_UCODE_CMD+16);
+	
+    err = EnQFrm(p_FmHc, &fmFd, seqNum);
+	
+    PutBuf(p_FmHc, p_HcFrame, seqNum);
+	
+    if (err != E_OK)
+	RETURN_ERROR(MAJOR, err, NO_MSG);
+	
+    return E_OK;
+}
+
+#endif //CONFIG_DMAR_TEST
+
+#endif // CONFIG_DBG_UCODE_INFRA 
+
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/dtsec.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/dtsec.c
index 38948f972002..c046d0457f39 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/dtsec.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/dtsec.c
@@ -1017,6 +1017,18 @@ static t_Error DtsecDelHashMacAddress(t_Handle h_Dtsec, t_EnetAddr *p_EthAddr)
     return E_OK;
 }
 
+/* .............................................................................. */
+static t_Error DtsecSetAllMulti(t_Handle h_Dtsec, bool newVal)
+{
+    t_Dtsec     *p_Dtsec = (t_Dtsec *)h_Dtsec;
+
+    SANITY_CHECK_RETURN_ERROR(p_Dtsec, E_INVALID_HANDLE);
+    SANITY_CHECK_RETURN_ERROR(!p_Dtsec->p_DtsecDriverParam, E_INVALID_STATE);
+
+    fman_dtsec_set_mc_promisc(p_Dtsec->p_MemMap, newVal);
+
+    return E_OK;
+}
 /* .............................................................................. */
 
 static t_Error DtsecSetPromiscuous(t_Handle h_Dtsec, bool newVal)
@@ -1376,6 +1388,7 @@ static void InitFmMacControllerDriver(t_FmMacControllerDriver *p_FmMacController
     p_FmMacControllerDriver->f_FM_MAC_SetException              = DtsecSetException;
 
     p_FmMacControllerDriver->f_FM_MAC_SetPromiscuous            = DtsecSetPromiscuous;
+    p_FmMacControllerDriver->f_FM_MAC_SetAllMulti               = DtsecSetAllMulti;
     p_FmMacControllerDriver->f_FM_MAC_AdjustLink                = DtsecAdjustLink;
     p_FmMacControllerDriver->f_FM_MAC_SetWakeOnLan              = DtsecSetWakeOnLan;
     p_FmMacControllerDriver->f_FM_MAC_RestartAutoneg            = DtsecRestartAutoneg;
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/fm_mac.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/fm_mac.c
index caf3940ad9df..dc21cc041870 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/fm_mac.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/fm_mac.c
@@ -590,6 +590,20 @@ t_Error FM_MAC_SetPromiscuous (t_Handle h_FmMac, bool newVal)
 
 /* ......................................................................... */
 
+t_Error FM_MAC_SetAllMulti (t_Handle h_FmMac, bool newVal)
+{
+    t_FmMacControllerDriver *p_FmMacControllerDriver = (t_FmMacControllerDriver *)h_FmMac;
+
+    SANITY_CHECK_RETURN_ERROR(p_FmMacControllerDriver, E_INVALID_HANDLE);
+
+    if (p_FmMacControllerDriver->f_FM_MAC_SetAllMulti)
+        return p_FmMacControllerDriver->f_FM_MAC_SetAllMulti(h_FmMac, newVal);
+
+    RETURN_ERROR(MINOR, E_NOT_SUPPORTED, NO_MSG);
+}
+
+/* ......................................................................... */
+
 t_Error FM_MAC_AdjustLink(t_Handle h_FmMac, e_EnetSpeed speed, bool fullDuplex)
 {
     t_FmMacControllerDriver *p_FmMacControllerDriver = (t_FmMacControllerDriver *)h_FmMac;
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/fm_mac.h b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/fm_mac.h
index ba3b9133a88f..16083b153335 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/fm_mac.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/fm_mac.h
@@ -115,6 +115,7 @@ typedef struct {
     t_Error (*f_FM_MAC_RemovelExactMatchMacAddr) (t_Handle h_FmMac, t_EnetAddr *p_EnetAddr);
 
     t_Error (*f_FM_MAC_SetPromiscuous) (t_Handle h_FmMac, bool newVal);
+    t_Error (*f_FM_MAC_SetAllMulti) (t_Handle h_FmMac, bool newVal);
     t_Error (*f_FM_MAC_AdjustLink)     (t_Handle h_FmMac, e_EnetSpeed speed, bool fullDuplex);
     t_Error (*f_FM_MAC_RestartAutoneg) (t_Handle h_FmMac);
 
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/memac.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/memac.c
index 0f299e729a19..c62a93a6560f 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/memac.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/memac.c
@@ -1042,6 +1042,63 @@ static t_Error MemacFree(t_Handle h_Memac)
 
 /* ......................................................................... */
 
+static t_Error MemacSetAllMulti(t_Handle h_Memac, bool newVal)
+{
+    t_Memac             *p_Memac = (t_Memac *)h_Memac;
+    uint32_t            ii;
+    char                *pChar;
+    char                EthAddr[6];
+
+    SANITY_CHECK_RETURN_ERROR(p_Memac, E_NULL_POINTER);
+    SANITY_CHECK_RETURN_ERROR(!p_Memac->p_MemacDriverParam, E_INVALID_STATE);
+    
+    /* For IPv4 Multicast packet first 3 bytes of dst mac remains the same.
+       so generating hash by varying remaining 3 bytes,which maps to 3 bits
+       in hash register. 
+       Similarly for IPv6 multicast packet, first 2 bytes of multicast packet 
+       remains the same, so generating hash by varying remaining 4 bytes,
+       which maps to 4 bits in hash register*/
+
+    pChar = EthAddr;
+    pChar[0] = 0x01;
+    pChar[1] = 0x00;
+    pChar[2] = 0x5e;
+    for(ii=0;ii<=7;ii++)
+    {
+        pChar[3] = ii>>2 & 1;
+        pChar[4] = ii>>1 & 1;
+        pChar[5] = ii>>0 & 1;
+        if(newVal)
+        {
+            MemacAddHashMacAddress(h_Memac, (t_EnetAddr *)EthAddr);
+        }
+        else
+        {
+            MemacDelHashMacAddress(h_Memac,(t_EnetAddr *)EthAddr);
+        }
+    }
+    pChar[0] = 0x33;
+    pChar[1] = 0x33;
+    for(ii=0;ii<=15;ii++)
+    {
+        pChar[2] = ii>>3 & 1;
+        pChar[3] = ii>>2 & 1;
+        pChar[4] = ii>>1 & 1;
+        pChar[5] = ii>>0 & 1;
+        if(newVal)
+        {
+            MemacAddHashMacAddress(h_Memac, (t_EnetAddr *)EthAddr);
+        }
+        else
+        {
+            MemacDelHashMacAddress(h_Memac, (t_EnetAddr *)EthAddr);
+        }
+    }
+    return E_OK;
+}
+
+/* ......................................................................... */
+
 static void InitFmMacControllerDriver(t_FmMacControllerDriver *p_FmMacControllerDriver)
 {
     p_FmMacControllerDriver->f_FM_MAC_Init                      = MemacInit;
@@ -1066,6 +1123,7 @@ static void InitFmMacControllerDriver(t_FmMacControllerDriver *p_FmMacController
     p_FmMacControllerDriver->f_FM_MAC_Disable1588TimeStamp      = NULL;
 
     p_FmMacControllerDriver->f_FM_MAC_SetPromiscuous            = MemacSetPromiscuous;
+    p_FmMacControllerDriver->f_FM_MAC_SetAllMulti               = MemacSetAllMulti;
     p_FmMacControllerDriver->f_FM_MAC_AdjustLink                = MemacAdjustLink;
     p_FmMacControllerDriver->f_FM_MAC_RestartAutoneg            = NULL;
 
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/tgec.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/tgec.c
index eb00759f9f46..a9bee8128796 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/tgec.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/tgec.c
@@ -932,6 +932,7 @@ static void InitFmMacControllerDriver(t_FmMacControllerDriver *p_FmMacController
     p_FmMacControllerDriver->f_FM_MAC_Disable1588TimeStamp      = TgecDisable1588TimeStamp;
 
     p_FmMacControllerDriver->f_FM_MAC_SetPromiscuous            = TgecSetPromiscuous;
+    p_FmMacControllerDriver->f_FM_MAC_SetAllMulti               = TgecSetPromiscuous;
     p_FmMacControllerDriver->f_FM_MAC_AdjustLink                = NULL;
     p_FmMacControllerDriver->f_FM_MAC_SetWakeOnLan              = NULL;
     p_FmMacControllerDriver->f_FM_MAC_RestartAutoneg            = NULL;
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/Makefile b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/Makefile
index 62fbd73c8797..7b6306c63548 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/Makefile
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/Makefile
@@ -12,7 +12,7 @@ ccflags-y += -I$(NCSW_FM_INC)
 
 obj-y		+= fsl-ncsw-Pcd.o
 
-fsl-ncsw-Pcd-objs	:= fman_kg.o fman_prs.o fm_cc.o fm_kg.o fm_pcd.o fm_plcr.o fm_prs.o fm_manip.o
+fsl-ncsw-Pcd-objs	:= fman_kg.o fman_prs.o fm_cc.o fm_kg.o fm_pcd.o fm_plcr.o fm_prs.o fm_manip.o fm_ehash.o
 
 ifeq ($(CONFIG_FMAN_V3H),y)
 fsl-ncsw-Pcd-objs	+= fm_replic.o
@@ -24,3 +24,7 @@ ifeq ($(CONFIG_FMAN_ARM),y)
 fsl-ncsw-Pcd-objs	+= fm_replic.o
 endif
 
+## To enable debug printing, set the env var FMAN_DEBUG to define the debug symbols
+## For example:
+##	setenv FMAN_DEBUG '-DFM_CC_MURAM_DEBUG=1'
+ccflags-y += $(FMAN_DEBUG)
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_cc.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_cc.c
index 17c933b45dd6..703a9c0b3924 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_cc.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_cc.c
@@ -49,7 +49,15 @@
 #include "fm_hc.h"
 #include "fm_cc.h"
 #include "crc64.h"
-
+#include "fm_cc_dbg.h"
+#include "fm_ehash.h"
+
+//#define FM_EHASH_DEBUG 1
+#ifdef USE_ENHANCED_EHASH
+extern t_Handle ExternalHashTableSet(t_Handle h_FmPcd, t_FmPcdHashTableParams *p_Param);
+extern t_Error ExternalHashTableAddKey(t_Handle h_HashTbl, uint8_t keySize,
+                                       t_FmPcdCcKeyParams *p_KeyParams);
+#endif
 /****************************************/
 /*       static functions               */
 /****************************************/
@@ -278,7 +286,7 @@ static void FillAdOfTypeContLookup(t_Handle h_Ad,
     t_AdOfTypeContLookup *p_AdContLookup = (t_AdOfTypeContLookup *)h_Ad;
     t_Handle h_TmpAd;
     t_FmPcd *p_FmPcd = (t_FmPcd*)h_FmPcd;
-    uint32_t tmpReg32;
+    uint32_t tmpReg32, agingMask;
     t_Handle p_AdNewPtr = NULL;
 
     UNUSED(h_Manip);
@@ -350,6 +358,28 @@ static void FillAdOfTypeContLookup(t_Handle h_Ad,
     /* if (p_AdNewPtr = NULL) --> Done. (case (3)) */
     if (p_AdNewPtr)
     {
+#if (DPAA_VERSION >= 11)
+        if (p_Node->externalHash) {
+            tmpReg32 = 0;
+            tmpReg32 |= FM_PCD_AD_CONT_LOOKUP_TYPE;
+            if (p_Node->extHashInfo.allocateBuffer)
+                tmpReg32 |= FM_PCD_AD_FE_ENTER_ALLOCATE;
+            WRITE_UINT32(p_AdContLookup->ccAdBase, tmpReg32);
+
+            tmpReg32 = 0;
+            WRITE_UINT32(p_AdContLookup->matchTblPtr, tmpReg32);
+
+            tmpReg32 = 0;
+            tmpReg32 |= p_Node->parseCode;
+            WRITE_UINT32(p_AdContLookup->pcAndOffsets, tmpReg32);
+
+            tmpReg32 = 0;
+            tmpReg32 |=
+                    (uint32_t)(XX_VirtToPhys(p_Node->extHashInfo.p_FE) - p_FmPcd->physicalMuramBase);
+            WRITE_UINT32(p_AdContLookup->gmask, tmpReg32);
+
+        } else {
+#endif /* (DPAA_VERSION >= 11) */
         /* cases (1) & (2) */
         tmpReg32 = 0;
         tmpReg32 |= FM_PCD_AD_CONT_LOOKUP_TYPE;
@@ -375,8 +405,19 @@ static void FillAdOfTypeContLookup(t_Handle h_Ad,
         tmpReg32 |= p_Node->parseCode;
         WRITE_UINT32(p_AdContLookup->pcAndOffsets, tmpReg32);
 
-        MemCpy8((void*)&p_AdContLookup->gmask, p_Node->p_GlblMask,
-                    CC_GLBL_MASK_SIZE);
+            if (p_Node->agingSupport)
+            {
+                /* Building a mask of 1-s for all node's keys */
+                agingMask = CC_BUILD_AGING_MASK(p_Node->numOfKeys);
+                memcpy((void*)&p_AdContLookup->gmask, &agingMask,
+                            CC_AGING_MASK_SIZE);
+            }
+            else
+                MemCpy8((void*)&p_AdContLookup->gmask, p_Node->p_GlblMask,
+                            CC_GLBL_MASK_SIZE);
+#if (DPAA_VERSION >= 11)
+        }
+#endif /* (DPAA_VERSION >= 11) */
     }
 }
 
@@ -860,6 +901,7 @@ static t_Handle BuildNewAd(
     p_FmPcdCcNodeTmp->h_AdTable =
             p_FmPcdModifyCcKeyAdditionalParams->p_AdTableNew;
 
+    p_FmPcdCcNodeTmp->agingSupport = p_CcNode->agingSupport;
     p_FmPcdCcNodeTmp->lclMask = p_CcNode->lclMask;
     p_FmPcdCcNodeTmp->parseCode = p_CcNode->parseCode;
     p_FmPcdCcNodeTmp->offset = p_CcNode->offset;
@@ -907,7 +949,8 @@ static t_Handle BuildNewAd(
 static t_Error DynamicChangeHc(
         t_Handle h_FmPcd, t_List *h_OldPointersLst, t_List *h_NewPointersLst,
         t_FmPcdModifyCcKeyAdditionalParams *p_AdditionalParams,
-        bool useShadowStructs)
+        bool useShadowStructs,
+        e_ModifyState modifyState)
 {
     t_List *p_PosOld, *p_PosNew;
     uint32_t oldAdAddrOffset, newAdAddrOffset;
@@ -952,7 +995,17 @@ static t_Error DynamicChangeHc(
             }
 
             /* Invoke host command to copy from new AD to old AD */
-            err = FmHcPcdCcDoDynamicChange(((t_FmPcd *)h_FmPcd)->h_Hc,
+	    display_pcd_cc_hc((t_FmPcd *)h_FmPcd, oldAdAddrOffset,
+			newAdAddrOffset);
+            if ((!p_AdditionalParams->tree) &&
+                    (((t_FmPcdCcNode *)(p_AdditionalParams->h_CurrentNode))->agingSupport))
+                err = FmHcPcdCcDoDynamicChangeWithAging(((t_FmPcd *)h_FmPcd)->h_Hc,
+                        oldAdAddrOffset,
+                        newAdAddrOffset,
+                        modifyState,
+                        p_AdditionalParams->savedKeyIndex);
+            else
+                err = FmHcPcdCcDoDynamicChange(((t_FmPcd *)h_FmPcd)->h_Hc,
                                            oldAdAddrOffset, newAdAddrOffset);
             if (err)
             {
@@ -1000,7 +1053,8 @@ static t_Error DoDynamicChange(
 
         /* Invoke host-command to copy from the new Ad to existing Ads */
         err = DynamicChangeHc(h_FmPcd, h_OldPointersLst, h_NewPointersLst,
-                              p_AdditionalParams, useShadowStructs);
+                              p_AdditionalParams, useShadowStructs,
+                              p_AdditionalParams->modifyState);
         if (err)
             RETURN_ERROR(MAJOR, err, NO_MSG);
 
@@ -1039,7 +1093,8 @@ static t_Error DoDynamicChange(
 
 			/* HC to copy from the new Ad (old updated structures) to current Ad (uses shadow structures) */
 			err = DynamicChangeHc(h_FmPcd, h_OldPointersLst, h_NewPointersLst,
-								  p_AdditionalParams, useShadowStructs);
+                                  p_AdditionalParams, useShadowStructs,
+                                  e_MODIFY_STATE_CHANGE);
 			if (err)
 				RETURN_ERROR(MAJOR, err, NO_MSG);
 		}
@@ -1077,6 +1132,7 @@ static bool IsCapwapApplSpecific(t_Handle h_Node)
 }
 #endif /* FM_CAPWAP_SUPPORT */
 
+#ifndef USE_ENHANCED_EHASH
 static t_Error CcUpdateParam(
         t_Handle h_FmPcd, t_Handle h_PcdParams, t_Handle h_FmPort,
         t_FmPcdCcKeyAndNextEngineParams *p_CcKeyAndNextEngineParams,
@@ -1090,6 +1146,9 @@ static t_Error CcUpdateParam(
     t_FmPcdCcTree *p_CcTree = (t_FmPcdCcTree *)h_FmTree;
 
     level++;
+    
+    printk("%s::p_CcKeyAndNextEngineParams %p, numOfEntries %d\n", __FUNCTION__,
+			p_CcKeyAndNextEngineParams, numOfEntries);
 
     if (p_CcTree->h_IpReassemblyManip)
     {
@@ -1118,13 +1177,22 @@ static t_Error CcUpdateParam(
             else
                 h_Ad = PTR_MOVE(h_Ad, FM_PCD_CC_AD_ENTRY_SIZE);
 
+	    printk("%s::.nextEngineParams %p\n", __FUNCTION__,
+			&p_CcKeyAndNextEngineParams[i].nextEngineParams);
             if (p_CcKeyAndNextEngineParams[i].nextEngineParams.nextEngine
                     == e_FM_PCD_CC)
             {
                 p_CcNode =
                         p_CcKeyAndNextEngineParams[i].nextEngineParams.params.ccParams.h_CcNode;
+		printk("%s::next engine is CC, node %p\n", __FUNCTION__, p_CcNode);
                 ASSERT_COND(p_CcNode);
 
+#if (DPAA_VERSION >= 11)
+		printk("%s::p_CcNode->externalHash %d\n", __FUNCTION__,
+				p_CcNode->externalHash);
+                if (p_CcNode->externalHash)
+                    FmPortSetFESupport(h_FmPort);
+#endif /* (DPAA_VERSION >= 11) */
                 if (p_CcKeyAndNextEngineParams[i].nextEngineParams.h_Manip)
                 {
                     err =
@@ -1153,6 +1221,9 @@ static t_Error CcUpdateParam(
             }
             else
             {
+		printk("%s::next engine is %d, h_manip %p\n", __FUNCTION__,		
+			p_CcKeyAndNextEngineParams[i].nextEngineParams.nextEngine,
+                	p_CcKeyAndNextEngineParams[i].nextEngineParams.h_Manip);
                 if (p_CcKeyAndNextEngineParams[i].nextEngineParams.h_Manip)
                 {
                     err =
@@ -1171,6 +1242,20 @@ static t_Error CcUpdateParam(
 
     return E_OK;
 }
+#else
+static t_Error CcUpdateParam(
+        t_Handle h_FmPcd, t_Handle h_PcdParams, t_Handle h_FmPort,
+        t_FmPcdCcKeyAndNextEngineParams *p_CcKeyAndNextEngineParams,
+        uint16_t numOfEntries, t_Handle h_Ad, bool validate, uint16_t level,
+        t_Handle h_FmTree, bool modify)
+{
+#if (DPAA_VERSION >= 11)
+  //  FmPortSetFESupport(h_FmPort);
+    return E_OK;
+#endif /* (DPAA_VERSION >= 11) */
+
+}
+#endif
 
 static ccPrivateInfo_t IcDefineCode(t_FmPcdCcNodeParams *p_CcNodeParam)
 {
@@ -1271,6 +1356,13 @@ static void DeleteNode(t_FmPcdCcNode *p_CcNode)
         p_CcNode->h_TmpAd = NULL;
     }
 
+    if (p_CcNode->h_TmpAd)
+    {
+        FM_MURAM_FreeMem(FmPcdGetMuramHandle(p_CcNode->h_FmPcd),
+                         p_CcNode->h_TmpAd);
+        p_CcNode->h_TmpAd = NULL;
+    }
+
     if (p_CcNode->h_StatsFLRs)
     {
         FM_MURAM_FreeMem(FmPcdGetMuramHandle(p_CcNode->h_FmPcd),
@@ -1286,7 +1378,8 @@ static void DeleteNode(t_FmPcdCcNode *p_CcNode)
 
     /* Restore the original counters pointer instead of the mutual pointer (mutual to all hash buckets) */
     if (p_CcNode->isHashBucket
-            && (p_CcNode->statisticsMode != e_FM_PCD_CC_STATS_MODE_NONE))
+            && (p_CcNode->statisticsMode != e_FM_PCD_CC_STATS_MODE_NONE) &&
+            p_CcNode->keyAndNextEngineParams[p_CcNode->numOfKeys].p_StatsObj)
         p_CcNode->keyAndNextEngineParams[p_CcNode->numOfKeys].p_StatsObj->h_StatsCounters =
                 p_CcNode->h_PrivMissStatsCounters;
 
@@ -1644,14 +1737,18 @@ t_Error ValidateNextEngineParams(
             if (relativeSchemeId == FM_PCD_KG_NUM_OF_SCHEMES)
                 RETURN_ERROR(MAJOR, E_NOT_IN_RANGE, NO_MSG);
             if (!FmPcdKgIsSchemeValidSw(
-                    p_FmPcdCcNextEngineParams->params.kgParams.h_DirectScheme))
+                    p_FmPcdCcNextEngineParams->params.kgParams.h_DirectScheme)) 
                 RETURN_ERROR(MAJOR, E_INVALID_STATE,
                              ("not valid schemeIndex in KG next engine param"));
+	    
+#if 0
+	    //we need to allow any scheme to be part of the KG next engine param
             if (!KgIsSchemeAlwaysDirect(h_FmPcd, relativeSchemeId))
                 RETURN_ERROR(
                         MAJOR,
                         E_INVALID_STATE,
                         ("CC Node may point only to a scheme that is always direct."));
+#endif
             break;
 
         case (e_FM_PCD_PLCR):
@@ -1704,7 +1801,8 @@ t_Error ValidateNextEngineParams(
 static uint8_t GetGenParseCode(e_FmPcdExtractFrom src,
                                uint32_t offset, bool glblMask,
                                uint8_t *parseArrayOffset, bool fromIc,
-                               ccPrivateInfo_t icCode)
+                               ccPrivateInfo_t icCode,
+                               bool aging)
 {
     if (!fromIc)
     {
@@ -1734,7 +1832,10 @@ static uint8_t GetGenParseCode(e_FmPcdExtractFrom src,
         {
             case (CC_PRIVATE_INFO_IC_KEY_EXACT_MATCH):
                 *parseArrayOffset = 0x50;
-                return CC_PC_GENERIC_IC_GMASK;
+                if (aging)
+                    return CC_PC_GENERIC_IC_AGING_MASK;
+                else
+                    return CC_PC_GENERIC_IC_GMASK;
 
             case (CC_PRIVATE_INFO_IC_HASH_EXACT_MATCH):
                 *parseArrayOffset = 0x48;
@@ -3521,6 +3622,7 @@ static t_FmPcdModifyCcKeyAdditionalParams * ModifyNodeCommonPart(
 
     p_FmPcdModifyCcKeyAdditionalParams->h_CurrentNode = h_FmPcdCcNodeOrTree;
     p_FmPcdModifyCcKeyAdditionalParams->savedKeyIndex = keyIndex;
+    p_FmPcdModifyCcKeyAdditionalParams->modifyState = modifyState;
 
     while (i < numOfKeys)
     {
@@ -4123,6 +4225,7 @@ static t_Error ModifyNextEngineParamNode(
         RETURN_ERROR(MAJOR, err, NO_MSG);
     }
 
+    display_cc_node(p_CcNode, __FUNCTION__);
     err = DoDynamicChange(p_FmPcd, &h_OldPointersLst, &h_NewPointersLst,
                           p_ModifyKeyParams, FALSE);
 
@@ -4551,7 +4654,7 @@ static t_Error MatchTableSet(t_Handle h_FmPcd, t_FmPcdCcNode *p_CcNode,
             p_CcNode->parseCode = GetGenParseCode(
                     p_CcNodeParam->extractCcParams.extractNonHdr.src,
                     p_CcNode->offset, glblMask, &p_CcNode->prsArrayOffset,
-                    fromIc, icCode);
+                    fromIc, icCode, p_CcNode->agingSupport);
 
             if (p_CcNode->parseCode == CC_PC_GENERIC_IC_HASH_INDEXED)
             {
@@ -4565,6 +4668,7 @@ static t_Error MatchTableSet(t_Handle h_FmPcd, t_FmPcdCcNode *p_CcNode,
                 }
             }
             if ((p_CcNode->parseCode == CC_PC_GENERIC_IC_GMASK)
+                    || (p_CcNode->parseCode == CC_PC_GENERIC_IC_AGING_MASK)
                     || (p_CcNode->parseCode == CC_PC_GENERIC_IC_HASH_INDEXED))
             {
                 p_CcNode->offset += p_CcNode->prsArrayOffset;
@@ -4594,6 +4698,9 @@ static t_Error MatchTableSet(t_Handle h_FmPcd, t_FmPcdCcNode *p_CcNode,
     if (p_CcNodeParam->keysParams.keySize != p_CcNode->sizeOfExtraction)
     {
         DeleteNode(p_CcNode);
+	printk("keySize %d, sizeOfExtraction %d\n",
+		p_CcNodeParam->keysParams.keySize,  
+		p_CcNode->sizeOfExtraction);
         RETURN_ERROR(MAJOR, E_INVALID_VALUE,
                      ("keySize has to be equal to sizeOfExtraction"));
     }
@@ -4914,124 +5021,2269 @@ static t_Error MatchTableSet(t_Handle h_FmPcd, t_FmPcdCcNode *p_CcNode,
 
     return E_OK;
 }
-/************************** End of static functions **************************/
-
-/*****************************************************************************/
-/*              Inter-module API routines                                    */
-/*****************************************************************************/
 
-t_CcNodeInformation* FindNodeInfoInReleventLst(t_List *p_List, t_Handle h_Info,
-                                               t_Handle h_Spinlock)
+#ifndef USE_ENHANCED_EHASH
+static t_Handle InternalHashTableSet(t_Handle h_FmPcd, t_FmPcdHashTableParams *p_Param)
 {
-    t_CcNodeInformation *p_CcInformation;
-    t_List *p_Pos;
-    uint32_t intFlags;
+    t_FmPcdCcNode *p_CcNodeHashTbl;
+    t_FmPcdCcNodeParams *p_IndxHashCcNodeParam, *p_ExactMatchCcNodeParam;
+    t_FmPcdCcNode *p_CcNode;
+    t_Handle h_MissStatsCounters = NULL;
+    t_FmPcdCcKeyParams *p_HashKeyParams;
+    int i;
+    uint16_t numOfSets, numOfWays, countMask, onesCount = 0;
+    bool statsEnForMiss = FALSE;
+    t_Error err;
 
-    intFlags = XX_LockIntrSpinlock(h_Spinlock);
+    p_ExactMatchCcNodeParam = (t_FmPcdCcNodeParams*)XX_Malloc(
+            sizeof(t_FmPcdCcNodeParams));
+    if (!p_ExactMatchCcNodeParam)
+    {
+        REPORT_ERROR(MAJOR, E_NO_MEMORY, ("p_ExactMatchCcNodeParam"));
+        return NULL;
+    }
+    memset(p_ExactMatchCcNodeParam, 0, sizeof(t_FmPcdCcNodeParams));
 
-    for (p_Pos = LIST_FIRST(p_List); p_Pos != (p_List);
-            p_Pos = LIST_NEXT(p_Pos))
+    p_IndxHashCcNodeParam = (t_FmPcdCcNodeParams*)XX_Malloc(
+            sizeof(t_FmPcdCcNodeParams));
+    if (!p_IndxHashCcNodeParam)
     {
-        p_CcInformation = CC_NODE_F_OBJECT(p_Pos);
+        XX_Free(p_ExactMatchCcNodeParam);
+        REPORT_ERROR(MAJOR, E_NO_MEMORY, ("p_IndxHashCcNodeParam"));
+        return NULL;
+    }
+    memset(p_IndxHashCcNodeParam, 0, sizeof(t_FmPcdCcNodeParams));
 
-        ASSERT_COND(p_CcInformation->h_CcNode);
+    /* Calculate number of sets and number of ways of the hash table */
+    countMask = (uint16_t)(p_Param->hashResMask >> 4);
+    while (countMask)
+    {
+        onesCount++;
+        countMask = (uint16_t)(countMask >> 1);
+    }
 
-        if (p_CcInformation->h_CcNode == h_Info)
+    numOfSets = (uint16_t)(1 << onesCount);
+    numOfWays = (uint16_t)DIV_CEIL(p_Param->maxNumOfKeys, numOfSets);
+
+    if (p_Param->maxNumOfKeys % numOfSets)
+        DBG(INFO, ("'maxNumOfKeys' is not a multiple of hash number of ways, so number of ways will be rounded up"));
+
+    if ((p_Param->agingSupport) && (numOfWays > 31))
+    {
+        XX_Free(p_ExactMatchCcNodeParam);
+        REPORT_ERROR(MAJOR, E_INVALID_VALUE,
+                     ("Aging supported enabled and %d keys requested per hash bucket. Aging cannot be supported when more then 31 keys", numOfWays));
+        return NULL;
+    }
+
+    if ((p_Param->statisticsMode == e_FM_PCD_CC_STATS_MODE_FRAME)
+            || (p_Param->statisticsMode == e_FM_PCD_CC_STATS_MODE_BYTE_AND_FRAME))
+    {
+        /* Allocating a statistics counters table that will be used by all
+         'miss' entries of the hash table */
+        h_MissStatsCounters = (t_Handle)FM_MURAM_AllocMem(
+                FmPcdGetMuramHandle(h_FmPcd), 2 * FM_PCD_CC_STATS_COUNTER_SIZE,
+                FM_PCD_CC_AD_TABLE_ALIGN);
+        if (!h_MissStatsCounters)
         {
-            XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
-            return p_CcInformation;
+            REPORT_ERROR(MAJOR, E_NO_MEMORY, ("MURAM allocation for statistics table for hash miss"));
+            XX_Free(p_IndxHashCcNodeParam);
+            XX_Free(p_ExactMatchCcNodeParam);
+            return NULL;
         }
+        memset(h_MissStatsCounters, 0, (2 * FM_PCD_CC_STATS_COUNTER_SIZE));
+
+        /* Always enable statistics for 'miss', so that a statistics AD will be
+         initialized from the start. We'll store the requested 'statistics enable'
+         value and it will be used when statistics are read by the user. */
+        statsEnForMiss = p_Param->ccNextEngineParamsForMiss.statisticsEn;
+        p_Param->ccNextEngineParamsForMiss.statisticsEn = TRUE;
     }
 
-    XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+    /* Building exact-match node params, will be used to create the hash buckets */
+    p_ExactMatchCcNodeParam->extractCcParams.type = e_FM_PCD_EXTRACT_NON_HDR;
 
-    return NULL;
-}
+    p_ExactMatchCcNodeParam->extractCcParams.extractNonHdr.src =
+            e_FM_PCD_EXTRACT_FROM_KEY;
+    p_ExactMatchCcNodeParam->extractCcParams.extractNonHdr.action =
+            e_FM_PCD_ACTION_EXACT_MATCH;
+    p_ExactMatchCcNodeParam->extractCcParams.extractNonHdr.offset = 0;
+    p_ExactMatchCcNodeParam->extractCcParams.extractNonHdr.size =
+            p_Param->matchKeySize;
 
-void EnqueueNodeInfoToRelevantLst(t_List *p_List, t_CcNodeInformation *p_CcInfo,
-                                  t_Handle h_Spinlock)
-{
-    t_CcNodeInformation *p_CcInformation;
-    uint32_t intFlags = 0;
+    p_ExactMatchCcNodeParam->keysParams.maxNumOfKeys = numOfWays;
+    p_ExactMatchCcNodeParam->keysParams.maskSupport = FALSE;
+    p_ExactMatchCcNodeParam->keysParams.statisticsMode =
+            p_Param->statisticsMode;
+    p_ExactMatchCcNodeParam->keysParams.numOfKeys = 0;
+    p_ExactMatchCcNodeParam->keysParams.keySize = p_Param->matchKeySize;
+    p_ExactMatchCcNodeParam->keysParams.ccNextEngineParamsForMiss =
+            p_Param->ccNextEngineParamsForMiss;
 
-    p_CcInformation = (t_CcNodeInformation *)XX_Malloc(
-            sizeof(t_CcNodeInformation));
+    p_HashKeyParams = p_IndxHashCcNodeParam->keysParams.keyParams;
 
-    if (p_CcInformation)
+    for (i = 0; i < numOfSets; i++)
     {
-        memset(p_CcInformation, 0, sizeof(t_CcNodeInformation));
-        memcpy(p_CcInformation, p_CcInfo, sizeof(t_CcNodeInformation));
-        INIT_LIST(&p_CcInformation->node);
+        /* Each exact-match node will be marked as a 'bucket' and provided with
+           a pointer to statistics counters, to be used for 'miss' entry
+           statistics */
+        p_CcNode = (t_FmPcdCcNode *)XX_Malloc(sizeof(t_FmPcdCcNode));
+        if (!p_CcNode)
+            break;
+        memset(p_CcNode, 0, sizeof(t_FmPcdCcNode));
 
-        if (h_Spinlock)
-            intFlags = XX_LockIntrSpinlock(h_Spinlock);
+        p_CcNode->isHashBucket = TRUE;
+        p_CcNode->agingSupport = p_Param->agingSupport;
+        p_CcNode->h_MissStatsCounters = h_MissStatsCounters;
 
-        LIST_AddToTail(&p_CcInformation->node, p_List);
+        err = MatchTableSet(h_FmPcd, p_CcNode, p_ExactMatchCcNodeParam);
+        if (err)
+            break;
 
-        if (h_Spinlock)
-            XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+        p_HashKeyParams[i].ccNextEngineParams.nextEngine = e_FM_PCD_CC;
+        p_HashKeyParams[i].ccNextEngineParams.statisticsEn = FALSE;
+        p_HashKeyParams[i].ccNextEngineParams.params.ccParams.h_CcNode =
+                p_CcNode;
     }
-    else
-        REPORT_ERROR(MAJOR, E_NO_MEMORY, ("CC Node Information"));
-}
 
-void DequeueNodeInfoFromRelevantLst(t_List *p_List, t_Handle h_Info,
-                                    t_Handle h_Spinlock)
-{
-    t_CcNodeInformation *p_CcInformation = NULL;
-    uint32_t intFlags = 0;
-    t_List *p_Pos;
+    if (i < numOfSets)
+    {
+        for (i = i - 1; i >= 0; i--)
+            FM_PCD_MatchTableDelete(
+                    p_HashKeyParams[i].ccNextEngineParams.params.ccParams.h_CcNode);
 
-    if (h_Spinlock)
-        intFlags = XX_LockIntrSpinlock(h_Spinlock);
+        FM_MURAM_FreeMem(FmPcdGetMuramHandle(h_FmPcd), h_MissStatsCounters);
 
-    if (LIST_IsEmpty(p_List))
-    {
-        XX_RestoreAllIntr(intFlags);
-        return;
+        REPORT_ERROR(MAJOR, E_NULL_POINTER, NO_MSG);
+        XX_Free(p_IndxHashCcNodeParam);
+        XX_Free(p_ExactMatchCcNodeParam);
+        return NULL;
     }
 
-    for (p_Pos = LIST_FIRST(p_List); p_Pos != (p_List);
-            p_Pos = LIST_NEXT(p_Pos))
-    {
-        p_CcInformation = CC_NODE_F_OBJECT(p_Pos);
-        ASSERT_COND(p_CcInformation);
-        ASSERT_COND(p_CcInformation->h_CcNode);
-        if (p_CcInformation->h_CcNode == h_Info)
-            break;
-    }
+    /* Creating indexed-hash CC node */
+    p_IndxHashCcNodeParam->extractCcParams.type = e_FM_PCD_EXTRACT_NON_HDR;
+    p_IndxHashCcNodeParam->extractCcParams.extractNonHdr.src =
+            e_FM_PCD_EXTRACT_FROM_HASH;
+    p_IndxHashCcNodeParam->extractCcParams.extractNonHdr.action =
+            e_FM_PCD_ACTION_INDEXED_LOOKUP;
+    p_IndxHashCcNodeParam->extractCcParams.extractNonHdr.icIndxMask =
+            p_Param->hashResMask;
+    p_IndxHashCcNodeParam->extractCcParams.extractNonHdr.offset =
+            p_Param->hashShift;
+    p_IndxHashCcNodeParam->extractCcParams.extractNonHdr.size = 2;
 
-    if (p_CcInformation)
+    p_IndxHashCcNodeParam->keysParams.maxNumOfKeys = numOfSets;
+    p_IndxHashCcNodeParam->keysParams.maskSupport = FALSE;
+    p_IndxHashCcNodeParam->keysParams.statisticsMode =
+            e_FM_PCD_CC_STATS_MODE_NONE;
+    /* Number of keys of this node is number of sets of the hash */
+    p_IndxHashCcNodeParam->keysParams.numOfKeys = numOfSets;
+    p_IndxHashCcNodeParam->keysParams.keySize = 2;
+
+    p_CcNodeHashTbl = FM_PCD_MatchTableSet(h_FmPcd, p_IndxHashCcNodeParam);
+
+    if (p_CcNodeHashTbl)
     {
-        LIST_DelAndInit(&p_CcInformation->node);
-        XX_Free(p_CcInformation);
+        /* Storing the allocated counters for buckets 'miss' in the hash table,
+         and if statistics for miss were enabled. */
+        p_CcNodeHashTbl->h_MissStatsCounters = h_MissStatsCounters;
+        p_CcNodeHashTbl->statsEnForMiss = statsEnForMiss;
     }
 
-    if (h_Spinlock)
-        XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+    XX_Free(p_IndxHashCcNodeParam);
+    XX_Free(p_ExactMatchCcNodeParam);
+
+    return p_CcNodeHashTbl;
 }
 
-void NextStepAd(t_Handle h_Ad, t_FmPcdCcStatsParams *p_FmPcdCcStatsParams,
-                t_FmPcdCcNextEngineParams *p_FmPcdCcNextEngineParams,
-                t_FmPcd *p_FmPcd)
+static t_Error InternalHashTableDelete(t_FmPcdCcNode *p_HashTbl)
 {
-    switch (p_FmPcdCcNextEngineParams->nextEngine)
-    {
-        case (e_FM_PCD_KG):
-        case (e_FM_PCD_PLCR):
-        case (e_FM_PCD_DONE):
-            /* if NIA is not CC, create a "result" type AD */
-            FillAdOfTypeResult(h_Ad, p_FmPcdCcStatsParams, p_FmPcd,
-                               p_FmPcdCcNextEngineParams);
-            break;
-#if (DPAA_VERSION >= 11)
-        case (e_FM_PCD_FR):
-            if (p_FmPcdCcNextEngineParams->params.frParams.h_FrmReplic)
-            {
-                FillAdOfTypeContLookup(
-                        h_Ad, p_FmPcdCcStatsParams, p_FmPcd,
-                        p_FmPcdCcNextEngineParams->params.ccParams.h_CcNode,
-                        p_FmPcdCcNextEngineParams->h_Manip,
+    t_Handle h_FmPcd;
+    t_Handle *p_HashBuckets, h_MissStatsCounters;
+    uint16_t i, numOfBuckets;
+    t_Error err;
+
+    /* Store all hash buckets before the hash is freed */
+    numOfBuckets = p_HashTbl->numOfKeys;
+
+    p_HashBuckets = (t_Handle *)XX_Malloc(numOfBuckets * sizeof(t_Handle));
+    if (!p_HashBuckets)
+        RETURN_ERROR(MAJOR, E_NO_MEMORY, NO_MSG);
+
+    for (i = 0; i < numOfBuckets; i++)
+        p_HashBuckets[i] =
+                p_HashTbl->keyAndNextEngineParams[i].nextEngineParams.params.ccParams.h_CcNode;
+
+    h_FmPcd = p_HashTbl->h_FmPcd;
+    h_MissStatsCounters = p_HashTbl->h_MissStatsCounters;
+
+    /* Free the hash */
+    err = FM_PCD_MatchTableDelete(p_HashTbl);
+
+    /* Free each hash bucket */
+    for (i = 0; i < numOfBuckets; i++)
+        err |= FM_PCD_MatchTableDelete(p_HashBuckets[i]);
+
+    XX_Free(p_HashBuckets);
+
+    /* Free statistics counters for 'miss', if these were allocated */
+    if (h_MissStatsCounters)
+        FM_MURAM_FreeMem(FmPcdGetMuramHandle(h_FmPcd), h_MissStatsCounters);
+
+    if (err)
+        RETURN_ERROR(MAJOR, err, NO_MSG);
+
+    return E_OK;
+}
+
+static t_Error InternalHashTableAddKey(t_Handle h_HashTbl, uint8_t keySize,
+                                       t_FmPcdCcKeyParams *p_KeyParams)
+{
+    t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
+    t_Handle h_HashBucket;
+    uint8_t bucketIndex;
+    uint16_t lastIndex;
+    t_Error err;
+
+    SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
+    SANITY_CHECK_RETURN_ERROR(p_KeyParams, E_NULL_POINTER);
+    SANITY_CHECK_RETURN_ERROR(p_KeyParams->p_Key, E_NULL_POINTER);
+
+    err = FM_PCD_MatchTableGetIndexedHashBucket(p_HashTbl, keySize,
+                                                p_KeyParams->p_Key,
+                                                0,
+                                                &h_HashBucket, &bucketIndex,
+                                                &lastIndex);
+    if (err)
+        RETURN_ERROR(MAJOR, err, NO_MSG);
+
+    return FM_PCD_MatchTableAddKey(h_HashBucket, FM_PCD_LAST_KEY_INDEX, keySize,
+                                   p_KeyParams);
+}
+
+/**
+ * Removes a specified key from Internal Hash Table
+ *
+ * @param[in] h_HashTbl Handle to hash table where to remove the key
+ * @param[in] keySize The size of Key to be removed
+ * @param[in] p_Key Pointer to key to be removed
+ *
+ * @return E_OK on success; Error code otherwise.
+ */
+static t_Error InternalHashTableRemoveKey(t_Handle h_HashTbl, uint8_t keySize,
+                                          uint8_t *p_Key)
+{
+    t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
+    t_Handle h_HashBucket;
+    uint8_t bucketIndex;
+    uint16_t lastIndex;
+    t_Error err;
+
+    SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
+    SANITY_CHECK_RETURN_ERROR(p_Key, E_NULL_POINTER);
+
+    err = FM_PCD_MatchTableGetIndexedHashBucket(p_HashTbl, keySize, p_Key,
+                                                0,
+                                                &h_HashBucket, &bucketIndex,
+                                                &lastIndex);
+    if (err)
+        RETURN_ERROR(MAJOR, err, NO_MSG);
+
+    return FM_PCD_MatchTableFindNRemoveKey(h_HashBucket, keySize, p_Key, NULL);
+}
+
+static t_Error InternalHashTableModifyNextEngine(t_Handle h_HashTbl, uint8_t keySize, uint8_t *p_Key,
+                                                 t_FmPcdCcNextEngineParams *p_FmPcdCcNextEngineParams)
+{
+    t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
+    t_Handle h_HashBucket;
+    uint8_t bucketIndex;
+    uint16_t lastIndex;
+    t_Error err;
+
+    SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
+    SANITY_CHECK_RETURN_ERROR(p_Key, E_NULL_POINTER);
+    SANITY_CHECK_RETURN_ERROR(p_FmPcdCcNextEngineParams, E_NULL_POINTER);
+
+    err = FM_PCD_MatchTableGetIndexedHashBucket(p_HashTbl, keySize, p_Key,
+                                                0,
+                                                &h_HashBucket, &bucketIndex,
+                                                &lastIndex);
+    if (err)
+        RETURN_ERROR(MAJOR, err, NO_MSG);
+
+    return FM_PCD_MatchTableFindNModifyNextEngine(h_HashBucket, keySize, p_Key,
+                                                  NULL,
+                                                  p_FmPcdCcNextEngineParams);
+}
+
+static t_Error InternalHashTableModifyMissNextEngine(t_Handle h_HashTbl, t_FmPcdCcNextEngineParams *p_FmPcdCcNextEngineParams)
+{
+    t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
+    t_Handle h_HashBucket;
+    uint8_t i;
+    bool nullifyMissStats = FALSE;
+    t_Error err;
+
+    SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
+
+    if ((!p_HashTbl->h_MissStatsCounters)
+            && (p_FmPcdCcNextEngineParams->statisticsEn))
+        RETURN_ERROR(
+                MAJOR,
+                E_CONFLICT,
+                ("Statistics are requested for a key, but statistics mode was set"
+                "to 'NONE' upon initialization"));
+
+    if (p_HashTbl->h_MissStatsCounters)
+    {
+        if ((!p_HashTbl->statsEnForMiss)
+                && (p_FmPcdCcNextEngineParams->statisticsEn))
+            nullifyMissStats = TRUE;
+
+        if ((p_HashTbl->statsEnForMiss)
+                && (!p_FmPcdCcNextEngineParams->statisticsEn))
+        {
+            p_HashTbl->statsEnForMiss = FALSE;
+            p_FmPcdCcNextEngineParams->statisticsEn = TRUE;
+        }
+    }
+
+    for (i = 0; i < p_HashTbl->numOfKeys; i++)
+    {
+        h_HashBucket =
+                p_HashTbl->keyAndNextEngineParams[i].nextEngineParams.params.ccParams.h_CcNode;
+
+        err = FM_PCD_MatchTableModifyMissNextEngine(h_HashBucket,
+                                                    p_FmPcdCcNextEngineParams);
+        if (err)
+            RETURN_ERROR(MAJOR, err, NO_MSG);
+    }
+
+    if (nullifyMissStats)
+    {
+        memset(p_HashTbl->h_MissStatsCounters, 0,
+               (2 * FM_PCD_CC_STATS_COUNTER_SIZE));
+        memset(p_HashTbl->h_MissStatsCounters, 0,
+               (2 * FM_PCD_CC_STATS_COUNTER_SIZE));
+        p_HashTbl->statsEnForMiss = TRUE;
+    }
+
+    return E_OK;
+}
+#endif // USE_ENHANCED_EHASH
+
+#if (DPAA_VERSION >= 11)
+void get_indexed_hash_bucket(uint8_t key_size,
+	uint8_t *key_ptr,
+	uint8_t crc_shift,
+	uint16_t mask,
+	uint16_t *bucket_index)
+{
+	uint64_t crc64 = 0;
+
+	crc64 = crc64_init();
+	crc64 = crc64_compute(key_ptr, key_size, crc64);
+
+	crc64 >>= ((6 - crc_shift) << 3); //the shift is byte shift
+	*bucket_index = (uint16_t)crc64 & mask;
+
+}
+
+#ifndef USE_ENHANCED_EHASH
+static int ext_hash_table_create(t_FmPcdHashTableParams *table_params,
+	void *table_handle)
+{
+	uint32_t temp;
+	uint8_t num_of_zeroes = 0;
+	uint32_t bit_counter;
+	int num_dynamic_buckets;
+	uint16_t hash_mask_temp;
+	int i;
+	t_FmPcdCcNodeExtHashInfo *table_struct_ptr;
+
+    SANITY_CHECK_RETURN_ERROR(table_params, E_NULL_POINTER);
+    SANITY_CHECK_RETURN_ERROR(table_handle, E_INVALID_HANDLE);
+
+    table_struct_ptr = &(((t_FmPcdCcNode *)(table_handle))->extHashInfo);
+
+	/* TODO - need to include also ARM assembly */
+	temp = (uint32_t)table_params->hashResMask;
+#ifdef CONFIG_FMAN_ARM
+	__asm__ ("clz %0,%1\n"
+			: "=r"(num_of_zeroes)
+			: "r"(temp));
+#else
+	__asm__ ("cntlzw %0,%1\n"
+			: "=r"(num_of_zeroes)
+			: "r"(temp));
+#endif
+	table_struct_ptr->hash_size = 32 - num_of_zeroes;
+
+	/* Allocation of the static buckets */
+	table_struct_ptr->table_base_ptr =
+		(t_FmExtHashBucket *)XX_MallocSmart(
+			CC_EXT_HASH_BUCKET_SIZE << (table_struct_ptr->hash_size),
+			table_params->externalHashParams.dataMemId,
+			256);
+	if (!table_struct_ptr->table_base_ptr) {
+		REPORT_ERROR(MAJOR, E_NO_MEMORY, ("malloc failed in function ext_hash_table_create"));
+		XX_FreeSmart(table_struct_ptr);
+		return -ENOMEM;
+	}
+	MemSet64(table_struct_ptr->table_base_ptr,
+			0,
+			CC_EXT_HASH_BUCKET_SIZE << (table_struct_ptr->hash_size));
+
+	table_struct_ptr->key_size = table_params->matchKeySize;
+	if (table_params->matchKeySize < 2) {
+		table_struct_ptr->aligned_key_size = 2;
+		table_struct_ptr->max_ways = 13;
+	} else {
+		if (table_params->matchKeySize < 4) {
+			table_struct_ptr->aligned_key_size = 4;
+			table_struct_ptr->max_ways = 12;
+		} else {
+			if (table_params->matchKeySize < 8) {
+				table_struct_ptr->aligned_key_size = 8;
+				table_struct_ptr->max_ways = 10;
+			} else {
+				if (table_params->matchKeySize < 16) {
+					table_struct_ptr->aligned_key_size = 16;
+					table_struct_ptr->max_ways = 7;
+				} else {
+					if (table_params->matchKeySize < 24) {
+						table_struct_ptr->aligned_key_size = 24;
+						table_struct_ptr->max_ways = 6;
+					} else {
+						if (table_params->matchKeySize < 32) {
+							table_struct_ptr->aligned_key_size = 32;
+							table_struct_ptr->max_ways =
+								5;
+						} else {
+							if (table_params->matchKeySize < 40) {
+								table_struct_ptr->aligned_key_size = 40;
+								table_struct_ptr->max_ways = 4;
+							} else {
+								if (table_params->matchKeySize < 48) {
+									table_struct_ptr->aligned_key_size = 48;
+									table_struct_ptr->max_ways = 3;
+								} else {
+									if (table_params->matchKeySize < 56) {
+										table_struct_ptr->aligned_key_size = 56;
+										table_struct_ptr->max_ways = 3;
+									} else {
+										REPORT_ERROR(MAJOR, E_NOT_IN_RANGE, ("Key size too big"));
+										XX_FreeSmart(table_struct_ptr->hash_bucket_pool.bucket_pool_base_ptr);
+										XX_FreeSmart(table_struct_ptr->table_base_ptr);
+										XX_FreeSmart(table_struct_ptr);
+										return -EINVAL;
+									}
+								}
+							}
+						}
+					}
+				}
+			}
+		}
+	}
+
+	/* Count number of ones in the mask */
+	hash_mask_temp = table_params->hashResMask;
+	bit_counter = 0;
+	for(i=0; i < 16; i++)
+	{
+		if(hash_mask_temp&0x8000)
+		{
+			bit_counter++;
+		}
+		hash_mask_temp<<=1;
+	}
+
+	/* Calculate the number of static buckets */
+	num_dynamic_buckets = 1 << bit_counter;
+
+	/* Initialize static buckets:
+	 * If no next bucket exists, should point to itself:*/
+	for (i = 0; i < num_dynamic_buckets; i++) {
+		WRITE_UINT32(table_struct_ptr->table_base_ptr[i].next_bucket_addr,
+			(uint32_t)(XX_VirtToPhys(&table_struct_ptr->table_base_ptr[i]) & 0xffffffff));
+	}
+
+	/* Calculate the number of dynamic buckets */
+	num_dynamic_buckets = table_params->maxNumOfKeys/(table_struct_ptr->max_ways) + 1 - num_dynamic_buckets;
+	if(num_dynamic_buckets > 0)
+	{
+
+		/* Allocation of the dynamic buckets */
+		table_struct_ptr->hash_bucket_pool.bucket_pool_base_ptr = XX_MallocSmart(
+			(uint32_t)(CC_EXT_HASH_BUCKET_SIZE * num_dynamic_buckets),
+			table_params->externalHashParams.dataMemId,
+			256);
+		if (!table_struct_ptr->hash_bucket_pool.bucket_pool_base_ptr) {
+			REPORT_ERROR(MAJOR, E_NO_MEMORY, ("malloc failed in function ext_hash_table_create"));
+			XX_FreeSmart(table_struct_ptr->table_base_ptr);
+			XX_FreeSmart(table_struct_ptr);
+			return -ENOMEM;
+		}
+		MemSet64(table_struct_ptr->hash_bucket_pool.bucket_pool_base_ptr,
+			0,
+			(uint32_t)(CC_EXT_HASH_BUCKET_SIZE * num_dynamic_buckets));
+
+		/* Allocation of the dynamic buckets pool management struct */
+		table_struct_ptr->hash_bucket_pool.bucket_stack = XX_MallocSmart(
+			(uint32_t)(num_dynamic_buckets * sizeof(t_FmExtHashBucket*)),
+			table_params->externalHashParams.dataMemId,
+			64);
+		if (!table_struct_ptr->hash_bucket_pool.bucket_stack) {
+			REPORT_ERROR(MAJOR, E_NO_MEMORY, ("malloc failed in function ext_hash_table_create"));
+			XX_FreeSmart(table_struct_ptr->hash_bucket_pool.bucket_pool_base_ptr);
+			XX_FreeSmart(table_struct_ptr->table_base_ptr);
+			XX_FreeSmart(table_struct_ptr);
+			return -ENOMEM;
+		}
+
+		table_struct_ptr->hash_bucket_pool.last_bucket = (uint32_t)(num_dynamic_buckets- 1);
+		for (i = 0; i < num_dynamic_buckets; i++)
+			table_struct_ptr->hash_bucket_pool.bucket_stack[i] = (t_FmExtHashBucket*)
+				(table_struct_ptr->hash_bucket_pool.bucket_pool_base_ptr + (i<<8));
+	}
+	else
+	{
+		/* There is no dynamic buckets needed */
+		num_dynamic_buckets = 0;
+		table_struct_ptr->hash_bucket_pool.bucket_pool_base_ptr = NULL;
+		table_struct_ptr->hash_bucket_pool.bucket_stack = NULL;
+		table_struct_ptr->hash_bucket_pool.last_bucket = -1;
+	}
+	DBG(TRACE, ("ext_hash_table_create() num_dynamic_buckets: %d", num_dynamic_buckets));
+	//fsl_print("num_dynamic_buckets: %d\n", num_dynamic_buckets);
+
+
+	table_struct_ptr->hash_mask = table_params->hashResMask;
+	table_struct_ptr->crc_shift = table_params->hashShift;
+	//XX_Print("External HASH table created. Base:0x%x ,Num of sets: %d\n", table_struct_ptr->table_base_ptr, 1<<(table_struct_ptr->hash_size));
+	//fsl_print("External HASH table created. Base:0x%x ,Num of sets: %d\n", table_struct_ptr->table_base_ptr, 1<<(table_struct_ptr->hash_size));
+
+	return E_OK;
+
+}
+
+static void ext_hash_table_delete(void *table_handle)
+{
+	t_FmPcdCcNodeExtHashInfo *table_struct_ptr;
+
+	SANITY_CHECK_RETURN(table_handle, E_INVALID_HANDLE);
+
+    table_struct_ptr = &(((t_FmPcdCcNode *)(table_handle))->extHashInfo);
+
+    if (table_struct_ptr->hash_bucket_pool.bucket_stack)
+        XX_FreeSmart(table_struct_ptr->hash_bucket_pool.bucket_stack);
+
+    if (table_struct_ptr->hash_bucket_pool.bucket_pool_base_ptr)
+    	XX_FreeSmart(table_struct_ptr->hash_bucket_pool.bucket_pool_base_ptr);
+
+    if (table_struct_ptr->table_base_ptr)
+    	XX_FreeSmart(table_struct_ptr->table_base_ptr);
+}
+
+static t_FmExtHashBucket * ext_hash_lookup(void *table_handle,
+	uint8_t *key_ptr,
+	uint16_t *set_index,
+	uint8_t *found_key_index)
+{
+
+	int not_found = 1;
+	uint8_t i, not_last;
+	uint16_t bucket_index;
+	t_FmExtHashBucket *found_bucket;
+	t_FmPcdCcNodeExtHashInfo *table_struct_ptr;
+
+    SANITY_CHECK_RETURN_VALUE(table_handle, E_INVALID_HANDLE, NULL);
+    SANITY_CHECK_RETURN_VALUE(key_ptr, E_NULL_POINTER, NULL);
+    SANITY_CHECK_RETURN_VALUE(set_index, E_NULL_POINTER, NULL);
+    SANITY_CHECK_RETURN_VALUE(found_key_index, E_NULL_POINTER, NULL);
+
+	table_struct_ptr = &(((t_FmPcdCcNode *)(table_handle))->extHashInfo);
+	/* Check if Hash table was created */
+	SANITY_CHECK_RETURN_VALUE(table_struct_ptr->table_base_ptr, E_NULL_POINTER, NULL);
+
+	get_indexed_hash_bucket(table_struct_ptr->key_size, key_ptr,
+				table_struct_ptr->crc_shift,
+				table_struct_ptr->hash_mask, &bucket_index);
+
+	*set_index = bucket_index;
+	found_bucket = &(table_struct_ptr->table_base_ptr[bucket_index]);
+
+	if (found_bucket->valid_keys == 0)
+	{
+		return NULL;
+	}
+
+	do {
+		for (i = 0; (i < found_bucket->valid_keys) && not_found; i++)
+		{
+			/*check if the current key is valid */
+			if (found_bucket->key_result[(table_struct_ptr->aligned_key_size * i)
+			                             + table_struct_ptr->key_size] == 0)
+			{
+				not_found =
+					memcmp(key_ptr,
+						&found_bucket->key_result[(table_struct_ptr->aligned_key_size) * i],
+						table_struct_ptr->key_size);
+
+				if (!not_found)
+				{
+					*found_key_index = i;
+					return found_bucket;
+				}
+			}
+		}
+		//XX_Print("ext_hash_lookup() found_bucket: 0x%x\n", found_bucket);
+		not_last = found_bucket->not_last;
+		//TODO need to add 32 MSB
+		found_bucket = (t_FmExtHashBucket *)XX_PhysToVirt((uint64_t)GET_UINT32(found_bucket->next_bucket_addr));
+		//XX_Print("ext_hash_lookup() new found_bucket: 0x%x\n", found_bucket);
+	} while (not_last);
+	return NULL;
+}
+
+static int ext_hash_add_key(void *table_handle,
+	uint8_t *key_ptr,
+	t_FmExtHashResult *result)
+{
+	uint16_t bucket_index;
+	uint8_t *valid_ptr;
+	t_FmExtHashBucket *new_bucket;
+	t_FmExtHashBucket *bucket, *static_bucket;
+	t_FmExtHashBucketPool *bucket_pool;
+	t_FmPcdCcNodeExtHashInfo *table_struct_ptr;
+
+    SANITY_CHECK_RETURN_ERROR(table_handle, E_INVALID_HANDLE);
+    SANITY_CHECK_RETURN_ERROR(key_ptr, E_NULL_POINTER);
+    SANITY_CHECK_RETURN_ERROR(result, E_NULL_POINTER);
+
+	table_struct_ptr = &(((t_FmPcdCcNode *)(table_handle))->extHashInfo);
+	/* Check if Hash table was created */
+	SANITY_CHECK_RETURN_ERROR(table_struct_ptr->table_base_ptr, E_NULL_POINTER);
+
+    get_indexed_hash_bucket(table_struct_ptr->key_size, key_ptr,
+				table_struct_ptr->crc_shift,
+				table_struct_ptr->hash_mask,
+				&bucket_index);
+	bucket = &(table_struct_ptr->table_base_ptr[bucket_index]);
+
+    DBG(TRACE, ("ext_hash_add_key() bucket_index: 0x%x", bucket_index));
+
+	/* TODO - need to use locking when updating the data structures */
+	/* Go to the last bucket in the current table set */
+
+	static_bucket = bucket; /* Save first bucket */
+	/* When static bucket last is NULL then it is the only one in the set */
+	if(bucket->prev_last_bucket_ptr)
+	{
+		bucket = (t_FmExtHashBucket *)XX_PhysToVirt(GET_UINT32(bucket->prev_last_bucket_ptr));
+		//XX_Print("static_bucket: 0x%x\n", static_bucket);
+	}
+
+	if (bucket->valid_keys == table_struct_ptr->max_ways)
+	{
+		/* Need to open new bucket */
+		bucket_pool = &(table_struct_ptr->hash_bucket_pool);
+		if(bucket_pool->last_bucket < 0)
+		{
+			REPORT_ERROR(MAJOR, E_NO_MEMORY, ("ext_hash_add_key failed: no more free buckets"));
+			return -ENOMEM; //no more buckets
+		}
+
+		new_bucket = bucket_pool->bucket_stack[bucket_pool->last_bucket];
+		bucket_pool->last_bucket--;
+
+		MemCpy8(&(new_bucket->key_result[0]),
+			key_ptr,
+			table_struct_ptr->key_size);
+
+		/*valid_ptr = (uint8_t *)((uint32_t)(&(new_bucket->key_result[0]))
+		             + table_struct_ptr->key_size); compilation warning */
+		valid_ptr = (new_bucket->key_result + table_struct_ptr->key_size);
+
+		/* Write key invalid bit */
+		WRITE_UINT8(valid_ptr, 0x0);
+		/* writing result to the bucket */
+		WRITE_UINT64(
+			new_bucket->key_result[0xE0],
+			result->contex_addr);
+		WRITE_UINT64(
+			new_bucket->key_result[0xE8],
+			result->monitoring_addr);
+		WRITE_UINT8(new_bucket->not_last, 0);
+		new_bucket->valid_keys = 1;
+		WRITE_UINT32(new_bucket->next_bucket_addr, (uint32_t)XX_VirtToPhys((void *)new_bucket));
+		new_bucket->prev_last_bucket_ptr = bucket->next_bucket_addr;
+
+		bucket->next_bucket_addr = new_bucket->next_bucket_addr;
+		WRITE_UINT8(bucket->not_last, 1);
+
+		/* Update static bucket */
+		static_bucket->prev_last_bucket_ptr = new_bucket->next_bucket_addr;
+
+	}
+	else
+	{
+		/* There is still place in the bucket */
+		/* copy key to the bucket */
+		MemCpy8(&(bucket->key_result[(table_struct_ptr->aligned_key_size) * bucket->valid_keys]),
+			key_ptr,
+			table_struct_ptr->key_size);
+		/* valid_ptr = (uint8_t *)((uint32_t)(&(bucket->key_result[
+		            (table_struct_ptr->aligned_key_size) * bucket->valid_keys]))
+		             + table_struct_ptr->key_size); compilation warning */
+		valid_ptr = ((&(bucket->key_result[
+		            (table_struct_ptr->aligned_key_size) * bucket->valid_keys]))
+		             + table_struct_ptr->key_size);
+
+
+		/* Write key valid bit */
+		WRITE_UINT8(valid_ptr, 0x0);
+		/* writing result to the bucket */
+		WRITE_UINT64(bucket->key_result[0xE0 - (bucket->valid_keys << 4)],
+			result->contex_addr);
+		WRITE_UINT64(bucket->key_result[0xE8 - (bucket->valid_keys << 4)],
+			result->monitoring_addr);
+		bucket->valid_keys++;
+		//XX_Print("ext_hash_add_key() Current bucket addr: 0x%x\n", bucket);
+		//XX_Print("ext_hash_add_key() Current bucket PHYS addr: 0x%x\n", (uint32_t)XX_VirtToPhys(bucket));
+		//XX_Print("bucket->valid_keys: %d\n", bucket->valid_keys);
+	}
+	return E_OK;
+}
+
+/**
+ * Low level routine to remove a specified key from External Hash Table
+ *
+ * @param[in] table_handle Handle to hash table where to remove the key
+ * @param[in] key_ptr Pointer to key to be removed
+ *
+ * @return E_OK on success; Error code otherwise.
+ */
+static int ext_hash_remove_key(void *table_handle, uint8_t *key_ptr)
+{
+	t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)table_handle;
+	uint16_t set_index;
+	uint8_t *valid_ptr;
+	t_FmExtHashBucket *prev_bucket;
+	t_FmExtHashBucket *static_bucket;
+	t_FmExtHashBucketPool *bucket_pool;
+	t_FmPcdCcNodeExtHashInfo *table_struct_ptr;
+	uint8_t rem_key_index;
+	t_FmExtHashBucket *rem_key_bucket, *last_key_bucket;
+
+	SANITY_CHECK_RETURN_ERROR(table_handle, E_INVALID_HANDLE);
+	SANITY_CHECK_RETURN_ERROR(key_ptr, E_NULL_POINTER);
+
+    table_struct_ptr = &(((t_FmPcdCcNode *)(table_handle))->extHashInfo);
+	/* Check if Hash table was created */
+    SANITY_CHECK_RETURN_ERROR(table_struct_ptr->table_base_ptr, E_NULL_POINTER);
+
+	bucket_pool = &(table_struct_ptr->hash_bucket_pool);
+
+	/* Lookup key in the set */
+	rem_key_bucket = ext_hash_lookup(table_handle, key_ptr, &set_index, &rem_key_index);
+    if (rem_key_bucket == NULL)
+        RETURN_ERROR(MAJOR, E_NOT_FOUND, ("Key was not found in external Hash Table"));
+
+    static_bucket = &(table_struct_ptr->table_base_ptr[set_index]);
+
+    /* When static bucket last/prev ptr is NULL then it is the only one in the set */
+    if (static_bucket->prev_last_bucket_ptr)
+        last_key_bucket = (t_FmExtHashBucket *)XX_PhysToVirt(GET_UINT32(static_bucket->prev_last_bucket_ptr));
+    else
+        last_key_bucket = static_bucket;
+
+    /* Is the last valid key in the set ? */
+    if (rem_key_index == rem_key_bucket->valid_keys - 1 && rem_key_bucket->not_last == 0)
+    {
+		/* Is the only valid key in the last dynamic bucket ? */
+    	/* The last bucket is a dynamic bucket if not_last is zero and has a pointer to previous: prev_last_bucket_ptr */
+    	/* The last bucket is static bucket when it is the only one in the set and prev_last_bucket_ptr is NULL */
+		/* if (rem_key_bucket->valid_keys == 1 && rem_key_bucket->prev_last_bucket_ptr != (uint32_t)NULL) compilation warning */
+		if (rem_key_bucket->valid_keys == 1 && (rem_key_bucket->prev_last_bucket_ptr))
+		{
+			/* Remove the last dynamic bucket:
+			 * -------------------------------*/
+
+			/* Unlink the last bucket from the previous one */
+			prev_bucket = (t_FmExtHashBucket *)(XX_PhysToVirt(GET_UINT32(rem_key_bucket->prev_last_bucket_ptr)));
+			prev_bucket->next_bucket_addr = rem_key_bucket->prev_last_bucket_ptr;
+
+			/* Now previous bucket is the last */
+			WRITE_UINT8(prev_bucket->not_last, 0);
+
+			/* Update the prev_last_bucket_ptr in static bucket: */
+			/* Is the removed bucket the only dynamic bucket in the set ? */
+			if (prev_bucket == static_bucket)
+				static_bucket->prev_last_bucket_ptr = 0; 
+			else
+				static_bucket->prev_last_bucket_ptr = rem_key_bucket->prev_last_bucket_ptr;
+
+			/* Update bucket pool */
+			bucket_pool->bucket_stack[++bucket_pool->last_bucket] = last_key_bucket;
+		}
+		else
+		{
+			/* Decrement number of valid keys in the bucket */
+			rem_key_bucket->valid_keys--;
+		}
+
+		/* Sync external request */
+	    FmPcdHcSync(p_HashTbl->h_FmPcd);
+    }
+    else
+    {
+        /* Key to remove is not on the last position in its bucket OR bucket is not last */
+    	/* Set 'invalidKey' to 0x01 */
+		valid_ptr = (uint8_t*)(rem_key_bucket->key_result + table_struct_ptr->aligned_key_size*rem_key_index + table_struct_ptr->key_size);
+		WRITE_UINT8(valid_ptr, 0x01);
+
+    	/* Eliminate invalid entry:
+    	 * ------------------------*/
+
+		/* Copy table's last key to removed key entry */
+		MemCpy8(&(rem_key_bucket->key_result[(table_struct_ptr->aligned_key_size) * rem_key_index]),
+				&(last_key_bucket->key_result[(table_struct_ptr->aligned_key_size) * (last_key_bucket->valid_keys - 1)]),
+				table_struct_ptr->key_size);
+
+		/* Copy table's last lookup result to removed key result entry */
+		MemCpy8(&(rem_key_bucket->key_result[0xE0 - 0x10 * rem_key_index]),
+				&(last_key_bucket->key_result[0xE0 - 0x10 * (last_key_bucket->valid_keys - 1)]),
+				16);
+
+    	/* Reset 'invalidKey' */
+		valid_ptr = (uint8_t*)(rem_key_bucket->key_result + table_struct_ptr->aligned_key_size*rem_key_index + table_struct_ptr->key_size);
+		WRITE_UINT8(valid_ptr, 0x00);
+
+		/* Sync external request */
+		FmPcdHcSync(p_HashTbl->h_FmPcd);
+
+	    /* Relocated key is the only valid key in the last dynamic bucket? */
+		if (last_key_bucket->valid_keys == 1 && (last_key_bucket->prev_last_bucket_ptr) )
+		{
+			/* Remove the last dynamic bucket:
+			 * -------------------------------*/
+
+			/* Unlink the last bucket from the previous one */
+			prev_bucket = (t_FmExtHashBucket *)(XX_PhysToVirt(GET_UINT32(last_key_bucket->prev_last_bucket_ptr)));
+			/* If no next bucket exists, should point to itself: */
+			prev_bucket->next_bucket_addr = last_key_bucket->prev_last_bucket_ptr;
+
+			/* Now previous bucket is the last */
+			WRITE_UINT8(prev_bucket->not_last, 0);
+
+			/* Update the prev_last_bucket_ptr in static bucket: */
+			/* Is the removed bucket the only dynamic bucket in the set ? */
+			if (prev_bucket == static_bucket)
+				static_bucket->prev_last_bucket_ptr = 0;
+			else
+				static_bucket->prev_last_bucket_ptr = last_key_bucket->prev_last_bucket_ptr;
+
+			/* Update bucket pool */
+			bucket_pool->bucket_stack[++bucket_pool->last_bucket] = last_key_bucket;
+		}
+		else
+		{
+			/* Decrement number of valid keys in the last bucket */
+			last_key_bucket->valid_keys--;
+		}
+
+		/* Sync external request */
+	    FmPcdHcSync(p_HashTbl->h_FmPcd);
+    }
+	return E_OK;
+}
+
+static int ext_hash_get_key_result(void *table_handle,
+	uint8_t *key_ptr,
+	t_FmExtHashResult *result)
+{
+	uint16_t set_index;
+	uint8_t key_index;
+	t_FmExtHashBucket *key_bucket;
+
+    SANITY_CHECK_RETURN_VALUE(table_handle, E_INVALID_HANDLE, E_INVALID_HANDLE);
+    SANITY_CHECK_RETURN_VALUE(key_ptr, E_NULL_POINTER, E_NULL_POINTER);
+    SANITY_CHECK_RETURN_VALUE(result, E_NULL_POINTER, E_NULL_POINTER);
+
+	/* Lookup key in the set */
+	key_bucket = ext_hash_lookup(table_handle, key_ptr, &set_index, &key_index);
+    if (key_bucket == NULL)
+        RETURN_ERROR(MAJOR, E_NOT_FOUND, ("Key was not found in external Hash Table"));
+
+	/* read result from the bucket */
+    result->contex_addr = GET_UINT64(key_bucket->key_result[0xE0 - (key_index << 4)]);
+    result->monitoring_addr = GET_UINT64(key_bucket->key_result[0xE8 - (key_index << 4)]);
+
+    return E_OK;
+}
+
+static int ext_hash_set_key_result(void *table_handle,
+	uint8_t *key_ptr,
+	t_FmExtHashResult *result)
+{
+	uint16_t set_index;
+	uint8_t key_index;
+	t_FmExtHashBucket *key_bucket;
+
+    SANITY_CHECK_RETURN_VALUE(table_handle, E_INVALID_HANDLE, E_INVALID_HANDLE);
+    SANITY_CHECK_RETURN_VALUE(key_ptr, E_NULL_POINTER, E_NULL_POINTER);
+    SANITY_CHECK_RETURN_VALUE(result, E_NULL_POINTER, E_NULL_POINTER);
+
+	/* Lookup key in the set */
+	key_bucket = ext_hash_lookup(table_handle, key_ptr, &set_index, &key_index);
+    if (key_bucket == NULL)
+        RETURN_ERROR(MAJOR, E_NOT_FOUND, ("Key was not found in external Hash Table"));
+
+	/* write result in the bucket */
+    WRITE_UINT64(key_bucket->key_result[0xE0 - (key_index << 4)], result->contex_addr);
+    WRITE_UINT64(key_bucket->key_result[0xE8 - (key_index << 4)], result->monitoring_addr);
+
+    return E_OK;
+}
+
+static void ReleaseFEsContextList(t_FmPcdCcNode *p_CcNodeHashTbl)
+{
+    t_FmPcdCcNodeFEContextObj *p_Obj;
+    uint32_t intFlags;
+
+    intFlags = XX_LockIntrSpinlock(p_CcNodeHashTbl->h_Spinlock);
+    while (!LIST_IsEmpty(&p_CcNodeHashTbl->extHashInfo.usedContextLst))
+    {
+        p_Obj = FM_PCD_FE_CONTEXT_OBJ(p_CcNodeHashTbl->extHashInfo.usedContextLst.p_Next);
+        LIST_DelAndInit(&p_Obj->node);
+        XX_FreeSmart(p_Obj->p_Context);
+        XX_Free(p_Obj);
+    }
+    while (!LIST_IsEmpty(&p_CcNodeHashTbl->extHashInfo.availableContextLst))
+    {
+        p_Obj = FM_PCD_FE_CONTEXT_OBJ(p_CcNodeHashTbl->extHashInfo.availableContextLst.p_Next);
+        LIST_DelAndInit(&p_Obj->node);
+        XX_FreeSmart(p_Obj->p_Context);
+        XX_Free(p_Obj);
+    }
+    XX_UnlockIntrSpinlock(p_CcNodeHashTbl->h_Spinlock, intFlags);
+}
+
+#endif // USE_ENHANCED_EHASH
+static __inline__ t_FmPcdCcNodeFEContextObj* DequeueFEContextObj(t_FmPcdCcNode *p_CcNodeHashTbl, t_List *p_List)
+{
+    t_FmPcdCcNodeFEContextObj *p_Obj = NULL;
+    uint32_t    intFlags;
+
+    intFlags = XX_LockIntrSpinlock(p_CcNodeHashTbl->h_Spinlock);
+    if (!LIST_IsEmpty(p_List))
+    {
+        p_Obj = FM_PCD_FE_CONTEXT_OBJ(p_List->p_Next);
+        LIST_DelAndInit(&p_Obj->node);
+    }
+    XX_UnlockIntrSpinlock(p_CcNodeHashTbl->h_Spinlock, intFlags);
+
+    return p_Obj;
+}
+
+static __inline__ void EnqueueFEContextObj(t_FmPcdCcNode *p_CcNodeHashTbl, t_List *p_List, t_FmPcdCcNodeFEContextObj *p_Obj)
+{
+    uint32_t   intFlags;
+
+    intFlags = XX_LockIntrSpinlock(p_CcNodeHashTbl->h_Spinlock);
+    LIST_AddToTail(&p_Obj->node, p_List);
+    XX_UnlockIntrSpinlock(p_CcNodeHashTbl->h_Spinlock, intFlags);
+}
+
+#ifndef USE_ENHANCED_EHASH
+static t_Error AllocFEContextObjs(t_FmPcdCcNode *p_CcNodeHashTbl)
+{
+    t_FmPcdCcNodeFEContextObj *p_FeContextObj;
+    uint32_t i;
+
+    ASSERT_COND(p_CcNodeHashTbl);
+
+    INIT_LIST(&p_CcNodeHashTbl->extHashInfo.usedContextLst);
+    INIT_LIST(&p_CcNodeHashTbl->extHashInfo.availableContextLst);
+
+    for (i=0; i<p_CcNodeHashTbl->maxNumOfKeys; i++) {
+        p_FeContextObj = (t_FmPcdCcNodeFEContextObj *)XX_Malloc(sizeof(t_FmPcdCcNodeFEContextObj));
+        if (!p_FeContextObj)
+            RETURN_ERROR(MAJOR, E_NO_MEMORY, ("FM-PCD FE-Context obj!"));
+        memset(p_FeContextObj, 0, sizeof(t_FmPcdCcNodeFEContextObj));
+ 
+        p_FeContextObj->p_Context = XX_MallocSmart(256, p_CcNodeHashTbl->extHashInfo.dataMemId, 256);
+        if (!p_FeContextObj->p_Context)
+            RETURN_ERROR(MAJOR, E_NO_MEMORY, ("allocation for context"));
+        memset(p_FeContextObj->p_Context, 0, 256);
+ 
+        EnqueueFEContextObj(p_CcNodeHashTbl, &p_CcNodeHashTbl->extHashInfo.availableContextLst, p_FeContextObj);
+    }
+
+    return E_OK;
+}
+
+static uint8_t* GetFEContext(t_FmPcdCcNode *p_CcNodeHashTbl)
+{
+    t_FmPcdCcNodeFEContextObj *p_Obj;
+
+    ASSERT_COND(p_CcNodeHashTbl);
+    p_Obj = DequeueFEContextObj(p_CcNodeHashTbl, &p_CcNodeHashTbl->extHashInfo.availableContextLst);
+    EnqueueFEContextObj(p_CcNodeHashTbl, &p_CcNodeHashTbl->extHashInfo.usedContextLst, p_Obj);
+    return p_Obj->p_Context;
+}
+
+static void PutFEContext(t_FmPcdCcNode *p_CcNodeHashTbl, uint8_t *p_Context)
+{
+    t_List *p_Pos;
+    uint32_t   intFlags;
+    t_FmPcdCcNodeFEContextObj *p_Obj;
+
+    ASSERT_COND(p_CcNodeHashTbl);
+    ASSERT_COND(p_Context);
+
+    intFlags = XX_LockIntrSpinlock(p_CcNodeHashTbl->h_Spinlock);
+    LIST_FOR_EACH(p_Pos, &p_CcNodeHashTbl->extHashInfo.usedContextLst)
+    {
+        p_Obj = FM_PCD_FE_CONTEXT_OBJ(p_Pos);
+        if (p_Obj->p_Context == p_Context) {
+            LIST_DelAndInit(&p_Obj->node);
+            LIST_AddToTail(&p_Obj->node, &p_CcNodeHashTbl->extHashInfo.availableContextLst);
+            memset(p_Context, 0, sizeof(256));
+            break;
+        }
+    }
+    XX_UnlockIntrSpinlock(p_CcNodeHashTbl->h_Spinlock, intFlags);
+}
+
+static t_Handle BuildFEChainAndContextFromNextEngine(t_Handle h_FmPcd,
+                                                     uint8_t *p_Context,
+                                                     t_FmPcdCcNextEngineParams *p_Param)
+{
+    t_FmPcd *p_FmPcd = (t_FmPcd *)h_FmPcd;
+    t_Handle h_FE = NULL, h_InternalAd = NULL, h_NonHmAd = NULL, h_ManipIter = NULL;
+    t_FmPcdFEContextParams feContextParams;
+    t_FmPcdFEParams feParams;
+    t_FmPcdManipHmCcParams hmCcParams;
+    t_Error err;
+    int i;
+
+    ASSERT_COND(h_FmPcd);
+    ASSERT_COND(p_Param);
+
+    if (p_Param->nextEngine == e_FM_PCD_FR)
+    {
+        /* transition ->  FRs AD */
+        memset(&feContextParams, 0, sizeof(t_FmPcdFEContextParams));
+        feContextParams.type = e_FM_PCD_FE_T_TRANSITION;
+        feContextParams.u.transition.h_NextAD = FrmReplicGroupGetSourceTableDescriptor(p_Param->params.frParams.h_FrmReplic);
+        err = FmPcdCcBuildContextByFE(h_FmPcd, p_Context, FE_TRANSITION_CONTEXT_OFFSET, &feContextParams);
+        ASSERT_COND(!err);
+        h_FE = p_FmPcd->feInfo.h_Transition;
+    } else if ((p_Param->nextEngine == e_FM_PCD_CC) ||
+            (p_Param->nextEngine == e_FM_PCD_HASH))
+    {
+        /* Two options :
+         * 1. If "internal HM" then transition -> HMTD
+         * 2. else, HM -> transition -> TD
+         */
+        REPORT_ERROR(MAJOR, E_NOT_SUPPORTED, ("CC/HASH"));
+        return NULL;
+    } else {
+        /* Several options :
+         * 1. No Manip: Enq -> Exit
+         * 2. "Internal HM": Enq -> transition -> HMTD
+         * 3. HM, No special manip: Enq -> HM -> Exit
+         * 4. No HM, special manip: Enq -> transition ->  manips AD
+         * 5. HM, special manip: Enq -> HM -> transition ->  manips AD
+         */
+        if (!p_Param->h_Manip)
+        {
+            h_FE = p_FmPcd->feInfo.h_Exit;
+        } else {
+            FmPcdManipGetInternaltHmTdAndNonHmAd(p_Param->h_Manip, &h_InternalAd, &h_NonHmAd);
+            if (h_InternalAd)
+            {
+                memset(&feContextParams, 0, sizeof(t_FmPcdFEContextParams));
+                feContextParams.type = e_FM_PCD_FE_T_TRANSITION;
+                feContextParams.u.transition.h_NextAD = h_InternalAd;
+                err = FmPcdCcBuildContextByFE(h_FmPcd, p_Context, FE_TRANSITION_CONTEXT_OFFSET, &feContextParams);
+                ASSERT_COND(!err);
+                h_FE = p_FmPcd->feInfo.h_Transition;
+            } else {
+                if (h_NonHmAd) {
+                    memset(&feContextParams, 0, sizeof(t_FmPcdFEContextParams));
+                    feContextParams.type = e_FM_PCD_FE_T_TRANSITION;
+                    feContextParams.u.transition.h_NextAD = h_NonHmAd;
+                    err = FmPcdCcBuildContextByFE(h_FmPcd, p_Context, FE_TRANSITION_CONTEXT_OFFSET, &feContextParams);
+                    ASSERT_COND(!err);
+                    h_FE = p_FmPcd->feInfo.h_Transition;
+                }
+                i = 0;
+                do {
+                    memset(&hmCcParams, 0, sizeof(t_FmPcdManipHmCcParams));
+                    FmPcdManipLocalHMGetParams(p_Param->h_Manip, &hmCcParams, &h_ManipIter);
+                    if (hmCcParams.tableSize) {
+                        ASSERT_COND(i<FM_MAX_HM_CONTEXTS);
+                        /* Now build "Local" HM */
+                        memset(&feContextParams, 0, sizeof(t_FmPcdFEContextParams));
+                        feContextParams.type = e_FM_PCD_FE_T_HM;
+                        feContextParams.u.hm.p_Hmct = hmCcParams.p_Hmct;
+                        feContextParams.u.hm.tableSize = hmCcParams.tableSize;
+                        err = FmPcdCcBuildContextByFE(h_FmPcd, p_Context, FE_HM_CONTEXT_OFFSET(i), &feContextParams);
+                        if (err) {
+                            REPORT_ERROR(MAJOR, err, ("FE's context"));
+                            return NULL;
+                        }
+
+                        if (hmCcParams.parseAfterHm)
+                            h_FE = p_FmPcd->feInfo.hm[i].h_HmWParse;
+                        else
+                            h_FE = p_FmPcd->feInfo.hm[i].h_HmWOParse;
+                        i = 1 + (hmCcParams.tableSize / FM_HM_CONTEXT_SIZE);
+                    }
+                } while (h_ManipIter != NULL);
+            }
+        }
+
+        /* Build Enqueue params */
+        memset(&feContextParams, 0, sizeof(t_FmPcdFEContextParams));
+        feContextParams.type = e_FM_PCD_FE_T_ENQ;
+
+        memset(&feParams, 0, sizeof(t_FmPcdFEParams));
+        feParams.type = e_FM_PCD_FE_T_ENQ;
+        feParams.wsOffset = FE_ENQUEUE_CONTEXT_OFFSET;
+        feParams.h_NextFE = h_FE;
+
+        if (p_Param->nextEngine == e_FM_PCD_DONE) {
+                if (p_Param->params.enqueueParams.action == e_FM_PCD_DROP_FRAME)
+                    feParams.u.enq.nia = GET_NIA_BMI_AC_DISCARD_FRAME(p_FmPcd);
+                else {
+                    if (p_Param->params.enqueueParams.overrideFqid) {
+                        feContextParams.u.enq.fqid = p_Param->params.enqueueParams.newFqid;
+                        feContextParams.u.enq.rspid = p_Param->params.enqueueParams.newRelativeStorageProfileId
+                                & FM_PCD_AD_RESULT_VSP_MASK;
+                        feParams.u.enq.fqidEn = TRUE;
+                        feParams.u.enq.spEn = TRUE;
+                    }
+                    feParams.u.enq.nia = GET_NIA_BMI_AC_ENQ_FRAME(p_FmPcd);
+                }
+        } else if (p_Param->nextEngine == e_FM_PCD_KG) {
+            if (p_Param->params.kgParams.overrideFqid) {
+                feContextParams.u.enq.fqid = p_Param->params.kgParams.newFqid;
+                feContextParams.u.enq.rspid = p_Param->params.kgParams.newRelativeStorageProfileId
+                        & FM_PCD_AD_RESULT_VSP_MASK;
+                feParams.u.enq.fqidEn = TRUE;
+                feParams.u.enq.spEn = TRUE;
+            }
+            feParams.u.enq.nia = NIA_ENG_KG | NIA_KG_DIRECT | NIA_KG_CC_EN |
+                FmPcdKgGetSchemeId(p_Param->params.kgParams.h_DirectScheme);
+        } else {
+            ASSERT_COND(p_Param->nextEngine == e_FM_PCD_PLCR);
+
+            if (p_Param->params.plcrParams.overrideParams) {
+                uint16_t profileId;
+
+                profileId = p_Param->params.plcrParams.newRelativeProfileId;
+                if (p_Param->params.plcrParams.sharedProfile)
+                {
+                    feParams.u.enq.nia |= NIA_PLCR_ABSOLUTE;
+                    FmPcdPlcrGetAbsoluteIdByProfileParams(
+                            (t_Handle)p_FmPcd,
+                            e_FM_PCD_PLCR_SHARED,
+                            NULL,
+                            profileId,
+                            &profileId);
+                }
+                feContextParams.u.enq.fqid = p_Param->params.plcrParams.newFqid;
+                feContextParams.u.enq.rspid = p_Param->params.plcrParams.newRelativeStorageProfileId
+                        & FM_PCD_AD_RESULT_VSP_MASK;
+                feContextParams.u.enq.ppid = profileId;
+                feParams.u.enq.fqidEn = TRUE;
+                feParams.u.enq.spEn = TRUE;
+                feParams.u.enq.ppEn = TRUE;
+            }
+            feParams.u.enq.mergePolicerWithNia = TRUE;
+            feParams.u.enq.nia |= NIA_ENG_PLCR; /* the policer-Id will come from the merge */
+        }
+
+        err = FmPcdCcBuildContextByFE(h_FmPcd, p_Context, FE_ENQUEUE_CONTEXT_OFFSET, &feContextParams);
+        ASSERT_COND(!err);
+
+        h_FE = FmPcdGetFE(h_FmPcd, &feParams);
+        if (!h_FE) {
+            REPORT_ERROR(MAJOR, E_NO_MEMORY, ("FE's memory"));
+            return NULL;
+        }
+    }
+    return h_FE;
+}
+#endif // USE_ENHANCED_EHASH
+
+#ifndef USE_ENHANCED_EHASH
+static t_Error DestroyFEChain(t_Handle h_FmPcd,
+                              t_Handle h_FE)
+{
+	/**
+	 * This method must destroy objects created by: BuildFEChainAndContextFromNextEngine
+	 * But there is nothing to destroy because
+	 * all p_FeObj and h_FE are destroyed by: static void ReleaseFEsList(t_FmPcd *p_FmPcd)
+	 *                                and by: t_Error FM_PCD_Free(t_Handle h_FmPcd)
+	 *
+	 */
+	return E_OK;
+}
+
+static t_Error ValidateNextEngineParamsAndManip(t_Handle h_FmPcd,
+                                                t_FmPcdCcNextEngineParams *p_Param,
+                                                e_FmPcdCcStatsMode statisticsMode)
+{
+    uint32_t tmp;
+    t_Error err;
+
+    err = ValidateNextEngineParams(h_FmPcd, p_Param, statisticsMode);
+    if (err)
+        RETURN_ERROR(MAJOR, err, ("For this node MissNextEngineParams are not valid"));
+
+    if (p_Param->h_Manip)
+    {
+        err = FmPcdManipCheckParamsForCcNextEngine(p_Param, &tmp);
+        if (err)
+            RETURN_ERROR(MAJOR, err, ("For this node MissNextEngineParams's manip are not valid"));
+    }
+
+    return E_OK;
+}
+
+static void ExternalHashTableDeleteContextAndFE(t_FmPcd *p_FmPcd, t_ExtHashResult *p_Result)
+{
+	/*
+    t_Handle h_Muram;
+    uintptr_t contextAddr;
+    //t_Handle h_FE;
+    //uint32_t *tmp;
+
+    ASSERT_COND(p_FmPcd);
+    ASSERT_COND(p_Result);
+
+    h_Muram = FmPcdGetMuramHandle(p_FmPcd);
+    contextAddr = (uintptr_t)GET_UINT32(p_Result->liodnContextAndContextPtrHi) << 32;
+    contextAddr |= GET_UINT32(p_Result->contextPtrLow);
+    contextAddr &= 0x0000000FFFFFFFFF;
+    */
+    //if (contextAddr) {
+    	/*
+    	 * It is not needed because there is nothing to be destroyed on FE Chain
+    	 *
+        tmp = (uint32_t *)PTR_MOVE(UINT_TO_PTR(contextAddr), FE_MUX_CONTEXT_OFFSET);
+        h_FE = (t_Handle)XX_PhysToVirt(GET_UINT32(*tmp) + p_FmPcd->physicalMuramBase);
+        DestroyFEChain(p_FmPcd, h_FE);
+    	 */
+
+        /**
+         * It is not needed because
+         * all p_FeObj and h_FE are destroyed by: static void ReleaseFEsList(t_FmPcd *p_FmPcd)
+         *
+        FM_MURAM_FreeMem(h_Muram, h_FE);
+        */
+
+    	/**
+    	 * It is not needed because
+    	 * all context pointers are destroyed by: static void ReleaseFEsContextList(t_FmPcdCcNode *p_CcNodeHashTbl)
+    	 *
+        XX_FreeSmart(XX_PhysToVirt((physAddress_t)contextAddr));
+        */
+    //}
+}
+#endif  //USE_ENHANCED_EHASH
+
+#ifndef USE_ENHANCED_EHASH
+static t_Error ExternalHashTableDelete(t_FmPcdCcNode *p_CcNodeHashTbl)
+{
+    t_Handle h_Muram = FmPcdGetMuramHandle(p_CcNodeHashTbl->h_FmPcd);
+
+    /* Free all FE Context lists */
+    ReleaseFEsContextList(p_CcNodeHashTbl);
+
+    /* Free Ext Hash FE pointer */
+    if (p_CcNodeHashTbl->extHashInfo.p_FE)
+        FM_MURAM_FreeMem(h_Muram, p_CcNodeHashTbl->extHashInfo.p_FE);
+
+    /* Call Hezi's delete function */
+    ext_hash_table_delete(p_CcNodeHashTbl);
+
+    /* Free miss Context and FE */
+    if (p_CcNodeHashTbl->extHashInfo.p_MissResult) {
+        ExternalHashTableDeleteContextAndFE(p_CcNodeHashTbl->h_FmPcd, p_CcNodeHashTbl->extHashInfo.p_MissResult);
+        FM_MURAM_FreeMem(h_Muram, p_CcNodeHashTbl->extHashInfo.p_MissResult);
+    }
+
+    /* Free statistics counters for 'miss', if these were allocated */
+    if (p_CcNodeHashTbl->h_MissStatsCounters) {
+        FM_MURAM_FreeMem(h_Muram, p_CcNodeHashTbl->h_MissStatsCounters);
+        p_CcNodeHashTbl->h_MissStatsCounters = NULL;
+    }
+
+    /* Free old miss monitor addr if it was automatically allocated by the driver */
+    if (p_CcNodeHashTbl->extHashInfo.missMonitorAddr && p_CcNodeHashTbl->extHashInfo.drvAllocMissMonitorAddr)
+        XX_FreeSmart((void*)p_CcNodeHashTbl->extHashInfo.missMonitorAddr);
+
+    DeleteNode(p_CcNodeHashTbl);
+
+    return E_OK;
+}
+
+
+static void ExternalHashBuildResult(t_ExtHashResult *p_Result,
+                                    uint16_t dataLiodnOffset,
+                                    uintptr_t contextAddr,
+                                    uintptr_t monitorAddr)
+{
+    uint64_t tmpReg64;
+
+    tmpReg64 = (uint64_t)(XX_VirtToPhys(UINT_TO_PTR(contextAddr)));
+    tmpReg64 |= ((uint64_t)(dataLiodnOffset & FM_PCD_FE_T_HASH_LIODN_MASK)
+            << (uint64_t)FM_PCD_FE_T_HASH_LIODN_SHIFT);
+    tmpReg64 |= ((uint64_t)(dataLiodnOffset & FM_PCD_FE_T_HASH_ELIODN_MASK)
+            << (uint64_t)FM_PCD_FE_T_HASH_ELIODN_SHIFT);
+    WRITE_UINT32(p_Result->liodnContextAndContextPtrHi, (uint32_t)(tmpReg64 >> 32));
+    WRITE_UINT32(p_Result->contextPtrLow, (uint32_t)tmpReg64);
+
+    tmpReg64 = (uint64_t)(XX_VirtToPhys(UINT_TO_PTR(monitorAddr)));
+    tmpReg64 |= ((uint64_t)(dataLiodnOffset & FM_PCD_FE_T_HASH_LIODN_MASK)
+            << (uint64_t)FM_PCD_FE_T_HASH_LIODN_SHIFT);
+    tmpReg64 |= ((uint64_t)(dataLiodnOffset & FM_PCD_FE_T_HASH_ELIODN_MASK)
+            << (uint64_t)FM_PCD_FE_T_HASH_ELIODN_SHIFT);
+    WRITE_UINT32(p_Result->liodnMonitorAndMonitorPtrHi, (uint32_t)(tmpReg64 >> 32));
+    WRITE_UINT32(p_Result->monitorPtrLow, (uint32_t)tmpReg64);
+}
+
+#endif // USE_ENHANCED_EHASH
+static void ExternalHashResultSetMonitorAddr(t_ExtHashResult *p_Result, uint16_t dataLiodnOffset, uintptr_t monitorAddr)
+{
+	uint64_t tmpReg64;
+
+    tmpReg64 = (uint64_t)(XX_VirtToPhys(UINT_TO_PTR(monitorAddr)));
+    tmpReg64 |= ((uint64_t)(dataLiodnOffset & FM_PCD_FE_T_HASH_LIODN_MASK)
+            << (uint64_t)FM_PCD_FE_T_HASH_LIODN_SHIFT);
+    tmpReg64 |= ((uint64_t)(dataLiodnOffset & FM_PCD_FE_T_HASH_ELIODN_MASK)
+            << (uint64_t)FM_PCD_FE_T_HASH_ELIODN_SHIFT);
+    WRITE_UINT32(p_Result->liodnMonitorAndMonitorPtrHi, (uint32_t)(tmpReg64 >> 32));
+    WRITE_UINT32(p_Result->monitorPtrLow, (uint32_t)tmpReg64);
+}
+
+#ifndef USE_ENHANCED_EHASH
+static uintptr_t ExternalHashResultGetContextAddr(t_ExtHashResult *p_Result)
+{
+	uint64_t tmpReg64;
+
+	tmpReg64 = ((uint64_t)(GET_UINT32(p_Result->liodnContextAndContextPtrHi) & FM_PCD_FE_T_HASH_LIODN_MASK)) << 32;
+	tmpReg64 |= (uint64_t)GET_UINT32(p_Result->contextPtrLow);
+
+	return (uintptr_t)XX_PhysToVirt(tmpReg64);
+}
+
+static uintptr_t ExternalHashResultGetMonitorAddr(t_ExtHashResult *p_Result)
+{
+	uint64_t tmpReg64;
+
+	tmpReg64 = ((uint64_t)(GET_UINT32(p_Result->liodnMonitorAndMonitorPtrHi) & FM_PCD_FE_T_HASH_LIODN_MASK)) << 32;
+	tmpReg64 |= (uint64_t)GET_UINT32(p_Result->monitorPtrLow);
+
+	return (uintptr_t)XX_PhysToVirt(tmpReg64);
+}
+
+static t_Handle ExternalHashTableSet(t_Handle h_FmPcd, t_FmPcdHashTableParams *p_Param)
+{
+    t_FmPcd *p_FmPcd = (t_FmPcd *)h_FmPcd;
+    t_FmPcdCcNode *p_CcNodeHashTbl;
+    t_FmPcdCcNodeExtHashInfo extHashInfo;
+    t_Handle h_FmMuram = NULL;
+    uint8_t *p_MissContext;
+
+    ASSERT_COND(h_FmPcd);
+    ASSERT_COND(p_Param);
+
+    if (p_Param->statisticsMode != e_FM_PCD_CC_STATS_MODE_NONE) {
+        if (p_Param->statisticsMode != e_FM_PCD_CC_STATS_MODE_BYTE_AND_FRAME)
+        {
+            REPORT_ERROR(MAJOR, E_INVALID_VALUE,
+                    ("Only byte+frame counters are supported for hash table"));
+            return NULL;
+        }
+        if (!p_Param->externalHashParams.missMonitorAddr)
+        {
+        	/*
+        	 * If Miss Monitor Addr is NULL it means user doesn't care about it,
+        	 * so the driver will automatically allocate it in order to have mechanism working instead of exiting with an error.
+        	 * In case user needs it, then he can use API method to allocate it: FM_PCD_HashTableModifyMissMonitorAddr
+        	 * This is useful in case of FMC initialization which cannot perform memory allocations.
+        	 */
+        	/*
+        	 * Miss Monitor Addr is automatically allocated instead of exiting with an error
+            REPORT_ERROR(MAJOR, E_NULL_POINTER,
+                    ("missMonitorAddr must be given to support statistics"));
+            return NULL;
+            */
+        }
+    }
+
+    if (p_Param->agingSupport && !p_Param->externalHashParams.missMonitorAddr) {
+    	/*
+    	 * If Miss Monitor Addr is NULL it means user doesn't care about it,
+    	 * so the driver will automatically allocate it in order to have mechanism working instead of exiting with an error.
+    	 * In case user needs it, then he can use API method to allocate it: FM_PCD_HashTableModifyMissMonitorAddr
+    	 * This is useful in case of FMC initialization which cannot perform memory allocations.
+    	 */
+    	/*
+         * Miss Monitor Addr is automatically allocated instead of exiting with an error
+        REPORT_ERROR(MAJOR, E_NULL_POINTER,
+                ("missMonitorAddr must be given to support aging"));
+        return NULL;
+        */
+    }
+
+    /* Validate next engine parameters on Miss */
+    if (ValidateNextEngineParamsAndManip(h_FmPcd, &p_Param->ccNextEngineParamsForMiss, p_Param->statisticsMode) != 0)
+    {
+        REPORT_ERROR(MAJOR, E_INVALID_VALUE, ("For this node MissNextEngineParams are not valid"));
+        return NULL;
+    }
+
+    h_FmMuram = FmPcdGetMuramHandle(h_FmPcd);
+    if (!h_FmMuram) {
+        REPORT_ERROR(MAJOR, E_INVALID_HANDLE, ("FM MURAM"));
+        return NULL;
+    }
+
+    memset(&extHashInfo, 0, sizeof(t_FmPcdCcNodeExtHashInfo));
+
+    /* Miss allocation */
+    p_MissContext = XX_MallocSmart(256, p_Param->externalHashParams.dataMemId, 256);
+    if (!p_MissContext)
+    {
+        REPORT_ERROR(MAJOR, E_NO_MEMORY,
+                     ("allocation for miss context"));
+        return NULL;
+    }
+    memset(p_MissContext, 0, 256);
+
+    extHashInfo.p_MissResult = (t_ExtHashResult *)FM_MURAM_AllocMem(h_FmMuram, sizeof(t_ExtHashResult), 16);
+    if (!extHashInfo.p_MissResult)
+    {
+        XX_FreeSmart(p_MissContext);
+        REPORT_ERROR(MAJOR, E_NO_MEMORY,
+                     ("MURAM allocation for miss result"));
+        return NULL;
+    }
+    memset(extHashInfo.p_MissResult, 0, sizeof(t_ExtHashResult));
+    extHashInfo.h_MissFE = BuildFEChainAndContextFromNextEngine(h_FmPcd,
+                                                                p_MissContext,
+                                                                &p_Param->ccNextEngineParamsForMiss);
+    if (!extHashInfo.h_MissFE)
+    {
+        XX_FreeSmart(p_MissContext);
+        FM_MURAM_FreeMem(h_FmMuram, extHashInfo.p_MissResult);
+        REPORT_ERROR(MAJOR, E_NO_MEMORY, ("MURAM allocation for miss FE & context"));
+        return NULL;
+    }
+
+    /* Build Miss result */
+    ExternalHashBuildResult(extHashInfo.p_MissResult,
+                            p_Param->externalHashParams.dataLiodnOffset,
+                            PTR_TO_UINT(p_MissContext),
+                            p_Param->externalHashParams.missMonitorAddr);
+
+    p_CcNodeHashTbl = FmPcdExternalHashTableSet(h_FmPcd,
+                                                p_Param,
+                                                TRUE,
+                                                256,
+                                                0,
+                                                p_FmPcd->feInfo.h_Mux,
+                                                extHashInfo.h_MissFE,
+                                                extHashInfo.p_MissResult);
+    if (!p_CcNodeHashTbl)
+    {
+        XX_FreeSmart(p_MissContext);
+        FM_MURAM_FreeMem(h_FmMuram, extHashInfo.p_MissResult);
+        return NULL;
+    }
+
+    return p_CcNodeHashTbl;
+}
+
+static t_Error ExternalHashTableAddKey(t_Handle h_HashTbl,
+                                       uint8_t keySize,
+                                       t_FmPcdCcKeyParams *p_KeyParams)
+{
+    t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
+    t_ExtHashResult result;
+    t_FmPcdFEContextParams feContextParams;
+    t_Handle h_FE;
+    uint8_t *p_Context;
+    t_Error err;
+
+    SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
+    SANITY_CHECK_RETURN_ERROR(p_KeyParams, E_NULL_POINTER);
+    SANITY_CHECK_RETURN_ERROR(p_KeyParams->p_Key, E_NULL_POINTER);
+
+    if (!FmPcdLockTryLockAll(p_HashTbl->h_FmPcd))
+    {
+        DBG(TRACE, ("FmPcdLockTryLockAll failed"));
+        return ERROR_CODE(E_BUSY);
+    }
+
+    if (p_HashTbl->numOfKeys == p_HashTbl->maxNumOfKeys)
+        RETURN_ERROR(MAJOR, E_FULL, ("Table is full"));
+
+    if ((p_HashTbl->statisticsMode != e_FM_PCD_CC_STATS_MODE_NONE) &&
+        !p_KeyParams->monitorAddr)
+        RETURN_ERROR(MAJOR, E_NULL_POINTER,
+                    ("monitorAddr must be given to support statistics"));
+
+    if (p_HashTbl->agingSupport && !p_KeyParams->monitorAddr)
+        RETURN_ERROR(MAJOR, E_NULL_POINTER,
+                ("monitorAddr must be given to support aging"));
+
+    /* Validate next engine parameters */
+    if (ValidateNextEngineParamsAndManip(p_HashTbl->h_FmPcd, &p_KeyParams->ccNextEngineParams, p_HashTbl->statisticsMode) != 0)
+        RETURN_ERROR(MAJOR, E_INVALID_VALUE, ("For this Key NextEngineParams are not valid"));
+
+    p_Context = GetFEContext(p_HashTbl);
+    h_FE = BuildFEChainAndContextFromNextEngine(p_HashTbl->h_FmPcd,
+                                                p_Context,
+                                                &p_KeyParams->ccNextEngineParams);
+    if (!h_FE)
+    {
+        PutFEContext(p_HashTbl, p_Context);
+        RETURN_ERROR(MAJOR, E_NO_MEMORY, ("MURAM allocation for FE & context"));
+    }
+
+    memset(&feContextParams, 0, sizeof(t_FmPcdFEContextParams));
+    feContextParams.type = e_FM_PCD_FE_T_MUX;
+    feContextParams.u.mux.h_NextFE = h_FE;
+    err = FmPcdCcBuildContextByFE(p_HashTbl->h_FmPcd,
+                                  p_Context,
+                                  FE_MUX_CONTEXT_OFFSET,
+                                  &feContextParams);
+    ASSERT_COND(!err);
+
+    ExternalHashBuildResult(&result,
+                            p_HashTbl->extHashInfo.dataLiodnOffset,
+                            PTR_TO_UINT(p_Context),
+                            p_KeyParams->monitorAddr);
+
+    err = ext_hash_add_key(p_HashTbl, p_KeyParams->p_Key, (t_FmExtHashResult*)&result);
+    if (err) {
+        ExternalHashTableDeleteContextAndFE(p_HashTbl->h_FmPcd, &result);
+        RETURN_ERROR(MAJOR, err, ("ext_hash_add_key failed"));
+    }
+
+    p_HashTbl->numOfKeys++;
+
+    FmPcdLockUnlockAll(p_HashTbl->h_FmPcd);
+
+    return E_OK;
+}
+#endif
+
+#ifndef USE_ENHANCED_EHASH
+/**
+ * Removes a specified key from External Hash Table
+ *
+ * @param[in] h_HashTbl Handle to hash table where to remove the key
+ * @param[in] keySize The size of Key to be removed
+ * @param[in] p_Key Pointer to key to be removed
+ *
+ * @return E_OK on success; Error code otherwise.
+ */
+static t_Error ExternalHashTableRemoveKey(t_Handle h_HashTbl, uint8_t keySize, uint8_t *p_Key)
+{
+    t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
+    t_FmExtHashResult result;
+    uint8_t *p_Context;
+    t_Error err;
+
+    SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
+    SANITY_CHECK_RETURN_ERROR(p_Key, E_NULL_POINTER);
+
+    if (!FmPcdLockTryLockAll(p_HashTbl->h_FmPcd))
+    {
+        DBG(TRACE, ("FmPcdLockTryLockAll failed"));
+        return ERROR_CODE(E_BUSY);
+    }
+
+    if (p_HashTbl->numOfKeys == 0)
+        RETURN_ERROR(MAJOR, E_EMPTY, ("There is no key to remove: Table is empty"));
+
+    if (keySize != p_HashTbl->extHashInfo.key_size)
+    	RETURN_ERROR(MAJOR, E_CONFLICT, ("Specified key size does not match Hash Table key size"));
+
+    err = ext_hash_get_key_result(p_HashTbl, p_Key, &result);
+    if (err) {
+        RETURN_ERROR(MAJOR, err, ("ext_hash_get_key_result"));
+    }
+
+    p_Context = (uint8_t *)ExternalHashResultGetContextAddr((t_ExtHashResult *)&result);
+
+    err = ext_hash_remove_key(p_HashTbl, p_Key);
+    if (err) {
+        RETURN_ERROR(MAJOR, err, ("ext_hash_remove_key failed"));
+    }
+    PutFEContext(p_HashTbl, p_Context);
+
+    p_HashTbl->numOfKeys--;
+
+    FmPcdLockUnlockAll(p_HashTbl->h_FmPcd);
+
+    return E_OK;
+}
+
+static t_Error ExternalHashTableModifyNextEngine(t_Handle h_HashTbl, uint8_t keySize, uint8_t *p_Key,
+                                                 t_FmPcdCcNextEngineParams *p_FmPcdCcNextEngineParams)
+{
+	t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
+	t_FmPcd *p_FmPcd = (t_FmPcd *)p_HashTbl->h_FmPcd;
+	t_Handle h_FmMuram = NULL;
+	t_Handle h_FE;
+	t_ExtHashResult result;
+	t_FmPcdFEContextParams feContextParams;
+	uint8_t *p_Context;
+	uintptr_t monitorAddr;
+	t_Error err;
+
+	ASSERT_COND(p_FmPcd);
+    ASSERT_COND(p_FmPcdCcNextEngineParams);
+
+    SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
+    SANITY_CHECK_RETURN_ERROR(p_Key, E_NULL_POINTER);
+
+    if (!FmPcdLockTryLockAll(p_HashTbl->h_FmPcd))
+    {
+        DBG(TRACE, ("FmPcdLockTryLockAll failed"));
+        return ERROR_CODE(E_BUSY);
+    }
+
+    /* Validate next engine parameters */
+    if (ValidateNextEngineParamsAndManip(p_HashTbl->h_FmPcd, p_FmPcdCcNextEngineParams, p_HashTbl->statisticsMode) != 0)
+        RETURN_ERROR(MAJOR, E_INVALID_VALUE, ("For this Key NextEngineParams are not valid"));
+
+    h_FmMuram = FmPcdGetMuramHandle(p_HashTbl->h_FmPcd);
+    if (!h_FmMuram) {
+        RETURN_ERROR(MAJOR, E_INVALID_HANDLE, ("FM MURAM"));
+    }
+
+    err = ext_hash_get_key_result(p_HashTbl, p_Key, (t_FmExtHashResult*)&result);
+    if (err) {
+        RETURN_ERROR(MAJOR, err, ("ext_hash_get_key_result"));
+    }
+
+    p_Context = (uint8_t *)ExternalHashResultGetContextAddr(&result);
+
+    /* Release Context and FE */
+    ExternalHashTableDeleteContextAndFE(p_HashTbl->h_FmPcd, &result);
+
+    h_FE = BuildFEChainAndContextFromNextEngine(p_HashTbl->h_FmPcd,
+                                                p_Context,
+                                                p_FmPcdCcNextEngineParams);
+    if (!h_FE) {
+        RETURN_ERROR(MAJOR, E_NO_MEMORY, ("MURAM allocation for FE & context"));
+    }
+
+    memset(&feContextParams, 0, sizeof(t_FmPcdFEContextParams));
+    feContextParams.type = e_FM_PCD_FE_T_MUX;
+    feContextParams.u.mux.h_NextFE = h_FE;
+    err = FmPcdCcBuildContextByFE(p_HashTbl->h_FmPcd,
+                                  p_Context,
+                                  FE_MUX_CONTEXT_OFFSET,
+                                  &feContextParams);
+    ASSERT_COND(!err);
+
+    monitorAddr = ExternalHashResultGetMonitorAddr(&result);
+
+    ExternalHashBuildResult(&result,
+                            p_HashTbl->extHashInfo.dataLiodnOffset,
+                            PTR_TO_UINT(p_Context),
+                            monitorAddr);
+
+	/* update result to the bucket */
+    err = ext_hash_set_key_result(p_HashTbl, p_Key, (t_FmExtHashResult *)&result);
+    if (err) {
+        RETURN_ERROR(MAJOR, err, ("ext_hash_set_key_result"));
+    }
+
+    FmPcdLockUnlockAll(p_HashTbl->h_FmPcd);
+
+    return E_OK;
+}
+#endif // USE_ENHANCED_EHASH
+
+extern t_Error ExternalHashTableModifyMissNextEngine(t_Handle h_HashTbl, t_FmPcdCcNextEngineParams *p_FmPcdCcNextEngineParams);
+#ifndef USE_ENHANCED_EHASH
+static t_Error ExternalHashTableModifyMissNextEngine(t_Handle h_HashTbl, t_FmPcdCcNextEngineParams *p_FmPcdCcNextEngineParams)
+{
+	t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
+	t_FmPcd *p_FmPcd = (t_FmPcd *)p_HashTbl->h_FmPcd;
+	t_Handle h_FmMuram = NULL;
+	uint8_t *p_MissContext;
+	uint32_t tmpReg32;
+
+    SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
+
+    ASSERT_COND(p_FmPcd);
+    ASSERT_COND(p_FmPcdCcNextEngineParams);
+
+    /* Validate next engine parameters on Miss */
+    if (ValidateNextEngineParamsAndManip(p_HashTbl->h_FmPcd, p_FmPcdCcNextEngineParams, p_HashTbl->statisticsMode) != 0)
+    {
+        RETURN_ERROR(MAJOR, E_INVALID_VALUE, ("For this node MissNextEngineParams are not valid"));
+    }
+
+    h_FmMuram = FmPcdGetMuramHandle(p_HashTbl->h_FmPcd);
+    if (!h_FmMuram) {
+    	RETURN_ERROR(MAJOR, E_INVALID_HANDLE, ("FM MURAM"));
+    }
+
+    /* Release miss Context and FE */
+    if (p_HashTbl->extHashInfo.p_MissResult)
+        ExternalHashTableDeleteContextAndFE(p_HashTbl->h_FmPcd, p_HashTbl->extHashInfo.p_MissResult);
+
+    /* Miss allocation */
+    p_MissContext = XX_MallocSmart(256, p_HashTbl->extHashInfo.dataMemId, 256);
+    if (!p_MissContext)
+    {
+    	RETURN_ERROR(MAJOR, E_NO_MEMORY,
+                     ("allocation for miss context"));
+    }
+    memset(p_MissContext, 0, 256);
+
+    memset(p_HashTbl->extHashInfo.p_MissResult, 0, sizeof(t_ExtHashResult));
+
+    p_HashTbl->extHashInfo.h_MissFE = BuildFEChainAndContextFromNextEngine(p_HashTbl->h_FmPcd,
+                                                                           p_MissContext,
+                                                                           p_FmPcdCcNextEngineParams);
+    if (!p_HashTbl->extHashInfo.h_MissFE)
+    {
+        XX_FreeSmart(p_MissContext);
+        FM_MURAM_FreeMem(h_FmMuram, p_HashTbl->extHashInfo.h_MissFE);
+        RETURN_ERROR(MAJOR, E_NO_MEMORY, ("MURAM allocation for miss FE & context"));
+    }
+
+    /* Modify miss next FE */
+    tmpReg32 = (uint32_t)(XX_VirtToPhys(p_HashTbl->extHashInfo.h_MissFE) - p_FmPcd->physicalMuramBase);
+    WRITE_UINT32(p_HashTbl->extHashInfo.p_FE->missNextFEPtr, tmpReg32);
+
+    /* Re-Build Miss result */
+    ExternalHashBuildResult(p_HashTbl->extHashInfo.p_MissResult,
+    		                p_HashTbl->extHashInfo.dataLiodnOffset,
+                            PTR_TO_UINT(p_MissContext),
+                            p_HashTbl->extHashInfo.missMonitorAddr);
+
+    return E_OK;
+}
+#endif
+
+static t_Error ExternalHashTableModifyMissMonitorAddr(t_Handle h_HashTbl, uintptr_t monitorAddr)
+{
+    t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
+
+    SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
+
+    /* Free old miss monitor addr if it was automatically allocated by the driver */
+    if (p_HashTbl->extHashInfo.missMonitorAddr && p_HashTbl->extHashInfo.drvAllocMissMonitorAddr)
+        XX_FreeSmart((void*)p_HashTbl->extHashInfo.missMonitorAddr);
+
+    p_HashTbl->extHashInfo.missMonitorAddr = monitorAddr;
+	p_HashTbl->extHashInfo.drvAllocMissMonitorAddr = FALSE;
+
+    ExternalHashResultSetMonitorAddr(p_HashTbl->extHashInfo.p_MissResult, p_HashTbl->extHashInfo.dataLiodnOffset, monitorAddr);
+
+    return E_OK;
+}
+
+#endif /* (DPAA_VERSION >= 11) */
+
+static t_Error GetAgingMask(t_Handle h_FmPcd,
+                            t_Handle h_FmPcdCcNode,
+                            uint16_t keyIndex,
+                            bool reset,
+                            uint32_t *p_Mask)
+{
+    t_FmPcd *p_FmPcd = (t_FmPcd *)h_FmPcd;
+    t_FmPcdCcNode *p_CcNode = (t_FmPcdCcNode *)h_FmPcdCcNode;
+    t_FmPcdCcNextEngineParams *p_NextEngineParams = NULL;
+    t_List h_NodesLst;
+    uint32_t newAgingMask, oldAgingMask, adAddrOffset;
+    t_AdOfTypeContLookup *p_AdContLookup;
+    t_Error err;
+
+    INIT_LIST(&h_NodesLst);
+
+    /* Building a list of all action descriptors that point to this node.
+       No sharing on AD with aging, so there should be only one parent. */
+    if (!LIST_IsEmpty(&p_CcNode->ccPrevNodesLst))
+        UpdateAdPtrOfNodesWhichPointsOnCrntMdfNode(p_CcNode, &h_NodesLst,
+                                                   &p_NextEngineParams);
+    ASSERT_COND(LIST_NumOfObjs(&h_NodesLst) == 1);
+
+    adAddrOffset = FmPcdCcGetNodeAddrOffsetFromNodeInfo(p_FmPcd, LIST_FIRST(&h_NodesLst));
+
+    if (reset)
+    {
+        if (keyIndex == FM_PCD_LAST_KEY_INDEX)
+            /* If no specific key index provided the entire aging mask will be reset */
+            newAgingMask = CC_BUILD_AGING_MASK(p_CcNode->numOfKeys);
+        else
+            /* Only the bit that corresponds to the provided index is reset,
+               other bits in the mask will be preserved */
+            newAgingMask = (0x80000000 >> keyIndex);
+
+        err = FmHcPcdCcResetAgingMask(p_FmPcd->h_Hc, adAddrOffset, newAgingMask, &oldAgingMask);
+        if (err)
+            RETURN_ERROR(MAJOR, err, NO_MSG);
+
+        *p_Mask = (oldAgingMask & newAgingMask);
+    }
+    else
+    {
+        p_AdContLookup = (t_AdOfTypeContLookup *)(PTR_MOVE(XX_PhysToVirt(p_FmPcd->physicalMuramBase), adAddrOffset));
+        *p_Mask = GET_UINT32(p_AdContLookup->gmask);
+    }
+
+    ReleaseLst(&h_NodesLst);
+
+    return E_OK;
+}
+
+/************************** End of static functions **************************/
+
+/*****************************************************************************/
+/*              Inter-module API routines                                    */
+/*****************************************************************************/
+
+t_CcNodeInformation* FindNodeInfoInReleventLst(t_List *p_List, t_Handle h_Info,
+                                               t_Handle h_Spinlock)
+{
+    t_CcNodeInformation *p_CcInformation;
+    t_List *p_Pos;
+    uint32_t intFlags;
+
+    intFlags = XX_LockIntrSpinlock(h_Spinlock);
+
+    for (p_Pos = LIST_FIRST(p_List); p_Pos != (p_List);
+            p_Pos = LIST_NEXT(p_Pos))
+    {
+        p_CcInformation = CC_NODE_F_OBJECT(p_Pos);
+
+        ASSERT_COND(p_CcInformation->h_CcNode);
+
+        if (p_CcInformation->h_CcNode == h_Info)
+        {
+            XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+            return p_CcInformation;
+        }
+    }
+
+    XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+
+    return NULL;
+}
+
+void EnqueueNodeInfoToRelevantLst(t_List *p_List, t_CcNodeInformation *p_CcInfo,
+                                  t_Handle h_Spinlock)
+{
+    t_CcNodeInformation *p_CcInformation;
+    uint32_t intFlags = 0;
+
+    p_CcInformation = (t_CcNodeInformation *)XX_Malloc(
+            sizeof(t_CcNodeInformation));
+
+    if (p_CcInformation)
+    {
+        memset(p_CcInformation, 0, sizeof(t_CcNodeInformation));
+        memcpy(p_CcInformation, p_CcInfo, sizeof(t_CcNodeInformation));
+        INIT_LIST(&p_CcInformation->node);
+
+        if (h_Spinlock)
+            intFlags = XX_LockIntrSpinlock(h_Spinlock);
+
+        LIST_AddToTail(&p_CcInformation->node, p_List);
+
+        if (h_Spinlock)
+            XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+    }
+    else
+        REPORT_ERROR(MAJOR, E_NO_MEMORY, ("CC Node Information"));
+}
+
+void DequeueNodeInfoFromRelevantLst(t_List *p_List, t_Handle h_Info,
+                                    t_Handle h_Spinlock)
+{
+    t_CcNodeInformation *p_CcInformation = NULL;
+    uint32_t intFlags = 0;
+    t_List *p_Pos;
+
+    if (h_Spinlock)
+        intFlags = XX_LockIntrSpinlock(h_Spinlock);
+
+    if (LIST_IsEmpty(p_List))
+    {
+        XX_RestoreAllIntr(intFlags);
+        return;
+    }
+
+    for (p_Pos = LIST_FIRST(p_List); p_Pos != (p_List);
+            p_Pos = LIST_NEXT(p_Pos))
+    {
+        p_CcInformation = CC_NODE_F_OBJECT(p_Pos);
+        ASSERT_COND(p_CcInformation);
+        ASSERT_COND(p_CcInformation->h_CcNode);
+        if (p_CcInformation->h_CcNode == h_Info)
+            break;
+    }
+
+    if (p_CcInformation)
+    {
+        LIST_DelAndInit(&p_CcInformation->node);
+        XX_Free(p_CcInformation);
+    }
+
+    if (h_Spinlock)
+        XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+}
+
+#if (DPAA_VERSION >= 11)
+void FmPcdCcBuildFE(t_Handle h_FmPcd, t_FmPcdFEParams *p_FeParams, t_Handle h_FE)
+{
+    t_FmPcd     *p_FmPcd = (t_FmPcd*)h_FmPcd;
+    uint32_t    feWords[FM_PCD_FE_MAX_SIZE/4];
+    uint8_t     feSize = 0, i;
+
+    ASSERT_COND(p_FmPcd);
+    ASSERT_COND(p_FeParams);
+    ASSERT_COND(p_FeParams->type != e_FM_PCD_FE_T_INVALID);
+    ASSERT_COND(h_FE);
+
+    memset(feWords, 0, FM_PCD_FE_MAX_SIZE);
+    feWords[0] |= p_FeParams->wsOffset;
+
+    switch (p_FeParams->type)
+    {
+        case e_FM_PCD_FE_T_HM:
+            feSize = FM_PCD_FE_T_HM_SIZE;
+            feWords[0] |= FM_PCD_FE_TYPE_HM;
+            if (p_FeParams->u.hm.parseAfterHm)
+                feWords[0] |= FM_PCD_FE_T_HM_PAHM;
+            feWords[3] |=
+                    (uint32_t)(XX_VirtToPhys(p_FeParams->h_NextFE) - p_FmPcd->physicalMuramBase);
+            break;
+        case e_FM_PCD_FE_T_ENQ:
+            feSize = FM_PCD_FE_T_ENQ_SIZE;
+            feWords[0] |= FM_PCD_FE_TYPE_ENQ;
+            if (p_FeParams->u.enq.mergePolicerWithNia)
+                feWords[0] |= FM_PCD_FE_T_ENQ_MPPN;
+            if (p_FeParams->u.enq.fqidEn)
+                feWords[0] |= FM_PCD_FE_T_ENQ_FQID;
+            if (p_FeParams->u.enq.ppEn)
+                feWords[0] |= FM_PCD_FE_T_ENQ_PP;
+            if (p_FeParams->u.enq.spEn)
+                feWords[0] |= FM_PCD_FE_T_ENQ_SP;
+            feWords[1] = p_FeParams->u.enq.nia;
+            feWords[3] |=
+                    (uint32_t)(XX_VirtToPhys(p_FeParams->h_NextFE) - p_FmPcd->physicalMuramBase);
+            break;
+        case e_FM_PCD_FE_T_MUX:
+            feSize = FM_PCD_FE_T_MUX_SIZE;
+            feWords[0] |= FM_PCD_FE_TYPE_MUX;
+            break;
+        case e_FM_PCD_FE_T_EXIT:
+            feSize = FM_PCD_FE_T_EXIT_SIZE;
+            feWords[0] |= FM_PCD_FE_TYPE_EXIT;
+            if (p_FeParams->u.exit.deallocateBuffer)
+                feWords[0] |= FM_PCD_FE_T_EXIT_DEALLOCATE;
+            break;
+        case e_FM_PCD_FE_T_TRANSITION:
+            feSize = FM_PCD_FE_T_TRANSITION_SIZE;
+            feWords[0] |= FM_PCD_FE_TYPE_TRANSITION;
+            if (p_FeParams->u.transition.deallocateBuffer)
+                feWords[0] |= FM_PCD_FE_T_EXIT_DEALLOCATE;
+            if (p_FeParams->u.transition.nextADFromWS)
+                feWords[0] |= FM_PCD_FE_T_TRANSITION_AD_FROM_WS;
+            else
+                feWords[2] |=
+                    (uint32_t)(XX_VirtToPhys(p_FeParams->h_NextFE) - p_FmPcd->physicalMuramBase);
+            break;
+        default :
+            ASSERT_COND(0);
+    }
+
+    ASSERT_COND((feSize % 4) == 0);
+
+    for(i = 0; i < feSize/4; i++) {
+        WRITE_UINT32(*(uint32_t *)PTR_MOVE(h_FE, i*4), feWords[i]);
+    }
+}
+
+t_Error FmPcdCcBuildContextByFE(t_Handle h_FmPcd,
+                                uint8_t *p_Context,
+                                uint16_t offset,
+                                t_FmPcdFEContextParams *p_FeParams)
+{
+    t_FmPcd     *p_FmPcd = (t_FmPcd*)h_FmPcd;
+    uint16_t    contextSize;
+    uint32_t    *tmp;
+
+    switch (p_FeParams->type)
+    {
+        case e_FM_PCD_FE_T_HM:
+            contextSize = p_FeParams->u.hm.tableSize;
+            if ((offset + contextSize) > FE_MAX_CONTEXT_SIZE)
+                RETURN_ERROR(MAJOR, E_FULL, ("exceeded the %dB for context", FE_MAX_CONTEXT_SIZE));
+            tmp = (uint32_t *)PTR_MOVE(p_Context, offset);
+            MemCpy8((uint8_t*)tmp, p_FeParams->u.hm.p_Hmct, contextSize);
+            break;
+        case e_FM_PCD_FE_T_ENQ:
+            contextSize = 8;
+            if ((offset + contextSize) > FE_MAX_CONTEXT_SIZE)
+                RETURN_ERROR(MAJOR, E_FULL, ("exceeded the %dB for context", FE_MAX_CONTEXT_SIZE));
+            tmp = (uint32_t *)PTR_MOVE(p_Context, offset);
+            WRITE_UINT32(*tmp, (uint32_t)((p_FeParams->u.enq.rspid << 24) |
+                    p_FeParams->u.enq.fqid));
+            WRITE_UINT32(*(tmp + 1), (uint32_t)(p_FeParams->u.enq.ppid << 16));
+		break;
+        case e_FM_PCD_FE_T_MUX:
+            contextSize = 4;
+            if ((offset + contextSize) > FE_MAX_CONTEXT_SIZE)
+                RETURN_ERROR(MAJOR, E_FULL, ("exceeded the %dB for context", FE_MAX_CONTEXT_SIZE));
+            tmp = (uint32_t *)PTR_MOVE(p_Context, offset);
+            WRITE_UINT32(*tmp, (uint32_t)(XX_VirtToPhys(p_FeParams->u.mux.h_NextFE)
+                    - p_FmPcd->physicalMuramBase));
+            break;
+        case e_FM_PCD_FE_T_TRANSITION:
+            contextSize = 4;
+            if ((offset + contextSize) > FE_MAX_CONTEXT_SIZE)
+                RETURN_ERROR(MAJOR, E_FULL, ("exceeded the %dB for context", FE_MAX_CONTEXT_SIZE));
+            tmp = (uint32_t *)PTR_MOVE(p_Context, offset);
+            WRITE_UINT32(*tmp, (uint32_t)(XX_VirtToPhys(p_FeParams->u.transition.h_NextAD)
+                    - p_FmPcd->physicalMuramBase));
+            break;
+        default :
+            ASSERT_COND(0);
+    }
+
+    return E_OK;
+}
+
+#ifndef USE_ENHANCED_EHASH
+t_Handle FmPcdExternalHashTableSet(t_Handle h_FmPcd,
+                                   t_FmPcdHashTableParams *p_Param,
+                                   bool allocateBuffer,
+                                   uint16_t contextSize,
+                                   uint16_t contextOffsetInWS,
+                                   t_Handle h_NextFE,
+                                   t_Handle h_MissFE,
+                                   t_ExtHashResult *p_MissResult)
+{
+    t_FmPcd *p_FmPcd = (t_FmPcd *)h_FmPcd;
+    t_FmPcdCcNode *p_CcNodeHashTbl;
+    t_Handle h_MissStatsCounters = NULL;
+    t_FmPcdCcNodeExtHashInfo *p_ExtHashInfo;
+    t_Handle h_FmMuram = NULL;
+    bool statsEnForMiss = FALSE;
+    uint64_t tmpReg64;
+    uint32_t tmpReg32;
+    t_Error err;
+
+    SANITY_CHECK_RETURN_VALUE(h_FmPcd, E_INVALID_HANDLE, NULL);
+    SANITY_CHECK_RETURN_VALUE(p_Param, E_NULL_POINTER, NULL);
+    SANITY_CHECK_RETURN_VALUE(h_NextFE, E_INVALID_HANDLE, NULL);
+    SANITY_CHECK_RETURN_VALUE(h_MissFE, E_INVALID_HANDLE, NULL);
+    SANITY_CHECK_RETURN_VALUE(p_MissResult, E_NULL_POINTER, NULL);
+    SANITY_CHECK_RETURN_VALUE(contextSize <= 256, E_INVALID_VALUE, NULL);
+    SANITY_CHECK_RETURN_VALUE(IS_ALIGNED(contextOffsetInWS, 8), E_INVALID_VALUE, NULL);
+
+    h_FmMuram = FmPcdGetMuramHandle(h_FmPcd);
+    if (!h_FmMuram) {
+        REPORT_ERROR(MAJOR, E_INVALID_HANDLE, ("FM MURAM"));
+        return NULL;
+    }
+
+    p_CcNodeHashTbl = (t_FmPcdCcNode *)XX_Malloc(sizeof(t_FmPcdCcNode));
+    if (!p_CcNodeHashTbl)
+    {
+        REPORT_ERROR(MAJOR, E_NO_MEMORY, ("No memory"));
+        return NULL;
+    }
+    memset(p_CcNodeHashTbl, 0, sizeof(t_FmPcdCcNode));
+    printk("%s::p_CcNodeHashTbl %p\n", __FUNCTION__, p_CcNodeHashTbl);
+
+    /* call Hezi's create function */
+    err = ext_hash_table_create(p_Param, p_CcNodeHashTbl);
+    if (err)
+    {
+       REPORT_ERROR(MAJOR, E_NO_MEMORY, ("No memory"));
+       return NULL;
+    }
+
+    INIT_LIST(&p_CcNodeHashTbl->availableStatsLst);
+    INIT_LIST(&p_CcNodeHashTbl->ccPrevNodesLst);
+    INIT_LIST(&p_CcNodeHashTbl->ccTreeIdLst);
+    INIT_LIST(&p_CcNodeHashTbl->ccTreesLst);
+
+    p_CcNodeHashTbl->h_Spinlock = XX_InitSpinlock();
+    if (!p_CcNodeHashTbl->h_Spinlock)
+    {
+        ExternalHashTableDelete(p_CcNodeHashTbl);
+        REPORT_ERROR(MAJOR, E_NO_MEMORY, ("CC node spinlock"));
+        return NULL;
+    }
+
+    p_CcNodeHashTbl->h_TmpAd = (t_Handle)FM_MURAM_AllocMem(
+            h_FmMuram, FM_PCD_CC_AD_ENTRY_SIZE, FM_PCD_CC_AD_TABLE_ALIGN);
+    if (!p_CcNodeHashTbl->h_TmpAd)
+    {
+        ExternalHashTableDelete(p_CcNodeHashTbl);
+        REPORT_ERROR(MAJOR, E_NO_MEMORY,
+                     ("MURAM allocation for CC action descriptor"));
+        return NULL;
+    }
+    memset((uint8_t *)p_CcNodeHashTbl->h_TmpAd, 0, FM_PCD_CC_AD_ENTRY_SIZE);
+    printk("%s::h_TmpAd %p\n", __FUNCTION__, p_CcNodeHashTbl->h_TmpAd);
+
+    if ((p_Param->statisticsMode == e_FM_PCD_CC_STATS_MODE_FRAME)
+            || (p_Param->statisticsMode == e_FM_PCD_CC_STATS_MODE_BYTE_AND_FRAME)
+#if (DPAA_VERSION >= 11)
+            || (p_Param->statisticsMode == e_FM_PCD_CC_STATS_MODE_RMON)
+#endif /* (DPAA_VERSION >= 11) */
+       )
+    {
+		/* Allocating a statistics counters table that will be used by all
+		 'miss' entries of the hash table */
+		h_MissStatsCounters = (t_Handle)FM_MURAM_AllocMem(
+				h_FmMuram, 2 * FM_PCD_CC_STATS_COUNTER_SIZE,
+				FM_PCD_CC_AD_TABLE_ALIGN);
+		if (!h_MissStatsCounters)
+		{
+			REPORT_ERROR(MAJOR, E_NO_MEMORY, ("MURAM allocation for statistics table for hash miss"));
+			ExternalHashTableDelete(p_CcNodeHashTbl);
+			return NULL;
+		}
+		memset(h_MissStatsCounters, 0, (2 * FM_PCD_CC_STATS_COUNTER_SIZE));
+
+		/* Always enable statistics for 'miss', so that a statistics AD will be
+		 initialized from the start. We'll store the requested 'statistics enable'
+		 value and it will be used when statistics are read by the user. */
+		statsEnForMiss = p_Param->ccNextEngineParamsForMiss.statisticsEn;
+		p_Param->ccNextEngineParamsForMiss.statisticsEn = TRUE;
+    }
+
+    p_ExtHashInfo = &p_CcNodeHashTbl->extHashInfo;
+
+    /* FE of type External Hash */
+    p_ExtHashInfo->p_FE = (t_ExtHashFe *)FM_MURAM_AllocMem(
+            h_FmMuram, sizeof(t_ExtHashFe), FM_PCD_FE_ALIGN);
+    if (!p_ExtHashInfo->p_FE)
+    {
+        ExternalHashTableDelete(p_CcNodeHashTbl);
+        REPORT_ERROR(MAJOR, E_NO_MEMORY,
+                     ("MURAM allocation for External Hash FE"));
+        return NULL;
+    }
+    memset((uint8_t *)p_ExtHashInfo->p_FE, 0, sizeof(t_ExtHashFe));
+
+    /* Build HASH FE */
+    tmpReg32 = FM_PCD_FE_TYPE_EXT_HASH;
+    tmpReg32 |= contextOffsetInWS; /* WS offset */
+    if (p_Param->agingSupport)
+        tmpReg32 |= FM_PCD_FE_T_HASH_UPDATE_TS;
+    if (p_Param->statisticsMode != e_FM_PCD_CC_STATS_MODE_NONE)
+        tmpReg32 |= FM_PCD_FE_T_HASH_UPDATE_STATS;
+    WRITE_UINT32(p_ExtHashInfo->p_FE->misc, tmpReg32);
+    WRITE_UINT16(p_ExtHashInfo->p_FE->hashMask, p_Param->hashResMask);
+    WRITE_UINT8(p_ExtHashInfo->p_FE->contextSize, contextSize - 1);
+    WRITE_UINT8(p_ExtHashInfo->p_FE->hashShift, p_Param->hashShift);
+    tmpReg64 = (uint64_t)(XX_VirtToPhys((uint8_t *)p_ExtHashInfo->table_base_ptr));
+    tmpReg64 |= ((uint64_t)(p_Param->externalHashParams.dataLiodnOffset
+            & FM_PCD_FE_T_HASH_LIODN_MASK)
+            << (uint64_t)FM_PCD_FE_T_HASH_LIODN_SHIFT);
+    tmpReg64 |= ((uint64_t)(p_Param->externalHashParams.dataLiodnOffset
+            & FM_PCD_FE_T_HASH_ELIODN_MASK)
+            << (uint64_t)FM_PCD_FE_T_HASH_ELIODN_SHIFT);
+    WRITE_UINT32(p_ExtHashInfo->p_FE->liodnTableAndTablePtrHi, (uint32_t)(tmpReg64 >> 32));
+    WRITE_UINT32(p_ExtHashInfo->p_FE->tablePtrLow, (uint32_t)tmpReg64);
+    tmpReg32 = (uint32_t)(XX_VirtToPhys(p_MissResult) - p_FmPcd->physicalMuramBase);
+    WRITE_UINT32(p_ExtHashInfo->p_FE->missResultPtr, tmpReg32);
+    tmpReg32 = (uint32_t)(XX_VirtToPhys(h_NextFE) - p_FmPcd->physicalMuramBase);
+    WRITE_UINT32(p_ExtHashInfo->p_FE->nextFEPtr, tmpReg32);
+    tmpReg32 = (uint32_t)(XX_VirtToPhys(h_MissFE) - p_FmPcd->physicalMuramBase);
+    WRITE_UINT32(p_ExtHashInfo->p_FE->missNextFEPtr, tmpReg32);
+
+    p_CcNodeHashTbl->h_FmPcd = h_FmPcd;
+    p_CcNodeHashTbl->parseCode = FM_PCD_AD_FE_ENTER_OPCODE;
+    p_CcNodeHashTbl->maxNumOfKeys = p_Param->maxNumOfKeys;
+    p_CcNodeHashTbl->agingSupport = p_Param->agingSupport;
+    p_CcNodeHashTbl->h_MissStatsCounters = h_MissStatsCounters;
+    p_CcNodeHashTbl->statsEnForMiss = statsEnForMiss;
+    p_CcNodeHashTbl->externalHash = TRUE;
+    p_CcNodeHashTbl->statisticsMode = p_Param->statisticsMode;
+    p_ExtHashInfo->allocateBuffer = allocateBuffer;
+    p_ExtHashInfo->h_MissFE = h_MissFE;
+    p_ExtHashInfo->p_MissResult = p_MissResult;
+    p_ExtHashInfo->dataMemId = p_Param->externalHashParams.dataMemId;
+    p_ExtHashInfo->dataLiodnOffset = p_Param->externalHashParams.dataLiodnOffset;
+    p_ExtHashInfo->missMonitorAddr = p_Param->externalHashParams.missMonitorAddr;
+    p_ExtHashInfo->drvAllocMissMonitorAddr = FALSE;
+    if (p_CcNodeHashTbl->statisticsMode != e_FM_PCD_CC_STATS_MODE_NONE || p_CcNodeHashTbl->agingSupport)
+    {
+		/*
+		 * If Miss Monitor Addr is NULL it means user doesn't care about it,
+		 * so the driver will automatically allocate it in order to have mechanism working instead of exiting with an error.
+		 * In case user needs it, then he can use API method to allocate it: FM_PCD_HashTableModifyMissMonitorAddr
+		 * This is useful in case of FMC initialization which cannot perform memory allocations.
+		 */
+		if (!p_ExtHashInfo->missMonitorAddr) {
+			p_ExtHashInfo->missMonitorAddr = (uintptr_t )XX_MallocSmart(16, p_Param->externalHashParams.dataMemId, 16);
+			p_ExtHashInfo->drvAllocMissMonitorAddr = TRUE;
+		}
+	}
+    err = AllocFEContextObjs(p_CcNodeHashTbl);
+    if (err)
+    {
+        ExternalHashTableDelete(p_CcNodeHashTbl);
+        REPORT_ERROR(MAJOR, E_NO_MEMORY,
+                     ("MURAM allocation for External Hash FE-Context"));
+        return NULL;
+    }
+ 
+    return p_CcNodeHashTbl;
+}
+#endif // USE_ENHANCED_EHASH
+#endif /* (DPAA_VERSION >= 11) */
+
+void NextStepAd(t_Handle h_Ad, t_FmPcdCcStatsParams *p_FmPcdCcStatsParams,
+                t_FmPcdCcNextEngineParams *p_FmPcdCcNextEngineParams,
+                t_FmPcd *p_FmPcd)
+{
+    switch (p_FmPcdCcNextEngineParams->nextEngine)
+    {
+        case (e_FM_PCD_KG):
+        case (e_FM_PCD_PLCR):
+        case (e_FM_PCD_DONE):
+            /* if NIA is not CC, create a "result" type AD */
+            FillAdOfTypeResult(h_Ad, p_FmPcdCcStatsParams, p_FmPcd,
+                               p_FmPcdCcNextEngineParams);
+            break;
+#if (DPAA_VERSION >= 11)
+        case (e_FM_PCD_FR):
+            if (p_FmPcdCcNextEngineParams->params.frParams.h_FrmReplic)
+            {
+                FillAdOfTypeContLookup(
+                        h_Ad, p_FmPcdCcStatsParams, p_FmPcd,
+                        p_FmPcdCcNextEngineParams->params.ccParams.h_CcNode,
+                        p_FmPcdCcNextEngineParams->h_Manip,
                         p_FmPcdCcNextEngineParams->params.frParams.h_FrmReplic);
                 FrmReplicGroupUpdateOwner(
                         p_FmPcdCcNextEngineParams->params.frParams.h_FrmReplic,
@@ -5418,6 +7670,7 @@ t_Error FmPcdCcRemoveKey(t_Handle h_FmPcd, t_Handle h_FmPcdCcNode,
         RETURN_ERROR(MAJOR, err, NO_MSG);
     }
 
+    display_cc_node(p_CcNode, __FUNCTION__);
     err = DoDynamicChange(p_FmPcd, &h_OldPointersLst, &h_NewPointersLst,
                           p_ModifyKeyParams, useShadowStructs);
 
@@ -5509,6 +7762,7 @@ t_Error FmPcdCcModifyKey(t_Handle h_FmPcd, t_Handle h_FmPcdCcNode,
         RETURN_ERROR(MAJOR, err, NO_MSG);
     }
 
+    display_cc_node(p_CcNode, __FUNCTION__);
     err = DoDynamicChange(p_FmPcd, &h_OldPointersLst, &h_NewPointersLst,
                           p_ModifyKeyParams, useShadowStructs);
 
@@ -5566,6 +7820,7 @@ t_Error FmPcdCcModifyMissNextEngineParamNode(
         RETURN_ERROR(MAJOR, err, NO_MSG);
     }
 
+    display_cc_node(p_CcNode, __FUNCTION__);
     err = DoDynamicChange(p_FmPcd, &h_OldPointersLst, &h_NewPointersLst,
                           p_ModifyKeyParams, FALSE);
 
@@ -5675,6 +7930,7 @@ t_Error FmPcdCcAddKey(t_Handle h_FmPcd, t_Handle h_FmPcdCcNode,
         RETURN_ERROR(MAJOR, err, NO_MSG);
     }
 
+    display_cc_node(p_CcNode, __FUNCTION__);
     err = DoDynamicChange(p_FmPcd, &h_OldPointersLst, &h_NewPointersLst,
                           p_ModifyKeyParams, useShadowStructs);
     if (p_CcNode->maxNumOfKeys)
@@ -5768,6 +8024,7 @@ t_Error FmPcdCcModifyKeyAndNextEngine(t_Handle h_FmPcd, t_Handle h_FmPcdCcNode,
         RETURN_ERROR(MAJOR, err, NO_MSG);
     }
 
+    display_cc_node(p_CcNode, __FUNCTION__);
     err = DoDynamicChange(p_FmPcd, &h_OldPointersLst, &h_NewPointersLst,
                           p_ModifyKeyParams, useShadowStructs);
 
@@ -6021,6 +8278,143 @@ void FmPcdCcGetAdTablesThatPointOnReplicGroup(t_Handle h_Node,
 /****************************************/
 /*       API Init unit functions        */
 /****************************************/
+#ifdef USE_ENHANCED_EHASH 
+
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+void set_reassembly_tds(void *handle, uint32_t ipv4_off, uint32_t ipv6_off)
+{
+        struct en_exthash_info *info;
+        struct en_exthash_node *ptr, *ccptr;
+
+        info = (struct en_exthash_info *)handle;
+        ptr = (struct en_exthash_node  *)&info->node;
+        ccptr = info->h_Ad;
+        ptr->ipv4_ad_offset = ipv4_off;
+        ptr->word_2 |= (ipv6_off << 24);
+        WRITE_UINT32(ccptr->word_0, ptr->word_0);
+        WRITE_UINT32(ccptr->word_2, ptr->word_2);
+#ifdef FM_EHASH_DEBUG
+        {
+                uint32_t ii;
+                uint8_t *ptr;
+                ptr = (uint8_t *)ccptr;
+                printk("%s::handle %p Ad %p ccptr %pi v4off %x, v6off %x\n", __F
+UNCTION__,
+                         handle, ptr, ccptr, ipv4_off, ipv6_off);
+                for (ii = 0; ii < 16; ii++)
+                        printk("%02x ", *(ptr + ii));
+                printk("\n");
+        }
+#endif
+}
+uint32_t copy_td_to_ccbase(void *handle, t_Handle p_CcTreeTmp, uint32_t *node)
+{
+	struct en_exthash_info *info;
+	struct en_exthash_node *ptr, *ccptr;
+	t_FmPcd *p_FmPcd;
+	uint32_t ii;
+
+	info = (struct en_exthash_info *)handle;
+	ptr = (struct en_exthash_node  *)&info->node;
+	ccptr = (struct en_exthash_node  *)p_CcTreeTmp;
+	WRITE_UINT32(ccptr->word_1, ptr->word_1);
+	WRITE_UINT32(ccptr->table_base_lo, ptr->table_base_lo);
+	WRITE_UINT32(ccptr->word_2,  ptr->word_2);
+	WRITE_UINT32(ccptr->word_0, ptr->word_0);
+#ifdef FM_EHASH_DEBUG
+	{
+		uint8_t *ptr;
+
+		printk("%s::handle %p Ad %p ccptr %p\n", __FUNCTION__,
+			 handle, ptr, p_CcTreeTmp);
+		ptr = (uint8_t *)ccptr;
+		for (ii = 0; ii < 16; ii++)
+			printk("%02x ", *(ptr + ii));
+		printk("\n");
+	}
+#endif
+	//save muram addr for AD in the tree 
+	info->h_Ad = ccptr;
+	p_FmPcd = info->pcd;
+	ii = (uint32_t)(XX_VirtToPhys(p_CcTreeTmp) - 
+			p_FmPcd->physicalMuramBase);
+	*node = ii;
+#ifdef FM_EHASH_DEBUG
+	if (info->ip_reassem_info) 
+	{
+		if (info->ip_reassem_info) { 
+			printk("%s::AD for reassembly %p %x\n",
+				__FUNCTION__, ccptr, ii);
+		} else {
+			printk("%s::AD for non-reassembly %p %x\n",
+				__FUNCTION__, ccptr, ii);
+		}
+		display_ehashtbl_info(info, __FUNCTION__);
+	}
+#endif
+	//return type
+	if (info->ip_reassem_info) 
+		return (info->ip_reassem_info->type);
+	return 0;
+}
+#else
+void copy_td_to_ccbase(void *handle, t_Handle p_CcTreeTmp)
+{
+	struct en_exthash_info *info;
+	struct en_exthash_node *ptr, *ccptr;
+
+	info = (struct en_exthash_info *)handle;
+	ptr = (struct en_exthash_node  *)&info->node;
+	ccptr = (struct en_exthash_node  *)p_CcTreeTmp;
+	WRITE_UINT32(ccptr->word_1, ptr->word_1);
+	WRITE_UINT32(ccptr->table_base_lo, ptr->table_base_lo);
+	WRITE_UINT32(ccptr->word_2,  ptr->word_2);
+	WRITE_UINT32(ccptr->word_0, ptr->word_0);
+#ifdef FM_EHASH_DEBUG
+	{
+		uint32_t ii;
+		uint8_t *ptr;
+
+		printk("%s::handle %p Ad %p ccptr %p\n", __FUNCTION__,
+			 handle, ptr, p_CcTreeTmp);
+		ptr = (uint8_t *)ccptr;
+		for (ii = 0; ii < 16; ii++)
+			printk("%02x ", *(ptr + ii));
+		printk("\n");
+	}
+#endif
+	//save muram addr for AD in the tree 
+	info->h_Ad = ccptr;
+
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+	{
+		uint32_t ii;
+		t_FmPcd *p_FmPcd;
+		p_FmPcd = info->pcd;
+		ii = (uint32_t)(XX_VirtToPhys(p_CcTreeTmp) - 
+			p_FmPcd->physicalMuramBase);
+#ifdef FM_EHASH_DEBUG
+		if (info->ip_reassem_info) 
+		{
+			if (info->ip_reassem_info) { 
+				printk("%s::AD for reassembly %p %x\n",
+					__FUNCTION__, ccptr, ii);
+			} else {
+				printk("%s::AD for non-reassembly %p %x\n",
+					__FUNCTION__, ccptr, ii);
+			}
+			display_ehashtbl_info(info, __FUNCTION__);
+		}
+	}
+#endif
+	//return type
+	if (info->ip_reassem_info) 
+		return (info->ip_reassem_info->type);
+#endif
+	return 0;
+}
+#endif
+#endif //USE_ENHANCED_EHASH
 
 t_Handle FM_PCD_CcRootBuild(t_Handle h_FmPcd,
                             t_FmPcdCcTreeParams *p_PcdGroupsParam)
@@ -6036,8 +8430,14 @@ t_Handle FM_PCD_CcRootBuild(t_Handle h_FmPcd,
     t_NetEnvParams netEnvParams;
     uint8_t lastOne = 0;
     uint32_t requiredAction = 0;
+#ifndef USE_ENHANCED_EHASH 
     t_FmPcdCcNode *p_FmPcdCcNextNode;
     t_CcNodeInformation ccNodeInfo, *p_CcInformation;
+#endif 
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+    uint32_t ipv4_reassly_offset;
+    uint32_t ipv6_reassly_offset;
+#endif
 
     SANITY_CHECK_RETURN_VALUE(h_FmPcd, E_INVALID_HANDLE, NULL);
     SANITY_CHECK_RETURN_VALUE(p_PcdGroupsParam, E_INVALID_HANDLE, NULL);
@@ -6088,6 +8488,7 @@ t_Handle FM_PCD_CcRootBuild(t_Handle h_FmPcd,
     numOfEntries = 0;
     p_FmPcdCcTree->netEnvId = FmPcdGetNetEnvId(p_PcdGroupsParam->h_NetEnv);
 
+    //printk("%s::num groups %d\n", __FUNCTION__, p_PcdGroupsParam->numOfGrps);
     for (i = 0; i < p_PcdGroupsParam->numOfGrps; i++)
     {
         p_FmPcdCcGroupParams = &p_PcdGroupsParam->ccGrpParams[i];
@@ -6200,6 +8601,7 @@ t_Handle FM_PCD_CcRootBuild(t_Handle h_FmPcd,
             k++;
         }
     }
+    //printk("%s::num entries %d\n", __FUNCTION__, numOfEntries);
 
     p_FmPcdCcTree->numOfEntries = (uint8_t)k;
     p_FmPcdCcTree->numOfGrps = p_PcdGroupsParam->numOfGrps;
@@ -6220,7 +8622,15 @@ t_Handle FM_PCD_CcRootBuild(t_Handle h_FmPcd,
             (uint32_t)(FM_PCD_MAX_NUM_OF_CC_GROUPS * FM_PCD_CC_AD_ENTRY_SIZE));
 
     p_CcTreeTmp = UINT_TO_PTR(p_FmPcdCcTree->ccTreeBaseAddr);
-
+#ifdef FM_EHASH_DEBUG
+    printk("%s::cctree root %p baseaddr %p numentries %d\n", __FUNCTION__,
+		p_CcTreeTmp, (void *)p_FmPcdCcTree->ccTreeBaseAddr, numOfEntries);
+
+    printk("%s::cctree root %p baseaddr %p numentries %d muram %x\n", __FUNCTION__,
+	          p_CcTreeTmp, (void *)p_FmPcdCcTree->ccTreeBaseAddr, numOfEntries,
+                (uint32_t)(XX_VirtToPhys(p_FmPcdCcTree->ccTreeBaseAddr) - p_FmPcd->physicalMuramBase)); 
+#endif
+#ifndef USE_ENHANCED_EHASH //jyos following code is crashing in case of EHASH
     for (i = 0; i < numOfEntries; i++)
     {
         p_KeyAndNextEngineParams = p_Params + i;
@@ -6256,10 +8666,175 @@ t_Handle FM_PCD_CcRootBuild(t_Handle h_FmPcd,
                 p_CcInformation->index++;
         }
     }
-
+#else
+    for (i = 0; i < numOfEntries; i++) {
+	struct t_FmPcdCcNextEngineParams *nexteng;
+	
+        p_KeyAndNextEngineParams = p_Params + i;
+	memcpy(&p_FmPcdCcTree->keyAndNextEngineParams[i],
+               p_KeyAndNextEngineParams,
+               sizeof(t_FmPcdCcKeyAndNextEngineParams));
+	nexteng = &p_FmPcdCcTree->keyAndNextEngineParams[i].nextEngineParams;
+
+	if (nexteng->nextEngine == e_FM_PCD_CC)
+	{
+		
+        	t_FmPcdCcNextCcParams *ccParams;       /**< Parameters in case next engine is CC */
+		ccParams = &nexteng->params.ccParams;
+		//printk("e_FM_PCD_CC ccnode handle %p\n", (void *)ccParams->h_CcNode);
+#ifdef EXCLUDE_FMAN_IPR_OFFLOAD
+		copy_td_to_ccbase(ccParams->h_CcNode, p_CcTreeTmp);
+#else
+		{
+			uint32_t node;
+			uint32_t type;
+			type = copy_td_to_ccbase(ccParams->h_CcNode, p_CcTreeTmp, &node);
+#ifdef FM_EHASH_DEBUG
+			printk("e_FM_PCD_CC ccnode handle %p type %d\n", (void *)ccParams->h_CcNode,
+				type);
+#endif
+			switch (type) {
+				case IPV4_REASSM_TABLE:
+					ipv4_reassly_offset = (node & 0xff);
+#ifdef FM_EHASH_DEBUG
+					printk("%s::ipv4_reassly_offset %x\n",
+						__FUNCTION__,
+						ipv4_reassly_offset);
+#endif
+					break;
+				case IPV6_REASSM_TABLE:
+					ipv6_reassly_offset = (node & 0xff);
+#ifdef FM_EHASH_DEBUG
+					printk("%s::ipv6_reassly_offset %x\n",
+						__FUNCTION__,
+						ipv6_reassly_offset);
+#endif
+					break;
+				default:
+					break;
+			}
+		}	
+#endif
+	}
+        p_CcTreeTmp = PTR_MOVE(p_CcTreeTmp, FM_PCD_CC_AD_ENTRY_SIZE);
+#ifdef FM_EHASH_DEBUG
+	printk("%s::entry %d tree %p p_KeyAndNextEngineParams %p p_CcTreeTmp %p\n", __FUNCTION__, 
+		i, p_FmPcdCcTree, &p_FmPcdCcTree->keyAndNextEngineParams[i], p_CcTreeTmp); 
+	
+	printk("nextEngineParams %p requiredAction %08x\n", 
+		nexteng,
+		p_FmPcdCcTree->keyAndNextEngineParams[i].requiredAction);
+	printk("nextEngine %d, statisticsEn %d\n",
+		nexteng->nextEngine, nexteng->statisticsEn);
+	if (nexteng->nextEngine == e_FM_PCD_CC)	{
+		printk("h_CcNode %p\n", nexteng->params.ccParams.h_CcNode);
+	}
+#endif
+    }
+
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD	
+    //set table indices for ipv4 and ipv6 reassly in other ADs
+    for (i = 0; i < numOfEntries; i++) {
+	struct t_FmPcdCcNextEngineParams *nexteng;
+
+	nexteng = &p_FmPcdCcTree->keyAndNextEngineParams[i].nextEngineParams;
+	if (nexteng->nextEngine == e_FM_PCD_CC) {
+        	t_FmPcdCcNextCcParams *ccParams;       
+		struct en_exthash_info *info;
+        	
+		ccParams = &nexteng->params.ccParams;
+		info = (struct en_exthash_info *)ccParams->h_CcNode;
+		if (info->type != ETHERNET_TABLE)
+			set_reassembly_tds(ccParams->h_CcNode, ipv4_reassly_offset,
+				ipv6_reassly_offset);
+		else
+			set_reassembly_tds(ccParams->h_CcNode, 0xff, 0xff);
+	}
+    }
+#endif
+    for (i = 0; i < numOfEntries; i++)
+    {
+	struct t_FmPcdCcNextEngineParams *nexteng;
+
+        p_KeyAndNextEngineParams = 
+		&p_FmPcdCcTree->keyAndNextEngineParams[i];
+	nexteng = &p_KeyAndNextEngineParams->nextEngineParams;
+	switch(nexteng->nextEngine) {
+		case e_FM_PCD_DONE:
+			{
+        			t_FmPcdCcNextEnqueueParams *enqueueParams;  /**< Parameters in case next engine is BMI */
+				printk("e_FM_PCD_DONE\n");
+				enqueueParams = &nexteng->params.enqueueParams;
+				printk("action %d, overrideFqid %d, newFqid %x(%d), storageid %d\n", 
+					enqueueParams->action,
+					enqueueParams->overrideFqid,
+					enqueueParams->newFqid,
+					enqueueParams->newFqid,
+					enqueueParams->newRelativeStorageProfileId);
+			}
+			break;
+    		case e_FM_PCD_KG:
+			{
+        			t_FmPcdCcNextKgParams *kgParams;       /**< Parameters in case next engine is KG */
+				printk("e_FM_PCD_KG\n");
+				kgParams = &nexteng->params.kgParams;
+				printk("overrideFqid %d, newFqid %x(%d), storageid %d directschhandle %d\n", 
+					kgParams->overrideFqid,
+					kgParams->newFqid,
+					kgParams->newFqid,
+					kgParams->newRelativeStorageProfileId,
+					kgParams->h_DirectScheme);
+			}
+			break;
+    		case e_FM_PCD_CC:
+			{
+        			t_FmPcdCcNextCcParams *ccParams;       /**< Parameters in case next engine is CC */
+				ccParams = &nexteng->params.ccParams;
+				//printk("e_FM_PCD_CC ccnode handle %p\n", (void *)ccParams->h_CcNode);
+				//display_ehashtbl_info(ccParams->h_CcNode, __FUNCTION__);
+			}
+			break;
+    		case e_FM_PCD_PLCR:
+			{
+        			t_FmPcdCcNextPlcrParams *plcrParams;     /**< Parameters in case next engine is PLCR */
+				printk("e_FM_PCD_PLCR\n");
+				plcrParams = &nexteng->params.plcrParams;
+				printk("overrideParams %d, sharedProfile %d, newRelativeProfileId %d, newfqid %x(%d)"
+					"storageid %d\n",
+       		                        plcrParams->overrideParams,
+       		                        plcrParams->sharedProfile,
+                                	plcrParams->newRelativeProfileId,
+                                	plcrParams->newFqid,
+                                	plcrParams->newFqid,
+                                	plcrParams->newRelativeStorageProfileId);
+			}
+			break;
+    		case e_FM_PCD_PRS:
+			printk("e_FM_PCD_PRS\n");
+			break;
+#if (DPAA_VERSION >= 11)
+		case e_FM_PCD_FR: 
+			{
+        			t_FmPcdCcNextFrParams *frParams;       /**< Parameters in case next engine is FR */
+				printk("e_FM_PCD_FR\n");
+				frParams = &nexteng->params.frParams;
+				printk("frhandle handle %d\n", frParams->h_FrmReplic);
+			}
+			break;
+#endif /* (DPAA_VERSION >= 11) */
+		case e_FM_PCD_HASH:
+			printk("e_FM_PCD_HASH\n");
+			break;
+		default:
+			printk("next engine %d\n", nexteng->nextEngine);
+			
+	}
+    }
+#endif
     FmPcdIncNetEnvOwners(h_FmPcd, p_FmPcdCcTree->netEnvId);
     p_CcTreeTmp = UINT_TO_PTR(p_FmPcdCcTree->ccTreeBaseAddr);
 
+#ifndef USE_ENHANCED_EHASH  // jyos following code is crashing in case of EHASH
     if (!FmPcdLockTryLockAll(p_FmPcd))
     {
         FM_PCD_CcRootDelete(p_FmPcdCcTree);
@@ -6290,6 +8865,7 @@ t_Handle FM_PCD_CcRootBuild(t_Handle h_FmPcd,
     }
 
     FmPcdLockUnlockAll(p_FmPcd);
+#endif
     p_FmPcdCcTree->p_Lock = FmPcdAcquireLock(p_FmPcd);
     if (!p_FmPcdCcTree->p_Lock)
     {
@@ -7143,16 +9719,6 @@ t_Error FM_PCD_MatchTableGetIndexedHashBucket(t_Handle h_CcNode,
 
 t_Handle FM_PCD_HashTableSet(t_Handle h_FmPcd, t_FmPcdHashTableParams *p_Param)
 {
-    t_FmPcdCcNode *p_CcNodeHashTbl;
-    t_FmPcdCcNodeParams *p_IndxHashCcNodeParam, *p_ExactMatchCcNodeParam;
-    t_FmPcdCcNode *p_CcNode;
-    t_Handle h_MissStatsCounters = NULL;
-    t_FmPcdCcKeyParams *p_HashKeyParams;
-    int i;
-    uint16_t numOfSets, numOfWays, countMask, onesCount = 0;
-    bool statsEnForMiss = FALSE;
-    t_Error err;
-
     SANITY_CHECK_RETURN_VALUE(h_FmPcd, E_INVALID_HANDLE, NULL);
     SANITY_CHECK_RETURN_VALUE(p_Param, E_NULL_POINTER, NULL);
 
@@ -7184,211 +9750,44 @@ t_Handle FM_PCD_HashTableSet(t_Handle h_FmPcd, t_FmPcdHashTableParams *p_Param)
     }
 #endif /* (DPAA_VERSION >= 11) */
 
-    p_ExactMatchCcNodeParam = (t_FmPcdCcNodeParams*)XX_Malloc(
-            sizeof(t_FmPcdCcNodeParams));
-    if (!p_ExactMatchCcNodeParam)
-    {
-        REPORT_ERROR(MAJOR, E_NO_MEMORY, ("p_ExactMatchCcNodeParam"));
-        return NULL;
-    }
-    memset(p_ExactMatchCcNodeParam, 0, sizeof(t_FmPcdCcNodeParams));
-
-    p_IndxHashCcNodeParam = (t_FmPcdCcNodeParams*)XX_Malloc(
-            sizeof(t_FmPcdCcNodeParams));
-    if (!p_IndxHashCcNodeParam)
-    {
-        XX_Free(p_ExactMatchCcNodeParam);
-        REPORT_ERROR(MAJOR, E_NO_MEMORY, ("p_IndxHashCcNodeParam"));
-        return NULL;
-    }
-    memset(p_IndxHashCcNodeParam, 0, sizeof(t_FmPcdCcNodeParams));
-
-    /* Calculate number of sets and number of ways of the hash table */
-    countMask = (uint16_t)(p_Param->hashResMask >> 4);
-    while (countMask)
-    {
-        onesCount++;
-        countMask = (uint16_t)(countMask >> 1);
-    }
-
-    numOfSets = (uint16_t)(1 << onesCount);
-    numOfWays = (uint16_t)DIV_CEIL(p_Param->maxNumOfKeys, numOfSets);
-
-    if (p_Param->maxNumOfKeys % numOfSets)
-        DBG(INFO, ("'maxNumOfKeys' is not a multiple of hash number of ways, so number of ways will be rounded up"));
-
-    if ((p_Param->statisticsMode == e_FM_PCD_CC_STATS_MODE_FRAME)
-            || (p_Param->statisticsMode == e_FM_PCD_CC_STATS_MODE_BYTE_AND_FRAME))
-    {
-        /* Allocating a statistics counters table that will be used by all
-         'miss' entries of the hash table */
-        h_MissStatsCounters = (t_Handle)FM_MURAM_AllocMem(
-                FmPcdGetMuramHandle(h_FmPcd), 2 * FM_PCD_CC_STATS_COUNTER_SIZE,
-                FM_PCD_CC_AD_TABLE_ALIGN);
-        if (!h_MissStatsCounters)
-        {
-            REPORT_ERROR(MAJOR, E_NO_MEMORY, ("MURAM allocation for statistics table for hash miss"));
-            XX_Free(p_IndxHashCcNodeParam);
-            XX_Free(p_ExactMatchCcNodeParam);
-            return NULL;
-        }
-        memset(h_MissStatsCounters, 0, (2 * FM_PCD_CC_STATS_COUNTER_SIZE));
-
-        /* Always enable statistics for 'miss', so that a statistics AD will be
-         initialized from the start. We'll store the requested 'statistics enable'
-         value and it will be used when statistics are read by the user. */
-        statsEnForMiss = p_Param->ccNextEngineParamsForMiss.statisticsEn;
-        p_Param->ccNextEngineParamsForMiss.statisticsEn = TRUE;
-    }
-
-    /* Building exact-match node params, will be used to create the hash buckets */
-    p_ExactMatchCcNodeParam->extractCcParams.type = e_FM_PCD_EXTRACT_NON_HDR;
-
-    p_ExactMatchCcNodeParam->extractCcParams.extractNonHdr.src =
-            e_FM_PCD_EXTRACT_FROM_KEY;
-    p_ExactMatchCcNodeParam->extractCcParams.extractNonHdr.action =
-            e_FM_PCD_ACTION_EXACT_MATCH;
-    p_ExactMatchCcNodeParam->extractCcParams.extractNonHdr.offset = 0;
-    p_ExactMatchCcNodeParam->extractCcParams.extractNonHdr.size =
-            p_Param->matchKeySize;
-
-    p_ExactMatchCcNodeParam->keysParams.maxNumOfKeys = numOfWays;
-    p_ExactMatchCcNodeParam->keysParams.maskSupport = FALSE;
-    p_ExactMatchCcNodeParam->keysParams.statisticsMode =
-            p_Param->statisticsMode;
-    p_ExactMatchCcNodeParam->keysParams.numOfKeys = 0;
-    p_ExactMatchCcNodeParam->keysParams.keySize = p_Param->matchKeySize;
-    p_ExactMatchCcNodeParam->keysParams.ccNextEngineParamsForMiss =
-            p_Param->ccNextEngineParamsForMiss;
-
-    p_HashKeyParams = p_IndxHashCcNodeParam->keysParams.keyParams;
-
-    for (i = 0; i < numOfSets; i++)
-    {
-        /* Each exact-match node will be marked as a 'bucket' and provided with
-           a pointer to statistics counters, to be used for 'miss' entry
-           statistics */
-        p_CcNode = (t_FmPcdCcNode *)XX_Malloc(sizeof(t_FmPcdCcNode));
-        if (!p_CcNode)
-            break;
-        memset(p_CcNode, 0, sizeof(t_FmPcdCcNode));
-
-        p_CcNode->isHashBucket = TRUE;
-        p_CcNode->h_MissStatsCounters = h_MissStatsCounters;
-
-        err = MatchTableSet(h_FmPcd, p_CcNode, p_ExactMatchCcNodeParam);
-        if (err)
-            break;
-
-        p_HashKeyParams[i].ccNextEngineParams.nextEngine = e_FM_PCD_CC;
-        p_HashKeyParams[i].ccNextEngineParams.statisticsEn = FALSE;
-        p_HashKeyParams[i].ccNextEngineParams.params.ccParams.h_CcNode =
-                p_CcNode;
-    }
-
-    if (i < numOfSets)
-    {
-        for (i = i - 1; i >= 0; i--)
-            FM_PCD_MatchTableDelete(
-                    p_HashKeyParams[i].ccNextEngineParams.params.ccParams.h_CcNode);
-
-        FM_MURAM_FreeMem(FmPcdGetMuramHandle(h_FmPcd), h_MissStatsCounters);
-
-        REPORT_ERROR(MAJOR, E_NULL_POINTER, NO_MSG);
-        XX_Free(p_IndxHashCcNodeParam);
-        XX_Free(p_ExactMatchCcNodeParam);
-        return NULL;
-    }
-
-    /* Creating indexed-hash CC node */
-    p_IndxHashCcNodeParam->extractCcParams.type = e_FM_PCD_EXTRACT_NON_HDR;
-    p_IndxHashCcNodeParam->extractCcParams.extractNonHdr.src =
-            e_FM_PCD_EXTRACT_FROM_HASH;
-    p_IndxHashCcNodeParam->extractCcParams.extractNonHdr.action =
-            e_FM_PCD_ACTION_INDEXED_LOOKUP;
-    p_IndxHashCcNodeParam->extractCcParams.extractNonHdr.icIndxMask =
-            p_Param->hashResMask;
-    p_IndxHashCcNodeParam->extractCcParams.extractNonHdr.offset =
-            p_Param->hashShift;
-    p_IndxHashCcNodeParam->extractCcParams.extractNonHdr.size = 2;
-
-    p_IndxHashCcNodeParam->keysParams.maxNumOfKeys = numOfSets;
-    p_IndxHashCcNodeParam->keysParams.maskSupport = FALSE;
-    p_IndxHashCcNodeParam->keysParams.statisticsMode =
-            e_FM_PCD_CC_STATS_MODE_NONE;
-    /* Number of keys of this node is number of sets of the hash */
-    p_IndxHashCcNodeParam->keysParams.numOfKeys = numOfSets;
-    p_IndxHashCcNodeParam->keysParams.keySize = 2;
-
-    p_CcNodeHashTbl = FM_PCD_MatchTableSet(h_FmPcd, p_IndxHashCcNodeParam);
-
-    if (p_CcNodeHashTbl)
-    {
-        p_CcNodeHashTbl->kgHashShift = p_Param->kgHashShift;
-
-        /* Storing the allocated counters for buckets 'miss' in the hash table
-         and if statistics for miss were enabled. */
-        p_CcNodeHashTbl->h_MissStatsCounters = h_MissStatsCounters;
-        p_CcNodeHashTbl->statsEnForMiss = statsEnForMiss;
-    }
+#ifdef FM_CC_DEBUG
+    disp_ht_params(p_Param);
+#endif //FM_CC_DEBUG
 
-    XX_Free(p_IndxHashCcNodeParam);
-    XX_Free(p_ExactMatchCcNodeParam);
-
-    return p_CcNodeHashTbl;
+#ifndef USE_ENHANCED_EHASH
+#if (DPAA_VERSION >= 11)
+    if (p_Param->externalHash) 
+        return ExternalHashTableSet(h_FmPcd, p_Param);
+    else
+#endif /* (DPAA_VERSION >= 11) */
+        return InternalHashTableSet(h_FmPcd, p_Param);
+#else
+        return ExternalHashTableSet(h_FmPcd, p_Param);
+#endif // USE_ENHANCED_EHASH
 }
 
 t_Error FM_PCD_HashTableDelete(t_Handle h_HashTbl)
 {
     t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
-    t_Handle h_FmPcd;
-    t_Handle *p_HashBuckets, h_MissStatsCounters;
-    uint16_t i, numOfBuckets;
-    t_Error err;
 
     SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
 
-    /* Store all hash buckets before the hash is freed */
-    numOfBuckets = p_HashTbl->numOfKeys;
-
-    p_HashBuckets = (t_Handle *)XX_Malloc(numOfBuckets * sizeof(t_Handle));
-    if (!p_HashBuckets)
-        RETURN_ERROR(MAJOR, E_NO_MEMORY, NO_MSG);
-
-    for (i = 0; i < numOfBuckets; i++)
-        p_HashBuckets[i] =
-                p_HashTbl->keyAndNextEngineParams[i].nextEngineParams.params.ccParams.h_CcNode;
-
-    h_FmPcd = p_HashTbl->h_FmPcd;
-    h_MissStatsCounters = p_HashTbl->h_MissStatsCounters;
-
-    /* Free the hash */
-    err = FM_PCD_MatchTableDelete(p_HashTbl);
-
-    /* Free each hash bucket */
-    for (i = 0; i < numOfBuckets; i++)
-        err |= FM_PCD_MatchTableDelete(p_HashBuckets[i]);
-
-    XX_Free(p_HashBuckets);
-
-    /* Free statistics counters for 'miss', if these were allocated */
-    if (h_MissStatsCounters)
-        FM_MURAM_FreeMem(FmPcdGetMuramHandle(h_FmPcd), h_MissStatsCounters);
-
-    if (err)
-        RETURN_ERROR(MAJOR, err, NO_MSG);
-
-    return E_OK;
+#ifndef USE_ENHANCED_EHASH
+#if (DPAA_VERSION >= 11)
+    if (p_HashTbl->externalHash)
+        return ExternalHashTableDelete(p_HashTbl);
+    else
+#endif /* (DPAA_VERSION >= 11) */
+        return InternalHashTableDelete(p_HashTbl);
+#else
+        return -1; // delete table code not added
+#endif // USE_ENHANCED_EHASH
 }
 
 t_Error FM_PCD_HashTableAddKey(t_Handle h_HashTbl, uint8_t keySize,
                                t_FmPcdCcKeyParams *p_KeyParams)
 {
     t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
-    t_Handle h_HashBucket;
-    uint8_t bucketIndex;
-    uint16_t lastIndex;
-    t_Error err;
 
     SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
     SANITY_CHECK_RETURN_ERROR(p_KeyParams, E_NULL_POINTER);
@@ -7398,38 +9797,33 @@ t_Error FM_PCD_HashTableAddKey(t_Handle h_HashTbl, uint8_t keySize,
         RETURN_ERROR(MAJOR, E_INVALID_VALUE,
                      ("Keys masks not supported for hash table"));
 
-    err = FM_PCD_MatchTableGetIndexedHashBucket(p_HashTbl, keySize,
-                                                p_KeyParams->p_Key,
-                                                p_HashTbl->kgHashShift,
-                                                &h_HashBucket, &bucketIndex,
-                                                &lastIndex);
-    if (err)
-        RETURN_ERROR(MAJOR, err, NO_MSG);
-
-    return FM_PCD_MatchTableAddKey(h_HashBucket, FM_PCD_LAST_KEY_INDEX, keySize,
-                                   p_KeyParams);
+#ifndef USE_ENHANCED_EHASH
+#if (DPAA_VERSION >= 11)
+    if (p_HashTbl->externalHash)
+        return ExternalHashTableAddKey(h_HashTbl, keySize, p_KeyParams);
+    else
+#endif /* (DPAA_VERSION >= 11) */
+        return InternalHashTableAddKey(h_HashTbl, keySize, p_KeyParams);
+#else
+        return ExternalHashTableAddKey(h_HashTbl, keySize, p_KeyParams);
+#endif // USE_ENHANCED_EHASH
 }
 
+#ifndef USE_ENHANCED_EHASH
 t_Error FM_PCD_HashTableRemoveKey(t_Handle h_HashTbl, uint8_t keySize,
                                   uint8_t *p_Key)
 {
     t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
-    t_Handle h_HashBucket;
-    uint8_t bucketIndex;
-    uint16_t lastIndex;
-    t_Error err;
 
     SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
     SANITY_CHECK_RETURN_ERROR(p_Key, E_NULL_POINTER);
 
-    err = FM_PCD_MatchTableGetIndexedHashBucket(p_HashTbl, keySize, p_Key,
-                                                p_HashTbl->kgHashShift,
-                                                &h_HashBucket, &bucketIndex,
-                                                &lastIndex);
-    if (err)
-        RETURN_ERROR(MAJOR, err, NO_MSG);
-
-    return FM_PCD_MatchTableFindNRemoveKey(h_HashBucket, keySize, p_Key, NULL);
+#if (DPAA_VERSION >= 11)
+    if (p_HashTbl->externalHash)
+        return ExternalHashTableRemoveKey(h_HashTbl, keySize, p_Key);
+    else
+#endif /* (DPAA_VERSION >= 11) */
+        return InternalHashTableRemoveKey(h_HashTbl, keySize, p_Key);
 }
 
 t_Error FM_PCD_HashTableModifyNextEngine(
@@ -7437,86 +9831,41 @@ t_Error FM_PCD_HashTableModifyNextEngine(
         t_FmPcdCcNextEngineParams *p_FmPcdCcNextEngineParams)
 {
     t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
-    t_Handle h_HashBucket;
-    uint8_t bucketIndex;
-    uint16_t lastIndex;
-    t_Error err;
 
     SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
     SANITY_CHECK_RETURN_ERROR(p_Key, E_NULL_POINTER);
     SANITY_CHECK_RETURN_ERROR(p_FmPcdCcNextEngineParams, E_NULL_POINTER);
 
-    err = FM_PCD_MatchTableGetIndexedHashBucket(p_HashTbl, keySize, p_Key,
-                                                p_HashTbl->kgHashShift,
-                                                &h_HashBucket, &bucketIndex,
-                                                &lastIndex);
-    if (err)
-        RETURN_ERROR(MAJOR, err, NO_MSG);
-
-    return FM_PCD_MatchTableFindNModifyNextEngine(h_HashBucket, keySize, p_Key,
-                                                  NULL,
-                                                  p_FmPcdCcNextEngineParams);
+#if (DPAA_VERSION >= 11)
+    if (p_HashTbl->externalHash)
+        return ExternalHashTableModifyNextEngine(h_HashTbl, keySize, p_Key, p_FmPcdCcNextEngineParams);
+    else
+#endif /* (DPAA_VERSION >= 11) */
+        return InternalHashTableModifyNextEngine(h_HashTbl, keySize, p_Key, p_FmPcdCcNextEngineParams);
 }
+#endif // USE_ENHANCED_EHASH
 
 t_Error FM_PCD_HashTableModifyMissNextEngine(
         t_Handle h_HashTbl,
         t_FmPcdCcNextEngineParams *p_FmPcdCcNextEngineParams)
 {
+#ifndef USE_ENHANCED_EHASH
     t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
-    t_Handle h_HashBucket;
-    uint8_t i;
-    bool nullifyMissStats = FALSE;
-    t_Error err;
 
     SANITY_CHECK_RETURN_ERROR(h_HashTbl, E_INVALID_HANDLE);
     SANITY_CHECK_RETURN_ERROR(p_FmPcdCcNextEngineParams, E_NULL_POINTER);
 
-    if ((!p_HashTbl->h_MissStatsCounters)
-            && (p_FmPcdCcNextEngineParams->statisticsEn))
-        RETURN_ERROR(
-                MAJOR,
-                E_CONFLICT,
-                ("Statistics are requested for a key, but statistics mode was set"
-                "to 'NONE' upon initialization"));
-
-    if (p_HashTbl->h_MissStatsCounters)
-    {
-        if ((!p_HashTbl->statsEnForMiss)
-                && (p_FmPcdCcNextEngineParams->statisticsEn))
-            nullifyMissStats = TRUE;
-
-        if ((p_HashTbl->statsEnForMiss)
-                && (!p_FmPcdCcNextEngineParams->statisticsEn))
-        {
-            p_HashTbl->statsEnForMiss = FALSE;
-            p_FmPcdCcNextEngineParams->statisticsEn = TRUE;
-        }
-    }
-
-    for (i = 0; i < p_HashTbl->numOfKeys; i++)
-    {
-        h_HashBucket =
-                p_HashTbl->keyAndNextEngineParams[i].nextEngineParams.params.ccParams.h_CcNode;
-
-        err = FM_PCD_MatchTableModifyMissNextEngine(h_HashBucket,
-                                                    p_FmPcdCcNextEngineParams);
-        if (err)
-            RETURN_ERROR(MAJOR, err, NO_MSG);
-    }
-
-    if (nullifyMissStats)
-    {
-        memset(p_HashTbl->h_MissStatsCounters, 0,
-               (2 * FM_PCD_CC_STATS_COUNTER_SIZE));
-        memset(p_HashTbl->h_MissStatsCounters, 0,
-               (2 * FM_PCD_CC_STATS_COUNTER_SIZE));
-        p_HashTbl->statsEnForMiss = TRUE;
-    }
-
-    return E_OK;
+#if (DPAA_VERSION >= 11)
+    if (p_HashTbl->externalHash)
+        return ExternalHashTableModifyMissNextEngine(h_HashTbl, p_FmPcdCcNextEngineParams);
+    else
+#endif /* (DPAA_VERSION >= 11) */
+        return InternalHashTableModifyMissNextEngine(h_HashTbl, p_FmPcdCcNextEngineParams);
+#else
+        return ExternalHashTableModifyMissNextEngine(h_HashTbl, p_FmPcdCcNextEngineParams);
+#endif
 }
 
-
 t_Error FM_PCD_HashTableGetMissNextEngine(
         t_Handle h_HashTbl,
         t_FmPcdCcNextEngineParams *p_FmPcdCcNextEngineParams)
@@ -7526,6 +9875,11 @@ t_Error FM_PCD_HashTableGetMissNextEngine(
 
     SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
 
+#if (DPAA_VERSION >= 11)
+    if (p_HashTbl->externalHash)
+        return E_NOT_SUPPORTED;
+#endif /* (DPAA_VERSION >= 11) */
+
     /* Miss next engine of each bucket was initialized with the next engine of the hash table */
     p_HashBucket =
             p_HashTbl->keyAndNextEngineParams[0].nextEngineParams.params.ccParams.h_CcNode;
@@ -7537,6 +9891,23 @@ t_Error FM_PCD_HashTableGetMissNextEngine(
     return E_OK;
 }
 
+t_Error FM_PCD_HashTableModifyMissMonitorAddr(
+        t_Handle h_HashTbl,
+        uintptr_t monitorAddr)
+{
+    t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
+
+    SANITY_CHECK_RETURN_ERROR(h_HashTbl, E_INVALID_HANDLE);
+    SANITY_CHECK_RETURN_ERROR(monitorAddr, E_NULL_POINTER);
+
+#if (DPAA_VERSION >= 11)
+    if (p_HashTbl->externalHash)
+        return ExternalHashTableModifyMissMonitorAddr(h_HashTbl, monitorAddr);
+    else
+#endif /* (DPAA_VERSION >= 11) */
+    	return E_NOT_SUPPORTED;
+}
+
 t_Error FM_PCD_HashTableFindNGetKeyStatistics(
         t_Handle h_HashTbl, uint8_t keySize, uint8_t *p_Key,
         t_FmPcdCcKeyStatistics *p_KeyStatistics)
@@ -7551,8 +9922,13 @@ t_Error FM_PCD_HashTableFindNGetKeyStatistics(
     SANITY_CHECK_RETURN_ERROR(p_Key, E_NULL_POINTER);
     SANITY_CHECK_RETURN_ERROR(p_KeyStatistics, E_NULL_POINTER);
 
+#if (DPAA_VERSION >= 11)
+    if (p_HashTbl->externalHash)
+        return E_NOT_SUPPORTED;
+#endif /* (DPAA_VERSION >= 11) */
+
     err = FM_PCD_MatchTableGetIndexedHashBucket(p_HashTbl, keySize, p_Key,
-                                                p_HashTbl->kgHashShift,
+                                                0,
                                                 &h_HashBucket, &bucketIndex,
                                                 &lastIndex);
     if (err)
@@ -7571,6 +9947,11 @@ t_Error FM_PCD_HashTableGetMissStatistics(
     SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
     SANITY_CHECK_RETURN_ERROR(p_MissStatistics, E_NULL_POINTER);
 
+#if (DPAA_VERSION >= 11)
+    if (p_HashTbl->externalHash)
+        return E_NOT_SUPPORTED;
+#endif /* (DPAA_VERSION >= 11) */
+
     if (!p_HashTbl->statsEnForMiss)
         RETURN_ERROR(MAJOR, E_INVALID_STATE,
                      ("Statistics were not enabled for miss"));
@@ -7580,3 +9961,148 @@ t_Error FM_PCD_HashTableGetMissStatistics(
 
     return FM_PCD_MatchTableGetMissStatistics(h_HashBucket, p_MissStatistics);
 }
+
+t_Error FM_PCD_HashTableGetKeyAging(t_Handle h_HashTbl,
+                                    uint8_t *p_Key,
+                                    uint8_t keySize,
+                                    bool reset,
+                                    bool *p_KeyAging)
+{
+    t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
+    t_FmPcd *p_FmPcd;
+    t_Handle h_HashBucket;
+    uint8_t bucketIndex;
+    uint16_t lastIndex, keyIndex;
+    uint32_t agingMask, keyAgingBit;
+    t_Error err;
+
+    SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
+    SANITY_CHECK_RETURN_ERROR(p_Key, E_NULL_POINTER);
+    SANITY_CHECK_RETURN_ERROR(p_KeyAging, E_NULL_POINTER);
+    p_FmPcd = (t_FmPcd *)p_HashTbl->h_FmPcd;
+    SANITY_CHECK_RETURN_ERROR(p_FmPcd, E_INVALID_HANDLE);
+    SANITY_CHECK_RETURN_ERROR(p_FmPcd->h_Hc, E_INVALID_HANDLE);
+
+#if (DPAA_VERSION >= 11)
+    if (p_HashTbl->externalHash)
+        return E_NOT_SUPPORTED;
+#endif /* (DPAA_VERSION >= 11) */
+
+    err = FM_PCD_MatchTableGetIndexedHashBucket(p_HashTbl, keySize, p_Key,
+                                                0,
+                                                &h_HashBucket, &bucketIndex,
+                                                &lastIndex);
+    if (err)
+        RETURN_ERROR(MAJOR, err, NO_MSG);
+
+    if (!((t_FmPcdCcNode *)h_HashBucket)->agingSupport)
+        RETURN_ERROR(MAJOR, E_INVALID_STATE, ("Aging support was not enabled for this hash table"));
+
+    if (!FmPcdLockTryLockAll(p_FmPcd))
+    {
+        DBG(TRACE, ("FmPcdLockTryLockAll failed"));
+        return ERROR_CODE(E_BUSY);
+    }
+
+    err = FindKeyIndex(h_HashBucket, keySize, p_Key, NULL, &keyIndex);
+    if (GET_ERROR_TYPE(err) != E_OK)
+    {
+        FmPcdLockUnlockAll(p_FmPcd);
+        RETURN_ERROR(
+                MAJOR,
+                err,
+                ("The received key and mask pair was not found in the match table of the provided node"));
+    }
+
+    err = GetAgingMask(p_FmPcd, h_HashBucket, keyIndex, reset, &agingMask);
+
+    keyAgingBit = (0x80000000 >> keyIndex);
+    *p_KeyAging = ((agingMask & keyAgingBit) ? TRUE : FALSE);
+
+    FmPcdLockUnlockAll(p_FmPcd);
+
+    switch(GET_ERROR_TYPE(err))
+    {
+        case E_OK:
+            return E_OK;
+
+        case E_BUSY:
+            DBG(TRACE, ("E_BUSY error"));
+            return ERROR_CODE(E_BUSY);
+
+        default:
+            RETURN_ERROR(MAJOR, err, NO_MSG);
+    }
+}
+
+t_Error FM_PCD_HashTableGetBucketAging(t_Handle h_HashTbl,
+                                       uint16_t bucketId,
+                                       bool reset,
+                                       uint32_t *p_BucketAgingMask,
+                                       uint8_t *agedKeysArray[31])
+{
+    t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
+    t_FmPcd *p_FmPcd;
+    t_FmPcdCcNode *p_HashBucket;
+    uint32_t tmpMask, keyIndex = 0, indx = 0;
+    t_Error err;
+
+    SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
+    p_FmPcd = (t_FmPcd *)p_HashTbl->h_FmPcd;
+    SANITY_CHECK_RETURN_ERROR(p_FmPcd, E_INVALID_HANDLE);
+    SANITY_CHECK_RETURN_ERROR(p_FmPcd->h_Hc, E_INVALID_HANDLE);
+
+#if (DPAA_VERSION >= 11)
+    if (p_HashTbl->externalHash)
+        return E_NOT_SUPPORTED;
+#endif /* (DPAA_VERSION >= 11) */
+
+    p_HashBucket = (t_FmPcdCcNode *)(p_HashTbl->keyAndNextEngineParams[bucketId].nextEngineParams.params.ccParams.h_CcNode);
+
+    if (!p_HashBucket->agingSupport)
+        RETURN_ERROR(MAJOR, E_INVALID_STATE, ("Aging support was not enabled for this hash table"));
+
+    if (!FmPcdLockTryLockAll(p_FmPcd))
+    {
+        DBG(TRACE, ("FmPcdLockTryLockAll failed"));
+        return ERROR_CODE(E_BUSY);
+    }
+
+    err = GetAgingMask(p_FmPcd, p_HashBucket, FM_PCD_LAST_KEY_INDEX, reset, p_BucketAgingMask);
+
+    /* If the user provided a valid pointer, the aged keys will be copied
+       into the provided array of pointers */
+    if ((agedKeysArray) && (*p_BucketAgingMask))
+    {
+        tmpMask = *p_BucketAgingMask;
+
+        while (tmpMask)
+        {
+            /* If a bit is set in the aging mask and it doesn't correspond to miss entry,
+               copy the key into the aged keys array */
+            if ((tmpMask & 0x80000000) && (keyIndex != p_HashBucket->numOfKeys))
+            {
+                memcpy(agedKeysArray[indx], p_HashBucket->keyAndNextEngineParams[keyIndex].key, p_HashBucket->userSizeOfExtraction);
+                indx++;
+            }
+
+            tmpMask = (tmpMask << 1);
+            keyIndex++;
+        }
+    }
+
+    FmPcdLockUnlockAll(p_FmPcd);
+
+    switch(GET_ERROR_TYPE(err))
+    {
+        case E_OK:
+            return E_OK;
+
+        case E_BUSY:
+            DBG(TRACE, ("E_BUSY error"));
+            return ERROR_CODE(E_BUSY);
+
+        default:
+            RETURN_ERROR(MAJOR, err, NO_MSG);
+    }
+}
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_cc.h b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_cc.h
index 3456bb565fd7..8271c0321fa9 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_cc.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_cc.h
@@ -132,6 +132,43 @@
 #define CC_PC_ILLEGAL                       0xff
 #define CC_SIZE_ILLEGAL                     0
 
+#if (DPAA_VERSION >= 11)
+#define FM_PCD_AD_FE_ENTER_ALLOCATE         0x00800000
+#define FM_PCD_AD_FE_ENTER_OPCODE           0x000000F6
+
+#define FM_PCD_FE_TYPE_MASK           		0x3f000000
+#define FM_PCD_FE_TYPE_HM           		0x01000000
+#define FM_PCD_FE_TYPE_ENQ           		0x02000000
+#define FM_PCD_FE_TYPE_EXIT           		0x03000000
+#define FM_PCD_FE_TYPE_MUX           		0x04000000
+#define FM_PCD_FE_TYPE_TRANSITION      		0x05000000
+#define FM_PCD_FE_TYPE_EXT_HASH      		0x06000000
+
+#define FM_PCD_FE_WS_OFFSET_MASK       		0x0000ffff
+#define FM_PCD_FE_NEXT_FE_ADDR_MASK    		0x00ffffff
+
+#define FM_PCD_FE_T_HM_PAHM         		0x00800000
+
+#define FM_PCD_FE_T_ENQ_MPPN                0x00800000
+#define FM_PCD_FE_T_ENQ_PP         			0x00040000
+#define FM_PCD_FE_T_ENQ_SP         			0x00020000
+#define FM_PCD_FE_T_ENQ_FQID       			0x00010000
+#define FM_PCD_FE_T_ENQ_NIA_MASK   			0x00ffffff
+
+#define FM_PCD_FE_T_EXIT_DEALLOCATE        	0x00800000
+
+#define FM_PCD_FE_T_TRANSITION_DEALLOCATE   0x00800000
+#define FM_PCD_FE_T_TRANSITION_AD_FROM_WS   0x00400000
+
+#define FM_PCD_FE_T_HASH_UPDATE_TS          0x00020000
+#define FM_PCD_FE_T_HASH_UPDATE_STATS       0x00010000
+#define FM_PCD_FE_T_HASH_LIODN_MASK         0x0000003F
+#define FM_PCD_FE_T_HASH_LIODN_SHIFT        56
+#define FM_PCD_FE_T_HASH_ELIODN_MASK        0x000003c0
+#define FM_PCD_FE_T_HASH_ELIODN_SHIFT       38
+
+#endif /* (DPAA_VERSION >= 11) */
+
 #define FM_PCD_CC_KEYS_MATCH_TABLE_ALIGN    16
 #define FM_PCD_CC_AD_TABLE_ALIGN            16
 #define FM_PCD_CC_AD_ENTRY_SIZE             16
@@ -186,6 +223,9 @@ typedef uint32_t ccPrivateInfo_t; /**< private info of CC: */
 #define CC_PRIVATE_INFO_IC_DEQ_FQID_INDEX_LOOKUP   0x10000000
 
 #define CC_BUILD_AGING_MASK(numOfKeys)      ((((1LL << ((numOfKeys) + 1)) - 1)) << (31 - (numOfKeys)))
+
+#define CC_EXT_HASH_BUCKET_SIZE					256
+
 /***********************************************************************/
 /*          Memory map                                                 */
 /***********************************************************************/
@@ -193,6 +233,31 @@ typedef uint32_t ccPrivateInfo_t; /**< private info of CC: */
 #pragma pack(push,1)
 #endif /* defined(__MWERKS__) && ... */
 
+#if (DPAA_VERSION >= 11)
+typedef _Packed struct t_ExtHashFe {
+    volatile uint32_t misc;
+    volatile uint16_t hashMask;
+    volatile uint8_t contextSize;
+    volatile uint8_t hashShift;
+    volatile uint32_t liodnTableAndTablePtrHi;
+    volatile uint32_t tablePtrLow;
+    volatile uint32_t missResultPtr;
+    volatile uint32_t nextFEPtr;
+    volatile uint32_t missNextFEPtr;
+} _PackedType t_ExtHashFe;
+
+typedef struct
+{
+    volatile uint32_t general;
+    volatile uint32_t maskOffset;
+    volatile uint32_t addrHigh;
+    volatile uint32_t addrLow;
+    volatile uint32_t missResultPointer;
+    volatile uint32_t nextFEPointer;
+    volatile uint32_t missNextFEPointer;
+} t_FEOfTypeHash;
+#endif /* (DPAA_VERSION >= 11) */
+
 typedef struct
 {
     volatile uint32_t fqid;
@@ -232,6 +297,32 @@ typedef union
 /*  Driver's internal structures                                       */
 /***********************************************************************/
 
+#pragma pack(push,1)
+typedef struct
+{
+    uint32_t		next_bucket_addr;
+    uint32_t		prev_last_bucket_ptr;
+    uint8_t			not_last;
+    uint8_t			valid_keys;
+    uint16_t		reserved1[0x3];
+    uint8_t			key_result[0xF0];
+} t_FmExtHashBucket;
+
+typedef struct {
+	uint64_t contex_addr;
+	uint64_t monitoring_addr;
+} t_FmExtHashResult;
+
+#pragma pack(pop)
+
+
+typedef struct
+{
+	uint8_t *bucket_pool_base_ptr;
+	int last_bucket;
+	t_FmExtHashBucket **bucket_stack;
+} t_FmExtHashBucketPool;
+
 typedef struct t_FmPcdStatsObj
 {
     t_Handle        h_StatsAd;
@@ -284,6 +375,7 @@ typedef struct
     t_Handle            h_FrmReplicForRmv;
 #endif /* (DPAA_VERSION >= 11) */
     bool                tree;
+    e_ModifyState   modifyState;
 
     t_FmPcdCcKeyAndNextEngineParams  keyAndNextEngineParams[CC_MAX_NUM_OF_KEYS];
 } t_FmPcdModifyCcKeyAdditionalParams;
@@ -294,6 +386,37 @@ typedef struct
     t_Handle    h_CcNode;
 } t_CcNextEngineInfo;
 
+#if (DPAA_VERSION >= 11)
+typedef struct {
+    uint8_t     *p_Context;
+    t_List      node;
+} t_FmPcdCcNodeFEContextObj;
+#define FM_PCD_FE_CONTEXT_OBJ(ptr)  LIST_OBJECT(ptr, t_FmPcdCcNodeFEContextObj, node)
+
+typedef struct
+{
+    bool                allocateBuffer;
+    t_ExtHashFe         *p_FE;
+    t_Handle            h_MissFE;
+    t_ExtHashResult     *p_MissResult;
+    uint8_t             dataMemId;
+    uint16_t            dataLiodnOffset;
+    uintptr_t           missMonitorAddr;
+    bool                drvAllocMissMonitorAddr;
+    t_List              availableContextLst;
+    t_List              usedContextLst;
+ 
+	t_FmExtHashBucketPool hash_bucket_pool;
+	t_FmExtHashBucket 	*table_base_ptr;
+	uint16_t 			hash_mask;
+	uint8_t 			hash_size;
+	uint8_t 			crc_shift;
+	uint8_t 			key_size;
+	uint8_t 			aligned_key_size;
+	uint8_t 			max_ways;
+} t_FmPcdCcNodeExtHashInfo;
+#endif /* (DPAA_VERSION >= 11) */
+
 typedef struct
 {
     uint16_t            numOfKeys;
@@ -307,6 +430,7 @@ typedef struct
     uint32_t            countersArraySize;
 
     bool                isHashBucket;               /**< Valid for match table node that is a bucket of a hash table only */
+    bool                agingSupport;               /**< Valid for match table node that is a bucket of a hash table only */
     t_Handle            h_MissStatsCounters;        /**< Valid for hash table node and match table that is a bucket;
                                                          Holds the statistics counters allocated by the hash table and
                                                          are shared by all hash table buckets; */
@@ -348,6 +472,12 @@ typedef struct
     uint32_t            shadowAction;
     uint8_t             userSizeOfExtraction;
     uint8_t             userOffset;
+ 
+#if (DPAA_VERSION >= 11)
+    bool                externalHash;
+    t_FmPcdCcNodeExtHashInfo extHashInfo;
+#endif /* (DPAA_VERSION >= 11) */
+
     uint8_t             kgHashShift;            /* used in hash-table */
 
     t_Handle            h_Spinlock;
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_cc_dbg.h b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_cc_dbg.h
new file mode 100644
index 000000000000..088eeba28943
--- /dev/null
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_cc_dbg.h
@@ -0,0 +1,1405 @@
+/*
+ * Copyright 2008-2012 Freescale Semiconductor Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+
+/******************************************************************************
+ @File          fm_cc_dbg.h
+
+ @Description   FM Coarse Classifier debug
+ *//***************************************************************************/
+
+#include <linux/slab.h>
+#include "fm_pcd_ext.h"
+//enable prints from FMD
+//#define FM_CC_DEBUG 		1
+
+//enable prints from host commands
+#define FM_CC_MURAM_DEBUG 	1
+	
+//table descriptor structure
+struct generic_5_off_ic_gmask {
+	union {
+		struct {
+			uint32_t cc_adbase:24;
+			uint32_t key_length:6;
+			uint32_t type:2;
+		}__attribute__((packed));
+		uint32_t word_0;
+	};
+	union {
+		struct {
+			uint32_t match_table_ptr:23;
+			uint32_t LM:1;
+			uint32_t match_table_entries_num:8;	
+		}__attribute__((packed));
+		uint32_t word_1;
+	};
+	union {	
+		struct {
+			uint32_t op_code:8;
+			uint32_t reserved:8;
+			uint32_t offset:8;
+			uint32_t offset_from_parse_result:8;
+		}__attribute__((packed));
+		uint32_t word_2;
+	};
+	uint32_t age_mask;
+}__attribute__((packed));
+
+//new class result descriptor structure
+struct new_class_res_desc {
+	union {
+		uint32_t word_0;
+		struct {
+			uint32_t fqid:24;
+			uint32_t rspid:6;
+			uint32_t type:2;
+		}__attribute__((packed));
+	};
+	union {
+		uint32_t word_1;
+		struct {
+			uint32_t next_ad_index:16;	
+			uint32_t policer_profile:8;	
+			uint32_t vspe:1;	
+			uint32_t resv:1;	
+			uint32_t nenq:1;	
+			uint32_t cwd:1;	
+			uint32_t nl:1;	
+			uint32_t fwd:1;	
+			uint32_t ebad:1;	
+			uint32_t ebd:1;	
+
+		}__attribute__((packed));
+	};
+	union {
+		uint32_t word_2;
+		struct {
+			uint32_t fpm_nia:24;
+			uint32_t ovom:1;
+			uint32_t no_cspen:1;
+			uint32_t resv_2:1;
+			uint32_t fr:1;
+			uint32_t resv_1:1;
+			uint32_t naden:1;
+			uint32_t stats_en:1;
+			uint32_t extended_mode:1;
+		}__attribute__((packed));
+	};
+	uint32_t word_3;
+};
+
+//statistics table descriptor structure
+struct stats_table_desc {
+	union {
+		uint32_t word_0;
+		struct {
+			uint32_t stats_prof_tbl_addr:24;
+			uint32_t reserved:8;
+			uint32_t type:2;
+		}__attribute__((packed));
+	};
+	uint32_t word_1;
+	union {
+		uint32_t word_2;
+		struct {
+			uint32_t opcode:8;
+			uint32_t reserved_1:5;
+			uint32_t cond_en:1;
+			uint32_t flr_en:1;
+			uint32_t nad_en:1;
+			uint32_t next_ad_index:16;
+		}__attribute__((packed));
+	};
+	union {
+		uint32_t word_3;
+		struct {
+			uint32_t stats_tbl_addr:24;
+			uint32_t reserved_2:8;
+		}__attribute__((packed));
+	};
+};
+
+//keep classification results descriptor structure
+struct keep_class_res_desc_ad {
+	union {
+		struct {
+			uint32_t reserved_1:29;
+			uint32_t PD:1;
+			uint32_t type:2;
+		}__attribute__((packed));
+		uint32_t word_0;
+	};
+	union {
+		struct {
+			uint32_t next_action_desc_index:16;
+			uint32_t reserved_2:16;
+		}__attribute__((packed));
+		uint32_t word_1;
+	};
+	union {
+		struct {
+			uint32_t fpm_nia:24;
+			uint32_t reserved_3:1;
+			uint32_t no_vspe:1;
+			uint32_t reserved_4:3;
+			uint32_t naden:1;
+			uint32_t statistics_enable:1;
+			uint32_t extended_mode:1;
+		}__attribute__((packed));
+		uint32_t word_2;
+	};
+	uint32_t statistic_counter;
+};
+
+//header modification table desc
+struct hmt_desc {
+	union {
+		struct {
+			uint32_t reserved_2:21;
+			uint32_t naden:1;
+			uint32_t pahm:1;
+			uint32_t reserved_1:7;
+			uint32_t type:2;
+		}__attribute__((packed));
+		uint32_t word_0;
+	};
+	union {
+		struct {
+			uint32_t internal_hmt_ptr:24;
+			uint32_t reserved_3:8;
+		}__attribute__((packed));
+		uint32_t word_1;
+	};
+	union {
+		struct {
+			uint32_t opcode:8;
+			uint32_t reserved_4:8;
+			uint32_t nextdescindex:16;
+		}__attribute__((packed));
+		uint32_t word_2;
+	};
+	uint32_t word_3;
+};
+
+//header removal header manipulation command
+struct hdr_removal_hmc {
+	union {
+		uint32_t word;
+		struct {
+			uint32_t hdrrmvoffset:8;
+			uint32_t hdrrmvsize:8;
+			uint32_t reserved:7;
+			uint32_t last:1;
+			uint32_t opcode:8;
+		}__attribute__((packed));
+	};
+};
+
+//header insert header manipulation command
+struct hdr_insert_hmc {
+	union {
+		uint32_t word;
+		struct {
+			uint32_t hdrinsoffset:8;
+			uint32_t hdrinssize:8;
+			uint32_t reserved:7;
+			uint32_t last:1;
+			uint32_t opcode:8;
+		}__attribute__((packed));
+	};
+};
+
+//header replace header manipulation command
+#define hdr_replace_hmc hdr_insert_hmc
+
+//internal header insert header manipulation command
+struct internal_hdr_insert_hmc {
+	union {
+		uint32_t word_0;
+		struct {
+			uint32_t hdrinsoffset:8;
+			uint32_t hdrinssize:8;
+			uint32_t reserved:7;
+			uint32_t last:1;
+			uint32_t opcode:8;
+		}__attribute__((packed));
+	};
+	union {
+		uint32_t word_1;
+		struct {
+			uint32_t hdrinsptr:24;
+			uint32_t reserved_1:8;
+		}__attribute__((packed));
+	};
+};
+//internal header replace header manipulation command
+#define internal_hdr_replace_hmc internal_hdr_insert_hmc
+
+//protocol specific header removal header manipulation command
+struct proto_specific_hdr_removal_hmc {
+	union {
+                uint32_t word;
+                struct {
+                        uint32_t reserved_1:16;
+                        uint32_t protospec_hdr_rmv_mode:4;
+                        uint32_t reserved:3;
+                        uint32_t last:1;
+                        uint32_t opcode:8;
+                }__attribute__((packed));
+        };
+};
+
+//protocol specific header insert header manipulation command
+struct proto_specific_hdr_insert_hmc {
+        union {
+                uint32_t word_0;
+                struct {
+                        uint32_t reserved_1:16;
+                        uint32_t protospec_hdr_ins_mode:4;
+                        uint32_t reserved:3;
+                        uint32_t last:1;
+                        uint32_t opcode:8;
+                }__attribute__((packed));
+        };
+        union {
+                uint32_t word_1;
+                struct {
+                        uint32_t inthdrptr:24;
+                        uint32_t hdrinssize:8;
+                }__attribute__((packed));
+        };
+
+
+};
+
+//vlan priority update header manipulation command
+struct vlan_priority_update_hmc {
+        union {
+                uint32_t word_0;
+	        struct {
+                        uint32_t vpri_def_value:3;
+                        uint32_t reserved_1:13;
+                        uint32_t vprihdr_rep_mode:3;
+                        uint32_t reserved:4;
+                        uint32_t last:1;
+                        uint32_t opcode:8;
+                }__attribute__((packed));
+        };
+        union {
+                uint32_t word_1;
+	        struct {
+			uint32_t int_hdr_rep_ptr:24;
+			uint32_t reserved_2:8;
+                }__attribute__((packed));
+        };
+};
+
+//local ipv4 update header manipulation command
+struct local_ipv4_update_hmc {
+        union {
+                uint32_t word;
+                struct {
+                        uint32_t ip_ttl:1;
+                        uint32_t ip_tos_mode:2;
+                        uint32_t reserved_1:2;
+                        uint32_t ip_dst:1;
+                        uint32_t ip_src:1;
+                        uint32_t ip_id_mode:1;
+                        uint32_t ip_tos:8;
+                        uint32_t reserved:7;
+                        uint32_t last:1;
+                        uint32_t opcode:8;
+                }__attribute__((packed));
+        };
+};
+
+
+//local tcp udp update header manipulation command
+struct local_tcp_udp_update_hmc {
+        union {
+                uint32_t word_0;
+                struct {
+                        uint32_t reserved:14;
+                        uint32_t tcp_udp_dst:1;
+                        uint32_t tcp_udp_src:1;
+                        uint32_t reserved_1:7;
+                        uint32_t last:1;
+                        uint32_t opcode:8;
+                }__attribute__((packed));
+        };
+        union {
+                uint32_t word_1;
+		struct {
+			uint32_t dst_port:16;
+			uint32_t src_port:16;
+		}__attribute__((packed));
+	};
+};
+
+
+//ipv6 header update header manipulation command
+struct ipv6_update_hmc {
+	union {
+		uint32_t word;
+		struct {
+			int32_t ip_hop_limit:1;
+			uint32_t ip_traffic_class_mode:2;
+			uint32_t reserved_1:3;
+			uint32_t ipdst:1;
+			uint32_t ipsrc:1;
+			uint32_t iptraffic_class:8;
+			uint32_t reserved:7;
+			uint32_t last:1;
+			uint32_t opcode:8;
+		}__attribute__((packed));;
+	};
+};
+
+//internal ipheader replace header manipulation command
+struct internal_iphdr_replace_hmc {
+	union {
+		uint32_t word_0;
+		struct {
+			uint32_t reserved:16;
+			uint32_t inl3smode:2;
+			uint32_t reserved_1:3;
+			int32_t ttl_hop_limit:1;
+			uint32_t ipid_mode:1;
+			uint32_t last:1;
+			uint32_t opcode:8;
+		}__attribute__((packed));
+	};
+	union {
+		uint32_t word_1;
+		struct {
+			uint32_t l3hdr_ptr:24;
+			uint32_t l3hdr_ins_size:8;
+		}__attribute__((packed));;
+	};
+	union {
+		uint32_t word_2;
+		struct {
+			uint32_t id_hdr_ptr:24;
+			uint32_t reserved_2:8;
+		}__attribute__((packed));
+	};
+};
+
+extern void *FmMurambaseAddr;
+static void display_pcd_cc_ad(void *ad);
+void display_cc_node(void *handle, const char *func_name);
+static void display_generic_5_off_ic_gmask(void *ptr);
+
+static void display_buf_data(void *dataptr, uint32_t size)
+{
+	uint32_t ii;
+	uint8_t *ptr;
+
+	ptr = (uint8_t *)dataptr;	
+	for (ii = 0; ii < size; ii++) {
+		if ((ii % 16) == 15) 
+			printk("%02x\n", *ptr);
+		else
+			printk("%02x ", *ptr);
+		ptr++;
+	}
+        if (ii % 16)
+		printk("\n");
+}
+
+static inline uint32_t swap_word(uint32_t *ptr)
+{
+	uint32_t val;
+	val =  ((*ptr >> 24) | (*ptr << 24) | 
+			((*ptr >> 8) & 0x0000ff00) |
+			((*ptr << 8) & 0xff0000));
+	return val;
+}
+
+#ifdef FM_CC_DEBUG 
+static void display_global_mask(t_FmPcdCcNode *ccnode)
+{
+	printk(KERN_CRIT "globalmask \t%p\n, size \t%d\n", 
+		ccnode->p_GlblMask, ccnode->glblMaskSize);
+	if (ccnode->p_GlblMask) {
+		display_buf_data (ccnode->p_GlblMask, ccnode->glblMaskSize);
+	}
+}
+	
+static void display_keymatch_table(t_FmPcdCcNode *ccnode)
+{
+	
+	uint32_t ii;
+	uint32_t keysize;
+	uint8_t *ptr;
+	t_FmPcd *p_FmPcd;
+
+	p_FmPcd = (t_FmPcd *)ccnode->h_FmPcd;
+	printk(KERN_CRIT "keymatchtable \t%p\n", ccnode->h_KeysMatchTable);
+	ii = (uint32_t)(XX_VirtToPhys(ccnode->h_KeysMatchTable) - 
+		p_FmPcd->physicalMuramBase);
+	printk(KERN_CRIT "keymatchtable in muram %08x\n", ii);
+	printk(KERN_CRIT "keysMatchTableMaxSize \t%d\n", 
+			ccnode->keysMatchTableMaxSize);
+	printk(KERN_CRIT "maxNumOfKeys \t%d\n", ccnode->maxNumOfKeys);
+	if (ccnode->lclMask)
+		printk(KERN_CRIT "local mask enabled\n");
+	else
+		printk(KERN_CRIT "No local mask\n");
+	keysize = (ccnode->ccKeySizeAccExtraction * sizeof(uint8_t));
+	printk(KERN_CRIT "keymatchtable in muram %08x, keysize %d, numkeys %d\n", 
+			ii, keysize, ccnode->numOfKeys);
+	ptr = (uint8_t *)ccnode->h_KeysMatchTable;
+	for (ii = 0; ii < ccnode->numOfKeys; ii++) {
+		printk("key %d::\n", ii);
+		display_buf_data((void *)ptr, keysize); 
+		if (ccnode->lclMask)
+			ptr += (2 * keysize);
+		else
+			ptr += keysize;
+	}
+}
+
+static void disp_ht_params(struct t_FmPcdHashTableParams *params)
+{
+	t_FmPcdCcNextEngineParams *missparams;
+	printk(KERN_CRIT "maxNumOfKeys\t%d\n", params->maxNumOfKeys);
+	printk(KERN_CRIT "statisticsMode\t%d\n", params->statisticsMode);
+	printk(KERN_CRIT "kgHashShift\t%d\n", params->kgHashShift);
+	printk(KERN_CRIT "hashResMask\t%d\n", params->hashResMask);
+	printk(KERN_CRIT "hashShift\t%d\n", params->hashShift);
+	printk(KERN_CRIT "matchKeySize\t%d\n", params->matchKeySize);
+	missparams = &params->ccNextEngineParamsForMiss;
+	printk(KERN_CRIT "h_Manip\t%p\n", missparams->h_Manip);
+	printk(KERN_CRIT "statisticsEn\t%d\n", missparams->statisticsEn);
+	switch(missparams->nextEngine) {
+		case e_FM_PCD_CC:
+			printk(KERN_CRIT "next eng - e_FM_PCD_CC\n"); 
+			printk(KERN_CRIT "next ccnode %p\n",
+				missparams->params.ccParams.h_CcNode);
+			break; 
+		case e_FM_PCD_PLCR:
+			printk(KERN_CRIT "next eng - e_FM_PCD_PLCR\n"); 
+			printk(KERN_CRIT "overrideParams %d\n",
+				missparams->params.plcrParams.overrideParams);
+			printk(KERN_CRIT "sharedProfile %d\n",
+				missparams->params.plcrParams.sharedProfile);
+			printk(KERN_CRIT "newFqid %d\n",
+				missparams->params.plcrParams.newFqid);
+			printk(KERN_CRIT "newRelativeStorageProfileId %d\n",
+			missparams->params.plcrParams.newRelativeStorageProfileId);
+			printk(KERN_CRIT "newFqid %d\n",
+				missparams->params.plcrParams.newFqid);
+			break; 
+		case e_FM_PCD_KG:
+			printk(KERN_CRIT "next eng - e_FM_PCD_KG\n"); 
+			printk(KERN_CRIT "overrideFqid %d\n",
+				missparams->params.kgParams.overrideFqid);
+			printk(KERN_CRIT "newFqid %d\n",
+				missparams->params.kgParams.newFqid);
+			printk(KERN_CRIT "newRelativeStorageProfileId %d\n",
+		         missparams->params.kgParams.newRelativeStorageProfileId);
+			printk(KERN_CRIT "h_DirectScheme %p\n",
+				missparams->params.kgParams.h_DirectScheme);
+			break; 
+		case e_FM_PCD_PRS:
+			printk(KERN_CRIT "next eng - e_FM_PCD_PRS\n"); 
+			break; 
+		case e_FM_PCD_FR:
+			printk(KERN_CRIT "next eng - e_FM_PCD_FR\n"); 
+			break; 
+		case e_FM_PCD_HASH:
+			printk(KERN_CRIT "next eng - e_FM_PCD_HASH\n"); 
+			break; 
+		case e_FM_PCD_DONE:
+			printk(KERN_CRIT "next eng - e_FM_PCD_DONE\n"); 
+			printk(KERN_CRIT "action %d\n",
+				missparams->params.enqueueParams.action);
+			printk(KERN_CRIT "overrideFqid %d\n",
+				missparams->params.enqueueParams.overrideFqid);
+			printk(KERN_CRIT "newFqid %d\n",
+				missparams->params.enqueueParams.newFqid);
+			printk(KERN_CRIT "newRelativeStorageProfileId %d\n",
+			missparams->params.enqueueParams.newRelativeStorageProfileId);
+			break;
+		default:
+			printk(KERN_CRIT "next eng %d is invalid\n",
+				missparams->nextEngine); 
+			break;
+	}
+}
+
+static void display_adtable(t_FmPcdCcNode *ccnode)
+{
+	uint32_t ii;
+	t_FmPcd *p_FmPcd;
+	uint8_t *ptr;
+
+	p_FmPcd = (t_FmPcd *)ccnode->h_FmPcd;
+	printk(KERN_CRIT "adtable \t%p\n", ccnode->h_AdTable);
+	ii = (uint32_t)((XX_VirtToPhys(ccnode->h_AdTable) - 
+		p_FmPcd->physicalMuramBase));
+	printk(KERN_CRIT "adtable in muram %08x\n", ii);
+	ptr = (uint8_t *)ccnode->h_AdTable;
+	for (ii = 0; ii < ccnode->numOfKeys; ii++) {
+		printk("ADENTRY %d::\n", ii);
+		display_pcd_cc_ad((uint32_t *)ptr);
+		ptr += FM_PCD_CC_AD_ENTRY_SIZE;
+	}
+}
+
+static void display_enq_params(t_FmPcdCcNextEnqueueParams *enq)
+{
+	printk(KERN_CRIT "action %08x\n", enq->action);
+	if (enq->overrideFqid)
+		printk(KERN_CRIT "Fqid override, new fqid %d(%08x)\n", 
+			enq->newFqid, enq->newFqid);
+	else 
+		printk(KERN_CRIT "No Fqid override\n");
+	printk(KERN_CRIT "newRelativeStorageProfileId %08x\n", 
+			enq->newRelativeStorageProfileId);
+}
+
+static void display_kg_params(t_FmPcdCcNextKgParams *kg)
+{
+	if (kg->overrideFqid)
+		printk(KERN_CRIT "Fqid override, new fqid %d(%08x)\n", 
+			kg->newFqid, kg->newFqid);
+	else 
+		printk(KERN_CRIT "No Fqid override\n");
+	printk(KERN_CRIT "newRelativeStorageProfileId %08x\n", 
+			kg->newRelativeStorageProfileId);
+	printk(KERN_CRIT "newscheme handle %p\n", 
+			kg->h_DirectScheme);
+}
+
+static void display_cc_params(t_FmPcdCcNextCcParams *cc)
+{
+	printk(KERN_CRIT "h_CcNode %p::\n", cc->h_CcNode);
+	display_cc_node((void *)cc->h_CcNode, __FUNCTION__);
+	
+}
+
+static void display_plcr_params(t_FmPcdCcNextPlcrParams *plcr)
+{
+	printk(KERN_CRIT "%s::fill this... plcr %p!!!!\n", __FUNCTION__, plcr);
+}
+
+static void display_next_engine(t_FmPcdCcNextEngineParams *nexteng)
+{
+	printk(KERN_CRIT "nextEngine %08x -> ", nexteng->nextEngine);
+
+	switch (nexteng->nextEngine) {
+		case e_FM_PCD_DONE:
+			{
+				t_FmPcdCcNextEnqueueParams *enq;
+				printk(KERN_CRIT "pcd done\n");
+				enq = (t_FmPcdCcNextEnqueueParams *)
+					&nexteng->params.enqueueParams;
+				display_enq_params(enq);
+				break;
+			}
+		case e_FM_PCD_KG:
+			{
+				t_FmPcdCcNextKgParams *kg;
+				printk(KERN_CRIT "keygen\n");
+				kg = &nexteng->params.kgParams;
+				display_kg_params(kg);
+				break;
+			}
+		case e_FM_PCD_CC:
+			{
+				t_FmPcdCcNextCcParams *cc;
+				printk(KERN_CRIT "coarse classification\n");
+				cc = &nexteng->params.ccParams;
+				display_cc_params(cc);
+				break;
+			}
+		case e_FM_PCD_PLCR:
+			{
+				t_FmPcdCcNextPlcrParams *plcr;
+				printk(KERN_CRIT "policer\n");
+				plcr = &nexteng->params.plcrParams;
+				display_plcr_params(plcr);
+				break;
+			}
+		case e_FM_PCD_PRS:
+			{
+				printk(KERN_CRIT "parser\n");
+				break;
+			}
+		default:
+			printk(KERN_CRIT "unknown type\n");
+			break;
+	}
+	printk(KERN_CRIT "h_Manip %p\n", nexteng->h_Manip);
+	printk(KERN_CRIT "statisticsEn %d\n", nexteng->statisticsEn);
+
+}
+
+static void display_next_engine_param(t_FmPcdCcNode *ccnode)
+{
+	uint32_t ii;
+	t_FmPcdCcKeyAndNextEngineParams *nextengparams;
+
+	nextengparams = &ccnode->keyAndNextEngineParams[0];	
+	for (ii = 0; ii < ccnode->numOfKeys; ii++) {
+		printk(KERN_CRIT "next eng param id %d\n", ii);
+		printk("key %d::", ii);
+		display_buf_data (&nextengparams->key[0], 
+			ccnode->ccKeySizeAccExtraction);
+		printk("mask %d::", ii);
+		display_buf_data (&nextengparams->mask[0], 
+			ccnode->ccKeySizeAccExtraction);
+		printk(KERN_CRIT "requiredAction %x, shadowAction %x\n",
+			nextengparams->requiredAction,
+			nextengparams->shadowAction);
+		display_next_engine(&nextengparams->nextEngineParams);
+		nextengparams++;
+	}
+}
+
+void display_cc_node(void *handle, const char *func_name)
+{
+	t_FmPcdCcNode *ccnode;
+
+	ccnode = (t_FmPcdCcNode *)handle;
+	printk(KERN_CRIT ">>>>>>>>\n%s::ccnode %p\n", func_name, ccnode);
+	if (!ccnode->externalHash) {
+		if (ccnode->maskSupport)
+			printk(KERN_CRIT "mask support enabled\n");
+		else
+			printk(KERN_CRIT "mask support disabled\n");
+		printk(KERN_CRIT "statisticsMode \t%d\n", ccnode->statisticsMode);
+		printk(KERN_CRIT "countersArraySize \t%d\n", ccnode->countersArraySize);
+		if (ccnode->isHashBucket)
+			printk(KERN_CRIT "node is a bucket of a hash table\n");
+		if (ccnode->glblMaskUpdated) {
+			printk(KERN_CRIT "global mask updated\n");
+			display_global_mask(ccnode);
+		} else
+			printk(KERN_CRIT "global mask not updated\n");
+		printk(KERN_CRIT "parseCode \t%d\n", ccnode->parseCode);
+		printk(KERN_CRIT "offset \t%d\n", ccnode->offset);
+		printk(KERN_CRIT "prsArrayOffset \t%d\n", ccnode->prsArrayOffset);
+		printk(KERN_CRIT "ccKeySizeAccExtraction \t%d\n", ccnode->ccKeySizeAccExtraction);
+		printk(KERN_CRIT "sizeOfExtraction \t%d\n", ccnode->sizeOfExtraction);
+
+		printk(KERN_CRIT "shadowAction %08x\n", ccnode->shadowAction);
+		printk(KERN_CRIT "userSizeOfExtraction %08x\n", ccnode->userSizeOfExtraction);
+		printk(KERN_CRIT "userOffset %08x\n", ccnode->userOffset);
+		printk(KERN_CRIT "kgHashShift %08x\n", ccnode->kgHashShift);
+
+		if (ccnode->h_KeysMatchTable) {
+			display_keymatch_table(ccnode);
+		} else {
+			printk(KERN_CRIT "No keymatch table\n");
+		}
+		if (ccnode->h_AdTable) {
+			display_adtable(ccnode);
+		} else {
+			printk(KERN_CRIT "No ad table\n");
+		}
+		display_next_engine_param(ccnode);
+		printk(KERN_CRIT "not ext hash >???\n");
+	} else {
+		printk(KERN_CRIT "ext hash\n");
+	}
+}
+#else
+#define display_cc_node(x, y)
+#define disp_ht_params(x)
+#endif
+
+
+#ifdef FM_CC_MURAM_DEBUG 
+static void *display_new_class_res_desc(void *ad)
+{
+	struct new_class_res_desc desc; 
+	uint32_t *ptr;
+
+	ptr = (uint32_t *)ad;
+	desc.word_0 = swap_word(ptr);
+	desc.word_1 = swap_word(ptr + 1);
+	desc.word_2 = swap_word(ptr + 2);
+	desc.word_3 = swap_word(ptr + 3);
+	printk("rspid %x, ", desc.rspid);
+	printk("fqid %x, ", desc.fqid);
+	printk("policer profile %x, ", desc.policer_profile);
+	printk("Fpm_nia %x\n", desc.fpm_nia);
+	printk("operational mode bits:: ebd %d, ebad %d, fwd %d, nl %d, cwd %d, nenq %d, vspe %d\n", 
+		desc.ebd,
+		desc.ebad,
+		desc.fwd,
+		desc.nl,
+		desc.cwd,
+		desc.nenq,
+		desc.vspe);
+	printk("ext mode %d, stats en %d, naden %d, FR %d, NO_CSPEN %d, OVOM %d\n",
+		desc.extended_mode,
+		desc.stats_en,
+		desc.naden,
+		desc.fr,
+		desc.no_cspen,
+		desc.ovom);
+	printk("Frindex/stats counter %x\n", desc.word_3);
+	if (desc.extended_mode && desc.naden) {
+		printk("next action desc %x\n", desc.next_ad_index);
+		return ((void *)((uint8_t *)FmMurambaseAddr + (desc.next_ad_index << 4)));	
+	}
+	return NULL;  
+}
+
+
+static void display_stats_ad(uint32_t *ptr)
+{
+
+	struct stats_table_desc desc;
+
+	desc.word_0 = swap_word(ptr);
+	desc.word_1 = swap_word(ptr + 1);
+	desc.word_2 = swap_word(ptr + 2);
+	desc.word_3 = swap_word(ptr + 3);
+	printk("SSSSSSSS\nstats table descriptor %p::\n", ptr);
+	printk("cond_en %d\n", desc.cond_en);
+	printk("stats_tbl_addr %x\n", desc.stats_tbl_addr);
+	if (desc.flr_en) {
+		printk("flr_stats_prof_tbl_addr %x\n", desc.stats_prof_tbl_addr);
+	}
+	if (desc.nad_en) {
+		void *ad;
+
+		printk("next action desc %x\n", desc.next_ad_index);
+		ad = (void *)((uint8_t *)FmMurambaseAddr + 
+				(desc.next_ad_index << 4));
+		printk("SSSSSSSS\n");
+		display_pcd_cc_ad(ad);
+	} else
+		printk("SSSSSSSS\n");
+}
+
+
+static uint32_t *display_hdr_removal_hmc(uint32_t *ptr)
+{
+	struct hdr_removal_hmc desc;
+
+	printk("HMC::header removal command:: muram ptr %x\n", 
+		(uint32_t)((uint8_t *)ptr - (uint8_t *)FmMurambaseAddr));
+	display_buf_data(ptr, sizeof(struct hdr_removal_hmc));
+	desc.word = swap_word(ptr);
+	printk("header removal offset %d, ", desc.hdrrmvoffset);
+	printk("header removal size %d\n", desc.hdrrmvsize);
+	ptr += (sizeof(struct hdr_removal_hmc) / sizeof(uint32_t));
+	return ptr;
+}
+
+static uint32_t *display_hdr_insert_hmc(uint32_t *ptr)
+{
+	struct hdr_insert_hmc desc;
+
+	printk("HMC::local header insert command:: muram ptr %x\n", 
+		(uint32_t)((uint8_t *)ptr - (uint8_t *)FmMurambaseAddr));
+	desc.word = swap_word(ptr);
+	printk("header insert offset %d, ", desc.hdrinsoffset);
+	printk("header insert size %d\n", desc.hdrinssize);
+	printk("header to insert::\n");
+        display_buf_data((void *)((uint32_t *)&desc + 1),
+		desc.hdrinssize);
+	ptr += (sizeof(struct hdr_insert_hmc) + 
+		(desc.hdrinssize / sizeof(uint32_t)));
+	return ptr;
+}
+
+
+static uint32_t *display_internal_hdr_insert_hmc(uint32_t *ptr)
+{
+	struct internal_hdr_insert_hmc desc;
+
+	printk("HMC::internal header insert command:: muram ptr %x\n", 
+		(uint32_t)((uint8_t *)ptr - (uint8_t *)FmMurambaseAddr));
+	desc.word_0 = swap_word(ptr);
+	desc.word_1 = swap_word(ptr + 1);
+	printk("header insert offset %d, ", desc.hdrinsoffset);
+	printk("header insert size %d\n", desc.hdrinssize);
+	printk("header ins ptr %d\n", desc.hdrinsptr);
+	printk("header to insert::\n");
+        display_buf_data(((void *)((uint8_t *)FmMurambaseAddr + 
+			desc.hdrinsptr)), desc.hdrinssize);
+	ptr += (sizeof(struct internal_hdr_insert_hmc) / sizeof(uint32_t));
+	return ptr;
+}
+
+static uint32_t *display_hdr_replace_hmc(uint32_t *ptr)
+{
+	struct hdr_replace_hmc desc;
+
+	printk("HMC::local header replace command:: muram ptr %x\n", 
+		(uint32_t)((uint8_t *)ptr - (uint8_t *)FmMurambaseAddr));
+	desc.word = swap_word(ptr);
+	printk("header replace offset %d, ", desc.hdrinsoffset);
+	printk("header replace size %d\n", desc.hdrinssize);
+	printk("header to replace::\n");
+        display_buf_data((void *)((uint8_t *)ptr + 
+		sizeof(struct hdr_replace_hmc)),
+		desc.hdrinssize);
+	ptr += ((sizeof(struct hdr_replace_hmc) + desc.hdrinssize) 
+			/ sizeof(uint32_t));
+	return ptr;
+}
+
+static uint32_t *display_internal_hdr_replace_hmc(uint32_t *ptr)
+{
+        struct internal_hdr_replace_hmc desc;
+
+        printk("HMC::internal header replace command:: muram ptr %x\n", 
+		(uint32_t)((uint8_t *)ptr - (uint8_t *)FmMurambaseAddr));
+        desc.word_0 = swap_word(ptr);
+        desc.word_1 = swap_word(ptr + 1);
+        printk("header replace offset %d, ", desc.hdrinsoffset);
+        printk("header replace size %d\n", desc.hdrinssize);
+        printk("header replace ptr %d\n", desc.hdrinsptr);
+        printk("header to replace::\n");
+        display_buf_data(((void *)((uint8_t *)FmMurambaseAddr +
+                        desc.hdrinsptr)), desc.hdrinssize);
+        ptr += (sizeof(struct internal_hdr_replace_hmc) / sizeof(uint32_t));
+        return ptr;
+}
+
+static uint32_t *display_protosprc_hdr_remove_hmc(uint32_t *ptr)
+{
+        struct proto_specific_hdr_removal_hmc desc;
+
+        printk("HMC::protocol specific header removal command:: muram ptr %x\n", 
+		(uint32_t)((uint8_t *)ptr - (uint8_t *)FmMurambaseAddr));
+        desc.word = swap_word(ptr);
+	switch (desc.protospec_hdr_rmv_mode) {
+		case 0:
+			printk("remove Ethernet/802.3 MAC header\n");
+			break;
+		case 1:
+			printk("remove stacked QTags\n");
+			break;
+		case 2:
+			printk("remove Ethernet/802.3 MAC header + MPLS hdr\n");
+			break;
+		case 3:
+			printk("remove MPLS hdr\n");
+			break;
+		default:
+			printk("reserved remove mode %x\n",
+				desc.protospec_hdr_rmv_mode);
+			break;
+	}
+        ptr += (sizeof(struct proto_specific_hdr_removal_hmc) / 
+		sizeof(uint32_t));
+        return ptr;
+}
+
+static uint32_t *display_protosprc_hdr_insert_hmc(uint32_t *ptr)
+{
+        struct proto_specific_hdr_insert_hmc desc;
+
+        printk("HMC::protocol specific header insert command:: muram ptr %x\n",
+		(uint32_t)((uint8_t *)ptr - (uint8_t *)FmMurambaseAddr));
+        desc.word_0 = swap_word(ptr);
+        desc.word_1 = swap_word(ptr + 1);
+        switch (desc.protospec_hdr_ins_mode) {
+                case 0:
+                        printk("insert MPLS hdr\n");
+                        break;
+                case 1:
+                        printk("insert and update MPLS hdr\n");
+                        break;
+		case 2:
+                        printk("insert and update PPPoE hdr\n");
+                        break;
+                default:
+                        printk("reserved insert mode %x\n",
+                                desc.protospec_hdr_ins_mode);
+			goto update_ptr;
+        }
+	display_buf_data(((void *)((uint8_t *)FmMurambaseAddr +
+                        desc.inthdrptr)), desc.hdrinssize);
+update_ptr:	
+        ptr += (sizeof(struct proto_specific_hdr_insert_hmc) /
+                sizeof(uint32_t));
+        return ptr;
+}
+
+static uint32_t *display_vlan_pri_hdr_update_hmc(uint32_t *ptr)
+{
+        struct vlan_priority_update_hmc desc;
+	uint32_t ii;
+	uint32_t val;
+	uint32_t *intptr;
+
+        printk("HMC::vlan pri header update command::muram ptr %x\n",
+		(uint32_t)((uint8_t *)ptr - (uint8_t *)FmMurambaseAddr));
+        desc.word_0 = swap_word(ptr);
+        desc.word_1 = swap_word(ptr + 1);
+        printk("default vpri value %x\n", desc.vpri_def_value);
+        switch (desc.vprihdr_rep_mode) {
+                case 0:
+                        printk("replace outermost vlan tag with defa value\n");
+                        break;
+                case 1:
+                        printk("translate dscp to vlan pri\n");
+                        printk("int hdr rep ptr %x\n", desc.int_hdr_rep_ptr);
+			intptr = (uint32_t *)((uint8_t *)FmMurambaseAddr +
+                        		desc.int_hdr_rep_ptr);
+			for (ii = 0; ii < 16; ii++) {
+				val = swap_word(intptr);	
+				printk("%02x %02x %02x %02x\n",		
+					(val >> 24), ((val >> 16) & 0xff),
+					((val >> 8) & 0xff), (val & 0xff));
+				intptr++;
+			}
+                        break;
+                default:
+                        printk("reserved vlan pri insert mode %x\n",
+                                desc.vprihdr_rep_mode);
+                        break;
+        }
+        ptr += (sizeof(struct vlan_priority_update_hmc) /
+                sizeof(uint32_t));
+        return ptr;
+}
+
+static uint32_t *display_ipv4_update_hmc(uint32_t *ptr)
+{
+        struct local_ipv4_update_hmc desc;
+	uint32_t size;
+        uint32_t val;
+        uint32_t *intptr;
+
+        printk("HMC::ipv4 update command:: muram ptr %x\n",
+		(uint32_t)((uint8_t *)ptr - (uint8_t *)FmMurambaseAddr));
+	size = (sizeof(struct local_ipv4_update_hmc) /
+                sizeof(uint32_t)); 
+        desc.word = swap_word(ptr);
+	intptr = (ptr + 1);
+ 
+	if (desc.ip_ttl)
+		printk("decrement TTL by 1\n");
+	switch (desc.ip_tos_mode) {
+		case 0:
+			break;
+		case 1:
+			printk("replace tos value with %x\n", desc.ip_tos);
+			break;
+		default:
+			printk("reserved value %x for tos mode\n", desc.ip_tos_mode);
+			break;
+	}
+	if (desc.ip_id_mode) {
+		val = swap_word(intptr);
+		printk("replace ipid field, muram ptr %x\n", (val & 0xffffff));
+		intptr++;
+		size++;
+	}
+	if (desc.ip_src) {
+		val = swap_word(intptr);
+		printk("replace sip field, ipv4 addr %08x\n", val);
+		intptr++;
+		size++;
+	}
+	if (desc.ip_dst) {
+		val = swap_word(intptr);
+		printk("replace dip field, ipv4 addr %08x\n", val);
+		size++;
+	}
+        return (ptr + size);
+}
+
+static uint32_t *display_tcp_udp_update_hmc(uint32_t *ptr)
+{
+        struct local_tcp_udp_update_hmc desc;
+
+        printk("HMC::tcp udp update command:: muram ptr %x\n", 
+		(uint32_t)((uint8_t *)ptr - (uint8_t *)FmMurambaseAddr));
+        desc.word_0 = swap_word(ptr);
+        desc.word_1 = swap_word(ptr + 1);
+	if (desc.tcp_udp_src) {
+		printk("new sport value %04x\n", desc.src_port);
+	}
+	if (desc.tcp_udp_dst) {
+		printk("new dport value %04x\n", desc.dst_port);
+	}
+        return (ptr + (sizeof(struct local_tcp_udp_update_hmc) /
+                sizeof(uint32_t)));
+}
+
+
+static uint32_t *display_ipv6_update_hmc(uint32_t *ptr)
+{
+        struct ipv6_update_hmc desc;
+	uint8_t *intptr;
+	uint32_t size;
+
+	size = (sizeof(struct ipv6_update_hmc) / sizeof(uint32_t));
+	desc.word = swap_word(ptr);
+	intptr = (uint8_t *)(ptr + 1);
+	printk("HMC::Local IPv6 update command\n");
+	if (desc.ip_hop_limit)
+		printk("decrement hop limit\n");
+	switch (desc.ip_traffic_class_mode) {
+		case 0:	
+			break;
+		case 1:
+			printk("replace traffic class with %x\n", desc.iptraffic_class);
+			break;
+		default:
+			printk("reserved traffic class mode %x\n", 
+				desc.ip_traffic_class_mode);
+			break;
+	}
+	if (desc.ipsrc) {
+		printk("new sip::\n");	
+	        display_buf_data((void *)intptr, 16);	
+		intptr += 16;
+		size += 4;
+	}
+	if (desc.ipdst) {
+		printk("new dip::\n");
+	        display_buf_data((void *)intptr, 16);	
+		size += 4;
+	}
+	return (ptr + size);
+}
+
+
+static uint32_t *display_internal_iphdr_replace_hmc(uint32_t *ptr)
+{
+        struct internal_iphdr_replace_hmc desc;
+
+	printk("HMC::Internal IP Header Replace command::\n");
+	desc.word_0 = swap_word(ptr);
+	desc.word_1 = swap_word(ptr + 1);
+	desc.word_2 = swap_word(ptr + 2);
+	if (desc.ipid_mode) {
+		printk("replace ipid, ipid ptr in muram %x\n",
+			desc.id_hdr_ptr);
+	}
+	switch (desc.inl3smode) {
+		case 0:
+			printk("replace ipv4 with ipv6 hdr, size %d::\n",
+				desc.l3hdr_ins_size);
+        		display_buf_data((void *)(desc.l3hdr_ptr + 
+					(uint8_t *)FmMurambaseAddr), 
+					desc.l3hdr_ins_size);
+			if (desc.ttl_hop_limit) 
+				printk("duplicate ttl from hop limit and decr\n");
+			break;
+		case 1:
+			printk("replace ipv6 with ipv4 hdr::\n");
+        		display_buf_data((void *)(desc.l3hdr_ptr + 
+					(uint8_t *)FmMurambaseAddr), 
+					desc.l3hdr_ins_size);
+			if (desc.ttl_hop_limit) 
+				printk("duplicate hop limit from ttl and decr\n");
+			break;
+		default:
+			printk("reserved insl3mode %d\n", desc.inl3smode);
+			break;
+	}
+	return (ptr + (sizeof(struct internal_iphdr_replace_hmc) / sizeof(uint32_t)));
+}
+
+
+static void display_hmt_entries(uint32_t hmtd_offset)
+{
+	uint32_t *ptr;
+	uint32_t opcode;
+
+	ptr = (uint32_t *)(hmtd_offset + (uint8_t *)FmMurambaseAddr);
+next_hmc:
+	printk("%s::ptr %p\n", __FUNCTION__, ptr);
+	opcode = swap_word(ptr);
+	switch (opcode >> 24) {
+		case 1:
+			ptr = display_hdr_removal_hmc(ptr);
+			break;
+		case 2:
+			ptr = display_hdr_insert_hmc(ptr);
+			break;
+		case 3:
+			ptr = display_internal_hdr_insert_hmc(ptr);
+			break;
+		case 5:
+			ptr = display_hdr_replace_hmc(ptr);
+			break;
+		case 6:
+			ptr = display_internal_hdr_replace_hmc(ptr);
+			break;
+		case 8:
+			ptr = display_protosprc_hdr_remove_hmc(ptr);
+			break;
+		case 9:
+			ptr = display_protosprc_hdr_insert_hmc(ptr);
+			break;
+		case 0xb:
+			ptr = display_vlan_pri_hdr_update_hmc(ptr);
+			break;
+		case 0xc:
+			ptr = display_ipv4_update_hmc(ptr);
+			break;
+		case 0xe:
+			ptr = display_tcp_udp_update_hmc(ptr);
+			break;
+		case 0x10:
+			ptr = display_ipv6_update_hmc(ptr);
+			break;
+		case 0x12:
+			ptr = display_internal_iphdr_replace_hmc(ptr);
+			break;
+		case 0x14:
+			printk("UDP/TCP checksum update command\n");
+			ptr++;
+			break;
+		default:
+			printk("unknown opcode %x, cannot continue\n", opcode);
+			return;
+	}
+	if (!(opcode & 0x00800000))
+		goto next_hmc;
+}
+
+static void *display_hmtd(uint32_t *ptr)
+{
+	struct hmt_desc *desc;
+	void *nextad;
+
+	printk("Header manip table desc::\n");
+	nextad = NULL;
+	desc = kzalloc (sizeof(struct hmt_desc), GFP_KERNEL);
+	if (desc) {
+		desc->word_0 = swap_word(ptr);
+		desc->word_1 = swap_word((ptr + 1));
+		desc->word_2 = swap_word((ptr + 2));
+		desc->word_3 = swap_word((ptr + 3));
+		printk("pahm\t%d, ", desc->pahm);
+		printk("internal hmt ptr\t%x\n", desc->internal_hmt_ptr);
+		if (desc->naden) {
+			printk("nextdescidx\t%x\n", (desc->nextdescindex << 4));
+			nextad = (void *)((uint8_t *)FmMurambaseAddr + 
+					(desc->nextdescindex << 4));
+		}
+		printk("HMC_HMC_HMC<<<\n");
+		display_hmt_entries(desc->internal_hmt_ptr);
+		printk("HMC_HMC_HMC>>>\n");
+		kfree(desc);
+	} else {
+		printk("kzalloc failed, cannot HM table descriptor\n");
+	}
+	return (nextad);
+}
+
+static void display_table_desc(uint32_t *ptr)
+{
+	uint32_t opcode;
+	
+	opcode = swap_word(ptr);
+	if ((opcode & 0xc0000000) == 0x40000000) {
+		opcode = swap_word(ptr + 2);
+		switch (opcode & 0xff) {
+			case 0x35:
+				display_hmtd(ptr);
+				break;
+			case 0x36:
+				display_stats_ad(ptr);
+				break;
+			case 0x2b:
+				display_generic_5_off_ic_gmask(ptr);
+				break;
+			default:
+				printk("unsupported opcode %x\n",
+					opcode);
+				break;
+		}
+	}
+}
+
+static void display_ad_table_using_offset(uint32_t ad_offset, 
+		uint32_t kt_offset, uint32_t num_entries,
+		uint32_t keylen)
+{
+	uint32_t ii;
+	uint8_t *ad_ptr;
+	uint8_t *kt_ptr;
+	uint32_t adj_keylen;
+
+	ad_ptr = (ad_offset + (uint8_t *)FmMurambaseAddr);
+	kt_ptr = (kt_offset + (uint8_t *)FmMurambaseAddr);	
+	keylen++;
+	if (keylen % 16) {
+		adj_keylen = (keylen + 16);
+		adj_keylen &= ~0xf;
+	} else
+		adj_keylen = keylen;
+	printk("keylen %d, adjkeylen %d\n", keylen, adj_keylen);
+	for (ii = 0; ii < (num_entries + 1); ii++) {
+		printk("......................\n");
+		//printk("ADENTRY %d::\n", ii);
+		display_buf_data(ad_ptr, FM_PCD_CC_AD_ENTRY_SIZE);
+		if (ii < num_entries) {
+			printk("key::\n");
+			display_buf_data((void *)kt_ptr, keylen);	
+			kt_ptr += adj_keylen;
+			printk("mask::\n");
+			display_buf_data((void *)kt_ptr, keylen);	
+			kt_ptr += adj_keylen;
+		}
+		display_pcd_cc_ad(ad_ptr);
+		ad_ptr += FM_PCD_CC_AD_ENTRY_SIZE;
+	}
+	printk("......................\n");
+}
+
+static void display_generic_5_off_ic_gmask(void *ad)
+{
+	struct generic_5_off_ic_gmask *desc;
+	uint32_t *ptr;
+
+	ptr = (uint32_t *)ad;
+	desc = kzalloc (sizeof(struct generic_5_off_ic_gmask), GFP_KERNEL);
+	if (desc) {
+		desc->word_0 = swap_word(ptr);
+		desc->word_1 = swap_word((ptr + 1));
+		desc->word_2 = swap_word((ptr + 2));
+		desc->age_mask = swap_word((ptr + 3));
+		printk("keylen\t%d\n", (desc->key_length + 1));
+		printk("cc_adbase\t%x\n", desc->cc_adbase);
+		printk("match_table_entries_num\t%d\n", 
+				desc->match_table_entries_num);
+		printk("local mask\t%d\n", desc->LM);
+		printk("match_table_ptr\t%x\n", desc->match_table_ptr);
+		printk("offset_from_parse_result\t%d\n", 
+			desc->offset_from_parse_result);
+		printk("offset\t%d\n", desc->offset);
+		printk("op_code\t%x\n", desc->op_code);
+		display_ad_table_using_offset(desc->cc_adbase,
+		desc->match_table_ptr, desc->match_table_entries_num,
+		desc->key_length);
+		kfree(desc);
+	} else {
+		printk("kzalloc failed, cannot display table descriptor\n");
+	}
+}
+
+static void *display_keep_class_result(void *ad)
+{
+	struct keep_class_res_desc_ad *desc;
+	uint32_t *ptr;
+	uint32_t next_ad_index;
+
+        ptr = (uint32_t *)ad;
+        desc = kzalloc (sizeof(struct keep_class_res_desc_ad), GFP_KERNEL);
+        if (desc) {
+                desc->word_0 = swap_word(ptr);
+                desc->word_1 = swap_word((ptr + 1));
+                desc->word_2 = swap_word((ptr + 2));
+                desc->statistic_counter = swap_word((ptr + 3));
+		if (desc->PD)
+                	printk("Policer disabled, ");
+		else
+                	printk("Policer enabled, ");
+                printk("extended mode %d,\n", desc->extended_mode);
+                printk("naden %d, ", desc->naden);
+                printk("novspe %d\n", desc->no_vspe);
+                printk("statistics_enable\t%d\n", desc->statistics_enable);
+                printk("fpm_nia\t%x\n", desc->fpm_nia);	
+		if (desc->naden) {
+                	printk("nextADindex\t%x\n", desc->next_action_desc_index);
+			next_ad_index = (desc->next_action_desc_index << 4);
+			return ((void *)((uint8_t *)FmMurambaseAddr + next_ad_index));  
+		}
+                kfree(desc);
+
+        } else {
+                printk("kzalloc failed, cannot display keep class descriptor\n");
+        }
+	return NULL;
+}
+
+static void display_pcd_cc_ad(void *ad)
+{
+	uint32_t val;
+
+	printk("============\n");
+disp_nextad:
+	val = swap_word((uint32_t *)ad);
+	switch (val >> 30) {
+		case 0:
+			printk("New Classification result type:: %p\n", ad);
+			ad = display_new_class_res_desc(ad);
+			break;
+		case 1:
+			printk("table desc type:: %p\n", ad);
+			display_table_desc(ad);
+			ad = NULL;
+			break;
+		case 2:
+			printk("Keep Classification result type:: %p\n", ad);
+			ad = display_keep_class_result(ad);
+			break;
+		case 3:
+			printk("reserved for dynamic update of CC tables\n");
+			ad = NULL;
+			break;
+	} 
+	if (ad) {
+		printk("next ad %p\n", ad);
+		display_buf_data(ad, FM_PCD_CC_AD_ENTRY_SIZE);
+		goto disp_nextad;
+	}
+	printk("============\n");
+}
+
+static void display_pcd_cc_hc(t_FmPcd *p_FmPcd, uint32_t oldAdAddrOffset,
+                        uint32_t newAdAddrOffset)
+{
+	void *ad;
+
+	ad = (void *)((uint8_t *)FmMurambaseAddr + oldAdAddrOffset);
+	printk("###### old ad::%x, ad %p\n", oldAdAddrOffset, ad);
+	display_pcd_cc_ad(ad);
+	printk("###### old ad end\n");
+	ad = (void *)((uint8_t *)FmMurambaseAddr + newAdAddrOffset);
+	printk("###### new ad::%x ad %p\n", newAdAddrOffset, ad);
+	display_pcd_cc_ad(ad);
+	printk("###### new ad end\n");
+}
+#else
+#define display_pcd_cc_hc(x, y, z);
+#endif
+
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_ehash.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_ehash.c
new file mode 100644
index 000000000000..e0a7d0d6358d
--- /dev/null
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_ehash.c
@@ -0,0 +1,1797 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+ */
+        
+/**     
+ * @file                fm_ehash.c     
+ * @description         DPAA enhanced external hash functions
+ */             
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/slab.h>
+//#include <linux/fsl_dpa_offload.h>
+//#include <linux/fsl_dpa_classifier.h>
+#include "fm_common.h"
+#include "fm_muram_ext.h"
+#include "fm_ehash.h"
+#include "fm_pcd.h"
+#include "fm_cc.h"
+#include "endian_ext.h"
+
+//#define FM_EHASH_DEBUG 1
+
+#ifdef FM_EHASH_DEBUG 
+#define FM_EHASH_PRINT printk
+#else
+#define FM_EHASH_PRINT(fmt, ...)
+#endif // CDX_DPA_DEBUG
+
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+#define REASSM_DEBUG_SIZE       128
+struct en_exthash_info *ipv4_reassly_tbl_info;
+struct en_exthash_info *ipv6_reassly_tbl_info;
+struct ipr_context_info *IprContextMem;
+
+extern void disp_sch_info(void *);
+extern void *FmMurambaseAddr;
+extern void get_indexed_hash_bucket(uint8_t key_size,  uint8_t *key_ptr,
+	        uint8_t crc_shift, uint16_t mask, uint16_t *bucket_index);
+
+void display_reassem_stats(uint32_t type);
+static void display_reassem_params(uint32_t type);
+#endif
+
+#ifdef USE_ENHANCED_EHASH
+static inline void copy_ipaddr(uint32_t *src, uint8_t *dest, uint32_t size)
+{	
+	uint32_t ii;
+	uint32_t val;
+
+	for (ii = 0; ii < size; ii++) {
+		val = cpu_to_be32(*src);
+		memcpy(dest, &val, 4);
+		dest += sizeof(uint32_t);
+	}
+}
+
+
+
+#if 0
+static int fill_ehash_key_info(PCtEntry entry, struct en_ehash_entry *entry)
+{
+	unsigned char *ptr;
+	
+	ptr = &entry->key[0];
+	switch (entry->proto) {
+		case IPPROTOCOL_TCP: 
+		case IPPROTOCOL_UDP:
+			if (IS_IPV6_FLOW(entry))
+			{
+				copy_ipaddr(&entry->Saddr_v6[i], ptr, 4);
+				ptr += 16;
+				copy_ipaddr(&entry->Daddr_v6[i], ptr, 4);
+				ptr += 16;
+			} else {
+				copy_ipaddr(&entry->Saddr_v4, ptr, 1);
+				ptr += 4;
+				copy_ipaddr(&entry->Daddr_v4, ptr, 1);
+				ptr += 4;
+			}
+			*ptr++ = entry->proto;
+			*ptr++ = (entry->Sport >> 8);
+			*ptr++ = (entry->Sport & 0xff);
+			*ptr++ = (entry->Dport >> 8);
+			*ptr++ = (entry->Dport & 0xff);
+			break;
+		default:
+			DPA_ERROR("%s::protocol %d not supported\n",
+					__FUNCTION__, entry->proto);
+			return FAILURE;
+
+	}
+#if 1//
+	{
+		uint32_t size;
+
+		size = (uint32_t)(ptr - &entry->key[0]);
+		printk("keysize %d\n", size);
+		display_buf(&entry->key[0]), size);
+#endif
+	}
+	return SUCCESS;
+}
+#endif
+
+static inline struct en_exthash_tbl_entry *find_entry_in_bucket(struct en_exthash_tbl_entry *entry, 
+		uint8_t *key, uint32_t size)
+{
+#ifdef NO_CUMULATIVE_ENTRY
+	while(1) {
+		if (!entry)
+			break;
+		if (memcmp(key, &entry->hashentry.key[0], size) == 0) 
+			return entry; 
+		entry = entry->next;
+	}
+#else
+	struct en_cumulative_tbl_entry *cumulative_tbl_node = (struct en_cumulative_tbl_entry *)entry;
+	struct en_cumulative_entry *cumulative_node;
+	int ii;
+	if (!entry)
+		return NULL;
+	cumulative_node = &cumulative_tbl_node->cumulative_entry;
+	if (cumulative_node->flags & EN_CUMULATIVE_NODE)
+	{
+		while (cumulative_node)
+		{
+			for(ii=0; ii<cumulative_node->num_key_entries; ii++)
+				if (memcmp(key, &cumulative_node->data[ii*cumulative_node->key_size], size) == 0)
+					return entry;
+			if (cumulative_tbl_node->next_entry)
+			{
+				cumulative_tbl_node = cumulative_tbl_node->next_entry;
+				cumulative_node = &cumulative_tbl_node->cumulative_entry;
+			}
+			else
+				cumulative_node = NULL;
+		}
+	}
+	else if(memcmp(key, &entry->hashentry.key[0], size) == 0) 
+		return entry; 
+#endif // NO_CUMULATIVE_ENTRY
+	return NULL;
+}
+
+void *ExternalHashTableAllocEntry(t_Handle h_HashTbl) 
+{
+	void *entry;
+	struct en_exthash_info *info;
+	
+	entry = NULL;
+	info = (struct en_exthash_info *)h_HashTbl;
+	if (info) {
+		//allocate new entry
+		entry = XX_MallocSmart(sizeof(struct en_exthash_tbl_entry),
+                        0 /*info->dataMemId not used */, EN_EHASH_ENTRY_ALIGN);
+		if (entry) 
+			memset(entry, 0, sizeof(struct en_exthash_tbl_entry));
+		else {
+        		REPORT_ERROR(MAJOR, E_NO_MEMORY,
+                		     ("en_ext_hash_entry"));
+		}
+	}
+	return entry;
+}
+EXPORT_SYMBOL(ExternalHashTableAllocEntry); 
+
+void ExternalHashTableEntryFree(void *entry)
+{
+	XX_FreeSmart(entry);
+}
+EXPORT_SYMBOL(ExternalHashTableEntryFree); 
+
+void *ExternalHashTableAllocCumulativeEntry(t_Handle h_HashTbl)
+{
+	void *entry;
+	struct en_exthash_info *info;
+
+	info = (struct en_exthash_info *) h_HashTbl;
+
+	entry = XX_MallocSmart(sizeof(struct en_cumulative_tbl_entry), 0 /*info->dataMemId not used */, EN_EHASH_ENTRY_ALIGN);
+	if (entry)
+	        memset(entry, 0, sizeof(struct en_cumulative_tbl_entry));
+	else
+	{
+	        REPORT_ERROR(MAJOR, E_NO_MEMORY, ("en_cumulative_entry"));
+	}
+	return entry;
+}
+void ExternalHashTableCumulativeEntryFree(void *entry)
+{
+	XX_FreeSmart(entry);
+}
+
+
+
+#define MAX_HIST_SIZE	15
+void EhashTableWalk(void *h_HashTbl)
+{
+	uint32_t ii;
+	struct en_exthash_info *info;
+	struct en_exthash_tbl_entry *entry;
+	uint64_t *bucket;
+	uint32_t num_entries;
+	uint32_t bucket_entries;
+	uint32_t max_collisions;
+	uint32_t min_collisions;
+	uint32_t histo[MAX_HIST_SIZE + 2];
+	
+
+	num_entries = 0;
+	max_collisions = 0;
+	min_collisions = 0xffffffff;
+	memset(&histo[0], 0, (sizeof(uint32_t) * (MAX_HIST_SIZE + 2)));
+	info = (struct en_exthash_info *)h_HashTbl;
+	bucket = (uint64_t *)info->table_base;
+	printk("%s::tbl %p, num buckets %d base %p\n",
+		__FUNCTION__, info, (info->hashmask + 1), bucket);
+	for (ii = 0; ii <= info->hashmask; ii++) {
+		if (*bucket) {
+			bucket_entries = 0;
+			entry = XX_PhysToVirt(SwapUint64(*bucket));
+			while(entry) {
+				bucket_entries++;
+				entry = entry->next;
+			}
+			num_entries += bucket_entries;
+			if (bucket_entries > max_collisions)
+				max_collisions = bucket_entries;
+			if (bucket_entries < min_collisions)
+				min_collisions = bucket_entries;
+			if (max_collisions > MAX_HIST_SIZE)
+				histo[MAX_HIST_SIZE + 1]++;
+			else 
+				histo[max_collisions]++;
+		} else {
+			histo[0]++;
+		}	
+		bucket++;
+	}
+	printk("%s::entries %d, max colls %d, min colls %d\n",
+			__FUNCTION__, num_entries, max_collisions, 
+			min_collisions);
+	printk("num collisions\t	num_buckets\n");	
+	for (ii = 0; ii < MAX_HIST_SIZE; ii++) {
+		printk("%d\t%d\n", ii, histo[ii]);
+	}
+	printk(">15\t%d\n", histo[ii]);
+}
+EXPORT_SYMBOL(EhashTableWalk); 
+
+int ExternalHashTableEntryGetStatsAndTS(void *tbl_entry,
+				struct en_tbl_entry_stats *stats)
+{
+	struct en_exthash_tbl_entry *hash_node;
+	struct en_ehash_entry *entry;
+//	uint32_t val;
+	uint16_t flags;
+
+	hash_node = (struct en_exthash_tbl_entry *)tbl_entry;
+	entry = &hash_node->hashentry;
+	if (!entry)
+		return -1;
+	flags = cpu_to_be16(entry->flags);
+	stats->flags = 0;
+        if (GET_TIMESTAMP_ENABLE(flags)) {
+		stats->flags |= TIMESTAMP_VALID;
+		stats->timestamp = cpu_to_be32(entry->timestamp);
+#ifdef FM_EHASH_DEBUG 
+                printk("external  timestamp %08x\n",
+                	 stats->timestamp);
+#endif // FM_EHASH_DEBUG
+        }
+	if (GET_STATS_ENABLE(flags))
+	{
+		stats->flags |= STATS_VALID;
+		stats->pkts = be64_to_cpu(entry->packet_count);
+		stats->bytes = be64_to_cpu(entry->packet_bytes);
+#ifdef FM_EHASH_DEBUG 
+		printk("%s(%d) stats pkts %lld , bytes %lld \n",
+			__FUNCTION__, __LINE__, stats->pkts, stats->bytes);
+#endif // FM_EHASH_DEBUG 
+	}
+#ifdef FM_EHASH_DEBUG 
+	printk("%s::stats flags %x\n", __FUNCTION__, stats->flags);
+#endif
+	return 0;
+}
+EXPORT_SYMBOL(ExternalHashTableEntryGetStatsAndTS);
+
+int ExternalHashTableAddKey(void *h_HashTbl, uint8_t keySize,
+                                      void *tbl_entry)
+{
+	struct en_exthash_info *info;
+	struct en_exthash_tbl_entry *first_entry;
+	struct en_exthash_tbl_entry *new_entry;
+	uint16_t index;
+	void *bucket;
+	t_Handle *h_Spinlock;
+	uint32_t intFlags;
+	int retval;
+	uint64_t phyaddr;
+#ifndef NO_CUMULATIVE_ENTRY
+	uint8_t key_align, flags;
+//	uint32_t ii;
+	struct en_cumulative_entry *cumulative_entry, *tmp;
+	struct en_cumulative_tbl_entry *tmp_tbl_entry, *cumulative_tbl_entry;
+	uint64_t bucket_phyaddr;
+#endif // NO_CUMULATIVE_ENTRY
+
+	SANITY_CHECK_RETURN_ERROR(h_HashTbl, E_INVALID_HANDLE);
+    	SANITY_CHECK_RETURN_ERROR(tbl_entry, E_NULL_POINTER);
+
+	new_entry = (struct en_exthash_tbl_entry *)tbl_entry;
+	info = (struct en_exthash_info *)h_HashTbl;
+#ifdef FM_EHASH_DEBUG 
+	printk("%s::keysize %d, shift %d, mask %x key::\n",
+		__FUNCTION__, keySize, info->hashshift,
+		info->hashmask);
+	disp_buf(&new_entry->hashentry.key[0], keySize);
+#endif
+	get_indexed_hash_bucket(keySize, &new_entry->hashentry.key[0],
+                                info->hashshift,
+                                (uint16_t)info->hashmask, &index);
+	bucket = ((uint64_t *)info->table_base + index);
+#ifdef FM_EHASH_DEBUG 
+	printk("%s::index %x\n", __FUNCTION__, index);
+	printk("%s::table base %p , basePhyAddr %p \n bucket %p, bucket phy %p spinlock %p \n", __FUNCTION__,
+		info->table_base, XX_VirtToPhys(info->table_base), bucket, XX_VirtToPhys(bucket), info->pSpinlock);
+#endif
+
+	h_Spinlock = *(info->pSpinlock + index);
+   	intFlags = XX_LockIntrSpinlock(h_Spinlock);
+
+	retval = index;
+	phyaddr = *((uint64_t *)bucket);
+#ifdef NO_CUMULATIVE_ENTRY
+	if (phyaddr) {
+		first_entry = XX_PhysToVirt(SwapUint64(phyaddr));
+		if (find_entry_in_bucket(first_entry, &new_entry->hashentry.key[0], 
+				keySize)) {
+        		REPORT_ERROR(MAJOR, E_ALREADY_EXISTS,
+                	     ("en_ext_hash_entry"));
+			retval = -1;
+			goto func_ret;
+		}
+		first_entry->prev = new_entry;
+	} else
+		first_entry = NULL;
+	//fill next pointer info and link into chain
+	new_entry->next = first_entry;
+	//adjust the prev pointer in the old entry
+	//fill next pointer physaddr for uCode
+	// physical address was swapped before adding to bucket, so reverse it and add
+	phyaddr = SwapUint64(phyaddr);
+	new_entry->hashentry.next_entry_hi = cpu_to_be16((phyaddr >> 32) & 0xffff);
+	new_entry->hashentry.next_entry_lo = cpu_to_be32((phyaddr & 0xffffffff));
+	//change the head pointer in the bucket
+	phyaddr = XX_VirtToPhys(new_entry);
+	*((uint64_t *)bucket) = SwapUint64(phyaddr);
+#else
+	/* key should be aligned to  8 byte boundary if size > 4*/
+	if (keySize <= 2)
+		key_align =  keySize;
+	else if (keySize <= 4)
+		key_align =  4;
+	else
+		key_align =  (keySize + 7) & 0x38;
+
+	FM_EHASH_PRINT("%s(%d) tbl_entry %p, key size %d, key-align %d\n",
+		__FUNCTION__,__LINE__,tbl_entry, keySize, key_align);
+	key_align -= keySize;
+
+	// if no nodes in bucket, just add the node as it is
+	if (!phyaddr)
+	{
+		new_entry->next =  NULL;
+		//change the head pointer in the bucket
+		phyaddr = XX_VirtToPhys(new_entry);
+		*((uint64_t *)bucket) = SwapUint64(phyaddr);
+	}
+	else
+	{
+		FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+		first_entry = XX_PhysToVirt(SwapUint64(phyaddr));
+		if (find_entry_in_bucket(first_entry, &new_entry->hashentry.key[0], 
+				keySize)) {
+        		REPORT_ERROR(MAJOR, E_ALREADY_EXISTS,
+                	     ("en_ext_hash_entry"));
+			retval = -1;
+			goto func_ret;
+		}
+		FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+		// check if node is cumulative or not
+		// if not cumulative, allocate cumulative node 
+		// add the existing node and the current node to the cumulative node
+		cumulative_tbl_entry = XX_PhysToVirt(SwapUint64(phyaddr));
+		cumulative_entry = &cumulative_tbl_entry->cumulative_entry;
+		FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+		if (cumulative_entry->flags & EN_CUMULATIVE_NODE)
+		{
+			FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+			if (((cumulative_entry->key_size+EN_CU_HASH_TABLE_ENTRY_ADDR_SIZE) * 
+				    (cumulative_entry->num_key_entries+1) + EN_CU_FIXED_ELEMENTS_SIZE) <= EN_CUMULATIVE_NODE_MAX_SIZE)
+			{
+				tmp_tbl_entry = ExternalHashTableAllocCumulativeEntry (h_HashTbl);
+				if (!tmp_tbl_entry)
+				{
+					REPORT_ERROR(MAJOR, E_NO_MEMORY,
+								 ("en_cumulative_entry"));
+					retval = -1;
+					goto func_ret;
+				}
+				FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+				tmp = &tmp_tbl_entry->cumulative_entry;
+				tmp->flags = cumulative_entry->flags; 
+				tmp->key_size =  cumulative_entry->key_size;
+				tmp->next_entry_addr = cumulative_entry->next_entry_addr;
+				tmp->num_key_entries = cumulative_entry->num_key_entries+1;
+				tmp->tbl_entry_index = cumulative_entry->tbl_entry_index + cumulative_entry->key_size;
+				memcpy(tmp->data, new_entry->hashentry.key, keySize);
+				memset(tmp->data+keySize, 0, key_align);
+				memcpy(tmp->data+keySize+key_align, cumulative_entry->data,
+							1+cumulative_entry->num_key_entries*cumulative_entry->key_size);
+				phyaddr = XX_VirtToPhys(new_entry);
+				phyaddr = SwapUint64(phyaddr);
+				memcpy(tmp->data+(cumulative_entry->num_key_entries+1)*cumulative_entry->key_size+1, &phyaddr,
+					EN_CU_HASH_TABLE_ENTRY_ADDR_SIZE);
+				memcpy(tmp->data+(cumulative_entry->num_key_entries+1)*cumulative_entry->key_size+1+EN_CU_HASH_TABLE_ENTRY_ADDR_SIZE, 
+					cumulative_entry->data+1+cumulative_entry->num_key_entries*cumulative_entry->key_size, 
+					8*cumulative_entry->num_key_entries);
+				tmp_tbl_entry->next_entry = cumulative_tbl_entry->next_entry;
+				if (cumulative_tbl_entry->next_entry)
+					cumulative_tbl_entry->next_entry->prev_entry = tmp_tbl_entry;
+				// initiate host command
+				FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+				if (cumulative_tbl_entry->prev_entry)
+				{
+					phyaddr =  XX_VirtToPhys(tmp_tbl_entry);
+					phyaddr =  SwapUint64(phyaddr);
+					cumulative_tbl_entry->prev_entry->cumulative_entry.next_entry_addr =  phyaddr;
+					cumulative_tbl_entry->prev_entry->next_entry = tmp_tbl_entry;
+					tmp_tbl_entry->prev_entry =  cumulative_tbl_entry->prev_entry;
+				}
+				phyaddr =  XX_VirtToPhys(cumulative_tbl_entry);
+				phyaddr =  SwapUint64(phyaddr);
+				bucket_phyaddr = *((uint64_t *)bucket);
+				if (bucket_phyaddr == phyaddr)
+				{
+					phyaddr =  XX_VirtToPhys(tmp_tbl_entry);
+					phyaddr =  SwapUint64(phyaddr);
+					*((uint64_t *)bucket) = phyaddr;
+				}
+				flags = cumulative_entry->flags;
+				flags = flags | EN_INVALID_CUMULATIVE_NODE;
+				cumulative_entry->flags = flags;
+				info = (struct en_exthash_info *)h_HashTbl;
+				XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+				if (FmPcdHcSync(info->pcd)) {
+					printk("%s::FmPcdHcSync failed\n", __FUNCTION__);
+					retval = -1;
+					goto func_ret;
+				}
+				ExternalHashTableCumulativeEntryFree(cumulative_tbl_entry);
+#ifdef FM_EHASH_DEBUG 
+				printk("new cumulative entry phyaddr : %p bucket content value : 0x%lx\n",
+							(void *)XX_VirtToPhys(cumulative_entry), (long unsigned int)*((uint64_t *)bucket));
+				cumulative_entry = (struct en_cumulative_entry *)XX_PhysToVirt((physAddress_t)SwapUint64(*((uint64_t *)bucket)));
+				while (cumulative_entry)
+				{
+					printk("cumulative entry : %p \n", cumulative_entry);
+							
+						
+					printk("flags: 0x%x, key-size %d, key_entries: %d, nodes_index: %d, next_entry 0x%lx\n", 
+							cumulative_entry->flags, 
+							cumulative_entry->key_size, cumulative_entry->num_key_entries, cumulative_entry->tbl_entry_index,
+							(long unsigned int)cumulative_entry->next_entry_addr);
+					printk("cumulative key: \n");
+					for (ii=0; ii<((cumulative_entry->key_size*cumulative_entry->num_key_entries)+1); ii++)
+					{
+						if ((ii % 16) == 0)
+							printk("\n");
+						printk("%02x ", cumulative_entry->data[ii]);
+					}
+					printk("\n table entries (%d) : \n",cumulative_entry->num_key_entries);
+					for (ii = 0; ii < cumulative_entry->num_key_entries; ii++) {
+						phyaddr = *((uint64_t *)(&cumulative_entry->data[cumulative_entry->tbl_entry_index-12+ii*8]));
+						printk("table_entry ptr[%d]: %p \n", ii, (void *)XX_PhysToVirt((physAddress_t)SwapUint64(phyaddr)));
+					}
+					printk("\n");
+					if (cumulative_entry->flags & EN_NEXT_CUMULATIVE_NODE)
+					{
+						cumulative_entry = XX_PhysToVirt(SwapUint64(cumulative_entry->next_entry_addr));
+					}
+					else
+						cumulative_entry = NULL;
+				}
+#endif
+				return retval;
+			}
+			else
+			{
+				FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+				tmp_tbl_entry = ExternalHashTableAllocCumulativeEntry (h_HashTbl);
+				if (!tmp_tbl_entry)
+				{
+					REPORT_ERROR(MAJOR, E_NO_MEMORY,
+								 ("en_cumulative_entry"));
+					retval = -1;
+					return retval;
+				}
+				tmp = &tmp_tbl_entry->cumulative_entry;
+				phyaddr = XX_VirtToPhys(cumulative_tbl_entry);
+				tmp->flags = EN_NEXT_CUMULATIVE_NODE | EN_CUMULATIVE_NODE;
+				tmp->next_entry_addr = SwapUint64(phyaddr);
+				tmp_tbl_entry->next_entry =  cumulative_tbl_entry;
+				cumulative_tbl_entry->prev_entry =  tmp_tbl_entry;
+				cumulative_entry = tmp;
+				cumulative_entry->key_size = keySize+key_align;
+				cumulative_entry->num_key_entries = 1;
+				memcpy(cumulative_entry->data, new_entry->hashentry.key, keySize);
+				memset(cumulative_entry->data+keySize, 0, key_align);
+				cumulative_entry->data[keySize+key_align] = 0;
+				cumulative_entry->tbl_entry_index =  EN_CU_FIXED_ELEMENTS_SIZE+1+cumulative_entry->num_key_entries*cumulative_entry->key_size;
+				phyaddr = XX_VirtToPhys(new_entry);
+				phyaddr = SwapUint64(phyaddr);
+				memcpy(&cumulative_entry->data[cumulative_entry->key_size+1], &phyaddr, EN_CU_HASH_TABLE_ENTRY_ADDR_SIZE);
+				
+				//change the head pointer in the bucket
+				phyaddr = XX_VirtToPhys(tmp_tbl_entry);
+				*((uint64_t *)bucket) = SwapUint64(phyaddr);
+			}
+		}
+		else
+		{
+			FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+			cumulative_tbl_entry = ExternalHashTableAllocCumulativeEntry (h_HashTbl);
+			if (!cumulative_tbl_entry)
+			{
+				REPORT_ERROR(MAJOR, E_NO_MEMORY,
+							 ("en_cumulative_entry"));
+				retval = -1;
+				return retval;
+				
+			}
+			cumulative_entry = &cumulative_tbl_entry->cumulative_entry;
+			cumulative_entry->flags = EN_CUMULATIVE_NODE;
+			cumulative_entry->key_size = keySize+key_align;
+			cumulative_entry->num_key_entries = 2;
+			FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+			memcpy(cumulative_entry->data, new_entry->hashentry.key, keySize);
+			memset(cumulative_entry->data+keySize, 0, key_align);
+			FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+			memcpy(cumulative_entry->data+keySize+key_align, first_entry->hashentry.key, keySize);
+			memset(cumulative_entry->data+2*keySize+key_align, 0, key_align);
+			cumulative_entry->data[2*(keySize+key_align)] = 0;
+			cumulative_entry->tbl_entry_index =  EN_CU_FIXED_ELEMENTS_SIZE+1+cumulative_entry->num_key_entries*(keySize+key_align);
+			phyaddr = XX_VirtToPhys(new_entry);
+			phyaddr = SwapUint64(phyaddr);
+			*((uint64_t *)(cumulative_entry->data+2*(keySize+key_align)+1)) = phyaddr;
+			phyaddr = XX_VirtToPhys(first_entry);
+			phyaddr = SwapUint64(phyaddr);
+			*((uint64_t *)(cumulative_entry->data+2*(keySize+key_align)+1+EN_CU_HASH_TABLE_ENTRY_ADDR_SIZE)) = phyaddr;
+			//change the head pointer in the bucket
+			FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+			phyaddr = XX_VirtToPhys(cumulative_tbl_entry);
+			*((uint64_t *)bucket) = SwapUint64(phyaddr);
+			FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+		}
+		
+#ifdef FM_EHASH_DEBUG 
+		printk("new cumulative entry phyaddr : %p bucket content value : 0x%lx\n",
+			(void *)XX_VirtToPhys(cumulative_entry), (long unsigned int)*((uint64_t *)bucket));
+		cumulative_entry = (struct en_cumulative_entry *)XX_PhysToVirt((physAddress_t)SwapUint64(*((uint64_t *)bucket)));
+		while (cumulative_entry)
+		{
+			printk("cumulative entry : %p \n", cumulative_entry);
+			
+//				uint32_t ii;
+			
+			printk("flags: 0x%x, key-size %d, key_entries: %d, nodes_index: %d, next_entry 0x%lx\n", 
+					cumulative_entry->flags, 
+					cumulative_entry->key_size, cumulative_entry->num_key_entries, cumulative_entry->tbl_entry_index,
+					(long unsigned int)cumulative_entry->next_entry_addr);
+			printk("cumulative key: \n");
+			for (ii=0; ii<((cumulative_entry->key_size*cumulative_entry->num_key_entries)+1); ii++)
+			{
+				if ((ii % 16) == 0)
+					printk("\n");
+				printk("%02x ", cumulative_entry->data[ii]);
+			}
+			printk("\n table entries (%d) : \n",cumulative_entry->num_key_entries);
+			for (ii = 0; ii < cumulative_entry->num_key_entries; ii++) {
+				phyaddr = *((uint64_t *)(&cumulative_entry->data[cumulative_entry->tbl_entry_index-12+ii*8]));
+				printk("table_entry ptr[%d]: %p \n", ii, (void *)XX_PhysToVirt((physAddress_t)SwapUint64(phyaddr)));
+			}
+			printk("\n");
+			if (cumulative_entry->flags & EN_NEXT_CUMULATIVE_NODE)
+			{
+				cumulative_entry = XX_PhysToVirt(SwapUint64(cumulative_entry->next_entry_addr));
+			}
+			else
+				cumulative_entry = NULL;
+		}
+#endif
+	}	
+#endif //NO_CUMULATIVE_ENTRY
+#ifdef FM_EHASH_DEBUG 
+	printk("new entry phyaddr : %p bucket content value : 0x%lx\n", phyaddr, *((uint64_t *)bucket));
+	{
+		uint32_t ii;
+		uint8_t *ptr;
+
+		printk("hash entry::%p, next %p, prev %p\n hashentry %p::\n", 
+			new_entry, 
+			new_entry->next, new_entry->prev, &new_entry->hashentry);
+		ptr = (uint8_t *)&new_entry->hashentry;
+		for (ii = 0; ii < sizeof(struct en_ehash_entry); ii++) {
+			if ((ii % 16) == 0)
+				printk("\n");
+			printk("%02x ", *ptr);
+			ptr++;
+		}
+		printk("\n");
+	}
+#endif
+func_ret:
+    	XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+	return retval;	
+}
+EXPORT_SYMBOL(ExternalHashTableAddKey); 
+
+//called from ExternalHashTableSet only when table init fails
+static void Delete_EnEhashInfo(t_Handle handle)
+{
+	struct en_exthash_info *info;
+	uint32_t ii;
+	
+	info = (struct en_exthash_info *)handle;
+	if (info) {
+		if (info->pSpinlock) {
+			//free all bucket locks
+			for (ii = 0; ii <= info->hashmask; ii++) {
+				if (*(info->pSpinlock + ii)) {
+					XX_FreeSpinlock(*(info->pSpinlock + ii));
+				} else 
+					break;
+			}	
+			//free lock handle array
+			XX_FreeSmart(info->pSpinlock);
+			info->pSpinlock = NULL;
+		}
+		//free table info
+		kfree(info);
+	}
+}
+
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+extern void disp_sch_info(void *);
+void ipr_update_timestamp(void)
+{
+        uint32_t ii;
+
+        if (ipv4_reassly_tbl_info) {
+                ii = cpu_to_be32(ipv4_reassly_tbl_info->ip_reassem_info->ipr_timer);
+                ii++;
+                ipv4_reassly_tbl_info->ip_reassem_info->ipr_timer =
+                        cpu_to_be32(ii);
+        }
+        if (ipv6_reassly_tbl_info)
+                ipv4_reassly_tbl_info->ip_reassem_info->ipr_timer =
+			cpu_to_be32(ii);
+
+}
+
+static int GetMuramIprContextMem(t_Handle h_FmPcd)
+{
+        int ii;
+        uint32_t *ptr;
+        uint32_t prev_addr;
+
+        if (!IprContextMem) {
+                //allocate memory for IPR context in muram and make a free list
+                IprContextMem = (struct ipr_context_info *)
+                        FM_MURAM_AllocMem(FmPcdGetMuramHandle(h_FmPcd),
+                        sizeof(struct ipr_context_info), IPR_CTX_ALIGN);
+                if (!IprContextMem)
+                {
+                        REPORT_ERROR(MAJOR, E_NO_MEMORY, ("MURAM allocation for reassem context"));
+                        return -1;
+                }
+                //make a free list
+                prev_addr = IPR_CONTEXT_EOL;
+                ptr = (uint32_t *)&IprContextMem->context_data[0][0];
+                for (ii = 0; ii < IPR_MAX_SESSIONS; ii++) {
+                        *ptr = cpu_to_be32(prev_addr);
+                        if (prev_addr == IPR_CONTEXT_EOL)
+                                prev_addr =
+                                (uint32_t)((uint8_t *)IprContextMem - (uint8_t *)FmMurambaseAddr);
+                        else
+                                prev_addr += IPR_MAX_SESSSIZE;
+                        ptr += (IPR_MAX_SESSSIZE / sizeof(uint32_t));
+                }
+                IprContextMem->next_free_ctx = cpu_to_be32(prev_addr);
+                ii = (int)((uint8_t *)IprContextMem - (uint8_t *)FmMurambaseAddr);
+                {
+                        uint32_t *ptr;
+                        uint32_t count;
+
+                        prev_addr = cpu_to_be32(IprContextMem->next_free_ctx);
+                        printk("%s::IprContextMem %p, %08x, next free ctx %08x\n",
+                                __FUNCTION__, IprContextMem, ii, prev_addr);
+                        count = 0;
+                        while(1) {
+                                if (prev_addr == IPR_CONTEXT_EOL)
+                                        break;
+#if 0
+                                printk("memaddr %08x\n", prev_addr);
+#endif
+                                ptr = (uint32_t *)(FmMurambaseAddr + prev_addr);
+                                prev_addr = cpu_to_be32(*ptr);
+                                count++;
+                        }
+                        printk("%d free contexts initialized\n", count);
+                }
+        } else {
+                ii = (int)((uint8_t *)IprContextMem - (uint8_t *)FmMurambaseAddr);
+        }
+        //return offset in muram of IPR context in muram
+        return ii;
+}
+#endif
+
+extern void disp_sch_info(void *);
+t_Handle ExternalHashTableSet(t_Handle h_FmPcd, t_FmPcdHashTableParams *p_Param)
+{
+	struct en_exthash_info *info;
+	t_Handle h_FmMuram;
+	uint32_t ii;
+	uint8_t num_of_zeroes = 0;
+	struct en_exthash_node *node;
+	uint64_t tblphysaddr;
+	t_FmPcd *p_FmPcd = (t_FmPcd*)h_FmPcd;
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+	uint32_t gpp_table;
+        uint32_t table_type;
+
+	p_Param->table_type &= TABLE_TYPE_MASK;
+        switch (p_Param->table_type) {
+                case IPV4_REASSM_TABLE:
+                        if (ipv4_reassly_tbl_info) {
+#ifdef FM_EHASH_DEBUG 
+                                printk("%s::ipv4_reassly_tbl_info already created %p\n",
+                                        __FUNCTION__, ipv4_reassly_tbl_info);
+#endif
+                                return (t_Handle)ipv4_reassly_tbl_info;
+                        }
+                        gpp_table = 0;
+                        table_type = REASSEMBLY_TABLE;
+                        //override xml definitions
+                        p_Param->hashResMask = (MAX_REASSM_BUCKETS - 1);
+                        break;
+                case IPV6_REASSM_TABLE:
+                        if (ipv6_reassly_tbl_info) {
+#ifdef FM_EHASH_DEBUG 
+                                printk("%s::ipv6_reassly_tbl_info already created %p\n",
+                                        __FUNCTION__, ipv6_reassly_tbl_info);
+#endif
+                                return (t_Handle)ipv6_reassly_tbl_info;
+                        }
+                        table_type = REASSEMBLY_TABLE;
+                        //override xml definitions
+                        p_Param->hashResMask = (MAX_REASSM_BUCKETS - 1);
+                        gpp_table = 0;
+                        break;
+		case IPV4_UDP_TABLE:
+		case IPV4_TCP_TABLE:
+                case ESP_IPV4_TABLE:
+                case IPV6_UDP_TABLE:
+                case IPV6_TCP_TABLE:
+                case ESP_IPV6_TABLE:
+		case IPV4_3TUPLE_UDP_TABLE:
+		case IPV4_3TUPLE_TCP_TABLE:
+ 	       	case IPV6_3TUPLE_UDP_TABLE:
+        	case IPV6_3TUPLE_TCP_TABLE:
+                        table_type = L4_TABLE;
+                        gpp_table = 1;
+                        break;
+
+                case IPV4_MULTICAST_TABLE:
+                case IPV6_MULTICAST_TABLE:
+                        table_type = L3_TABLE;
+                        gpp_table = 1;
+                        break;
+                default:
+                        table_type = L2_TABLE;
+                        gpp_table = 1;
+                        break;
+
+        }
+#endif
+	//allocate table info structure
+	info = kzalloc(sizeof(struct en_exthash_info), GFP_KERNEL);
+	if (!info) {
+        	REPORT_ERROR(MAJOR, E_NO_MEMORY,
+                	     ("allocation for en_ext_hash_info"));
+        	return NULL;
+	}
+#ifdef FM_EHASH_DEBUG 
+	printk("%s(%d) info %p \n",__FUNCTION__,__LINE__,info);
+#endif
+	memset(info, 0, sizeof(struct en_exthash_info));
+		
+	//determine number of bits set in the hash mask
+	ii = p_Param->hashResMask;
+#ifdef CONFIG_FMAN_ARM
+        __asm__ ("clz %0,%1\n"
+                        : "=r"(num_of_zeroes)
+                        : "r"(ii));
+#else
+        __asm__ ("cntlzw %0,%1\n"
+                        : "=r"(num_of_zeroes)
+                        : "r"(ii));
+#endif
+	h_FmMuram = FmPcdGetMuramHandle(h_FmPcd);
+    	if (!h_FmMuram) {
+        	REPORT_ERROR(MAJOR, E_INVALID_HANDLE,
+                	     ("muram"));
+		goto err_ret;
+	}
+	info->hashmask = p_Param->hashResMask;
+	info->pcd = h_FmPcd;
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD 
+	info->type = p_Param->table_type;
+	if (gpp_table) 
+#endif
+	{
+                //spin locks are required for tables filled by GPP
+                //not required for reassembly tables, used by uCode only
+                //allocate memory for bucket lock handles
+                info->pSpinlock = XX_MallocSmart((sizeof(t_Handle *) * (info->hashmask + 1)),
+                        0, sizeof(t_Handle));
+                if (!info->pSpinlock) {
+                        REPORT_ERROR(MAJOR, E_NO_MEMORY,
+                             ("spin lock array"));
+                        goto err_ret;
+                }
+                //allocate and initialize spin locks on all buckets
+                for (ii = 0; ii <= info->hashmask; ii++) {
+                        *(info->pSpinlock + ii) = XX_InitSpinlock();
+                        if (!*(info->pSpinlock + ii)) {
+                                REPORT_ERROR(MAJOR, E_NO_MEMORY,
+                                 ("spinlock for en_ext_hash"));
+                                goto err_ret;
+                        }
+                }
+        }
+	//each bucket entry is a 64 bit physical address  
+        info->tablesize = (sizeof(uint64_t) << (64 - num_of_zeroes));
+    	info->table_base = XX_MallocSmart(info->tablesize, 0 /*p_Param->externalHashParams.dataMemId not used */, 
+			EN_EXTHASH_TBL_ALIGNMENT);
+    	if (!info->table_base)
+    	{
+        	REPORT_ERROR(MAJOR, E_NO_MEMORY,
+                	     ("en_ext_hash_table"));
+		goto err_ret;
+    	}
+	//clear table
+	memset(info->table_base, 0, info->tablesize);
+	//allocate node for table in muram
+// following code may not be rqd -- TBD
+//	{
+//		t_FmPcd *p_FmPcd = (t_FmPcd *)h_FmPcd;
+ //       	ii = (uint32_t)((XX_VirtToPhys(info->h_Ad)
+ //                               - p_FmPcd->physicalMuramBase));
+//	}
+	info->keysize = p_Param->matchKeySize;       
+        info->hashshift = p_Param->hashShift;
+        //info->dataMemId = p_Param->externalHashParams.dataMemId;
+//        info->dataLiodnOffset = p_Param->externalHashParams.dataMemId;
+//	if (p_Param->agingSupport) 
+		info->flags |= TIMESTAMP_EN;
+	if (p_Param->statisticsMode) 
+		info->flags |= STATS_EN;
+	//fill AD
+	node = &info->node;
+	memset(node, 0, sizeof(struct en_exthash_node));
+	node->key_size = info->keysize;		
+	node->hash_bytes_offset = info->hashshift;	
+	node->hash_mask = info->hashmask ;
+	node->int_buf_pool_addr = p_FmPcd->InternalBufMgmtMuramArea;
+	tblphysaddr = XX_VirtToPhys(info->table_base);
+#ifdef FM_EHASH_DEBUG 
+	printk("%s::table base %p, physaddr %p\n", __FUNCTION__, info->table_base, (void *)tblphysaddr);
+#endif
+	node->table_base_hi = ((tblphysaddr >> 32) & 0xffff);	
+	node->table_base_lo = (tblphysaddr & 0xffffffff);		
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+	node->table_type = table_type;
+#endif
+	//check next engine for miss action
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+	if (gpp_table) 
+#endif
+	{
+		switch (p_Param->ccNextEngineParamsForMiss.nextEngine) {
+			case e_FM_PCD_KG:
+			{
+				//Keygen
+				t_FmPcdCcNextKgParams *kgparams;
+				kgparams =
+					&p_Param->ccNextEngineParamsForMiss.params.kgParams;
+#ifdef FM_EHASH_DEBUG 
+				printk("%s::Nextengine = KG, kgparams->h_DirectScheme %p\n", 
+					__FUNCTION__, kgparams->h_DirectScheme);
+#endif
+				node->nia = (NIA_ENG_KG | NIA_KG_DIRECT);
+				if (kgparams->overrideFqid) 
+                    			node->nia |= (kgparams->newFqid | NIA_KG_CC_EN);
+                		node->nia |= FmPcdKgGetSchemeId(kgparams->h_DirectScheme);
+#ifdef FM_EHASH_DEBUG 
+				disp_sch_info(kgparams->h_DirectScheme);
+#endif
+				node->miss_action_type = EN_EHASH_MISS_ACTION_NIA;
+				break;
+		}
+		case e_FM_PCD_DONE:
+		{
+				//BMI
+				t_FmPcdCcNextEnqueueParams *enqparams;
+				enqparams = 
+					&p_Param->ccNextEngineParamsForMiss.params.enqueueParams;
+#ifdef FM_EHASH_DEBUG
+                               printk("%s:: EN_EHASH_MISS_ACTION_NIA %d , ovrdfqid %d\n",
+                                       __FUNCTION__, EN_EHASH_MISS_ACTION_NIA,enqparams->overrideFqid);
+#endif
+				if (enqparams->overrideFqid)
+					node->fqid = enqparams->newFqid;
+				if (enqparams->overrideFqid)
+				{
+					node->miss_action_type = EN_EHASH_MISS_ACTION_ENQUE;
+				}
+				else
+					node->miss_action_type = EN_EHASH_MISS_ACTION_DONE;
+#ifdef FM_EHASH_DEBUG
+printk("node->fqid : %d \n", node->fqid);
+#endif
+				break;
+		}
+		default:
+			node->miss_action_type = EN_EHASH_MISS_ACTION_DROP;
+#ifdef FM_EHASH_DEBUG
+			printk("%s::Nextengine type %d not supported, drop case\n", __FUNCTION__,
+				p_Param->ccNextEngineParamsForMiss.nextEngine);
+#endif
+			break;
+		}
+	}
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+ 	else {
+		//ipr table
+                uint32_t mem_size;
+		int iprctxinfo;
+
+		iprctxinfo = GetMuramIprContextMem(h_FmPcd);
+                if (iprctxinfo == -1)
+                        goto err_ret;
+
+		mem_size = (sizeof(struct ip_reassembly_params) +
+                                        REASSM_DEBUG_SIZE);
+                //reassembly table, allocate stats and other info
+                info->ip_reassem_info = (struct ip_reassembly_params *)
+                        PTR_TO_UINT(FM_MURAM_AllocMem(FmPcdGetMuramHandle(h_FmPcd),
+                                mem_size, sizeof(uint64_t)));
+                if (!info->ip_reassem_info)
+                {
+                        REPORT_ERROR(MAJOR, E_NO_MEMORY, ("MURAM allocation for reassem info"));
+                        goto err_ret;
+                }
+                node->reassm_param =
+                        (uint32_t)((uint8_t *)info->ip_reassem_info - (uint8_t *)FmMurambaseAddr);
+                info->ip_reassem_info->type = (p_Param->table_type);
+                info->ip_reassem_info->table_base_hi =
+                        cpu_to_be32(tblphysaddr >> 32);
+                info->ip_reassem_info->table_base_lo = cpu_to_be32(tblphysaddr & 0xffffffff);
+                info->ip_reassem_info->table_mask = cpu_to_be32(node->hash_mask);
+                info->ip_reassem_info->timeout_val = cpu_to_be32(p_Param->timeout_val);
+                info->ip_reassem_info->timeout_fqid = cpu_to_be32(p_Param->timeout_fqid);
+                info->ip_reassem_info->max_frags = cpu_to_be32(p_Param->max_frags);
+                info->ip_reassem_info->min_frag_size = cpu_to_be32(p_Param->min_frag_size);
+                info->ip_reassem_info->max_con_reassm = cpu_to_be32(p_Param->max_sessions);
+                info->ip_reassem_info->timer_tnum = 0xffffffff; //no task assigned yet
+                info->ip_reassem_info->curr_sessions = 0;
+                info->ip_reassem_info->reassly_dbg =
+                        cpu_to_be32(node->reassm_param + sizeof(struct ip_reassembly_params));
+		info->ip_reassem_info->context_info = cpu_to_be32(iprctxinfo);
+                memset(&info->ip_reassem_info->stats, 0, sizeof(struct ip_reassembly_stats));
+		for (ii = 0; ii < MAX_REASSM_BUCKETS; ii++) {
+                        info->ip_reassem_info->bucket_lock[ii] = 0;
+                        info->ip_reassem_info->bucket_head[ii] = (uint64_t)0;
+                }
+#if 1//def FM_EHASH_DEBUG
+                if (p_Param->table_type == IPV4_REASSM_TABLE)
+                        printk("%s::ipv4 reassem param ", __FUNCTION__);
+                else
+                        printk("%s::ipv6 reassem param ", __FUNCTION__);
+                printk("%x, size %d dbg %x\n",
+                                node->reassm_param,
+                                (uint32_t)(sizeof(struct ip_reassembly_params) +
+                                REASSM_DEBUG_SIZE),
+                                cpu_to_be32(info->ip_reassem_info->reassly_dbg));
+                printk(KERN_INFO "%s::en ext hash reassem table created, handle %p\n",
+                        __FUNCTION__, info);
+#endif
+	}
+#endif
+
+#ifdef FM_EHASH_DEBUG
+	printk(KERN_INFO "%s::en ext hash table created, handle %p\n",
+			__FUNCTION__, info);
+	printk("ad_word_0::%08x\n", node->word_0);
+	printk("ad_word_1::%08x\n", node->table_base_lo);
+	printk("ad_word_2::%08x\n", node->word_1);
+	printk("ad_word_3::%08x\n", node->word_2);
+#endif //FM_EHASH_DEBUG
+
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+	 switch (p_Param->table_type) {
+                case IPV4_REASSM_TABLE:
+                        ipv4_reassly_tbl_info = info;
+#ifdef FM_EHASH_DEBUG
+                        printk("%s::saving ipv4_reassly_tbl_info %p\n",
+                                        __FUNCTION__, ipv4_reassly_tbl_info);
+#endif
+                        break;
+                case IPV6_REASSM_TABLE:
+                        ipv6_reassly_tbl_info = info;
+#ifdef FM_EHASH_DEBUG
+                        printk("%s::saving ipv6_reassly_tbl_info %p\n",
+                                        __FUNCTION__, ipv6_reassly_tbl_info);
+#endif
+                        break;
+                default:
+                        break;
+        }
+#endif
+#ifdef FM_EHASH_DEBUG
+	//display_ehashtbl_info(info, __FUNCTION__);
+	printk("%s::handle %p\n", __FUNCTION__, info);
+#endif //FM_EHASH_DEBUG
+	return (t_Handle)info;
+err_ret:
+	Delete_EnEhashInfo(info);	
+	return NULL;
+}
+
+
+t_Error ExternalHashTableModifyMissNextEngine(t_Handle h_HashTbl, t_FmPcdCcNextEngineParams *p_FmPcdCcNextEngineParams)
+{
+	struct en_exthash_info *info;
+	struct en_exthash_node node;
+
+	info = (struct en_exthash_info *)h_HashTbl;
+
+	node.word_0 = GET_UINT32(((struct en_exthash_node *)info->h_Ad)->word_0);
+	node.word_2 = GET_UINT32(((struct en_exthash_node *)info->h_Ad)->word_2);
+
+	//set action type to miss temporarily
+	node.miss_action_type = EN_EHASH_MISS_ACTION_DROP;
+	WRITE_UINT32(((struct en_exthash_node *)info->h_Ad)->word_0, node.word_0);
+
+	//set new miss action
+	switch (p_FmPcdCcNextEngineParams->nextEngine) {
+		case e_FM_PCD_KG:
+		{
+			//Keygen
+			t_FmPcdCcNextKgParams *kgparams;
+			kgparams = &p_FmPcdCcNextEngineParams->params.kgParams;
+#ifdef FM_EHASH_DEBUG
+			printk("%s::Nextengine = KG, kgparams->h_DirectScheme %p\n",
+				__FUNCTION__, kgparams->h_DirectScheme);
+#endif
+			node.nia = (NIA_ENG_KG | NIA_KG_DIRECT | NIA_KG_CC_EN);
+			node.nia |= FmPcdKgGetSchemeId(kgparams->h_DirectScheme);
+#ifdef FM_EHASH_DEBUG
+			disp_sch_info(kgparams->h_DirectScheme);
+#endif
+			node.miss_action_type = EN_EHASH_MISS_ACTION_NIA;
+			break;
+		}
+               case e_FM_PCD_DONE:
+		{
+			//BMI
+			t_FmPcdCcNextEnqueueParams *enqparams;
+			enqparams =
+				&p_FmPcdCcNextEngineParams->params.enqueueParams;
+#ifdef FM_EHASH_DEBUG
+			printk("%s:: EN_EHASH_MISS_ACTION_NIA %d , ovrdfqid %d\n",
+				__FUNCTION__, EN_EHASH_MISS_ACTION_NIA,enqparams->overrideFqid);
+#endif
+			if (enqparams->overrideFqid)
+				node.fqid = enqparams->newFqid;
+			if (enqparams->overrideFqid)
+			{
+				node.miss_action_type = EN_EHASH_MISS_ACTION_ENQUE;
+			}
+			else
+				node.miss_action_type = EN_EHASH_MISS_ACTION_DONE;
+			break;
+		}
+		default:
+			node.miss_action_type = EN_EHASH_MISS_ACTION_DROP;
+#ifdef FM_EHASH_DEBUG
+			printk("%s::Nextengine type %d not supported, drop case\n", __FUNCTION__,
+				p_FmPcdCcNextEngineParams->nextEngine);
+#endif
+			break;
+	}
+	//write the new params
+	WRITE_UINT32(((struct en_exthash_node *)info->h_Ad)->word_2, node.word_2);
+	WRITE_UINT32(((struct en_exthash_node *)info->h_Ad)->word_0, node.word_0);
+#ifdef FM_EHASH_DEBUG
+	node.word_0 = GET_UINT32(((struct en_exthash_node *)info->h_Ad)->word_0);
+	node.table_base_lo = GET_UINT32(((struct en_exthash_node *)info->h_Ad)->table_base_lo);
+	printk("ad_word_0::%p, %08x\n", &(((struct en_exthash_node *)info->h_Ad)->word_0),
+                                       node.word_0);
+	printk("ad_word_1::%p, %08x\n", &(((struct en_exthash_node *)info->h_Ad)->table_base_lo),
+                                       node.table_base_lo);
+	printk("ad_word_2::%p, %08x\n", &(((struct en_exthash_node *)info->h_Ad)->word_1),
+                                       node.word_1);
+	printk("ad_word_3::%p, %08x\n", &(((struct en_exthash_node *)info->h_Ad)->word_2),
+                                       node.word_2);
+#endif
+	return E_OK;
+}
+
+int ExternalHashTableFmPcdHcSync(void *h_HashTbl)
+{
+	struct en_exthash_info *info;
+	info = (struct en_exthash_info *)h_HashTbl;
+	if (FmPcdHcSync(info->pcd)) {
+		printk("%s::FmPcdHcSync failed\n", __FUNCTION__);
+		return -1;
+	}
+	return 0;
+}
+EXPORT_SYMBOL(ExternalHashTableFmPcdHcSync); 
+
+int ExternalHashTableDeleteKey(void *h_HashTbl, uint16_t index, void *tbl_entry)
+{
+	t_Handle *h_Spinlock;
+	uint32_t intFlags;
+	uint64_t phyaddr;
+	struct en_exthash_info *info;
+	void *bucket;
+	struct en_exthash_tbl_entry *entry;
+	struct en_exthash_tbl_entry *temp_entry;
+#ifndef NO_CUMULATIVE_ENTRY
+	struct en_cumulative_entry *cumulative_entry, *tmp;
+	struct en_cumulative_tbl_entry *cumulative_tbl_entry, *tmp_tbl_entry = NULL;
+	uint8_t ii, match=0, flags;
+#else
+	uint64_t update_entry; 
+#endif // NO_CUMULATIVE_ENTRY
+
+#ifdef FM_EHASH_DEBUG
+	printk("%s::tbl %p, index %x\n", __FUNCTION__, h_HashTbl, index);
+#endif
+	info = (struct en_exthash_info *)h_HashTbl;
+	bucket = ((uint64_t *)info->table_base + index);
+	entry = (struct en_exthash_tbl_entry *)tbl_entry;
+	h_Spinlock = *(info->pSpinlock + index);
+	intFlags = XX_LockIntrSpinlock(h_Spinlock);
+#ifdef NO_CUMULATIVE_ENTRY
+	//SET_INVALID_ENTRY(entry->hashentry.flags); // setting invalid flag
+        update_entry = SwapUint64(entry->hashentry.next_entry);
+        SET_INVALID_ENTRY_64BIT(update_entry);
+        entry->hashentry.next_entry = SwapUint64(update_entry);
+	if (entry->prev) {
+                //adjust software links
+		temp_entry = entry->prev;
+		temp_entry->next = entry->next;
+		if (entry->next)
+			(entry->next)->prev = temp_entry;
+		//temp_entry->hashentry.next_entry_lo = entry->hashentry.next_entry_lo;
+		//temp_entry->hashentry.next_entry_hi = entry->hashentry.next_entry_hi;
+                update_entry = (entry->hashentry.next_entry & (~0xffff));
+                temp_entry->hashentry.next_entry = (update_entry | (temp_entry->hashentry.flags));
+	} else {
+		phyaddr = XX_VirtToPhys(entry->next);
+		*((uint64_t *)bucket) = SwapUint64(phyaddr);
+//                phyaddr = SwapUint64(entry->hashentry.next_entry_lo |
+  //                      (entry->hashentry.next_entry_hi << 32));
+                //remove from head
+                //zero prev of next entry
+		if (entry->next)
+			(entry->next)->prev = NULL;
+	}
+	XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+	if (FmPcdHcSync(info->pcd)) {
+		printk("%s::FmPcdHcSync failed\n", __FUNCTION__);
+		return -1;
+	}
+	return 0;
+#else
+	FM_EHASH_PRINT("%s(%d) tbl_entry %p\n", __FUNCTION__,__LINE__,tbl_entry);
+	// check if it normal node or cumulative node 
+	// no cumulative node, its only one node in hash bucket, delete
+	phyaddr = XX_VirtToPhys(entry);
+	if (*((uint64_t *)bucket) == SwapUint64(phyaddr))
+	{
+		FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+		*((uint64_t *)bucket) = 0;
+		XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+		if (FmPcdHcSync(info->pcd)) {
+			printk("%s::FmPcdHcSync failed\n", __FUNCTION__);
+			return -1;
+		}
+		return 0;
+	}
+	else
+	{
+		FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+		// get cumulative entry node address.
+		phyaddr = *((uint64_t *)bucket);
+		cumulative_tbl_entry = XX_PhysToVirt(SwapUint64(phyaddr));
+		cumulative_entry = &cumulative_tbl_entry->cumulative_entry;
+		if (!(cumulative_entry->flags & EN_CUMULATIVE_NODE))
+		{
+			FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+       		REPORT_ERROR(MAJOR, E_INVALID_STATE,
+                	     ("Invalid state"));
+			XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+			return -1;
+		}
+		// find matching cumulative entry
+		do
+		{
+			for (ii=0; ii<cumulative_entry->num_key_entries; ii++)
+			{
+				FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+				phyaddr = *((uint64_t *)(&cumulative_entry->data[cumulative_entry->tbl_entry_index - 12 + ii*8]));
+				temp_entry = XX_PhysToVirt(SwapUint64(phyaddr));
+				if (temp_entry == tbl_entry)
+				{
+					match = 1;
+					break;
+				}
+			}
+			if (match)
+				break;
+			if (cumulative_tbl_entry->next_entry)
+			{
+				cumulative_tbl_entry = cumulative_tbl_entry->next_entry;
+				cumulative_entry = &cumulative_tbl_entry->cumulative_entry;
+			}
+			else
+				cumulative_entry =  NULL;
+		}while (cumulative_entry);
+		if (match) // if found
+		{
+			FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+			// cumulative entry might have the next entry, in that case, get the last table entry in last cumulative entry
+			// and overwrite it with to-be-deleted table entry
+			flags =  cumulative_entry->flags | EN_INVALID_CUMULATIVE_NODE;
+			cumulative_entry->flags = flags;
+			if ((cumulative_entry->num_key_entries > 2) ||
+				((cumulative_entry->num_key_entries == 2) &&
+				  ((cumulative_tbl_entry->prev_entry) || (cumulative_tbl_entry->next_entry))))
+			{
+				tmp_tbl_entry = ExternalHashTableAllocCumulativeEntry (h_HashTbl);
+				if (!tmp_tbl_entry)
+				{
+					REPORT_ERROR(MAJOR, E_NO_MEMORY,
+								 ("en_cumulative_entry"));
+					XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+					return -1;
+				}
+				FM_EHASH_PRINT(" case 1 num keys > 1 %s(%d)\n",__FUNCTION__,__LINE__);
+				tmp = &tmp_tbl_entry->cumulative_entry;
+				tmp->flags = cumulative_entry->flags & 0xbf; 
+				tmp->key_size =  cumulative_entry->key_size;
+				tmp->next_entry_addr = cumulative_entry->next_entry_addr;
+				tmp->num_key_entries = cumulative_entry->num_key_entries-1;
+				tmp->tbl_entry_index = cumulative_entry->tbl_entry_index - cumulative_entry->key_size;
+				FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+				if (ii)
+				{
+					FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+					memcpy(tmp->data, &cumulative_entry->data, (ii*cumulative_entry->key_size));
+					memcpy(&tmp->data[tmp->num_key_entries*tmp->key_size+1], 
+						&cumulative_entry->data[cumulative_entry->num_key_entries*tmp->key_size+1], ii*EN_CU_HASH_TABLE_ENTRY_ADDR_SIZE);
+				}
+				if (ii < cumulative_entry->num_key_entries-1)
+				{
+					FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+					memcpy(tmp->data+(ii*cumulative_entry->key_size), 
+						&cumulative_entry->data[(ii+1)*cumulative_entry->key_size],
+					(cumulative_entry->num_key_entries-ii-1)*cumulative_entry->key_size+1);
+					memcpy(&tmp->data[(tmp->num_key_entries*tmp->key_size)+1+(ii*EN_CU_HASH_TABLE_ENTRY_ADDR_SIZE)], 
+						&cumulative_entry->data[cumulative_entry->num_key_entries*tmp->key_size+1+((ii+1)*EN_CU_HASH_TABLE_ENTRY_ADDR_SIZE)],
+						(tmp->num_key_entries - ii)*EN_CU_HASH_TABLE_ENTRY_ADDR_SIZE);
+				}
+				if (cumulative_tbl_entry->next_entry)
+				{
+					FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+					tmp_tbl_entry->next_entry = cumulative_tbl_entry->next_entry;
+					cumulative_tbl_entry->next_entry->prev_entry = tmp_tbl_entry;
+				}
+				phyaddr = SwapUint64(XX_VirtToPhys(tmp_tbl_entry));
+				if (cumulative_tbl_entry->prev_entry)
+				{
+					FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+					cumulative_tbl_entry->prev_entry->cumulative_entry.next_entry_addr = phyaddr;
+					tmp_tbl_entry->prev_entry = cumulative_tbl_entry->prev_entry;
+					cumulative_tbl_entry->prev_entry->next_entry =  tmp_tbl_entry;
+				}
+				else
+				{
+					FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+					*((uint64_t *)bucket) = phyaddr;
+				}
+				XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+				if (FmPcdHcSync(info->pcd)) {
+					printk("%s::FmPcdHcSync failed\n", __FUNCTION__);
+					return -1;
+				}
+				ExternalHashTableCumulativeEntryFree(cumulative_tbl_entry);
+			}
+			else  // if only one entry in list and there is next pointer
+			{
+				FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+				if ((!(cumulative_tbl_entry->next_entry) &&
+					  !(cumulative_tbl_entry->prev_entry) &&
+					 (cumulative_entry->num_key_entries == 2)) || 
+					((!cumulative_tbl_entry->prev_entry) && 
+					 (cumulative_tbl_entry->next_entry) && 
+					 (cumulative_tbl_entry->next_entry->cumulative_entry.num_key_entries == 1) &&
+					 (!cumulative_tbl_entry->next_entry->next_entry)) ||
+					((cumulative_tbl_entry->prev_entry) && 
+					 !(cumulative_tbl_entry->next_entry) && 
+					 (cumulative_tbl_entry->prev_entry->cumulative_entry.num_key_entries == 1) &&
+					 (!cumulative_tbl_entry->prev_entry->prev_entry))) 
+				{
+					// special case where only one entry in list exists
+					if (cumulative_tbl_entry->next_entry)
+					{
+						FM_EHASH_PRINT("%s(%d) special case where only one entry in list exists\n",__FUNCTION__,__LINE__);
+						tmp_tbl_entry = cumulative_tbl_entry->next_entry;
+						flags = tmp_tbl_entry->cumulative_entry.flags | EN_INVALID_CUMULATIVE_NODE;
+						tmp_tbl_entry->cumulative_entry.flags =	flags;
+						phyaddr = *((uint64_t *)
+							(&tmp_tbl_entry->cumulative_entry.data[tmp_tbl_entry->cumulative_entry.tbl_entry_index-EN_CU_FIXED_ELEMENTS_SIZE]));
+						*((uint64_t *)bucket) = phyaddr;
+					}
+					else if (cumulative_tbl_entry->prev_entry)
+					{
+						FM_EHASH_PRINT("%s(%d) special case where only one entry in list exists\n",__FUNCTION__,__LINE__);
+						tmp_tbl_entry = cumulative_tbl_entry->prev_entry;
+						flags = tmp_tbl_entry->cumulative_entry.flags | EN_INVALID_CUMULATIVE_NODE;
+						tmp_tbl_entry->cumulative_entry.flags =	flags;
+						phyaddr = *((uint64_t *)
+							(&tmp_tbl_entry->cumulative_entry.data[tmp_tbl_entry->cumulative_entry.tbl_entry_index-EN_CU_FIXED_ELEMENTS_SIZE]));
+						*((uint64_t *)bucket) = phyaddr;
+					}
+					else
+					{
+						tmp_tbl_entry = NULL;
+						if (ii)
+							phyaddr = *((uint64_t *)(&cumulative_entry->data[cumulative_entry->tbl_entry_index-EN_CU_FIXED_ELEMENTS_SIZE]));
+						else					
+							phyaddr = *((uint64_t *)(&cumulative_entry->data[cumulative_entry->tbl_entry_index-EN_CU_FIXED_ELEMENTS_SIZE+EN_CU_HASH_TABLE_ENTRY_ADDR_SIZE]));
+						*((uint64_t *)bucket) = phyaddr;
+						FM_EHASH_PRINT("%s(%d) special case where only one entry %p in list exists\n",__FUNCTION__,__LINE__,
+							XX_PhysToVirt(SwapUint64(phyaddr)));
+					}
+					XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+					if (FmPcdHcSync(info->pcd)) {
+						printk("%s::FmPcdHcSync failed\n", __FUNCTION__);
+						return -1;
+					}
+					if (tmp_tbl_entry)
+						ExternalHashTableCumulativeEntryFree(tmp_tbl_entry);
+					ExternalHashTableCumulativeEntryFree(cumulative_tbl_entry);
+				}
+				else if (!cumulative_tbl_entry->prev_entry) // this is the first cumulative entry in list
+				{
+					if (cumulative_tbl_entry->next_entry)
+					{
+						// update the bucket with next cumulative node
+						FM_EHASH_PRINT("%s(%d) update the bucket with next cumulative node as no prev entry \n",__FUNCTION__,__LINE__);
+						cumulative_tbl_entry->next_entry->prev_entry =  NULL;
+						phyaddr = SwapUint64(XX_VirtToPhys(cumulative_tbl_entry->next_entry));
+						*((uint64_t *)bucket) = phyaddr;
+						XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+						if (FmPcdHcSync(info->pcd)) {
+							printk("%s::FmPcdHcSync failed\n", __FUNCTION__);
+							return -1;
+						}
+						ExternalHashTableCumulativeEntryFree(cumulative_tbl_entry);						
+					}
+					else // no next node , no prev node , only table entry in node ==> invalid case
+					{
+						FM_EHASH_PRINT("%s(%d)no next node , no prev node , only table entry in node ==> invalid case\n",__FUNCTION__,__LINE__);
+						REPORT_ERROR(MAJOR, E_INVALID_STATE,
+									 ("Invalid state"));
+						XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+						return -1;
+					}
+				}
+				else // this node is not the first node
+				{
+					FM_EHASH_PRINT("%s(%d) this node is not the first node \n",__FUNCTION__,__LINE__);
+					if (cumulative_tbl_entry->next_entry)
+					{
+						// update the bucket with next cumulative node
+						FM_EHASH_PRINT("%s(%d) update the next cumulative node with prev entry\n",__FUNCTION__,__LINE__);
+						cumulative_tbl_entry->next_entry->prev_entry =  cumulative_tbl_entry->prev_entry;
+						cumulative_tbl_entry->prev_entry->next_entry =	cumulative_tbl_entry->next_entry;
+						cumulative_tbl_entry->prev_entry->cumulative_entry.next_entry_addr = cumulative_tbl_entry->cumulative_entry.next_entry_addr ;
+					}
+					else
+					{
+						flags = cumulative_tbl_entry->prev_entry->cumulative_entry.flags & ~EN_NEXT_CUMULATIVE_NODE;
+						FM_EHASH_PRINT("%s(%d) update the next cumulative node with prev entry\n",__FUNCTION__,__LINE__);
+						cumulative_tbl_entry->prev_entry->cumulative_entry.flags = flags;
+						cumulative_tbl_entry->prev_entry->next_entry =	NULL;
+						cumulative_tbl_entry->prev_entry->cumulative_entry.next_entry_addr = 0;
+					}
+					XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+					if (FmPcdHcSync(info->pcd)) {
+						printk("%s::FmPcdHcSync failed\n", __FUNCTION__);
+						return -1;
+					}
+					ExternalHashTableCumulativeEntryFree(cumulative_tbl_entry);						
+				}
+			}
+		}// match not found
+		else
+		{
+			XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+			REPORT_ERROR(MAJOR, E_INVALID_STATE,
+						 ("No matching node"));
+			return -1;
+		}
+		
+	}
+
+#ifdef FM_EHASH_DEBUG
+	printk("%s(%d)\n",__FUNCTION__,__LINE__);
+	cumulative_entry = XX_PhysToVirt(SwapUint64(*((uint64_t *)bucket)));
+	if (!cumulative_entry)
+		return 0;
+	if (!(cumulative_entry->flags & EN_CUMULATIVE_NODE))
+	{
+		printk("head ptr: %p\n", cumulative_entry);
+	}
+	while (cumulative_entry && (cumulative_entry->flags & EN_CUMULATIVE_NODE))
+	{
+		printk("cumulative entry : %p \n", cumulative_entry);
+		{
+			uint32_t ii;
+		
+			printk("flags: 0x%x, key-size %d, key_entries: %d, nodes_index: %d, next_entry 0x%lx\n", 
+				cumulative_entry->flags, 
+				cumulative_entry->key_size, cumulative_entry->num_key_entries, cumulative_entry->tbl_entry_index,
+				(long unsigned int)(cumulative_entry->next_entry_addr));
+			printk("cumulative key: \n");
+			for (ii=0; ii<((cumulative_entry->key_size*cumulative_entry->num_key_entries)+1); ii++)
+			{
+				if ((ii % 16) == 0)
+					printk("\n");
+				printk("%02x ", cumulative_entry->data[ii]);
+			}
+			printk(" table entries (%d) : \n",cumulative_entry->num_key_entries);
+			for (ii = 0; ii < cumulative_entry->num_key_entries; ii++) {
+				phyaddr = *((uint64_t *)(&cumulative_entry->data[cumulative_entry->tbl_entry_index-12+ii*8]));
+				printk("table_entry ptr[%d]: %p\n", ii, XX_PhysToVirt(SwapUint64(phyaddr)));
+			}
+			printk("\n");
+		}
+		if (cumulative_entry->flags & EN_NEXT_CUMULATIVE_NODE)
+		{
+			cumulative_entry = XX_PhysToVirt(SwapUint64(cumulative_entry->next_entry_addr));
+		}
+		else
+			cumulative_entry = NULL;
+	}
+#endif // FM_EHASH_DEBUG
+#endif // NO_CUMULATIVE_ENTRY
+#ifdef NO_CUMULATIVE_ENTRY
+	XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+	if (FmPcdHcSync(info->pcd)) {
+		printk("%s::FmPcdHcSync failed\n", __FUNCTION__);
+		return -1;
+	}
+#endif //NO_CUMULATIVE_ENTRY
+	return 0;
+}
+
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+int ExternalHashSetReasslyPool(uint32_t type, uint32_t ctx_bpid, 
+		uint32_t ctx_bsize, uint32_t frag_bpid, uint32_t frag_bsize, 
+		uint32_t txc_fqid, uint32_t ipr_timer_freq)
+{
+	uint32_t ii;
+
+        switch (type)
+        {
+                case IPV4_REASSM_TABLE:
+                        if (!ipv4_reassly_tbl_info) {
+                                printk("%s::ipv4 frag table not setup\n", __FUNCTION__);
+                                return -1;
+                        }
+			printk("ipv4 reassembly ctx_bpid %d, frag_bpid %d timerfreq %d\n", 
+				ctx_bpid, frag_bpid, ipr_timer_freq);
+			ipv4_reassly_tbl_info->ip_reassem_info->reassem_bpid = 
+				cpu_to_be32(ctx_bpid);
+			ipv4_reassly_tbl_info->ip_reassem_info->reassem_bsize = 
+				cpu_to_be32(ctx_bsize);
+			ipv4_reassly_tbl_info->ip_reassem_info->frag_bpid = 
+				cpu_to_be32(frag_bpid);
+			ipv4_reassly_tbl_info->ip_reassem_info->frag_bsize = 
+				cpu_to_be32(frag_bsize);
+			ii = cpu_to_be32(ipv4_reassly_tbl_info->ip_reassem_info->timeout_val);  
+			ipv4_reassly_tbl_info->ip_reassem_info->timeout_val = 
+				cpu_to_be32(ii / ipr_timer_freq);  
+			ipv4_reassly_tbl_info->ip_reassem_info->txc_fqid = 
+				cpu_to_be32(txc_fqid);
+                        break;
+                case IPV6_REASSM_TABLE:
+                        if (!ipv6_reassly_tbl_info) {
+                                printk("%s::ipv6 frag table not setup\n", __FUNCTION__);
+                                return -1;
+                        }
+			printk("ipv6 reassembly ctx_bpid %d, frag_bpid %d timerfreq %d\n", 
+				ctx_bpid, frag_bpid, ipr_timer_freq);
+			ipv6_reassly_tbl_info->ip_reassem_info->reassem_bpid = 
+				cpu_to_be32(ctx_bpid);
+			ipv6_reassly_tbl_info->ip_reassem_info->reassem_bsize = 
+				cpu_to_be32(ctx_bsize);
+			ipv6_reassly_tbl_info->ip_reassem_info->frag_bpid = 
+				cpu_to_be32(frag_bpid);
+			ipv6_reassly_tbl_info->ip_reassem_info->frag_bsize = 
+				cpu_to_be32(frag_bsize);
+			ii = cpu_to_be32(ipv4_reassly_tbl_info->ip_reassem_info->timeout_val);  
+			ipv6_reassly_tbl_info->ip_reassem_info->timeout_val = 
+				cpu_to_be32(ii / ipr_timer_freq);  
+			ipv6_reassly_tbl_info->ip_reassem_info->txc_fqid = 
+				cpu_to_be32(txc_fqid);
+                        break;
+
+
+                default:
+                        printk("%s::invalid frag table type %d\n", __FUNCTION__, type);
+                        return -1;
+        }
+	return 0;
+}
+
+static void display_debug_info(struct ip_reassembly_params *params)
+{
+	char *sbuf;
+	char *buf;
+	uint8_t *ptr;
+	uint32_t ii;
+
+	buf = (char *)kzalloc(1024, GFP_KERNEL);
+	sbuf = buf;
+ 	if (sbuf) {	
+		sbuf += sprintf(sbuf, "debug info::\n");
+		ptr = ((uint8_t *)params + sizeof(struct ip_reassembly_params));
+		for (ii = 0; ii < REASSM_DEBUG_SIZE; ii++) {
+                	if ((ii % 16) == 15)
+                        	sbuf += sprintf(sbuf, "%02x\n", *ptr);
+               		else
+                        	sbuf += sprintf(sbuf, "%02x ", *ptr);
+        	        ptr++;
+ 	       }
+	}
+        sbuf += sprintf(sbuf, "\n");
+	printk("%s", buf);
+	kfree(buf);	
+}
+
+static void display_reassem_params(uint32_t type)
+{
+        struct ip_reassembly_params *params;
+
+        switch (type)
+        {
+                case IPV4_REASSM_TABLE:
+                        if (!ipv4_reassly_tbl_info) {
+                                printk("%s::ipv4 frag table not setup\n", __FUNCTION__);
+                                return;
+                        }
+			printk("ipv4 reassembly params::");
+			params = ipv4_reassly_tbl_info->ip_reassem_info; 
+                        break;
+                case IPV6_REASSM_TABLE:
+                        if (!ipv6_reassly_tbl_info) {
+                                printk("%s::ipv6 frag table not setup\n", __FUNCTION__);
+                                return;
+                        }
+			printk("ipv6 reassembly params::");
+			params = ipv6_reassly_tbl_info->ip_reassem_info; 
+                        break;
+
+                default:
+                        printk("%s::invalid frag table type %d\n", __FUNCTION__, type);
+                        return;
+        }
+	printk("%p\n", params);
+	{
+		uint64_t ii;
+
+		ii = ((uint64_t)(cpu_to_be32(params->table_base_hi)) << 32);
+		ii |= cpu_to_be32(params->table_base_lo);
+		printk("table base\t%p\n", (void *)ii);
+	}
+	printk("type\t%x\n", cpu_to_be32(params->type));
+	printk("ipr_timer\t%d\n",
+				cpu_to_be32(params->ipr_timer));
+	printk("timeoutval\t%d\n",
+				cpu_to_be32(params->timeout_val));
+	printk("timeout_fqid\t%x(%d)\n",
+				cpu_to_be32(params->timeout_fqid),
+				cpu_to_be32(params->timeout_fqid));
+	printk("max_frags\t%d\n",
+				cpu_to_be32(params->max_frags));
+	printk("min_frag_size\t%d\n",
+				cpu_to_be32(params->min_frag_size));
+	printk("max_con_reassm\t%d\n",
+				cpu_to_be32(params->max_con_reassm));
+	printk("reassem_bpid\t%d\n",
+				cpu_to_be32(params->reassem_bpid));
+	printk("table mask\t%d\n",
+				cpu_to_be32(params->table_mask));
+	printk("reassly_dbg\t%x\n",
+				cpu_to_be32(params->reassly_dbg));
+	printk("timer_info\t%x\n",
+				cpu_to_be32(params->timer_tnum));
+	printk("txc_fqid\t0x%x\n",
+				(cpu_to_be32(params->txc_fqid) & 0xffffff));
+#if 0
+	{
+		uint32_t ii;
+		uint8_t *ptr;
+
+		ptr = (uint8_t *)params;
+		for (ii = 0; ii < sizeof(struct ip_reassembly_params); ii++) {
+			if (ii % 16 == 15)
+				printk("%02x\n", *(ptr + ii));
+			else
+				printk("%02x ", *(ptr + ii));
+		}
+		printk("\n");
+	}
+#endif
+}
+
+int get_ip_reassem_info(uint32_t type, struct ip_reassembly_info *info)
+{
+	struct ip_reassembly_params *params;
+
+        switch (type)
+        {
+                case IPV4_REASSM_TABLE:
+                        if (!ipv4_reassly_tbl_info) {
+                                printk("%s::ipv4 frag table not setup\n", __FUNCTION__);
+                                return -1;
+                        }
+			params = ipv4_reassly_tbl_info->ip_reassem_info; 
+                        break;
+                case IPV6_REASSM_TABLE:
+                        if (!ipv6_reassly_tbl_info) {
+                                printk("%s::ipv6 frag table not setup\n", __FUNCTION__);
+                                return -1;
+                        }
+			params = ipv6_reassly_tbl_info->ip_reassem_info; 
+                        break;
+                default:
+                        printk("%s::invalid frag table type %d\n", __FUNCTION__, type);
+                        return -1;
+        }
+	info->num_frag_pkts = params->stats.num_frag_pkts;
+	info->num_reassemblies = params->stats.num_reassemblies;
+	info->num_completed_reassly = params->stats.num_completed_reassly;
+	info->num_sess_matches = params->stats.num_sess_matches;
+	info->num_frags_too_small = params->stats.num_frags_too_small;
+	info->num_reassm_timeouts = params->stats.num_reassm_timeouts;
+	info->num_overlapping_frags = params->stats.num_overlapping_frags;
+	info->num_too_many_frags = params->stats.num_too_many_frags;
+	info->num_failed_bufallocs = params->stats.num_failed_bufallocs;
+	info->num_failed_ctxallocs = params->stats.num_failed_ctxallocs;
+	info->num_fatal_errors = params->stats.num_fatal_errors;
+	info->num_failed_ctxdeallocs = params->stats.num_failed_ctxdeallocs;
+	info->table_mask = params->table_mask;
+	info->ipr_timer = params->ipr_timer;
+	info->timeout_val = params->timeout_val;
+	info->timeout_fqid = params->timeout_fqid;
+	info->max_frags = params->max_frags; 
+	info->min_frag_size = params->min_frag_size;
+	info->max_con_reassm = params->max_con_reassm;
+	info->reassem_bpid = params->reassem_bpid;
+	info->reassem_bsize = params->reassem_bsize;
+	info->frag_bpid = params->frag_bpid; 
+	info->frag_bsize = params->frag_bsize;
+	info->timer_tnum = params->timer_tnum;
+	info->reassly_dbg = params->reassly_dbg;
+	info->curr_sessions = params->curr_sessions;
+	info->txc_fqid = params->txc_fqid; 
+	display_debug_info(params);
+	return 0;
+}
+
+void display_reassem_stats(uint32_t type)
+{
+        struct ip_reassembly_stats *stats;
+
+	display_reassem_params(type);
+        switch (type)
+        {
+                case IPV4_REASSM_TABLE:
+                        if (!ipv4_reassly_tbl_info) {
+                                printk("%s::ipv4 frag table not setup\n", __FUNCTION__);
+                                return;
+                        }
+                        stats = &ipv4_reassly_tbl_info->ip_reassem_info->stats;
+			printk("ipv4 reassembly statistics::\n");
+                        break;
+                case IPV6_REASSM_TABLE:
+                        if (!ipv6_reassly_tbl_info) {
+                                printk("%s::ipv6 frag table not setup\n", __FUNCTION__);
+                                return;
+                        }
+                        stats = &ipv6_reassly_tbl_info->ip_reassem_info->stats;
+			printk("ipv6 reassembly statistics::\n");
+                        break;
+
+                default:
+                        printk("%s::invalid frag table type %d\n", __FUNCTION__, type);
+                        return;
+        }
+
+        printk("num_frag_pkts\t%p\n",
+                (void *)(cpu_to_be64(stats->num_frag_pkts)));
+        printk("num_reassemblies\t%p\n",
+                (void *)(cpu_to_be64(stats->num_reassemblies)));
+        printk("num_completed_reassly\t%p\n",
+                (void *)(cpu_to_be64(stats->num_completed_reassly)));
+        printk("num_sess_matches\t%p\n",
+                (void *)(cpu_to_be64(stats->num_sess_matches)));
+        printk("frags too small\t%p\n",
+                (void *)(cpu_to_be64(stats->num_frags_too_small)));
+        printk("num_reassm_failures\t%p\n",
+                (void *)(cpu_to_be64(stats->num_reassm_timeouts)));
+        printk("overlapping fragments\t%p\n",
+                (void *)(cpu_to_be64(stats->num_overlapping_frags)));
+        printk("too many frags\t%p\n",
+                (void *)(cpu_to_be64(stats->num_too_many_frags)));
+	printk("num_failed_bufallocs\t%p\n",
+                (void *)(cpu_to_be64(stats->num_failed_bufallocs)));
+	printk("num_failed_ctxallocs\t%p\n",
+                (void *)(cpu_to_be64(stats->num_failed_ctxallocs)));
+        printk("reassm_count\t%p\n",
+                (void *)(cpu_to_be64(stats->reassm_count)));
+        printk("num_failed_ctxdeallocs\t%p\n",
+                (void *)(cpu_to_be64(stats->num_failed_ctxdeallocs)));
+        printk("num_fatal_errors\t%p\n",
+                (void *)(cpu_to_be64(stats->num_fatal_errors)));
+
+}
+EXPORT_SYMBOL(get_ip_reassem_info);
+EXPORT_SYMBOL(display_reassem_stats);
+EXPORT_SYMBOL(ipv4_reassly_tbl_info);
+EXPORT_SYMBOL(ipv6_reassly_tbl_info);
+EXPORT_SYMBOL(ExternalHashSetReasslyPool);
+EXPORT_SYMBOL(ipr_update_timestamp);
+#endif
+EXPORT_SYMBOL(ExternalHashTableDeleteKey); 
+#endif
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_kg.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_kg.c
index f183d2f9ee05..2f4b14147e4d 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_kg.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_kg.c
@@ -1237,6 +1237,7 @@ static t_Error BuildSchemeRegs(t_FmPcdKgScheme            *p_Scheme,
                         p_SchemeRegs->kgse_ppc = ppcTmp;
                     }
                 }
+                printk("%s::kgse_ppc %08x\n", __FUNCTION__, ppcTmp);
             }
             break;
         case (e_FM_PCD_DONE):
@@ -1248,6 +1249,14 @@ static t_Error BuildSchemeRegs(t_FmPcdKgScheme            *p_Scheme,
         default:
              RETURN_ERROR(MAJOR, E_NOT_SUPPORTED, ("Next engine not supported"));
     }
+#if 0 //BMR bypass classification
+    printk("%s::actual_kgse_mode %08x\n", __FUNCTION__, tmpReg);
+    if (p_SchemeParams->nextEngine == e_FM_PCD_CC) {
+		tmpReg =  (KG_SCH_MODE_EN | GET_NIA_BMI_AC_ENQ_FRAME(p_FmPcd));
+		tmpReg |= (uint32_t)(grpBase << KG_SCH_MODE_CCOBASE_SHIFT);
+    }
+    printk("%s::kgse_mode %08x\n", __FUNCTION__, tmpReg);
+#endif
     p_SchemeRegs->kgse_mode = tmpReg;
 
     p_SchemeRegs->kgse_mv = p_Scheme->matchVector;
@@ -1569,6 +1578,8 @@ static t_Error BuildSchemeRegs(t_FmPcdKgScheme            *p_Scheme,
                 generic = FALSE;
             }
         }
+	//bmr
+	knownTmp |= KG_SCH_KN_PORT_ID;
         p_SchemeRegs->kgse_ekfc = knownTmp;
 
         selectTmp = 0;
@@ -2771,6 +2782,16 @@ uint8_t FmPcdKgGetSchemeId(t_Handle h_Scheme)
 
 }
 
+void disp_sch_info(t_Handle h_Scheme)
+{
+	t_FmPcdKgScheme *scheme;
+
+	scheme = (t_FmPcdKgScheme *)h_Scheme;
+	printk("scheme %p\n", h_Scheme);
+	printk("id %d, mv %x\n", scheme->schemeId,
+		scheme->matchVector);
+
+}
 #if (DPAA_VERSION >= 11)
 bool FmPcdKgGetVspe(t_Handle h_Scheme)
 {
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_manip.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_manip.c
index 113777e5e678..7e82ed432cc2 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_manip.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_manip.c
@@ -4666,6 +4666,74 @@ static t_Error FmPcdManipModifyUpdate(t_Handle h_Manip, t_Handle h_Ad,
 /*****************************************************************************/
 /*              Inter-module API routines                                    */
 /*****************************************************************************/
+void FmPcdManipGetInternaltHmTdAndNonHmAd(t_Handle h_Manip, t_Handle *p_InernalHmtd, t_Handle *p_NonHmAd)
+{
+    t_FmPcdManip *p_FirstManip, *p_Manip = (t_FmPcdManip *)h_Manip;
+
+    ASSERT_COND(h_Manip);
+    ASSERT_COND(p_InernalHmtd);
+    ASSERT_COND(p_NonHmAd);
+
+    *p_InernalHmtd = NULL;
+    *p_NonHmAd = NULL;
+ 
+    p_FirstManip = p_Manip;
+    do {
+        if ((p_Manip->type == e_FM_PCD_MANIP_HDR) && (p_Manip->dataSize)) {
+            *p_InernalHmtd = p_FirstManip->h_Ad;
+            break;
+        }
+        if (p_Manip->type != e_FM_PCD_MANIP_HDR) {
+            *p_NonHmAd = p_Manip->h_Ad;
+            break;
+        }
+        p_Manip = p_Manip->h_NextManip;
+    } while (p_Manip);
+}
+
+void FmPcdManipLocalHMGetParams(t_Handle h_Manip, t_FmPcdManipHmCcParams *p_Params, t_Handle *h_ManipIter)
+{
+    t_FmPcdManip *p_Manip;
+
+    ASSERT_COND(h_Manip);
+    ASSERT_COND(h_ManipIter);
+    ASSERT_COND(p_Params);
+
+    p_Manip = (t_FmPcdManip *)h_Manip;
+ 
+    if (p_Manip->type != e_FM_PCD_MANIP_HDR)
+    {
+        p_Params->p_Hmct = NULL;
+        p_Params->tableSize = 0;
+        *h_ManipIter = NULL;
+        return;
+    }
+ 
+    if (*h_ManipIter == NULL) {
+        /* jump to the end of the HM chain */
+        while (p_Manip->h_NextManip &&
+                (((t_FmPcdManip *)p_Manip->h_NextManip)->type == e_FM_PCD_MANIP_HDR))
+            p_Manip = p_Manip->h_NextManip;
+    } else {
+        p_Manip = *h_ManipIter;
+    }
+
+    do {
+        if (!MANIP_IS_UNIFIED(p_Manip) ||
+                MANIP_IS_UNIFIED_FIRST(p_Manip))
+        {
+            p_Params->p_Hmct = p_Manip->p_Hmct;
+            p_Params->tableSize += p_Manip->tableSize;
+            p_Params->parseAfterHm = !p_Manip->dontParseAfterManip;
+            p_Manip = p_Manip->h_PrevManip;
+            break;
+        }
+        p_Params->tableSize += p_Manip->tableSize;
+        p_Manip = p_Manip->h_PrevManip;
+    } while (p_Manip);
+
+    *h_ManipIter = p_Manip;
+}
 
 t_Error FmPcdManipUpdate(t_Handle h_FmPcd, t_Handle h_PcdParams,
                          t_Handle h_FmPort, t_Handle h_Manip, t_Handle h_Ad,
@@ -5569,3 +5637,61 @@ t_Handle FM_PCD_StatisticsSetNode(t_Handle h_FmPcd, t_FmPcdStatsParams *p_StatsP
     return p_Manip;
 }
 #endif /* (defined(FM_CAPWAP_SUPPORT) && (DPAA_VERSION == 10)) */
+
+#ifdef CONFIG_DBG_UCODE_INFRA 
+t_Error FmPcdDbgUcodeHCmd(t_Handle h_FmPcd, 
+									uint32_t muram_addr_offset,
+									uint8_t  *data,
+									uint8_t  size)
+{
+    t_FmPcd *p_FmPcd = (t_FmPcd*)h_FmPcd;
+    t_Error err = E_OK;
+
+    ASSERT_COND(p_FmPcd);
+
+    if ((err = FmHcPcdDbgUcodeHCmd(p_FmPcd->h_Hc, muram_addr_offset,
+                                      data, size)) != E_OK)
+        RETURN_ERROR(MAJOR, err, NO_MSG);
+
+    return E_OK;
+}
+EXPORT_SYMBOL(FmPcdDbgUcodeHCmd);
+
+t_Error FmPcdDbgUcodeTest(t_Handle h_FmPcd,
+				uint32_t opcode,
+				uint32_t *data,
+				uint16_t data_size)
+{
+	t_FmPcd *p_FmPcd = (t_FmPcd*)h_FmPcd;
+	t_Error err = E_OK;
+	
+	ASSERT_COND(p_FmPcd);
+	
+	if ((err = FmHcPcdDbgUcodeTest(p_FmPcd->h_Hc, 
+							opcode, data, data_size)) != E_OK)
+		RETURN_ERROR(MAJOR, err, NO_MSG);
+	
+	return E_OK;
+}
+EXPORT_SYMBOL(FmPcdDbgUcodeTest);
+
+#ifdef CONFIG_DMAR_TEST
+t_Error FmPcdDMAreadTest(t_Handle h_FmPcd, 
+						uint32_t muram_addr_offset,
+						uint8_t *ptr, uint8_t size)
+{
+	t_FmPcd *p_FmPcd = (t_FmPcd*)h_FmPcd;
+	t_Error err = E_OK;
+	
+	ASSERT_COND(p_FmPcd);
+	
+	if ((err = FmHcPcdDMAreadTest(p_FmPcd->h_Hc, muram_addr_offset,
+							ptr, size)) != E_OK)
+		RETURN_ERROR(MAJOR, err, NO_MSG);
+	
+	return E_OK;
+}
+EXPORT_SYMBOL(FmPcdDMAreadTest);
+#endif //CONFIG_DMAR_TEST
+#endif // CONFIG_DBG_UCODE_INFRA 
+
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_pcd.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_pcd.c
index 91f70a1a290e..2e4fec6bb298 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_pcd.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_pcd.c
@@ -52,6 +52,11 @@
 #include "fm_hc.h"
 #include "fm_muram_ext.h"
 
+#if (DPAA_VERSION >= 11)
+//time stamp infrastructure for use in the case of ext hash tables
+struct ext_hash_ts_info extHashTsInfo;
+EXPORT_SYMBOL(extHashTsInfo);
+#endif
 
 /****************************************/
 /*       static functions               */
@@ -364,7 +369,89 @@ static void ReleaseFreeLocksLst(t_FmPcd *p_FmPcd)
     }
 }
 
+#if (DPAA_VERSION >= 11)
+static void ReleaseFEsList(t_FmPcd *p_FmPcd)
+{
+    t_FmPcdFEObj *p_FeObj;
+    uint32_t intFlags;
+
+    intFlags = XX_LockIntrSpinlock(p_FmPcd->h_Spinlock);
+    while (!LIST_IsEmpty(&p_FmPcd->feInfo.enqLst))
+    {
+        p_FeObj = FM_PCD_FE_OBJ(p_FmPcd->feInfo.enqLst.p_Next);
+        LIST_DelAndInit(&p_FeObj->node);
+        FM_MURAM_FreeMem(p_FmPcd->h_FmMuram, p_FeObj->h_FE);
+        XX_Free(p_FeObj);
+    }
+    while (!LIST_IsEmpty(&p_FmPcd->feInfo.availableFeLst))
+    {
+        p_FeObj = FM_PCD_FE_OBJ(p_FmPcd->feInfo.availableFeLst.p_Next);
+        LIST_DelAndInit(&p_FeObj->node);
+        FM_MURAM_FreeMem(p_FmPcd->h_FmMuram, p_FeObj->h_FE);
+        XX_Free(p_FeObj);
+    }
+    XX_UnlockIntrSpinlock(p_FmPcd->h_Spinlock, intFlags);
+}
+
+static __inline__ t_FmPcdFEObj* DequeueFEObj(t_FmPcd *p_FmPcd, t_List *p_List)
+{
+    t_FmPcdFEObj *p_FeObj = NULL;
+    uint32_t    intFlags;
+
+    intFlags = XX_LockIntrSpinlock(p_FmPcd->h_Spinlock);
+    if (!LIST_IsEmpty(p_List))
+    {
+        p_FeObj = FM_PCD_FE_OBJ(p_List->p_Next);
+        LIST_DelAndInit(&p_FeObj->node);
+    }
+    XX_UnlockIntrSpinlock(p_FmPcd->h_Spinlock, intFlags);
+
+    return p_FeObj;
+}
+
+static __inline__ void EnqueueFEObj(t_FmPcd *p_FmPcd, t_List *p_List, t_FmPcdFEObj *p_FeObj)
+{
+    uint32_t   intFlags;
+
+    intFlags = XX_LockIntrSpinlock(p_FmPcd->h_Spinlock);
+    LIST_AddToTail(&p_FeObj->node, p_List);
+    XX_UnlockIntrSpinlock(p_FmPcd->h_Spinlock, intFlags);
+}
+
+static t_Error AllocFEObjs(t_FmPcd *p_FmPcd)
+{
+    t_Handle h_FmMuram = NULL;
+    t_FmPcdFEObj *p_FeObj;
+    uint32_t i;
+
+    ASSERT_COND(p_FmPcd);
 
+    h_FmMuram = FmPcdGetMuramHandle(p_FmPcd);
+    if (!h_FmMuram)
+        RETURN_ERROR(MAJOR, E_INVALID_HANDLE, ("FM MURAM"));
+
+    INIT_LIST(&p_FmPcd->feInfo.availableFeLst);
+
+    for (i=0; i<100; i++) {
+        p_FeObj = (t_FmPcdFEObj *)XX_Malloc(sizeof(t_FmPcdFEObj));
+        if (!p_FeObj)
+            RETURN_ERROR(MAJOR, E_NO_MEMORY, ("FM-PCD FE obj!"));
+        memset(p_FeObj, 0, sizeof(t_FmPcdFEObj));
+ 
+        p_FeObj->h_FE = (t_Handle)FM_MURAM_AllocMem(h_FmMuram,
+                                                    FM_PCD_FE_MAX_SIZE,
+                                                    FM_PCD_FE_ALIGN);
+        if (!p_FeObj->h_FE)
+            RETURN_ERROR(MAJOR, E_NO_MEMORY, ("MURAM allocation for FE"));
+        memset((uint8_t *)p_FeObj->h_FE, 0, FM_PCD_FE_MAX_SIZE);
+ 
+        EnqueueFEObj(p_FmPcd, &p_FmPcd->feInfo.availableFeLst, p_FeObj);
+    }
+
+    return E_OK;
+}
+
+#endif /* (DPAA_VERSION >= 11) */
 
 /*****************************************************************************/
 /*              Inter-module API routines                                    */
@@ -776,6 +863,49 @@ bool FmPcdIsAdvancedOffloadSupported(t_Handle h_FmPcd)
     ASSERT_COND(h_FmPcd);
     return ((t_FmPcd*)h_FmPcd)->advancedOffloadSupport;
 }
+
+#if (DPAA_VERSION >= 11)
+t_Handle FmPcdGetFE(t_Handle h_FmPcd, t_FmPcdFEParams *p_FeParams)
+{
+    t_FmPcd     *p_FmPcd = (t_FmPcd *)h_FmPcd;
+    uint32_t    intFlags;
+    t_List      *p_Pos, *p_List;
+    t_Handle    h_FE = NULL;
+    t_FmPcdFEObj *p_FeObj;
+
+    ASSERT_COND(h_FmPcd);
+    ASSERT_COND((p_FeParams->type == e_FM_PCD_FE_T_ENQ));
+
+    p_List = &p_FmPcd->feInfo.enqLst;
+
+    intFlags = FmPcdLock(h_FmPcd);
+    LIST_FOR_EACH(p_Pos, p_List)
+    {
+        p_FeObj = FM_PCD_FE_OBJ(p_Pos);
+        if (memcmp(&p_FeObj->feParams, p_FeParams, sizeof(t_FmPcdFEParams)) == 0)
+        {
+            h_FE = p_FeObj->h_FE;
+            break;
+        }
+    }
+    FmPcdUnlock(h_FmPcd, intFlags);
+
+    if (!h_FE) {
+        p_FeObj = DequeueFEObj(p_FmPcd, &p_FmPcd->feInfo.availableFeLst);
+        if (!p_FeObj) {
+            REPORT_ERROR(MAJOR, E_EMPTY, ("FM-PCD FE obj!"));
+            return NULL;
+        }
+        h_FE = p_FeObj->h_FE;
+        FmPcdCcBuildFE(h_FmPcd, p_FeParams, h_FE);
+        memcpy(&p_FeObj->feParams, p_FeParams, sizeof(t_FmPcdFEParams));
+        EnqueueFEObj(p_FmPcd, p_List, p_FeObj);
+    }
+
+    return h_FE;
+}
+#endif /* DPAA_VERSION >= 11 */
+
 /*********************** End of inter-module routines ************************/
 
 
@@ -908,6 +1038,11 @@ t_Error FM_PCD_Init(t_Handle h_FmPcd)
     t_FmPcd         *p_FmPcd = (t_FmPcd*)h_FmPcd;
     t_Error         err = E_OK;
     t_FmPcdIpcMsg   msg;
+#if (DPAA_VERSION >= 11)
+    t_FmPcdFEObj *p_FeObj;
+    t_FmPcdFEParams feParams;
+    int i;
+#endif /* DPAA_VERSION >= 11 */
 
     SANITY_CHECK_RETURN_ERROR(p_FmPcd, E_INVALID_HANDLE);
     SANITY_CHECK_RETURN_ERROR(p_FmPcd->p_FmPcdDriverParam, E_INVALID_HANDLE);
@@ -1007,11 +1142,131 @@ t_Error FM_PCD_Init(t_Handle h_FmPcd)
     }
     IOMemSet32(UINT_TO_PTR(p_FmPcd->capwapFrameIdAddr), 0,  2);
 
+#if (DPAA_VERSION >= 11)
+    {
+       extHashTsInfo.max_ext_ts_timers = MAX_EXT_TS_TIMERS;
+       /* allocate memory for external timestamp used in ext hash table */
+       extHashTsInfo.ptr =
+               FM_MURAM_AllocMem(p_FmPcd->h_FmMuram, (MAX_EXT_TS_TIMERS * EXT_TS_SIZE), EXT_TS_SIZE);
+       if (!extHashTsInfo.ptr) {
+               FM_PCD_Free(p_FmPcd);
+               RETURN_ERROR(MAJOR, E_NO_MEMORY, ("MURAM allocation for Ext TS"));
+       }
+       extHashTsInfo.offset = (uint32_t)(XX_VirtToPhys(extHashTsInfo.ptr) -
+                       p_FmPcd->physicalMuramBase);
+       printk("%s::ext timers %d, base ptr %p, muram base %p, offset %x\n", __FUNCTION__,
+                       extHashTsInfo.max_ext_ts_timers, extHashTsInfo.ptr,
+                       (void *)p_FmPcd->physicalMuramBase, extHashTsInfo.offset);
+   }
+#endif
+
+#if (DPAA_VERSION >= 11)
+    err = AllocFEObjs(p_FmPcd);
+    if (err) {
+        FM_PCD_Free(p_FmPcd);
+        RETURN_ERROR(MAJOR, err, NO_MSG);
+    }
+ 
+    /* Singleton MUX-FE */
+    p_FeObj = DequeueFEObj(p_FmPcd, &p_FmPcd->feInfo.availableFeLst);
+    if (!p_FeObj) {
+        FM_PCD_Free(p_FmPcd);
+        RETURN_ERROR(MAJOR, E_EMPTY, ("No Free FE-Obj"));
+    }
+    memset(&feParams, 0, sizeof(t_FmPcdFEParams));
+    feParams.type = e_FM_PCD_FE_T_MUX;
+    feParams.wsOffset = FE_MUX_CONTEXT_OFFSET;
+    p_FmPcd->feInfo.h_Mux = p_FeObj->h_FE;
+    FmPcdCcBuildFE(p_FmPcd, &feParams, p_FmPcd->feInfo.h_Mux);
+    XX_Free(p_FeObj);
+ 
+    /* Singleton Transition-FE */
+    p_FeObj = DequeueFEObj(p_FmPcd, &p_FmPcd->feInfo.availableFeLst);
+    if (!p_FeObj) {
+        FM_PCD_Free(p_FmPcd);
+        RETURN_ERROR(MAJOR, E_EMPTY, ("No Free FE-Obj"));
+    }
+    memset(&feParams, 0, sizeof(t_FmPcdFEParams));
+    feParams.type = e_FM_PCD_FE_T_TRANSITION;
+    feParams.wsOffset = FE_TRANSITION_CONTEXT_OFFSET;
+    feParams.u.transition.deallocateBuffer = TRUE;
+    feParams.u.transition.nextADFromWS = TRUE;
+    p_FmPcd->feInfo.h_Transition = p_FeObj->h_FE;
+    FmPcdCcBuildFE(p_FmPcd, &feParams, p_FmPcd->feInfo.h_Transition);
+    XX_Free(p_FeObj);
+
+    /* Singleton Exit-FE */
+    p_FeObj = DequeueFEObj(p_FmPcd, &p_FmPcd->feInfo.availableFeLst);
+    if (!p_FeObj) {
+        FM_PCD_Free(p_FmPcd);
+        RETURN_ERROR(MAJOR, E_EMPTY, ("No Free FE-Obj"));
+    }
+    memset(&feParams, 0, sizeof(t_FmPcdFEParams));
+    feParams.type = e_FM_PCD_FE_T_EXIT;
+    feParams.u.exit.deallocateBuffer = TRUE;
+    p_FmPcd->feInfo.h_Exit = p_FeObj->h_FE;
+    FmPcdCcBuildFE(p_FmPcd, &feParams, p_FmPcd->feInfo.h_Exit);
+    XX_Free(p_FeObj);
+
+    memset(&feParams, 0, sizeof(t_FmPcdFEParams));
+    feParams.type = e_FM_PCD_FE_T_HM;
+    feParams.h_NextFE = p_FmPcd->feInfo.h_Exit;
+    for (i=0; i<FM_MAX_HM_CONTEXTS; i++) {
+        /* Singleton HM (with-parse)-FE */
+        p_FeObj = DequeueFEObj(p_FmPcd, &p_FmPcd->feInfo.availableFeLst);
+        if (!p_FeObj) {
+            FM_PCD_Free(p_FmPcd);
+            RETURN_ERROR(MAJOR, E_EMPTY, ("No Free FE-Obj"));
+        }
+        feParams.wsOffset = FE_HM_CONTEXT_OFFSET(i);
+        feParams.u.hm.parseAfterHm = TRUE;
+        p_FmPcd->feInfo.hm[i].h_HmWParse = p_FeObj->h_FE;
+        FmPcdCcBuildFE(p_FmPcd, &feParams, p_FmPcd->feInfo.hm[i].h_HmWParse);
+        XX_Free(p_FeObj);
+
+        /* Singleton HM (without-parse)-FE */
+        p_FeObj = DequeueFEObj(p_FmPcd, &p_FmPcd->feInfo.availableFeLst);
+        if (!p_FeObj) {
+            FM_PCD_Free(p_FmPcd);
+            RETURN_ERROR(MAJOR, E_EMPTY, ("No Free FE-Obj"));
+        }
+        feParams.wsOffset = FE_HM_CONTEXT_OFFSET(i);
+        feParams.u.hm.parseAfterHm = FALSE;
+        p_FmPcd->feInfo.hm[i].h_HmWOParse = p_FeObj->h_FE;
+        FmPcdCcBuildFE(p_FmPcd, &feParams, p_FmPcd->feInfo.hm[i].h_HmWOParse);
+        XX_Free(p_FeObj);
+    }
+
+    INIT_LIST(&p_FmPcd->feInfo.enqLst);
+#endif /* DPAA_VERSION >= 11 */
+
     XX_Free(p_FmPcd->p_FmPcdDriverParam);
     p_FmPcd->p_FmPcdDriverParam = NULL;
 
     FmRegisterPcd(p_FmPcd->h_Fm, p_FmPcd);
 
+#ifdef USE_ENHANCED_EHASH
+#define MURAM_ALLOC_SIZE (256 * 128)
+
+    p_FmPcd->pIntMuramPtr = FM_MURAM_AllocMem(p_FmPcd->h_FmMuram, MURAM_ALLOC_SIZE, 256);
+    if (!p_FmPcd->pIntMuramPtr)
+    {
+        FM_PCD_Free(p_FmPcd);
+        RETURN_ERROR(MAJOR, E_EMPTY, ("MURAM alloc error"));	
+    }
+    p_FmPcd->InternalBufMgmtMuramArea = (uint32_t)(XX_VirtToPhys(p_FmPcd->pIntMuramPtr) -
+                       p_FmPcd->physicalMuramBase);
+    printk("%s(%d) pIntMuramPtr %p InternalBufMgmtMuramArea %x \n",__FUNCTION__,__LINE__, p_FmPcd->pIntMuramPtr,p_FmPcd->InternalBufMgmtMuramArea);
+
+    if (p_FmPcd->InternalBufMgmtMuramArea & 0xff)
+    {
+        FM_PCD_Free(p_FmPcd);
+        RETURN_ERROR(MAJOR, E_EMPTY, ("InternalBufMgmtMuramArea should be aligned to 256"));	
+    }
+    p_FmPcd->InternalBufMgmtMuramArea >>= 8;
+    printk("%s(%d) pIntMuramPtr %p InternalBufMgmtMuramArea %x \n",__FUNCTION__,__LINE__, p_FmPcd->pIntMuramPtr,p_FmPcd->InternalBufMgmtMuramArea);
+#endif //USE_ENHANCED_EHASH
+
     return E_OK;
 }
 
@@ -1019,6 +1274,28 @@ t_Error FM_PCD_Free(t_Handle h_FmPcd)
 {
     t_FmPcd                             *p_FmPcd =(t_FmPcd *)h_FmPcd;
     t_Error                             err = E_OK;
+#if (DPAA_VERSION >= 11)
+    int         i;
+
+    ReleaseFEsList(p_FmPcd);
+
+    if (p_FmPcd->feInfo.h_Exit)
+        FM_MURAM_FreeMem(p_FmPcd->h_FmMuram, p_FmPcd->feInfo.h_Exit);
+
+    if (p_FmPcd->feInfo.h_Mux)
+        FM_MURAM_FreeMem(p_FmPcd->h_FmMuram, p_FmPcd->feInfo.h_Mux);
+
+    if (p_FmPcd->feInfo.h_Transition)
+        FM_MURAM_FreeMem(p_FmPcd->h_FmMuram, p_FmPcd->feInfo.h_Transition);
+
+    for (i=0; i<FM_MAX_HM_CONTEXTS; i++) {
+        if (p_FmPcd->feInfo.hm[i].h_HmWParse)
+            FM_MURAM_FreeMem(p_FmPcd->h_FmMuram, p_FmPcd->feInfo.hm[i].h_HmWParse);
+
+        if (p_FmPcd->feInfo.hm[i].h_HmWOParse)
+            FM_MURAM_FreeMem(p_FmPcd->h_FmMuram, p_FmPcd->feInfo.hm[i].h_HmWOParse);
+    }
+#endif /* (DPAA_VERSION >= 11) */
 
     if (p_FmPcd->ipv6FrameIdAddr)
         FM_MURAM_FreeMem(p_FmPcd->h_FmMuram, UINT_TO_PTR(p_FmPcd->ipv6FrameIdAddr));
@@ -1026,6 +1303,11 @@ t_Error FM_PCD_Free(t_Handle h_FmPcd)
     if (p_FmPcd->capwapFrameIdAddr)
         FM_MURAM_FreeMem(p_FmPcd->h_FmMuram, UINT_TO_PTR(p_FmPcd->capwapFrameIdAddr));
 
+#ifdef USE_ENHANCED_EHASH
+    if (p_FmPcd->pIntMuramPtr)
+        FM_MURAM_FreeMem(p_FmPcd->h_FmMuram, p_FmPcd->pIntMuramPtr);
+#endif //USE_ENHANCED_EHASH
+
     if (p_FmPcd->enabled)
         FM_PCD_Disable(p_FmPcd);
 
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_pcd.h b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_pcd.h
index 27ec9c5bf672..534f3f98bdaf 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_pcd.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_pcd.h
@@ -202,6 +202,28 @@ typedef struct {
                                 portId for PLCR in any environment */
 } t_FmPcdAllocMng;
 
+#if (DPAA_VERSION >= 11)
+typedef struct {
+    t_FmPcdFEParams feParams;
+    t_Handle        h_FE;
+    t_List          node;
+} t_FmPcdFEObj;
+#define FM_PCD_FE_OBJ(ptr)  LIST_OBJECT(ptr, t_FmPcdFEObj, node)
+
+typedef struct {
+    t_Handle    h_Mux;
+    t_Handle    h_Exit;
+    t_Handle    h_Transition;
+    struct {
+        t_Handle    h_HmWParse;
+        t_Handle    h_HmWOParse;
+    } hm[FM_MAX_HM_CONTEXTS];
+
+    t_List      availableFeLst;
+    t_List      enqLst;
+} t_FmPcdFEInfo;
+#endif /* DPAA_VERSION >= 11 */
+
 typedef struct {
     volatile bool       lock;
     bool                used;
@@ -374,6 +396,14 @@ typedef struct {
     uintptr_t                   capwapFrameIdAddr;
     bool                        advancedOffloadSupport;
 
+#if (DPAA_VERSION >= 11)
+    t_FmPcdFEInfo               feInfo;
+#endif /* DPAA_VERSION >= 11 */
+ 
+#ifdef USE_ENHANCED_EHASH
+    uint32_t			InternalBufMgmtMuramArea; // MURAM address area used for internal buffers in EHASH
+    void *pIntMuramPtr; // MURAM pointer for internal buffers in EHASH
+#endif //USE_ENHANCED_EHASH
     t_FmPcdDriverParam          *p_FmPcdDriverParam;
 } t_FmPcd;
 
@@ -476,6 +506,16 @@ t_CcNodeInformation* FindNodeInfoInReleventLst(t_List *p_List, t_Handle h_Info,
 t_List *FmPcdManipGetSpinlock(t_Handle h_Manip);
 t_List *FmPcdManipGetNodeLstPointedOnThisManip(t_Handle h_Manip);
 
+typedef struct
+{
+    uint8_t     *p_Hmct;
+    uint16_t    tableSize;
+    bool        parseAfterHm;
+} t_FmPcdManipHmCcParams;
+
+void FmPcdManipLocalHMGetParams(t_Handle h_Manip, t_FmPcdManipHmCcParams *p_Params, t_Handle *h_ManipIter);
+void FmPcdManipGetInternaltHmTdAndNonHmAd(t_Handle h_Manip, t_Handle *p_InernalHmtd, t_Handle *p_NonHmAd);
+
 typedef struct
 {
     t_Handle    h_StatsAd;
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Port/fm_port.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Port/fm_port.c
index ec6e0ed59376..df27f51b2729 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Port/fm_port.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Port/fm_port.c
@@ -677,7 +677,9 @@ static t_Error InitLowLevelDriver(t_FmPort *p_FmPort)
     {
         case (e_FM_PORT_TYPE_RX_10G):
         case (e_FM_PORT_TYPE_RX):
-            portParams.err_mask = (RX_ERRS_TO_ENQ & ~portParams.discard_mask);
+            //portParams.err_mask = (RX_ERRS_TO_ENQ & ~portParams.discard_mask);
+	    //not required to enqueue error frames
+            portParams.err_mask = 0;
             if (!p_FmPort->imEn)
             {
                 if (p_DriverParams->forwardReuseIntContext)
@@ -2202,6 +2204,89 @@ t_Error FmPortGetSetCcParams(t_Handle h_FmPort,
 
     return E_OK;
 }
+
+#if (DPAA_VERSION >= 11)
+t_Error FmPortSetFESupport(t_Handle h_FmPort)
+{
+    t_FmPort *p_FmPort = (t_FmPort*)h_FmPort;
+    t_FmPcdCtrlParamsPage *p_ParamsPage;
+    uint8_t *p_Ptr, i, totalNumOfTnums;
+
+    if (p_FmPort->supportFE)
+    	return E_OK;
+
+    FmPortSetGprFunc(p_FmPort, e_FM_PORT_GPR_MURAM_PAGE,
+                     (void**)&p_ParamsPage);
+    ASSERT_COND(p_ParamsPage);
+
+
+    totalNumOfTnums =
+            (uint8_t)(p_FmPort->tasks.num + p_FmPort->tasks.extra);
+
+    p_FmPort->internalFEBufferPoolAddr =
+            PTR_TO_UINT(FM_MURAM_AllocMem(p_FmPort->h_FmMuram,
+                            (uint32_t)(totalNumOfTnums * BMI_FIFO_UNITS*2),
+                            BMI_FIFO_UNITS));
+    if (!p_FmPort->internalFEBufferPoolAddr)
+        RETURN_ERROR(
+                MAJOR, E_NO_MEMORY,
+                ("MURAM alloc for FE internal buffers pool"));
+    IOMemSet32(UINT_TO_PTR(p_FmPort->internalFEBufferPoolAddr),
+            0, (uint32_t)(totalNumOfTnums * BMI_FIFO_UNITS*2));
+
+    p_FmPort->internalFEBufferPoolManagementIndexAddr =
+            PTR_TO_UINT(FM_MURAM_AllocMem(p_FmPort->h_FmMuram,
+                            (uint32_t)(5 + totalNumOfTnums),
+                            4));
+    if (!p_FmPort->internalFEBufferPoolManagementIndexAddr)
+        RETURN_ERROR(
+                MAJOR,
+                E_NO_MEMORY,
+                ("MURAM alloc for FE internal buffers management"));
+
+    p_Ptr =
+            (uint8_t*)UINT_TO_PTR(p_FmPort->internalFEBufferPoolManagementIndexAddr);
+    WRITE_UINT32(
+            *(uint32_t*)p_Ptr,
+            (uint32_t)(XX_VirtToPhys(UINT_TO_PTR(p_FmPort->internalFEBufferPoolAddr)) - p_FmPort->fmMuramPhysBaseAddr));
+    /* Initialize the pool management index to 4: */
+    WRITE_UINT8(*p_Ptr, 4);
+    for (i = 0, p_Ptr += 4; i < totalNumOfTnums; i++, p_Ptr++)
+        WRITE_UINT8(*p_Ptr, i);
+    WRITE_UINT8(*p_Ptr, 0xFF);
+
+    WRITE_UINT32(p_ParamsPage->internalFEBufferDepletionCounter, 0);
+    WRITE_UINT32(p_ParamsPage->internalFEBufferManagementIndexAddr,
+            (uint32_t)(XX_VirtToPhys(UINT_TO_PTR(p_FmPort->internalFEBufferPoolManagementIndexAddr))
+                                            - p_FmPort->fmMuramPhysBaseAddr));
+
+    p_FmPort->supportFE = TRUE;
+
+    return E_OK;
+}
+
+t_Error FmPortDeleteFESupport(t_Handle h_FmPort)
+{
+    t_FmPort *p_FmPort = (t_FmPort*)h_FmPort;
+    t_FmPcdCtrlParamsPage *p_ParamsPage;
+
+    if (!p_FmPort->supportFE)
+        return E_OK;
+
+    FmPortSetGprFunc(p_FmPort, e_FM_PORT_GPR_MURAM_PAGE,
+                     (void**)&p_ParamsPage);
+    ASSERT_COND(p_ParamsPage);
+
+    p_FmPort->supportFE = FALSE;
+    WRITE_UINT32(p_ParamsPage->internalFEBufferManagementIndexAddr, 0);
+ 
+    FM_MURAM_FreeMem(p_FmPort->h_FmMuram, UINT_TO_PTR(p_FmPort->internalFEBufferPoolAddr));
+    FM_MURAM_FreeMem(p_FmPort->h_FmMuram, UINT_TO_PTR(p_FmPort->internalFEBufferPoolManagementIndexAddr));
+ 
+    return E_OK;
+}
+#endif /* (DPAA_VERSION >= 11) */
+
 /*********************** End of inter-module routines ************************/
 
 /****************************************/
@@ -2741,9 +2826,12 @@ t_Error FM_PORT_Init(t_Handle h_FmPort)
                     p_ParamsPage->errorsDiscardMask,
                     (GET_UINT32(p_FmPort->p_FmPortBmiRegs->rxPortBmiRegs.fmbm_rfsdm) | GET_UINT32(p_FmPort->p_FmPortBmiRegs->rxPortBmiRegs.fmbm_rfsem)));
 #endif /* FM_ERROR_VSP_NO_MATCH_SW006 */
+    WRITE_UINT32(p_ParamsPage->errorsDiscardMask, FM_RFSDM_DEFAULT);
+    	WRITE_UINT32(p_ParamsPage->errorsDiscardMask, FM_RFSDM_DEFAULT);
     }
 #endif /* (DPAA_VERSION >= 11) */
 
+
     if (p_FmPort->deepSleepVars.autoResMaxSizes)
         FmPortConfigAutoResForDeepSleepSupport1(p_FmPort);
     return E_OK;
@@ -5341,7 +5429,14 @@ t_Error FM_PORT_DeletePCD(t_Handle h_FmPort)
             RETURN_ERROR(MAJOR, err, NO_MSG);
         }
         p_FmPort->h_ReassemblyTree = NULL;
-    }RELEASE_LOCK(p_FmPort->lock);
+    }
+ 
+#if (DPAA_VERSION >= 11)
+	if (p_FmPort->supportFE)
+		FmPortDeleteFESupport(h_FmPort);
+#endif /* (DPAA_VERSION >= 11) */
+
+    RELEASE_LOCK(p_FmPort->lock);
 
     return err;
 }
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Port/fm_port.h b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Port/fm_port.h
index 85986f553c3f..610e10fd7b0b 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Port/fm_port.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Port/fm_port.h
@@ -941,6 +941,9 @@ typedef struct {
     uint8_t                     dfltRelativeId;
     e_FmPortGprFuncType         gprFunc;
     t_FmPcdCtrlParamsPage       *p_ParamsPage;
+    bool						supportFE;
+    uintptr_t                   internalFEBufferPoolManagementIndexAddr;
+    uintptr_t                   internalFEBufferPoolAddr;
 #endif /* (DPAA_VERSION >= 11) */
     t_FmPortDsarVars            deepSleepVars;
     t_FmPortDriverParam         *p_FmPortDriverParam;
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Port/fman_port.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Port/fman_port.c
index aaca1d711c78..3d66c798fda8 100755
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Port/fman_port.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Port/fman_port.c
@@ -103,6 +103,7 @@ static int init_bmi_rx(struct fman_port *port,
     tmp |= ((uint32_t)cfg->ic_int_offset / FMAN_PORT_IC_OFFSET_UNITS) <<
             BMI_IC_FROM_INT_SHIFT;
     tmp |= cfg->ic_size / FMAN_PORT_IC_OFFSET_UNITS;
+    tmp = 0x00000007;
     iowrite32be(tmp, &regs->fmbm_ricp);
 
     /* Internal buffer offset */
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/fm.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/fm.c
index a870b47e88bd..dd003931dc3a 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/fm.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/fm.c
@@ -52,6 +52,9 @@
 #include <linux/fsl/svr.h>
 #endif
 #include "fsl_fman.h"
+#ifdef AUTO_FIRMWARE_LOAD
+#include <linux/fsl/ls1043_r2.h>
+#endif // AUTO_FIRMWARE_LOAD
 
 
 /****************************************/
@@ -3289,6 +3292,9 @@ t_Error FmDumpPortRegs (t_Handle h_Fm, uint8_t hardwarePortId)
 }
 #endif /* (defined(DEBUG_ERRORS) && (DEBUG_ERRORS > 0)) */
 
+#ifdef AUTO_FIRMWARE_LOAD
+uint32_t fman_firmware[] = LS1043_R1_0_UC_IMG;
+#endif //AUTO_FIRMWARE_LOAD
 
 /*****************************************************************************/
 /*                      API Init unit functions                              */
@@ -3410,6 +3416,7 @@ t_Handle FM_Config(t_FmParams *p_FmParam)
     p_Fm->resetOnInit                          = DEFAULT_resetOnInit;
     p_Fm->f_ResetOnInitOverride                = DEFAULT_resetOnInitOverrideCallback;
     p_Fm->fwVerify                             = DEFAULT_VerifyUcode;
+#ifndef AUTO_FIRMWARE_LOAD
     p_Fm->firmware.size                        = p_FmParam->firmware.size;
     if (p_Fm->firmware.size)
     {
@@ -3425,6 +3432,23 @@ t_Handle FM_Config(t_FmParams *p_FmParam)
         }
         memcpy(p_Fm->firmware.p_Code, p_FmParam->firmware.p_Code ,p_Fm->firmware.size);
     }
+#else
+    p_Fm->firmware.size                        = 0;
+    {
+        p_Fm->firmware.size = sizeof(fman_firmware);
+        p_Fm->firmware.p_Code = fman_firmware;
+    }
+    printk("%s(%d) FMAN version extracted from ls1043_r2.h: (%d.%d.%d) (0x%x) \n",
+		 __FUNCTION__,__LINE__, (fman_firmware[1] & 0xffff0000) >> 16, (fman_firmware[1] & 0x0000ff00) >> 8,
+		fman_firmware[1] & 0x000000ff, fman_firmware[1]);
+#endif //AUTO_FIRMWARE_LOAD
+    printk("***************************************************************\n");
+    printk("%s(%d) FMan-Controller code (ver %d.%d.%d) (0x%x)\n", __FUNCTION__,__LINE__,
+               ((p_Fm->firmware.p_Code)[1] & 0xffff0000) >> 16 ,
+               ((p_Fm->firmware.p_Code)[1] & 0x0000ff00) >> 8,
+               (p_Fm->firmware.p_Code)[1] & 0x000000ff, (p_Fm->firmware.p_Code)[1]);
+     printk("&*&*^&^&^^&*^&*^&*^&*^&*^&^&*^&*^&*^&*^&*^&*^&*^&*^&*^&*^&*^&*^&*\n");
+
 
     if (p_Fm->guestId != NCSW_MASTER_ID)
         return p_Fm;
@@ -3548,6 +3572,11 @@ t_Error FM_Init(t_Handle h_Fm)
             RETURN_ERROR(MAJOR, err, NO_MSG);
 #else  /* not FM_UCODE_NOT_RESET_ERRATA_BUGZILLA6173 */
 
+#ifdef CONFIG_FMAN_ARM
+	WRITE_UINT32(p_Fm->p_FmFpmRegs->fm_rstc, FPM_RSTC_FM_RESET);
+	CORE_MemoryBarrier();
+	XX_UDelay(100);
+#endif
         if (p_Fm->f_ResetOnInitOverride)
         {
         	/* Perform user specific FMan reset */
@@ -3696,12 +3725,13 @@ t_Error FM_Init(t_Handle h_Fm)
 
     EnableTimeStamp(p_Fm);
 
-    if (p_Fm->firmware.p_Code)
-    {
+#ifndef AUTO_FIRMWARE_LOAD
+   if (p_Fm->firmware.p_Code)
+   {
         XX_Free(p_Fm->firmware.p_Code);
         p_Fm->firmware.p_Code = NULL;
     }
-
+#endif //AUTO_FIRMWARE_LOAD
     XX_Free(p_Fm->p_FmDriverParam);
     p_Fm->p_FmDriverParam = NULL;
 
@@ -3788,8 +3818,10 @@ t_Error FM_Free(t_Handle h_Fm)
 
     if (p_Fm->p_FmDriverParam)
     {
+#ifndef AUTO_FIRMWARE_LOAD
         if (p_Fm->firmware.p_Code)
-            XX_Free(p_Fm->firmware.p_Code);
+           XX_Free(p_Fm->firmware.p_Code);
+#endif //AUTO_FIRMWARE_LOAD
         XX_Free(p_Fm->p_FmDriverParam);
         p_Fm->p_FmDriverParam = NULL;
     }
@@ -3804,6 +3836,43 @@ t_Error FM_Free(t_Handle h_Fm)
     return E_OK;
 }
 
+uint32_t FM_ReadTimeStamp(t_Handle h_Fm)
+{
+    t_Fm *p_Fm = (t_Fm*)h_Fm;
+    struct fman_fpm_regs *fpm_reg;
+
+    SANITY_CHECK_RETURN_ERROR(p_Fm, 0);
+
+    fpm_reg = p_Fm->p_FmFpmRegs;
+
+    ASSERT_COND(p_Fm->p_FmStateStruct);
+
+    if (!p_Fm->p_FmStateStruct->enabledTimeStamp) {
+        REPORT_ERROR(MAJOR, E_INVALID_STATE,
+				("Timestamp not enabled on this FMan"));
+	return 0;
+    }
+
+    return GET_UINT32(fpm_reg->fmfp_tsp);
+}
+
+uint32_t FM_GetTimeStampIncrementPerUsec(t_Handle h_Fm)
+{
+    t_Fm *p_Fm = (t_Fm*)h_Fm;
+
+    SANITY_CHECK_RETURN_ERROR(p_Fm, 0);
+
+    ASSERT_COND(p_Fm->p_FmStateStruct);
+
+    if (!p_Fm->p_FmStateStruct->enabledTimeStamp) {
+        REPORT_ERROR(MAJOR, E_INVALID_STATE,
+				("Timestamp not enabled on this FMan"));
+	return 0;
+    }
+
+    return (uint32_t)0x1 << p_Fm->p_FmStateStruct->count1MicroBit;
+}
+
 /*************************************************/
 /*       API Advanced Init unit functions        */
 /*************************************************/
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/fm_muram.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/fm_muram.c
index 0bc67cb74b99..76d630cc99b8 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/fm_muram.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/fm_muram.c
@@ -44,8 +44,25 @@
 #include "fm_muram_ext.h"
 #include "fm_common.h"
 
-#define __ERR_MODULE__  MODULE_FM_MURAM
+#include <linux/slab.h>
 
+#define __ERR_MODULE__  MODULE_FM_MURAM
+void *FmMurambaseAddr;
+static uint32_t FmMuramsize;
+
+
+#ifdef CONFIG_DBG_UCODE_INFRA
+#ifdef CONFIG_DMAR_TEST
+#define DBG_UCODE_RESVD_MURAM_SIZE    1328 //1024+48+256 // per task basis
+//#define DBG_UCODE_RESVD_MURAM_SIZE  256 //per risk core
+#else
+// If EHASH dbg is enabled , then use 576 bytes
+//#define DBG_UCODE_RESVD_MURAM_SIZE  576 // 64+512 // using 512 bytes for enhash dbg
+#define DBG_UCODE_RESVD_MURAM_SIZE   64
+#endif //CONFIG_DMAR_TEST
+#else
+#define DBG_UCODE_RESVD_MURAM_SIZE  0
+#endif // CONFIG_DBG_UCODE_INFRA 
 
 typedef struct
 {
@@ -63,6 +80,22 @@ void FmMuramClear(t_Handle h_FmMuram)
     IOMemSet32(UINT_TO_PTR(p_FmMuram->baseAddr), 0, p_FmMuram->size);
 }
 
+void *get_muram_data(uint32_t *size)
+{
+        uint8_t *src;
+        uint8_t *dst;
+
+        printk("%s::base %p size %d\n", __FUNCTION__,
+                FmMurambaseAddr,
+                FmMuramsize);
+        *size = FmMuramsize;
+        src = (uint8_t *)FmMurambaseAddr;
+        dst = (uint8_t *)kzalloc(FmMuramsize, GFP_KERNEL);
+        if (dst)
+                memcpy(dst, src, FmMuramsize);
+        return (dst);
+}
+EXPORT_SYMBOL(get_muram_data);
 
 t_Handle FM_MURAM_ConfigAndInit(uintptr_t baseAddress, uint32_t size)
 {
@@ -90,8 +123,12 @@ t_Handle FM_MURAM_ConfigAndInit(uintptr_t baseAddress, uint32_t size)
     }
     memset(p_FmMuram, 0, sizeof(t_FmMuram));
 
+#ifdef CONFIG_DBG_UCODE_INFRA 
+	printk(KERN_INFO "%s(%d) size %d 0x%x\n", __FUNCTION__,__LINE__, size, size);
+#endif //CONFIG_DBG_UCODE_INFRA
 
-    if ((MM_Init(&h_Mem, baseAddress, size) != E_OK) || (!h_Mem))
+    if ((MM_Init(&h_Mem, baseAddress, size - DBG_UCODE_RESVD_MURAM_SIZE) 
+					!= E_OK) || (!h_Mem))
     {
         XX_Free(p_FmMuram);
         REPORT_ERROR(MAJOR, E_INVALID_HANDLE, ("FM-MURAM partition!!!"));
@@ -100,9 +137,10 @@ t_Handle FM_MURAM_ConfigAndInit(uintptr_t baseAddress, uint32_t size)
 
     /* Initialize FM MURAM parameters which will be kept by the driver */
     p_FmMuram->baseAddr = baseAddress;
-    p_FmMuram->size = size;
+    p_FmMuram->size = size - DBG_UCODE_RESVD_MURAM_SIZE;
     p_FmMuram->h_Mem = h_Mem;
-
+    FmMurambaseAddr = (void *)baseAddress;
+    FmMuramsize = size;
     return p_FmMuram;
 }
 
@@ -133,6 +171,7 @@ void  * FM_MURAM_AllocMem(t_Handle h_FmMuram, uint32_t size, uint32_t align)
 
     return UINT_TO_PTR(addr);
 }
+EXPORT_SYMBOL(FM_MURAM_AllocMem);
 
 void  * FM_MURAM_AllocMemForce(t_Handle h_FmMuram, uint64_t base, uint32_t size)
 {
@@ -162,6 +201,7 @@ t_Error FM_MURAM_FreeMem(t_Handle h_FmMuram, void *ptr)
 
     return E_OK;
 }
+EXPORT_SYMBOL(FM_MURAM_FreeMem);
 
 uint64_t FM_MURAM_GetFreeMemSize(t_Handle h_FmMuram)
 {
@@ -172,3 +212,5 @@ uint64_t FM_MURAM_GetFreeMemSize(t_Handle h_FmMuram)
 
     return MM_GetFreeMemSize(p_FmMuram->h_Mem);
 }
+EXPORT_SYMBOL(FmMurambaseAddr);
+
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/inc/fm_common.h b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/inc/fm_common.h
index 204840c9df39..5bf4485526ca 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/inc/fm_common.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/inc/fm_common.h
@@ -189,9 +189,19 @@ typedef _Packed struct t_FmPcdCtrlParamsPage {
     volatile uint32_t discardMask;
     volatile uint8_t  reserved3[4];
     volatile uint32_t postBmiFetchNia;
-    volatile uint8_t  reserved4[172];
+    volatile uint32_t internalFEBufferManagementIndexAddr;
+    volatile uint32_t internalFEBufferDepletionCounter;
+    volatile uint8_t  reserved4[164];
 } _PackedType t_FmPcdCtrlParamsPage;
 
+#if (DPAA_VERSION >= 11)
+typedef _Packed struct t_ExtHashResult {
+    volatile uint32_t liodnContextAndContextPtrHi;
+    volatile uint32_t contextPtrLow;
+    volatile uint32_t liodnMonitorAndMonitorPtrHi;
+    volatile uint32_t monitorPtrLow;
+} _PackedType t_ExtHashResult;
+#endif /* (DPAA_VERSION >= 11) */
 
 
 #if defined(__MWERKS__) && !defined(__GNUC__)
@@ -444,6 +454,17 @@ static __inline__ bool TRY_LOCK(t_Handle h_Spinlock, volatile bool *p_Flag)
 
 #define NIA_BMI_AC_ENQ_FRAME_WITHOUT_DMA    0x00000202
 
+#if (DPAA_VERSION >= 11)
+#define FE_MAX_CONTEXT_SIZE             256
+#define FE_MUX_CONTEXT_OFFSET           0
+#define FE_TRANSITION_CONTEXT_OFFSET    4
+#define FE_ENQUEUE_CONTEXT_OFFSET       8
+#define FE_HM_CONTEXT_OFFSET_START      16
+#define FM_MAX_HM_CONTEXTS              3
+#define FM_HM_CONTEXT_SIZE              ((FE_MAX_CONTEXT_SIZE-FE_HM_CONTEXT_OFFSET_START)/FM_MAX_HM_CONTEXTS)
+#define FE_HM_CONTEXT_OFFSET(i)         (FE_HM_CONTEXT_OFFSET_START + i*FM_HM_CONTEXT_SIZE)
+#endif /* (DPAA_VERSION >= 11) */
+
 #if defined(FM_OP_NO_VSP_NO_RELEASE_ERRATA_FMAN_A006675) || defined(FM_ERROR_VSP_NO_MATCH_SW006)
 #define GET_NIA_BMI_AC_ENQ_FRAME(h_FmPcd)   \
     (uint32_t)((FmPcdIsAdvancedOffloadSupported(h_FmPcd)) ? \
@@ -669,6 +690,76 @@ typedef struct t_FmPcdLock {
 typedef t_Error (t_FmPortGetSetCcParamsCallback) (t_Handle                  h_FmPort,
                                                   t_FmPortGetSetCcParams    *p_FmPortGetSetCcParams);
 
+#if (DPAA_VERSION >= 11)
+#define FM_PCD_FE_ALIGN                     8
+#define FM_PCD_FE_T_EXT_HASH_SIZE           (4*7)
+#define FM_PCD_FE_T_HM_SIZE                 (4*4)
+#define FM_PCD_FE_T_ENQ_SIZE                (4*4)
+#define FM_PCD_FE_T_MUX_SIZE                (4*1)
+#define FM_PCD_FE_T_EXIT_SIZE               (4*1)
+#define FM_PCD_FE_T_TRANSITION_SIZE         (4*2)
+
+#define FM_PCD_FE_MAX_SIZE                   FM_PCD_FE_T_EXT_HASH_SIZE
+
+typedef enum e_FmPcdFEType
+{
+    e_FM_PCD_FE_T_INVALID = 0,
+    e_FM_PCD_FE_T_HM,
+    e_FM_PCD_FE_T_ENQ,
+    e_FM_PCD_FE_T_EXIT,
+    e_FM_PCD_FE_T_MUX,
+    e_FM_PCD_FE_T_TRANSITION,
+    e_FM_PCD_FE_T_EXT_HASH
+} e_FmPcdFEType;
+
+typedef struct
+{
+    uint16_t    wsOffset;
+    t_Handle    h_NextFE;
+    e_FmPcdFEType type;
+    union {
+        struct {
+            bool parseAfterHm;
+        } hm;
+        struct {
+            bool    fqidEn;
+            bool    spEn;
+            bool    ppEn;
+            bool    mergePolicerWithNia;
+            uint32_t    nia;
+        } enq;
+        struct {
+            bool deallocateBuffer;
+        } exit;
+        struct {
+            bool deallocateBuffer;
+            bool nextADFromWS;
+        } transition;
+    } u;
+} t_FmPcdFEParams;
+
+typedef struct
+{
+    e_FmPcdFEType type;
+    union {
+        struct {
+            uint8_t     *p_Hmct;
+            uint16_t    tableSize;
+        } hm;
+        struct {
+            uint32_t    fqid;
+            uint8_t     rspid;
+            uint8_t     ppid;
+        } enq;
+        struct {
+            t_Handle h_NextAD;
+        } transition;
+        struct {
+            t_Handle h_NextFE;
+        } mux;
+    } u;
+} t_FmPcdFEContextParams;
+#endif /* DPAA_VERSION >= 11) */
 
 /***********************************************************************/
 /*          Common API for FM-PCD module                               */
@@ -688,6 +779,9 @@ t_Error     FmPcdFragHcScratchPoolInit(t_Handle h_FmPcd, uint8_t scratchBpid);
 t_Error     FmPcdRegisterReassmPort(t_Handle h_FmPcd, t_Handle h_IpReasmCommonPramTbl);
 t_Error     FmPcdUnregisterReassmPort(t_Handle h_FmPcd, t_Handle h_IpReasmCommonPramTbl);
 bool        FmPcdIsAdvancedOffloadSupported(t_Handle h_FmPcd);
+#if (DPAA_VERSION >= 11)
+t_Handle    FmPcdGetFE(t_Handle h_FmPcd, t_FmPcdFEParams *p_FeParams);
+#endif /* DPAA_VERSION >= 11) */
 bool        FmPcdLockTryLockAll(t_Handle h_FmPcd);
 void        FmPcdLockUnlockAll(t_Handle h_FmPcd);
 t_Error     FmPcdHcSync(t_Handle h_FmPcd);
@@ -782,6 +876,21 @@ t_Error     FmPcdCcTreeAddIPR(t_Handle h_FmPcd, t_Handle h_FmTree, t_Handle h_Ne
 t_Error     FmPcdCcTreeAddCPR(t_Handle h_FmPcd, t_Handle h_FmTree, t_Handle h_NetEnv, t_Handle h_ReassemblyManip, bool schemes);
 t_Error     FmPcdCcBindTree(t_Handle h_FmPcd, t_Handle h_PcdParams, t_Handle h_CcTree,  uint32_t  *p_Offset,t_Handle h_FmPort);
 t_Error     FmPcdCcUnbindTree(t_Handle h_FmPcd, t_Handle h_CcTree);
+#if (DPAA_VERSION >= 11)
+void        FmPcdCcBuildFE(t_Handle h_FmPcd, t_FmPcdFEParams *p_FeParams, t_Handle h_FE);
+t_Error     FmPcdCcBuildContextByFE(t_Handle h_FmPcd,
+                                    uint8_t *p_Context,
+                                    uint16_t offset,
+                                    t_FmPcdFEContextParams *p_FeParams);
+t_Handle FmPcdExternalHashTableSet(t_Handle h_FmPcd,
+                                   t_FmPcdHashTableParams *p_Param,
+                                   bool allocateBuffer,
+                                   uint16_t contextSize,
+                                   uint16_t contextOffsetInWS,
+                                   t_Handle h_NextFE,
+                                   t_Handle h_MissFE,
+                                   t_ExtHashResult *p_MissResult);
+#endif /* DPAA_VERSION >= 11) */
 
 /***********************************************************************/
 /*          Common API for FM-PCD Manip module                            */
@@ -799,6 +908,8 @@ typedef enum e_FmPortGprFuncType
 } e_FmPortGprFuncType;
 
 t_Error     FmPortSetGprFunc(t_Handle h_FmPort, e_FmPortGprFuncType gprFunc, void **p_Value);
+t_Error     FmPortSetFESupport(t_Handle h_FmPort);
+t_Error     FmPortDeleteFESupport(t_Handle h_FmPort);
 #endif /* DPAA_VERSION >= 11) */
 t_Error     FmGetSetParams(t_Handle h_Fm, t_FmGetSetParams *p_FmGetSetParams);
 t_Error     FmPortGetSetCcParams(t_Handle h_FmPort, t_FmPortGetSetCcParams *p_FmPortGetSetCcParams);
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/inc/fm_hc.h b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/inc/fm_hc.h
index 492aa8a3aa78..db3f715371a3 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/inc/fm_hc.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/inc/fm_hc.h
@@ -71,6 +71,8 @@ t_Error     FmHcPcdKgSetSchemeCounter(t_Handle h_FmHc, t_Handle h_Scheme, uint32
 uint32_t    FmHcPcdKgGetSchemeCounter(t_Handle h_FmHc, t_Handle h_Scheme);
 
 t_Error     FmHcPcdCcDoDynamicChange(t_Handle h_FmHc, uint32_t oldAdAddrOffset, uint32_t newAdAddrOffset);
+t_Error     FmHcPcdCcDoDynamicChangeWithAging(t_Handle h_FmHc, uint32_t oldAdAddrOffset, uint32_t newAdAddrOffset, e_ModifyState modifyState, uint16_t keyIndex);
+t_Error     FmHcPcdCcResetAgingMask(t_Handle h_FmHc, uint32_t adAddrOffset, uint32_t newAgeMask, uint32_t *p_OldAgeMask);
 
 t_Error     FmHcPcdPlcrSetProfile(t_Handle h_FmHc, t_Handle h_Profile, t_FmPcdPlcrProfileRegs *p_PlcrRegs);
 t_Error     FmHcPcdPlcrDeleteProfile(t_Handle h_FmHc, t_Handle h_Profile);
@@ -88,6 +90,20 @@ t_Error     FmHcPcdSync(t_Handle h_FmHc);
 t_Handle    FmHcGetPort(t_Handle h_FmHc);
 
 
+#ifdef CONFIG_DBG_UCODE_INFRA 
+t_Error FmHcPcdDbgUcodeHCmd(t_Handle h_FmHc, 
+			   uint32_t muram_offset,
+			   uint8_t  *data,
+			   uint8_t	size);
 
+t_Error FmHcPcdDbgUcodeTest(t_Handle h_FmHc,
+				uint32_t opcode,
+				uint32_t *data,
+				uint16_t data_size);
 
+#ifdef CONFIG_DMAR_TEST
+t_Error FmHcPcdDMAreadTest(t_Handle h_FmPcd, 
+						uint32_t muram_addr_offset, uint8_t *ptr, uint8_t size);
+#endif //CONFIG_DMAR_TEST
+#endif // CONFIG_DBG_UCODE_INFRA 
 #endif /* __FM_HC_H */
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/inc/fm_sp_common.h b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/inc/fm_sp_common.h
index f9dd384bb685..b9cc5aa2bd1e 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/inc/fm_sp_common.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/inc/fm_sp_common.h
@@ -50,7 +50,7 @@
 /**************************************************************************//**
  @Description       defaults
 *//***************************************************************************/
-#define DEFAULT_FM_SP_bufferPrefixContent_privDataSize      0
+#define DEFAULT_FM_SP_bufferPrefixContent_privDataSize      128//0
 #define DEFAULT_FM_SP_bufferPrefixContent_passPrsResult     FALSE
 #define DEFAULT_FM_SP_bufferPrefixContent_passTimeStamp     FALSE
 #define DEFAULT_FM_SP_bufferPrefixContent_allOtherPCDInfo   FALSE
diff --git a/drivers/net/ethernet/freescale/sdk_fman/etc/memcpy.c b/drivers/net/ethernet/freescale/sdk_fman/etc/memcpy.c
index fa203ec7cebf..1b1fb4bcc262 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/etc/memcpy.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/etc/memcpy.c
@@ -56,6 +56,7 @@ void * MemSet8(void* pDst, int c, uint32_t size)
     return pDst;
 }
 
+#define USE_ALTERNATE 1
 void * MemCpy32(void* pDst,void* pSrc, uint32_t size)
 {
     uint32_t leftAlign;
@@ -69,6 +70,10 @@ void * MemCpy32(void* pDst,void* pSrc, uint32_t size)
 
     p_Src8 = (uint8_t*)(pSrc);
     p_Dst8 = (uint8_t*)(pDst);
+#ifdef USE_ALTERNATE
+    memcpy(p_Dst8, p_Src8, size);
+    return pDst;
+#endif
     /* first copy byte by byte till the source first alignment
      * this step is necessary to ensure we do not even try to access
      * data which is before the source buffer, hence it is not ours.
@@ -143,6 +148,11 @@ void * IO2IOCpy32(void* pDst,void* pSrc, uint32_t size)
 
     p_Src8 = (uint8_t*)(pSrc);
     p_Dst8 = (uint8_t*)(pDst);
+#ifdef USE_ALTERNATE
+    memcpy(p_Dst8, p_Src8, size);
+    return pDst;
+#endif
+
     /* first copy byte by byte till the source first alignment
      * this step is necessary to ensure we do not even try to access
      * data which is before the source buffer, hence it is not ours.
@@ -222,6 +232,11 @@ void * Mem2IOCpy32(void* pDst,void* pSrc, uint32_t size)
 
     p_Src8 = (uint8_t*)(pSrc);
     p_Dst8 = (uint8_t*)(pDst);
+#ifdef USE_ALTERNATE
+    memcpy(p_Dst8, p_Src8, size);
+    return pDst;
+#endif
+
     /* first copy byte by byte till the source first alignment
      * this step is necessary to ensure we do not even try to access
      * data which is before the source buffer, hence it is not ours.
@@ -300,6 +315,10 @@ void * IO2MemCpy32(void* pDst,void* pSrc, uint32_t size)
 
     p_Src8 = (uint8_t*)(pSrc);
     p_Dst8 = (uint8_t*)(pDst);
+#ifdef USE_ALTERNATE
+    memcpy(p_Dst8, p_Src8, size);
+    return pDst;
+#endif
     /* first copy byte by byte till the source first alignment
      * this step is necessary to ensure we do not even try to access
      * data which is before the source buffer, hence it is not ours.
diff --git a/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_eh_types.h b/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_eh_types.h
new file mode 100644
index 000000000000..394b2771ccdb
--- /dev/null
+++ b/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_eh_types.h
@@ -0,0 +1,52 @@
+/*
+ *  Copyright 2018 NXP
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+ */
+        
+/**     
+ * @file                fm_eh_types.h     
+ * @description         DPAA enhanced external hash table types
+ */
+
+
+#ifndef FM_EH_TYPES_H
+#define FM_EH_TYPES_H 1
+
+//type field in table_info
+enum {
+        IPV4_UDP_TABLE,
+        IPV4_TCP_TABLE,
+        IPV6_UDP_TABLE,
+        IPV6_TCP_TABLE,
+        ESP_IPV4_TABLE,
+        ESP_IPV6_TABLE,
+        IPV4_MULTICAST_TABLE,
+        IPV6_MULTICAST_TABLE,
+        PPPOE_RELAY_TABLE,
+        ETHERNET_TABLE,
+        IPV4_3TUPLE_UDP_TABLE,
+        IPV4_3TUPLE_TCP_TABLE,
+        IPV6_3TUPLE_UDP_TABLE,
+        IPV6_3TUPLE_TCP_TABLE,
+        IPV4_REASSM_TABLE,
+        IPV6_REASSM_TABLE,
+        MAX_MATCH_TABLES
+};
+
+#define TABLE_TYPE_MASK 0xf
+
+#endif
diff --git a/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_ehash.h b/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_ehash.h
new file mode 100644
index 000000000000..f037424a19e8
--- /dev/null
+++ b/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_ehash.h
@@ -0,0 +1,1402 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+ */
+        
+/**     
+ * @file                fm_ehash.c     
+ * @description         DPAA enhanced external hash functions
+ */             
+
+#ifndef FM_EHASH_H
+#define FM_EHASH_H 1
+
+#define MAX_KEY_LEN			56
+#define MAX_EN_EHASH_ENTRY_SIZE		256
+#define EN_EHASH_ENTRY_ALIGN		256
+#define TBLENTRY_OPC_ALIGN      	sizeof(uint32_t)
+#define MAX_OPCODES			16
+
+//enhanced external hash structure
+//flags field in struct en_ehash_entry
+
+#define SET_INVALID_ENTRY_64BIT(entry)  (entry |= (((uint64_t)1) << 63))
+#define SET_INVALID_ENTRY(flags)	(flags |= (1 << 15))
+#define SET_TIMESTAMP_ENABLE(flags) 	(flags |= (1 << 13))
+#define SET_STATS_ENABLE(flags)		(flags |= (1 << 12))
+#define SET_OPC_OFFSET(flags, offset)	(flags |= ((offset >> 2) << 6))
+#define SET_PARAM_OFFSET(flags, offset)	(flags |= (offset >> 2))
+
+#define GET_INVALID_ENTRY_64BIT(entry)  (entry &  (((uint64_t)1) << 63))
+#define GET_INVALID_ENTRY(flags)	(flags & (1 << 15))
+#define GET_TIMESTAMP_ENABLE(flags) 	((flags >> 13) & 1)  // only one bit is used to indicate TS
+#define GET_STATS_ENABLE(flags)		(flags & (1 << 12))
+#define GET_OPC_OFFSET(x)		(((x >> 6) & 0x1f) << 2)
+#define GET_PARAM_OFFSET(x)		((x & 0x3f) << 2)
+
+struct en_ehash_entry {
+	union {
+		struct {
+			uint64_t packet_count;	//number of packet handled by flow
+			uint64_t packet_bytes;	//number of bytes handled by flow
+			uint32_t timestamp;		//flow timestamp
+			uint32_t reserved;		//padding for 24 bytes dma
+			uint32_t timestamp_counter;	//address of timestamp counter in muram
+			union {
+				struct {
+					uint16_t flags;
+					uint16_t next_entry_hi;		//link to next entry (upper)
+					uint32_t next_entry_lo;		//link to next entry (lower)
+				};
+				uint64_t next_entry;
+			};
+			uint8_t key[0];			//variable size key
+		}__attribute__ ((packed));
+		uint8_t	hash_entry[MAX_EN_EHASH_ENTRY_SIZE];
+	}__attribute__ ((packed));
+}__attribute__ ((packed));
+
+/*** cumulative entry is to add multiple table entries of same hash bucket into one entry
+   This is reduce the overhead of going through collisions.
+   This structure can have the following fields:
+     --flags: to specify info about the node,  some info can be:
+        bit 1 (1<<0) : may indicate that this is invalid node
+        bit 2 (1<<1) : may indicate that this cumulative entry contains the next entry
+        bit 3 (1<<2) : indicate that this cumulative entry contains only one table entry and
+                that table entry data is added inside this cumulative entry.
+     --key size
+     --number of key entries
+     -- next cumulative entry address
+     -- cumulative key
+     -- array of table entries
+**/
+
+#define EN_CUMULATIVE_NODE_MAX_SIZE 256
+
+struct en_cumulative_entry {
+	union {
+		struct {
+	        uint8_t flags;
+    	    uint8_t num_key_entries;
+        	uint8_t key_size;
+			uint8_t	tbl_entry_index;
+			uint64_t next_entry_addr;
+        	uint8_t data[244];
+		}__attribute__ ((packed));
+		uint8_t node_data[EN_CUMULATIVE_NODE_MAX_SIZE];
+	}__attribute__ ((packed));
+}__attribute__ ((packed));
+
+#define EN_CUMULATIVE_NODE  0x80
+#define EN_INVALID_CUMULATIVE_NODE 0x40
+#define EN_NEXT_CUMULATIVE_NODE  0x20
+//#define EN_CRC_BASED_NODE 	0x10
+#define EN_CU_HASH_TABLE_ENTRY_ADDR_SIZE 8
+#define EN_CU_FIXED_ELEMENTS_SIZE 12
+
+struct en_cumulative_tbl_entry {
+	struct en_cumulative_entry cumulative_entry;
+	struct en_cumulative_tbl_entry *next_entry;
+	struct en_cumulative_tbl_entry *prev_entry;
+};
+
+/* DPA Classifier table entry statistics */
+#define STATS_VALID		(1 << 0)
+#define TIMESTAMP_VALID		(1 << 1)
+struct en_tbl_entry_stats {
+	/* The total number of packets that have hit the entry */
+	uint64_t	pkts;
+
+	/* The total number of bytes that have hit the entry */
+	uint64_t	bytes;
+	
+	/* timestamp */
+	uint32_t 	timestamp;
+
+	/* flags to indicate field validity */
+	uint32_t flags;
+};
+
+//opcodes
+#define	ENQUEUE_PKT		0x01
+#define	REPLICATE_PKT		0x02
+#define	UPDATE_ETH_RX_STATS 	0x04
+#define	STRIP_ETH_HDR		0x11
+#define	STRIP_ALL_VLAN_HDRS	0x12
+#define	STRIP_PPPoE_HDR		0x14
+#define	STRIP_L2_HDR		0x17	
+#define STRIP_FIRST_VLAN_HDR	0x18
+#define	REMOVE_FIRST_IP_HDR	0x19
+#define	VALIDATE_IPSEC_ID	0x1a
+#define	UPDATE_TTL		0x21
+#define	UPDATE_SIP_V4		0x22
+#define	UPDATE_DIP_V4		0x24
+#define	UPDATE_HOPLIMIT		0x29
+#define	UPDATE_SIP_V6		0x2A
+#define	UPDATE_DIP_V6		0x2C
+#define	UPDATE_SPORT		0x31
+#define	UPDATE_DPORT		0x32
+#define	INSERT_L2_HDR		0x41
+#define	INSERT_VLAN_HDR		0x42
+#define	INSERT_PPPoE_HDR	0x43
+#define	INSERT_L3_HDR		0x44
+#define	REPLACE_PPPOE_HDR	0x45
+#define	NATPT_4to6		0x51
+#define	NATPT_6to4		0x52
+#define PROCESS_RTP_PAYLOAD		0x61
+#define PROCESS_RTCP_PAYLOAD		0x62
+#define	UPDATE_GLOBAL_STATS	0x80
+
+
+//parameters for opcode	ENQUEUE_PKT 
+#define EN_EHASH_DISABLE_FRAG	0xffff	//set in mtu to disable fragmentation
+struct en_ehash_enqueue_param {
+	uint16_t mtu;		//mtu size in bytes for fragmentation
+	uint8_t pad;
+	uint8_t bpid;		//buffer pool id for frag buffers
+	uint32_t fqid;		//fqid to which pkt needs to be enqueued
+	uint32_t stats_ptr;	//interface egress stats
+	uint32_t muram_frag_param_addr; // MURAM address of fragmentation module parameters
+}__attribute__ ((packed));
+
+
+#define EEH_RTP_SEND_FIRST_PACKET_TO_CP  0x0001
+#define EEH_RTP_DUPLICATE_PKT_SEND_TO_CP  0x0002
+#define EEH_RTP_ENABLE_VLAN_P_BIT_LEARN	  0x0004
+
+
+struct en_ehash_rtprelay_param {
+	uint32_t	rtpinfo_ptr;
+	uint32_t	in_sock_stats_ptr;
+	uint32_t	out_sock_stats_ptr;
+	union
+	{
+		uint32_t src_ipv4_val;			//ipv4 address 
+		uint32_t src_ipv6_val[4];		//ipv6 address
+	}__attribute__ ((packed));
+//	// 2 types of timestamp takeover: a) Fixed TS increment value, b) real timing using sampling frequency
+	// in case (a) TimeStampIncr is configured
+	uint32_t	   	TimeStampIncr; // fixed TS increment value
+	uint32_t		SSRC_1; // configured SSRC_1 value;
+	uint16_t		seq_base; // configured sequence base value
+	uint16_t	   	egress_socketID; // used for generation of SSRC value
+	uint8_t 		DTMF_PT[2];
+	uint16_t		rtp_flags;
+	// temp variables for functionality in ucode 
+	uint16_t	seq_incr;
+	uint32_t	chksum_ptr;
+	uint32_t	rtp_hdr;
+	uint32_t	ts_incr;
+	uint32_t	cur_ts_msec;
+	int32_t  	rtp_check;
+}__attribute__ ((packed));
+
+//update ether receive stats
+//parameters for opcode REPLICATE_PKT
+struct en_ehash_replicate_param {
+	union {
+		struct {
+			uint16_t	rsvd; // num_mcast_members; // number of multicast members
+			uint16_t	first_member_flow_addr_hi;
+			uint32_t	first_member_flow_addr_lo; // first multicast member flow entry address
+			};
+		uint64_t first_member_flow_addr;
+	};
+	void	*first_listener_entry;
+}__attribute__ ((packed));
+
+//update ether receive stats
+struct en_ehash_update_ether_rx_stats {
+	uint32_t stats_ptr;
+}__attribute__ ((packed));
+
+//parameters for opcode	STRIP_FIRST_VLAN_HDR
+struct en_ehash_strip_first_vlan_hdr {
+	uint32_t stats_ptr;	//muram location address for interface statistics
+}__attribute__ ((packed));
+
+//parameters for opcode	STRIP_ALL_VLAN_HDRS
+struct en_ehash_strip_all_vlan_hdrs {
+	union {
+		struct {
+			uint32_t padding:2;	//padding to align structure to next 4 bytes boundary	
+			uint32_t num_entries:6;	//number of stats entries
+			uint32_t stats_ptr:24;	//pointer to stats table
+		};
+		uint32_t word;
+	};
+	uint8_t stats_offsets[0];		//array of offsets into stats base
+}__attribute__ ((packed));
+
+//parameters for STRIP_PPPoE_HDR
+struct en_ehash_strip_pppoe_hdr {
+	uint32_t stats_ptr;	//muram location address for interface statistics
+}__attribute__ ((packed));
+
+//strip all l2 headers
+struct en_ehash_strip_l2_hdrs {
+	union {
+		struct {
+			uint32_t padding:2;	//padding to align structure to next 4 bytes boundary	
+			uint32_t num_entries:6;	//number of stats entries
+			uint32_t stats_ptr:24;	//pointer to stats table
+		};
+		uint32_t word;
+	};
+	uint8_t stats_offsets[0];		//array of offsets into stats base
+}__attribute__ ((packed));
+
+//parameters for opcode VALIDATE_IPSEC_ID
+struct en_ehash_validate_ipsec {
+	uint32_t reserved:16;
+	uint32_t identifier:16;		//tunnel identifier opaque value
+}__attribute__ ((packed));
+
+//parameters for opcode UPDATE_SIP,DIP
+struct en_ehash_update_ipv4_ip {
+	uint32_t ip_v4;			//ipv4 address 
+}__attribute__ ((packed));
+
+struct en_ehash_update_ipv6_ip {
+	uint8_t ip_v6[16];		//ipv6 address
+}__attribute__ ((packed));
+
+//parameters for opcode UPDATE_SPORT, UPDATE_DPORT
+struct en_ehash_update_port{
+	uint16_t dport;			//dest port info
+	uint16_t sport;			//source port info
+}__attribute__ ((packed));
+
+//parameters for opcode INSERT_L2_HDR
+struct en_ehash_insert_l2_hdr {
+	union {
+		struct {
+        		uint8_t replace:1;		//replace header, do not insert
+			uint8_t header_padding:2;	//padding for L2 header field adjust
+			uint8_t reserved:5;
+			uint8_t stats_count;		//number of statistics offsets
+			uint8_t reserved_1;
+			uint8_t hdr_len;		//length of L2 header
+		};
+		uint32_t word;
+	};
+        uint8_t l2hdr[0];               //l2 hdr padded to next 4 bytes boundary
+}__attribute__ ((packed));
+
+struct en_ehash_insert_l2_hdr_stats {
+	union {
+        	struct {
+                	uint32_t padding:2;     //padding to align structure to next 4 bytes boundary
+                        uint32_t reserved:6; 
+                        uint32_t stats_ptr:24;  //pointer to stats table
+                };
+                uint32_t word;
+        };
+        uint8_t stats_offsets[0];               //array of offsets into stats base
+}__attribute__ ((packed));
+
+
+//parameters for opcode INSERT_VLAN_HDR
+struct en_ehash_insert_vlan_hdr {
+	union {
+		struct {
+			uint32_t padding:2;
+			uint32_t num_hdrs:6;	//number of headers to insert
+			uint32_t statptr:24;	//base of stats area or stats pointer, null no stats
+		}__attribute__ ((packed));
+		uint32_t word;
+	}__attribute__ ((packed));
+	uint32_t vlanhdr[0];		//array of vlan header includes TPID
+}__attribute__ ((packed));
+
+struct en_ehash_insert_vlan_hdr_stats {
+        uint8_t stats_offsets[1];               //array of offsets into stats base
+}__attribute__ ((packed));
+
+//default version, code and type fields 
+#define PPPoE_VERSION   1
+#define PPPoE_TYPE      1
+#define PPPoE_CODE      0
+//parameters for opcode INSERT_PPPoE_HDR - session offload
+struct en_ehash_insert_pppoe_hdr {
+	uint32_t stats_ptr;		//interface stats pointer
+	union {
+		struct {
+			uint32_t version:4;
+			uint32_t type:4;
+			uint32_t code:8;
+			uint32_t session_id:16;
+		};
+		uint32_t word;
+	};
+}__attribute__ ((packed));
+
+//parameters for opcode REPLACE_PPPOE_HDR - session offload
+struct en_ehash_replace_pppoe_hdr_params {
+	uint8_t   destination_mac[6];
+	uint8_t   source_mac[6];
+	uint16_t  session_id;
+	uint16_t  pad;
+	uint32_t  fqid;
+	uint32_t  stats_ptr;
+}__attribute__ ((packed));
+
+//parameters for opcode INSERT_L3 HDR 
+#define TYPE_CUSTOM	0
+#define TYPE_4o6	1
+#define TYPE_6o4	2
+
+#define IPID_STARTVAL	1
+struct en_ehash_insert_l3_hdr {
+	union {
+		struct {
+			uint8_t reserved:3;
+			uint8_t calc_cksum:1;
+			uint8_t df:1;
+			uint8_t qos:1;
+			uint8_t type:2;
+			uint8_t hdr_len;
+			uint16_t ipident;
+		};
+		uint32_t word;
+	};
+	union {
+		struct {
+			uint32_t route_dest_offset:8;
+			uint32_t stats_ptr:24;
+		};
+		uint32_t word_1;
+	};
+        uint8_t l3hdr[0];               //l3 hdr padded to next 4 bytes boundary
+}__attribute__ ((packed));
+
+//remove tunnel header
+struct en_ehash_remove_first_ip_hdr {
+	uint32_t stats_ptr;
+}__attribute__ ((packed));
+
+//basic statistics structure
+struct en_ehash_stats
+{
+	uint64_t pkts;
+	uint64_t bytes;
+}__attribute__ ((packed));
+
+struct en_ehash_stats_with_ts {
+	uint64_t pkts;
+	uint64_t bytes;
+	uint64_t timestamp;
+}__attribute__ ((packed));
+
+//statistics structure
+struct en_ehash_ifstats {
+	struct en_ehash_stats rxstats;
+	struct en_ehash_stats txstats;
+}__attribute__ ((packed));
+
+#define STATS_WITH_TS	(1 << 7)
+//statistics structure with timestamp
+struct en_ehash_ifstats_with_ts {
+	struct en_ehash_stats_with_ts rxstats;
+	struct en_ehash_stats_with_ts txstats;
+}__attribute__ ((packed));
+
+//statistics table structure
+struct en_ehash_stats_tbl {
+	uint32_t table_indicator:1;	//set for table indication, valid in the first entry only
+	uint32_t num_entries:7;		//number of entries in table, valid in the first entry only
+	uint32_t stats_ptr:24;		//muRam address of en_ehash_stats member
+}__attribute__ ((packed));
+
+//NATPT structures
+struct en_ehash_natpt_hdr {
+	union {
+		struct {
+			uint32_t reserved:6;
+			uint32_t tcu:1; //traffic class update
+			uint32_t hlu:1; //hop limit update
+			uint32_t hdrlen:8; //length of header
+			uint32_t reserved1:16;
+		}ip4to6;
+		struct {
+			uint16_t reserved:5;
+			uint16_t ipu:1; //ipidentifier update
+			uint16_t tou:1; //tos update
+			uint16_t tlu:1; //ttl update
+			uint16_t hdrlen:8; //length of header
+			uint16_t ipident; //flow based ipidentifier
+		}ip6to4;
+		uint32_t word;
+	};
+        uint8_t l3hdr[0];               //l3 hdr padded to next 4 bytes boundary
+}__attribute__ ((packed));
+
+//4 to 6 
+#define NATPT_TCU	(1 << 25)
+#define NATPT_HLU	(1 << 24)
+//6 to 4 
+#define NATPT_IPU	(1 << 26)
+#define NATPT_TOU	(1 << 25)
+#define NATPT_TLU	(1 << 24)
+
+
+//types for miss_action_type
+#define EN_EHASH_MISS_ACTION_DROP       3
+#define EN_EHASH_MISS_ACTION_NIA        1
+#define EN_EHASH_MISS_ACTION_ENQUE      2
+#define EN_EHASH_MISS_ACTION_DONE       0
+//AD for this table, defines assuming a LE GPP core
+
+
+#ifdef EXCLUDE_FMAN_IPR_OFFLOAD 
+struct en_exthash_node {
+	union {
+		struct {
+			uint32_t table_base_hi:16;	//upper addr of 40 bit table phys addr
+			uint32_t hash_bytes_offset:2;	//bytes of FMAN hash result to use
+			uint32_t reserved_1:6;
+			uint32_t key_size:6;		//size in bytes of key
+			uint32_t miss_action_type:2;	//miss action
+		}__attribute__ ((packed));
+		uint32_t word_0;
+	}__attribute__ ((packed));
+	uint32_t table_base_lo;		//lower addr of 40 bit table phys addr
+	union {
+		struct {
+			uint32_t hash_mask:16;	
+			uint32_t int_buf_pool_addr:16;
+		}__attribute__ ((packed));;
+		uint32_t word_1;
+	}__attribute__ ((packed));
+	union {
+		union {
+			uint32_t nia;		//nia  to use if type is EN_EHASH_MISS_ACTION_NIA
+			uint32_t fqid;		//fqid to use if type is EN_EHASH_MISS_ACTION_ENQUE
+		}__attribute__ ((packed));
+		uint32_t word_2;
+	}__attribute__ ((packed));
+}__attribute__ ((packed));
+#else
+//table type
+#define REASSEMBLY_TABLE                (1 << 3)
+#define L4_TABLE                        (1 << 2)
+#define L3_TABLE                        (1 << 1)
+#define L2_TABLE                        (1 << 0)
+struct en_exthash_node {
+        union {
+                struct {
+                        uint32_t table_base_hi:8;       //upper addr of 40 bit table phys addr
+                        uint32_t ipv4_ad_offset:8;      //ipv4 ad offset in this tree
+                        uint32_t hash_bytes_offset:3;   //offset in hash value
+                        uint32_t reserved:1;
+                        uint32_t table_type:4;
+                        uint32_t key_size:6;            //size in bytes of key
+                        uint32_t miss_action_type:2;    //miss action
+                }__attribute__ ((packed));
+                uint32_t word_0;
+        }__attribute__ ((packed));
+        uint32_t table_base_lo;         //lower addr of 40 bit table phys addr
+        union {
+                struct {
+                        uint32_t hash_mask:16;
+                        uint32_t int_buf_pool_addr:16;
+                }__attribute__ ((packed));;
+                uint32_t word_1;
+        }__attribute__ ((packed));
+        union {
+                uint32_t nia;   //nia if type is EN_EHASH_MISS_ACTION_NIA
+                uint32_t fqid;  //fqid if type  EN_EHASH_MISS_ACTION_ENQUE
+                uint32_t reassm_param;//pointer to reassembly parameters in muram, for ipv4/v6 reassembly tables
+                uint32_t word_2;
+        }__attribute__ ((packed));
+}__attribute__ ((packed));
+
+//ipv4/6 reassembly statistics
+struct ip_reassembly_stats {
+        uint64_t num_frag_pkts;
+        uint64_t num_reassemblies;
+        uint64_t num_completed_reassly;
+        uint64_t num_sess_matches;
+        uint64_t num_frags_too_small;
+        uint64_t num_reassm_timeouts;
+        uint64_t num_overlapping_frags;
+        uint64_t num_too_many_frags;
+        uint64_t num_failed_bufallocs;
+        uint64_t num_failed_ctxallocs;
+        uint64_t num_fatal_errors;
+        uint64_t num_failed_ctxdeallocs;
+        uint32_t reassm_count;
+        uint32_t pad;
+}__attribute__ ((packed));
+
+
+#define IPR_MAX_SESSIONS        256
+#define IPR_MAX_SESSSIZE        256
+#define IPR_CTX_ALIGN           256
+#define UCODE_MAX_TASKS         128
+#define TASK_PRIV_MEMSIZE       32
+#define IPR_CONTEXT_EOL         0xffffffff
+struct ipr_context_info {
+        uint8_t context_data[IPR_MAX_SESSIONS][IPR_MAX_SESSSIZE];
+        uint8_t task_priv_data[UCODE_MAX_TASKS][TASK_PRIV_MEMSIZE];
+        uint32_t next_free_ctx;
+}__attribute__ ((packed));
+
+#define MAX_REASSM_BUCKETS              (1 << 4)
+//ipv4/6 reassembly info
+struct ip_reassembly_params {
+        uint32_t table_base_hi;         //reassembly table base
+        uint32_t table_base_lo;
+        struct ip_reassembly_stats stats; //stats
+        uint32_t table_mask;            //hash mask
+        uint32_t type;                  //type of table
+        uint32_t ipr_timer;             //ipr timer location
+        uint32_t timeout_val;           //reassembly timeout
+        uint32_t timeout_fqid;          //fqid for timeout fragments
+        uint32_t min_frag_size;         //min frag size other than last
+        uint32_t reassem_bpid;          //buffer pool for re-assembly context
+        uint32_t reassem_bsize;         //size of buffers in reassem_context
+        uint32_t frag_bpid;             //buffer pool for re-assembly fragments
+        uint32_t frag_bsize;            //size of buffers in reassem_bpid
+        uint32_t reassly_dbg;           //debug area
+        uint32_t context_info;          //context info structute ptr in muram
+        uint32_t curr_sessions;         //curr reassembly sessions
+        uint32_t txc_fqid;              //fqid for handling SG buffers
+        uint32_t timer_tnum;            //timer task number
+        uint32_t max_frags;             //max allowed frags per session
+        uint32_t max_con_reassm;        //max concurrent reassemblies
+        uint32_t bucket_base;           //base of bucket
+        uint32_t bucket_lock[MAX_REASSM_BUCKETS];//locks for hash buckets, should be the last member
+        uint32_t bucket_head[MAX_REASSM_BUCKETS];//head pointers of collision list
+}__attribute__ ((packed));
+
+//ipv4/v6 config and stats info required by cmm
+struct ip_reassembly_info {
+        u_int64_t num_frag_pkts;
+        u_int64_t num_reassemblies;
+        u_int64_t num_completed_reassly;
+        u_int64_t num_sess_matches;
+        u_int64_t num_frags_too_small;
+        u_int64_t num_reassm_timeouts;
+        u_int64_t num_overlapping_frags;
+        u_int64_t num_too_many_frags;
+        u_int64_t num_failed_bufallocs;
+        u_int64_t num_failed_ctxallocs;
+        u_int64_t num_fatal_errors;
+        u_int64_t num_failed_ctxdeallocs;
+        uint32_t table_mask;            //hash mask
+        uint32_t ipr_timer;             //ipr timer location
+        uint32_t timeout_val;           //reassembly timeout
+        uint32_t timeout_fqid;          //fqid for timeout fragments
+        uint32_t max_frags;             //max allowed sessions per session
+        uint32_t min_frag_size;         //min frag size other than last
+        uint32_t max_con_reassm;        //max concurrent reassemblies
+        uint32_t reassem_bpid;          //buffer pool for re-assembly context
+        uint32_t reassem_bsize;         //size of buffers in reassem_context
+        uint32_t frag_bpid;             //buffer pool for re-assembly fragments
+        uint32_t frag_bsize;            //size of buffers in reassem_bpid
+        uint32_t timer_tnum;            //timer task number
+        uint32_t reassly_dbg;           //debug area
+        uint32_t curr_sessions;         //curr reassembly sessions
+        uint32_t txc_fqid;              //fqid for handling SG buffers
+};
+#endif
+
+#define EN_EXTHASH_TBL_ALIGNMENT	8
+#define TIMESTAMP_EN	(1 << 0)
+#define STATS_EN	(1 << 1)
+struct en_exthash_info {
+	uint32_t flags;
+	void *table_base;	//base of table in DDR
+	void **pSpinlock;	//array of spin locks for each bucket
+	void *h_Ad;		//handle to muRam holding AD
+	struct en_exthash_node node; //ccnode
+	uint32_t tablesize;	//number of bytes allocated for hash table
+	uint32_t hashmask;	//mask to be used on hash value to get to bucket
+	uint32_t keysize;	//size of key in bytes
+	uint32_t hashshift;	//number of bytes to shift the fman hash result
+	uint32_t dataMemId;	//memory partition id
+	uint32_t dataLiodnOffset; //LIODN offsdet for access to ext hash table
+	uint32_t num_keys; 	// number of keys in the table currently
+	uint32_t max_collisions;//max collisions in the table that occured anytime upto now.
+	void *pcd;		//pcd handle
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+	uint32_t type;          //table type
+	struct ip_reassembly_params *ip_reassem_info; //muram area,used in case of reassembly tables only 
+#endif
+};
+
+struct en_exthash_tbl_entry {
+	struct en_ehash_entry hashentry;
+	struct en_exthash_tbl_entry *prev;
+	struct en_exthash_tbl_entry *next;
+	uint8_t	*replicate_params;
+	uint8_t *enqueue_params;
+};
+
+static inline void display_mcast_member_tbl_entry(struct en_ehash_entry *entry);
+static inline void display_tbl_ad(void *h_Ad)
+{
+	uint8_t *ptr;
+	uint32_t ii;
+
+	ptr = (uint8_t *)h_Ad;
+	for (ii = 0; ii < sizeof(struct en_exthash_node); ii++) 
+		printk("%02x ", *(ptr + ii));
+	printk("\n");
+}
+
+static inline void display_ehashtbl_info(void *handle, char *func)
+{
+	struct en_exthash_info *info;
+	
+	info = (struct en_exthash_info *)handle;
+	printk("%s::en_ehash info %p\n", func, info);
+	printk("flags\t%08x\n", info->flags);
+	printk("table_base\t%p\n", info->table_base);
+	printk("hash mask\t%x\n", info->hashmask);
+	printk("key size\t%d\n", info->keysize);
+	printk("hash shift\t%d\n", info->hashshift);
+	printk("table size\t%d\n", info->tablesize);
+	printk("datamemId\t%d\n", info->dataMemId);
+	printk("dataLiodnOffset\t%d\n", info->dataLiodnOffset);
+	printk("num keys\t%d\n", info->num_keys);
+	printk("max collisions \t%d\n", info->max_collisions);
+	printk("Ad handle\t%p\n", info->h_Ad);
+	display_tbl_ad(info->h_Ad);
+}
+
+static inline void disp_buf(void *buf, uint32_t size)
+{
+        uint8_t *ptr;
+        uint32_t ii;
+
+        ptr = buf;
+        for (ii = 0; ii < size; ii++) {
+                if ((ii % 16) == 15)
+                        printk("%02x\n", *ptr);
+                else
+                        printk("%02x ", *ptr);
+                ptr++;
+        }
+        printk("\n");
+}
+
+
+static inline void *display_l2hdr_insert_opc(void *ptr)
+{
+	struct en_ehash_insert_l2_hdr *l2hdrins;
+	struct en_ehash_insert_l2_hdr_stats *stats;
+	uint32_t size;
+	uint32_t word;
+	uint32_t len;
+	uint32_t padding;
+
+	printk("opcode : INSERT_L2_HDR\n");
+	l2hdrins = (struct en_ehash_insert_l2_hdr *)ptr;
+	word = cpu_to_be32(l2hdrins->word);
+	len = (word & 0xff);
+	padding = ((word >> 29) & 3);
+	if (word & (1 << 31))
+		printk("Replace hdr, size %d\n", len);
+	else
+		printk("insert hdr, size %d\n", len);
+        disp_buf(&l2hdrins->l2hdr[0], len);
+	printk("stats count %d\n", l2hdrins->stats_count);
+	size = (sizeof(struct en_ehash_insert_l2_hdr) + len + padding);
+	//stats count
+	len = ((word >> 16) & 0xff);
+	if (len) {
+		size += sizeof(struct en_ehash_insert_l2_hdr_stats);
+		stats = (struct en_ehash_insert_l2_hdr_stats *)((uint8_t *)ptr + size);
+		word = cpu_to_be32(stats->word);
+		padding = (word >> 30);
+		//get stats pointer
+		word &= 0xffffffff;
+		if (len == 1) {
+			printk("stats pointer %x\n", word);
+		} else {
+			uint32_t ii;
+			for (ii = 0; ii < len; ii++) {
+				printk("offset %d stats ptr %lx\n", 
+					stats->stats_offsets[ii], 
+				  	(word + stats->stats_offsets[ii] * 
+						sizeof(struct en_ehash_stats)));	
+			}
+		}
+		size += padding;
+	}
+	return ((uint8_t *)ptr + size);
+}
+
+static inline void *display_enqparams_opc(void *ptr)
+{
+	struct en_ehash_enqueue_param *param;
+
+	printk("opcode : ENQUEUE_PKT\n");
+	param = (struct en_ehash_enqueue_param *)ptr;
+	printk("mtu\t%d\n", cpu_to_be16(param->mtu));
+	//printk("bpid\t%d\n", cpu_to_be16(param->bpid));
+	printk("bpid\t%d\n", param->bpid);
+	printk("fqid\t%d(0x%x)\n", 
+		cpu_to_be32(param->fqid),
+		cpu_to_be32(param->fqid));
+	printk("stats_ptr\t%x\n", cpu_to_be32(param->stats_ptr));
+	return ((uint8_t *)ptr + sizeof(struct en_ehash_enqueue_param));
+}
+
+static inline void *display_pppoe_relay_opc(void *ptr)
+{
+  struct en_ehash_replace_pppoe_hdr_params *param;
+
+  printk("opcode : REPLACE_PPPOE_HDR\n");
+  param = (struct en_ehash_replace_pppoe_hdr_params *)ptr;
+  printk("\nDestination Mac:");
+  disp_buf(ptr, 6);
+  printk("\nSource Mac:");
+  disp_buf(ptr+6,6);
+  printk("\nsession id:%d",cpu_to_be16(param->session_id));
+  printk("\r\n");
+  //printk("stats_ptr\t%x\n", cpu_to_be32(param->stats_ptr));
+  return ((uint8_t *)ptr + sizeof(struct en_ehash_replace_pppoe_hdr_params));
+}
+
+static inline void *display_ttlupdate_opc(void *ptr)
+{
+	printk("opcode : UPDATE_TTL\n");
+	return ptr;
+}
+
+static inline void *display_hoplupdate_opc(void *ptr)
+{
+	printk("opcode : UPDATE_HOPLIMIT\n");
+	return ptr;
+}
+
+static inline void *display_replicate_opc(void *ptr)
+{
+	struct en_ehash_replicate_param *param = (struct en_ehash_replicate_param *)ptr;
+	struct en_exthash_tbl_entry *tbl_entry;
+	int ii = 0;
+	uint64_t phyaddr;
+
+	printk("opcode : REPLICATE_PKT\n");
+	printk("Group table entry addr HI : 0x%04x, LO : 0x%08x\n", 
+		param->first_member_flow_addr_hi, param->first_member_flow_addr_lo);
+	phyaddr = be16_to_cpu(param->first_member_flow_addr_hi);
+	phyaddr = (phyaddr << 32);
+	phyaddr |= be32_to_cpu(param->first_member_flow_addr_lo);
+	while(1)//	for (ii=0; ii< be16_to_cpu(param->num_mcast_members); ii++)
+	{
+		printk("mcast member(%d) info:\n",ii);
+		//tbl_entry = (struct en_exthash_tbl_entry *)XX_PhysToVirt(phyaddr);
+		tbl_entry = (struct en_exthash_tbl_entry *)phys_to_virt(phyaddr);
+		display_mcast_member_tbl_entry(&tbl_entry->hashentry);
+		phyaddr =  be16_to_cpu(tbl_entry->hashentry.next_entry_hi);
+		phyaddr = phyaddr << 32;
+		phyaddr |=  be32_to_cpu(tbl_entry->hashentry.next_entry_lo);
+		ii++;
+		if (!phyaddr)	
+			break;
+	}
+	printk("no. of mcast members : %d\n", ii);
+	return (param + 1);
+}
+
+static inline void *display_strip_eth_hdr_opc(void *ptr)
+{
+	printk("opcode : STRIP_ETH_HDR\n");
+	return ptr;
+}
+
+static inline void *display_update_eth_rx_stats_opc(void *ptr)
+{
+	struct en_ehash_update_ether_rx_stats *param;
+
+	param = (struct en_ehash_update_ether_rx_stats *)ptr;
+	printk("opcode : UPDATE_ETH_RX_STATS\n");
+	printk("interface stats pointer %08x\n",
+			cpu_to_be32(param->stats_ptr));
+	return (param + 1);
+}
+
+static inline void *display_strip_allvlan_hdr_opc(void *ptr)
+{
+	struct en_ehash_strip_all_vlan_hdrs *param;
+	uint32_t size;
+	uint32_t word;
+	uint32_t padding;
+	uint32_t num_entries;
+	uint32_t stats_ptr;
+
+	param = (struct en_ehash_strip_all_vlan_hdrs *)ptr;
+	printk("opcode : STRIP_ALL_VLAN_HDRS\n");
+	size = sizeof(struct en_ehash_strip_all_vlan_hdrs);
+	word = cpu_to_be32(param->word);
+	padding = (word >> 30);
+	stats_ptr = (word & 0xffffff);
+	num_entries = ((word >> 24) & 0x3f);
+	printk("num entries %d, padding %d\n", num_entries, padding);
+	if (stats_ptr) {
+		if (num_entries > 1) {
+			uint32_t ii;
+			size += (num_entries + padding);
+			for (ii = 0; ii < num_entries; ii++) {
+				printk("offset %d, statsptr %lx\n",
+					param->stats_offsets[ii],	
+					(stats_ptr + 
+					(param->stats_offsets[ii] * sizeof(struct en_ehash_stats))));
+			} 
+		} else {
+			printk("stats ptr %x\n", stats_ptr);
+		}
+	}
+	return ((uint8_t *)ptr + size);
+}
+
+static inline void *display_strip_pppoe_hdr_opc(void *ptr)
+{
+	struct en_ehash_strip_pppoe_hdr *param;
+
+	param = (struct en_ehash_strip_pppoe_hdr *)ptr;
+	printk("opcode : STRIP_PPPoE_HDR\n");
+	printk("stats ptr %08x\n", cpu_to_be32(param->stats_ptr));
+	return (param + 1);
+}
+
+static inline void *display_strip_firstvlan_opc(void *ptr)
+{
+	struct en_ehash_strip_first_vlan_hdr *param;
+
+	param = (struct en_ehash_strip_first_vlan_hdr *)ptr;
+	printk("opcode : STRIP_FIRST_VLAN_HDR\n");
+	printk("interface stats pointer %08x\n",
+			param->stats_ptr);
+	return (param + 1);
+}
+
+static inline void *display_strip_first_iphdr(void *ptr)
+{
+	
+	struct en_ehash_remove_first_ip_hdr *param;
+
+	param = (struct en_ehash_remove_first_ip_hdr *)ptr;
+	printk("opcode : REMOVE_FIRST_IP_HDR\n");
+	printk("stats ptr %x\n", cpu_to_be32(param->stats_ptr));
+	return (param + 1);
+}
+
+static inline void *display_validate_ipsecid_opc(void *ptr)
+{
+	printk("opcode : VALIDATE_IPSEC_ID\n");
+	return ptr;
+}
+
+static inline void *display_update_nat_ipv4_opc(void *ptr, uint32_t opcode)
+{
+	struct en_ehash_update_ipv4_ip *param;
+
+	printk("opcode : %02x\n", opcode);
+	param = (struct en_ehash_update_ipv4_ip *)ptr;
+	if ((opcode & UPDATE_TTL) == UPDATE_TTL)
+		printk("update TTL\n");
+	if ((opcode & UPDATE_SIP_V4) == UPDATE_SIP_V4) {
+		printk("update SIP V4 - SIP::%08x\n", htonl(param->ip_v4));
+		param++;
+	}
+	if ((opcode & UPDATE_DIP_V4) == UPDATE_DIP_V4) {
+		printk("update DIP V4 - DIP::%08x\n", htonl(param->ip_v4));
+		param++;
+	}
+	return param;
+}
+
+static inline void *display_update_nat_ipv6_opc(void *ptr, uint32_t opcode)
+{
+	struct en_ehash_update_ipv6_ip *param;
+
+	printk("opcode : %02x\n", opcode);
+	param = (struct en_ehash_update_ipv6_ip *)ptr;
+	if ((opcode & UPDATE_HOPLIMIT) == UPDATE_HOPLIMIT)
+		printk("update UPDATE_HOPLIMIT\n");
+	if ((opcode & UPDATE_SIP_V6) == UPDATE_SIP_V6) {
+		printk("update SIP V6 - SIP::%pI6c", param->ip_v6);
+		param++;
+	}
+	if ((opcode & UPDATE_DIP_V6) == UPDATE_DIP_V6) {
+		printk("update DIP V6 - DIP::%pI6c", param->ip_v6);
+		param++;
+	}
+	return param;
+}
+
+static inline void *display_update_nat_port_opc(void *ptr, uint32_t opcode)
+{
+	struct en_ehash_update_port *param;
+	
+	printk("opcode : %02x\n", opcode);
+	param = (struct en_ehash_update_port *)ptr;
+	if ((opcode & UPDATE_SPORT) == UPDATE_SPORT) {
+		printk("update SPORT - SPORT::%d\n", htons(param->sport));
+	}
+	if ((opcode & UPDATE_DPORT) == UPDATE_DPORT) {
+		printk("update DPORT - DPORT::%d\n", htons(param->dport));
+	}
+	param++;
+	return param;
+}
+
+static inline void *display_vlanhdr_insert_opc(void *ptr)
+{
+	uint32_t ii;
+	uint32_t stats_addr;
+	struct en_ehash_insert_vlan_hdr *param;
+	struct en_ehash_insert_vlan_hdr_stats *vlan_stats;
+	uint32_t *vlanhdr;
+	uint32_t num_hdrs;
+	uint32_t padding;
+	uint32_t size;
+
+	printk("opcode : INSERT_VLAN_HDR\n");
+	param = (struct en_ehash_insert_vlan_hdr *)ptr;
+	ii = cpu_to_be32(param->word);
+	num_hdrs = ((ii >> 24) & 0x3f);
+	stats_addr = (ii & 0xffffff);
+	printk("num headers %d stats ptr %x\n", 
+		num_hdrs, stats_addr);
+	padding = (ii >> 30);
+	vlanhdr = &param->vlanhdr[0];
+	for (ii = 0; ii < num_hdrs; ii++) {
+		disp_buf(vlanhdr, sizeof(uint32_t));	
+		printk("vlan hdr %08x\n", htonl(*vlanhdr));
+		vlanhdr++;
+	}
+	size = (sizeof(struct en_ehash_insert_vlan_hdr) + 
+		(num_hdrs * sizeof(uint32_t))); 
+	if (stats_addr) {
+		vlan_stats = (struct en_ehash_insert_vlan_hdr_stats *)vlanhdr;
+		if (param->num_hdrs == 1)
+			printk("stats ptr %x\n", stats_addr);
+		else {
+			for (ii = 0; ii < num_hdrs; ii++) 
+				printk ("stats offset %d:: %lx\n", 
+					vlan_stats->stats_offsets[ii],
+				  	(stats_addr + (vlan_stats->stats_offsets[ii] * 
+						sizeof(struct en_ehash_stats))));
+		}
+		size += (padding + num_hdrs);	
+	}
+	return(ptr + size);
+}
+
+static inline void *display_pppoehdr_insert_opc(void *ptr)
+{
+	uint32_t size;
+	struct en_ehash_insert_pppoe_hdr *param;
+
+	printk("opcode : INSERT_PPPoE_HDR\n");
+	param = (struct en_ehash_insert_pppoe_hdr *)ptr;
+	printk("version %d, type %d, code %d\n\n",
+			param->version,
+			param->type,
+			param->code);
+	printk("session id %d\n", param->session_id);
+	printk("stats ptr %x\n", param->stats_ptr);
+	size = sizeof(struct en_ehash_insert_pppoe_hdr);
+	return ((uint8_t *)ptr + ALIGN(size, sizeof(uint32_t)));
+}
+
+static inline void *display_l3hdr_insert_opc(void *ptr)
+{
+	struct en_ehash_insert_l3_hdr *param;
+	uint32_t word;
+
+	printk("opcode : INSERT_L3_HDR - ");
+	param = (struct en_ehash_insert_l3_hdr *)ptr;
+	word = cpu_to_be32(param->word);
+	switch ((word >> 24) & 3) {
+
+		case TYPE_4o6:
+			printk("TYPE_4o6\n");
+			break;
+		case TYPE_6o4:
+			printk("TYPE_6o4\n");
+			break;
+		default:
+			printk("TYPE_CUSTOM\n");
+			break;
+	}
+	printk("hdr len %d\n", param->hdr_len);
+	printk("df %d, qos %d, cs %d\n", 
+		((word >> 28) & 1),
+		((word >> 27) & 1),
+		((word >> 29) & 1));
+	printk("stats ptr %x\n", param->stats_ptr);
+	disp_buf(&param->l3hdr[0], param->hdr_len);
+	return ((uint8_t *)ptr + 
+		ALIGN((sizeof(struct en_ehash_insert_l3_hdr) + 
+					param->hdr_len), sizeof(uint32_t)));
+}
+
+static inline void *display_upd_glbl_stats_opc(void *ptr)
+{
+	printk("opcode : UPDATE_GLOBAL_STATS\n");
+	return ptr;
+}
+
+static inline void *display_rtp_opc(void *ptr)
+{
+        struct en_ehash_rtprelay_param   *param;
+        uint32_t  word;
+
+        printk("opcode : PROCESS_RTP_PAYLOAD\n");
+        param = (struct en_ehash_rtprelay_param *)ptr;
+
+        word = be32_to_cpu(param->in_sock_stats_ptr);
+        printk ("In Socket stats ptr: %x \n", word);
+        word = be32_to_cpu(param->out_sock_stats_ptr);
+        printk ("Out Socket stats ptr: %x \n", word);
+        word = be32_to_cpu(param->rtpinfo_ptr);
+        printk("RTP info ptr: %x\n", word);
+        word = be32_to_cpu(param->src_ipv4_val);
+        printk("src ipv4: %x\n", word);
+        word = be32_to_cpu(param->TimeStampIncr);
+        printk("TimestampiIncr :0x%x(%d) \n", word, word);
+        word = be16_to_cpu(param->seq_base);
+        printk("seq_base : %x(%d)\n", word, word);
+        word = be16_to_cpu(param->egress_socketID);
+        printk("egress_socketID : %x(%d)\n", word, word);
+        printk("DTMF_PT[0] %d DTMF_PT[1] %d\n",param->DTMF_PT[0], param->DTMF_PT[1]);
+		word = be16_to_cpu(param->rtp_flags);
+	printk("Send first packet to CP : %s \n", 
+			(word & EEH_RTP_SEND_FIRST_PACKET_TO_CP) ? "TRUE" : "FALSE");
+	printk("Duplicate packet and send to CP: %s \n",
+			(word & EEH_RTP_DUPLICATE_PKT_SEND_TO_CP) ? "TRUE" : "FALSE");
+
+	printk("VLAN P bit learning feature : %s \n",
+		(word & EEH_RTP_ENABLE_VLAN_P_BIT_LEARN) ? "Enabled" : "Disabled");
+        return ((uint8_t*) ptr +(sizeof (struct en_ehash_rtprelay_param)));
+}
+
+static inline void *display_rtcp_opc(void *ptr)
+{
+        struct en_ehash_rtprelay_param   *param;
+        uint32_t  word;
+
+        printk("opcode : PROCESS_RTCP_PAYLOAD\n");
+        param = (struct en_ehash_rtprelay_param *)ptr;
+
+        word = be32_to_cpu(param->in_sock_stats_ptr);
+        printk ("In Socket stats ptr: %x \n", word);
+        word = be32_to_cpu(param->out_sock_stats_ptr);
+        printk ("Out Socket stats ptr: %x \n", word);
+        word = be32_to_cpu(param->rtpinfo_ptr);
+        printk("RTP info ptr: %x\n", word);
+        word = be32_to_cpu(param->src_ipv4_val);
+        printk("src ipv4: %x\n", word);
+		word = be32_to_cpu(param->SSRC_1);
+		printk("SSRC_1	: %x (%d)\n", word, word);
+		word = be16_to_cpu(param->rtp_flags);
+		printk("Send first packet to CP : %s \n", 
+			(word & EEH_RTP_SEND_FIRST_PACKET_TO_CP) ? "TRUE" : "FALSE");
+		printk("Duplicate packet and send to CP: %s \n",
+			(word & EEH_RTP_DUPLICATE_PKT_SEND_TO_CP) ? "TRUE" : "FALSE");
+        return ((uint8_t*) ptr +(sizeof (struct en_ehash_rtprelay_param)));
+}
+
+
+static inline void display_mcast_member_tbl_entry(struct en_ehash_entry *entry)
+{
+	uint8_t *opc_ptr;
+	uint8_t *param_ptr;
+	uint64_t addr;
+	uint32_t ii;
+	uint16_t flags;
+	flags = cpu_to_be16(entry->flags);
+	opc_ptr = ((uint8_t *)entry + GET_OPC_OFFSET(flags));
+	param_ptr = ((uint8_t *)entry + GET_PARAM_OFFSET(flags));
+	addr = ((uint64_t)entry->next_entry_hi << 32);
+	addr |= entry->next_entry_lo;
+	printk("next_entry\t%p\n", (void *)addr);
+	for (ii = 0; ii < MAX_OPCODES; ii++) {
+		printk("opc ptr\t%p\n", opc_ptr);
+		printk("param ptr\t%p\n", param_ptr);
+		switch (*opc_ptr) {
+			case 0:
+				printk("end of opcodelist\n");
+				return;
+			case ENQUEUE_PKT:
+				param_ptr = display_enqparams_opc(param_ptr);	
+				return;
+			case UPDATE_ETH_RX_STATS:	
+				param_ptr = display_update_eth_rx_stats_opc(param_ptr);	
+				break;
+			case STRIP_ETH_HDR:          
+				param_ptr = display_strip_eth_hdr_opc(param_ptr);
+				break;
+			case STRIP_ALL_VLAN_HDRS:
+				param_ptr = display_strip_allvlan_hdr_opc(param_ptr);
+				break;
+			case STRIP_PPPoE_HDR:
+				param_ptr = display_strip_pppoe_hdr_opc(param_ptr);
+				break;
+			case STRIP_FIRST_VLAN_HDR: 
+				param_ptr = display_strip_firstvlan_opc(param_ptr);
+				break;
+			case REMOVE_FIRST_IP_HDR:
+				param_ptr = display_strip_first_iphdr(param_ptr);
+				break;
+			case VALIDATE_IPSEC_ID:
+				param_ptr = display_validate_ipsecid_opc(param_ptr);
+				break;
+			case UPDATE_TTL:
+				param_ptr = display_ttlupdate_opc(param_ptr);
+				break;
+			case UPDATE_HOPLIMIT:
+				param_ptr = display_hoplupdate_opc(param_ptr);
+				break;
+			case UPDATE_SIP_V4:
+			case (UPDATE_SIP_V4 | UPDATE_TTL):
+			case UPDATE_DIP_V4:
+			case (UPDATE_DIP_V4 | UPDATE_TTL):
+			case (UPDATE_SIP_V4 | UPDATE_DIP_V4):
+			case (UPDATE_SIP_V4 | UPDATE_DIP_V4 | UPDATE_TTL):
+				param_ptr = display_update_nat_ipv4_opc(param_ptr, *opc_ptr);
+				break;
+			case UPDATE_SIP_V6:
+			case (UPDATE_SIP_V6 | UPDATE_HOPLIMIT): 
+			case UPDATE_DIP_V6:
+			case (UPDATE_DIP_V6 | UPDATE_HOPLIMIT):
+			case (UPDATE_SIP_V6 | UPDATE_DIP_V6):
+			case (UPDATE_SIP_V6 | UPDATE_DIP_V6 | UPDATE_HOPLIMIT):
+				param_ptr = display_update_nat_ipv6_opc(param_ptr, *opc_ptr);
+				break;
+			case UPDATE_SPORT:
+			case UPDATE_DPORT:
+			case (UPDATE_SPORT | UPDATE_DPORT):
+				param_ptr = display_update_nat_port_opc(param_ptr, *opc_ptr);
+				break;
+			case INSERT_L2_HDR:
+				param_ptr = display_l2hdr_insert_opc(param_ptr);
+				break;
+			case INSERT_VLAN_HDR:
+				param_ptr = display_vlanhdr_insert_opc(param_ptr);
+				break;
+			case INSERT_PPPoE_HDR:        
+				param_ptr = display_pppoehdr_insert_opc(param_ptr);
+				break;
+			case INSERT_L3_HDR:
+				param_ptr = display_l3hdr_insert_opc(param_ptr);
+				break;
+			case UPDATE_GLOBAL_STATS:
+				param_ptr = display_upd_glbl_stats_opc(param_ptr);
+				break;
+			default:
+				printk("unknown opcode %d\n", *opc_ptr);
+			break;
+
+		}
+		opc_ptr++;
+	}
+}
+
+static inline void *display_natpt_4to6_opc(void *ptr)
+{
+	struct en_ehash_natpt_hdr *param;
+	uint32_t word;
+	uint32_t hdrlen;
+
+	printk("opcode : NATPT_4to6 - ");
+	param = (struct en_ehash_natpt_hdr *)ptr;
+	word = cpu_to_be32(param->word);
+	hdrlen = ((word >> 16) & 0xff);
+	printk("header length %d\n", hdrlen);
+	if (word & NATPT_TCU)
+		printk("update traffic class from ipv4 header\n");
+	else
+		printk("use traffic class from template\n");
+	if (word & NATPT_HLU)
+		printk("update HOP length from ipv4 header TTL\n");
+	else
+		printk("use HOP length from template\n");
+	disp_buf(&param->l3hdr, hdrlen);	
+	return ((uint8_t *)ptr + sizeof(struct en_ehash_natpt_hdr) + 
+			((word >> 16) & 0xff));
+}
+
+static inline void *display_natpt_6to4_opc(void *ptr)
+{
+	uint32_t word;
+	struct en_ehash_natpt_hdr *param;
+	uint32_t hdrlen;
+
+	printk("opcode : NATPT_6to4 - ");
+	param = (struct en_ehash_natpt_hdr *)ptr;
+	word = cpu_to_be32(param->word);
+	printk("ipident %d\n", (word & 0xffff));
+	hdrlen = ((word >> 16) & 0xff);
+	printk("header length %d\n", hdrlen);
+	if (word & NATPT_IPU)
+		printk("use ipident from template\n");
+	else
+		printk("update ipident from flow\n");
+	
+	if (word & NATPT_TOU)
+		printk("update tos from ipv6 header\n");
+	else
+		printk("use tos from template\n");
+
+	if (word & NATPT_TLU)
+		printk("update ttl value from ipv6 header\n");
+	else
+		printk("use ttl value from template\n");
+	disp_buf(&param->l3hdr, hdrlen);	
+	return ((uint8_t *)ptr + sizeof(struct en_ehash_natpt_hdr) + 
+			((word >> 16) & 0xff));
+}
+
+static inline void display_ehash_tbl_entry(struct en_ehash_entry *entry, uint32_t keysize)
+{
+	uint8_t *opc_ptr;
+	uint8_t *param_ptr;
+	uint64_t addr;
+	uint32_t ii;
+	uint16_t flags;
+
+	printk("entry %p\n", entry);
+	disp_buf(entry, MAX_EN_EHASH_ENTRY_SIZE);
+	flags = cpu_to_be16(entry->flags);
+	opc_ptr = ((uint8_t *)entry + GET_OPC_OFFSET(flags));
+	param_ptr = ((uint8_t *)entry + GET_PARAM_OFFSET(flags));
+	if (GET_TIMESTAMP_ENABLE(flags)) {	
+		printk("external timestamp addr %08x\n",
+			cpu_to_be32(entry->timestamp_counter));
+	} 
+	if (GET_STATS_ENABLE(flags))
+		printk("statistics\tenabled\n");
+	printk("opc offset\t%d\n", GET_OPC_OFFSET(flags));
+	printk("param offset\t%d\n", GET_PARAM_OFFSET(flags));
+	addr = ((uint64_t)entry->next_entry_hi << 32);
+	addr |= entry->next_entry_lo;
+	printk("next_entry\t%p\n", (void *)addr);
+	printk("key :: size %d\n", keysize);
+	disp_buf(&entry->key[0], keysize);
+	for (ii = 0; ii < MAX_OPCODES; ii++) {
+		printk("opc ptr\t%p\n", opc_ptr);
+		printk("param ptr\t%p\n", param_ptr);
+		switch (*opc_ptr) {
+			case 0:
+				printk("end of opcodelist\n");
+				return;
+			case ENQUEUE_PKT:
+				param_ptr = display_enqparams_opc(param_ptr);	
+				return;
+			case REPLICATE_PKT:
+				param_ptr = display_replicate_opc(param_ptr);
+				break;
+			case UPDATE_ETH_RX_STATS:	
+				param_ptr = display_update_eth_rx_stats_opc(param_ptr);	
+				break;
+			case STRIP_ETH_HDR:          
+				param_ptr = display_strip_eth_hdr_opc(param_ptr);
+				break;
+			case STRIP_ALL_VLAN_HDRS:
+				param_ptr = display_strip_allvlan_hdr_opc(param_ptr);
+				break;
+			case STRIP_PPPoE_HDR:
+				param_ptr = display_strip_pppoe_hdr_opc(param_ptr);
+				break;
+			case STRIP_FIRST_VLAN_HDR: 
+				param_ptr = display_strip_firstvlan_opc(param_ptr);
+				break;
+			case REMOVE_FIRST_IP_HDR:
+				param_ptr = display_strip_first_iphdr(param_ptr);
+				break;
+			case VALIDATE_IPSEC_ID:
+				param_ptr = display_validate_ipsecid_opc(param_ptr);
+				break;
+			case UPDATE_TTL:
+				param_ptr = display_ttlupdate_opc(param_ptr);
+				break;
+			case UPDATE_HOPLIMIT:
+				param_ptr = display_hoplupdate_opc(param_ptr);
+				break;
+			case UPDATE_SIP_V4:
+			case (UPDATE_SIP_V4 | UPDATE_TTL):
+			case UPDATE_DIP_V4:
+			case (UPDATE_DIP_V4 | UPDATE_TTL):
+			case (UPDATE_SIP_V4 | UPDATE_DIP_V4):
+			case (UPDATE_SIP_V4 | UPDATE_DIP_V4 | UPDATE_TTL):
+				param_ptr = display_update_nat_ipv4_opc(param_ptr, *opc_ptr);
+				break;
+			case UPDATE_SIP_V6:
+			case (UPDATE_SIP_V6 | UPDATE_HOPLIMIT): 
+			case UPDATE_DIP_V6:
+			case (UPDATE_DIP_V6 | UPDATE_HOPLIMIT):
+			case (UPDATE_SIP_V6 | UPDATE_DIP_V6):
+			case (UPDATE_SIP_V6 | UPDATE_DIP_V6 | UPDATE_HOPLIMIT):
+				param_ptr = display_update_nat_ipv6_opc(param_ptr, *opc_ptr);
+				break;
+			case UPDATE_SPORT:
+			case UPDATE_DPORT:
+			case (UPDATE_SPORT | UPDATE_DPORT):
+				param_ptr = display_update_nat_port_opc(param_ptr, *opc_ptr);
+				break;
+			case INSERT_L2_HDR:
+				param_ptr = display_l2hdr_insert_opc(param_ptr);
+				break;
+			case INSERT_VLAN_HDR:
+				param_ptr = display_vlanhdr_insert_opc(param_ptr);
+				break;
+			case INSERT_PPPoE_HDR:        
+				param_ptr = display_pppoehdr_insert_opc(param_ptr);
+				break;
+			case INSERT_L3_HDR:
+				param_ptr = display_l3hdr_insert_opc(param_ptr);
+				break;
+			case UPDATE_GLOBAL_STATS:
+				param_ptr = display_upd_glbl_stats_opc(param_ptr);
+				break;
+			case NATPT_4to6:
+				param_ptr = display_natpt_4to6_opc(param_ptr);
+				break;
+			case NATPT_6to4:
+				param_ptr = display_natpt_6to4_opc(param_ptr);
+				break;
+			case REPLACE_PPPOE_HDR:
+				param_ptr = display_pppoe_relay_opc(param_ptr);
+				break;
+			case PROCESS_RTP_PAYLOAD:
+				param_ptr = display_rtp_opc(param_ptr);
+				break;
+			case PROCESS_RTCP_PAYLOAD:
+				param_ptr = display_rtcp_opc(param_ptr);
+				break;
+			default:
+				printk("unknown opcode %d\n", *opc_ptr);
+			break;
+
+		}
+		opc_ptr++;
+	}
+}
+
+extern void *ExternalHashTableAllocEntry(void *h_HashTbl);
+extern void ExternalHashTableEntryFree(void *entry);
+extern int ExternalHashTableFmPcdHcSync(void *h_HashTbl);
+
+#endif
diff --git a/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_ext.h b/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_ext.h
index a8a64386cc45..c37f97e4d2d9 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_ext.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_ext.h
@@ -187,6 +187,21 @@ typedef _Packed struct t_FmPrsResult {
                                          FM_FD_ERR_LENGTH               | \
                                          FM_FD_ERR_DMA) /**< TX Error FD bits */
 
+#define FM_RFSDM_DEFAULT		(FM_FD_ERR_DMA |\
+					 FM_FD_ERR_PHYSICAL |\
+					 FM_FD_ERR_SIZE |\
+					 FM_FD_ERR_CLS_DISCARD |\
+					 FM_FD_ERR_EXTRACTION |\
+					 FM_FD_ERR_NO_SCHEME |\
+					 FM_FD_ERR_KEYSIZE_OVERFLOW |\
+					 FM_FD_ERR_ILL_PLCR|\
+					 FM_FD_ERR_PRS_TIMEOUT|\
+					 FM_FD_ERR_PLCR_FRAME_LEN|\
+					 FM_FD_ERR_PRS_ILL_INSTRUCT|\
+					 FM_FD_ERR_PRS_HDR_ERR|\
+					 FM_FD_ERR_BLOCK_LIMIT_EXCEEDED)
+					 
+
 #define FM_FD_RX_STATUS_ERR_MASK        (FM_FD_ERR_UNSUPPORTED_FORMAT   | \
                                          FM_FD_ERR_LENGTH               | \
                                          FM_FD_ERR_DMA                  | \
@@ -1701,6 +1716,38 @@ t_Error FM_SetPortsBandwidth(t_Handle h_Fm, t_FmPortsBandwidthParams *p_PortsBan
 *//***************************************************************************/
 t_Handle FM_GetMuramHandle(t_Handle h_Fm);
 
+/**************************************************************************//*
+ @Function      FM_ReadTimeStamp
+
+ @Description   Reads the FMan engine's timestamp.
+
+ @Param[in]     h_Fm                A handle to an FM Module.
+
+ @Return        The indicated engine's timestamp on success; zero otherwise.
+
+ @Cautions      Allowed only following FM_Init().
+                This routine should NOT be called from guest-partition
+                (i.e. guestId != NCSW_MASTER_ID)
+*//***************************************************************************/
+uint32_t FM_ReadTimeStamp(t_Handle h_Fm);
+
+/**************************************************************************//*
+ @Function      FM_GetTimeStampIncrementPerUsec
+
+ @Description   Provides the value of the FMan engine's timestamp increment
+                per microsecond.
+
+ @Param[in]     h_Fm                A handle to an FM Module.
+
+ @Return        The value the timestamp is incremented with each microsecond
+                on success; zero otherwise.
+
+ @Cautions      Allowed only following FM_Init().
+                This routine should NOT be called from guest-partition
+                (i.e. guestId != NCSW_MASTER_ID)
+*//***************************************************************************/
+uint32_t FM_GetTimeStampIncrementPerUsec(t_Handle h_Fm);
+
 /** @} */ /* end of FM_runtime_control_grp group */
 /** @} */ /* end of FM_lib_grp group */
 /** @} */ /* end of FM_grp group */
diff --git a/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_mac_ext.h b/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_mac_ext.h
index be99b7c9f93b..1fa06b0ea359 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_mac_ext.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_mac_ext.h
@@ -766,6 +766,7 @@ t_Error FM_MAC_RemovelExactMatchMacAddr(t_Handle h_FmMac, t_EnetAddr *p_EnetAddr
  @Cautions      Allowed only after FM_MAC_Init().
 *//***************************************************************************/
 t_Error FM_MAC_SetPromiscuous(t_Handle h_FmMac, bool enable);
+t_Error FM_MAC_SetAllMulti(t_Handle h_FmMac, bool enable);
 
 /**************************************************************************//**
  @Function      FM_MAC_AdjustLink
diff --git a/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_pcd_ext.h b/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_pcd_ext.h
index 8d1c3d889451..5099490bf1ef 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_pcd_ext.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_pcd_ext.h
@@ -44,8 +44,10 @@
 #include "list_ext.h"
 #include "fm_ext.h"
 #include "fsl_fman_kg.h"
+#include "fm_eh_types.h"
 
-
+//use enhanced external hash implementation
+#define USE_ENHANCED_EHASH 1
 /**************************************************************************//**
  @Group         FM_grp Frame Manager API
 
@@ -1718,6 +1720,7 @@ typedef struct t_FmPcdKgSchemeParams {
         uint8_t                         relativeSchemeId;       /**< if modify=FALSE:Partition relative scheme id */
         t_Handle                        h_Scheme;               /**< if modify=TRUE: a handle of the existing scheme */
     } id;
+    bool                                shared;           	/**< This scheme is shared */
     bool                                alwaysDirect;           /**< This scheme is reached only directly, i.e. no need
                                                                      for match vector; KeyGen will ignore it when matching */
     struct {                                                    /**< HL Relevant only if alwaysDirect = FALSE */
@@ -1893,6 +1896,14 @@ typedef struct t_FmPcdCcKeyParams {
     t_FmPcdCcNextEngineParams   ccNextEngineParams;
                                             /**< parameters for the next for the defined Key in
                                                  the p_Key */
+#if 0 // not reqd
+#if (DPAA_VERSION >= 11)
+    uint32_t                   internal_tstamp:1; /* set to use internal FMAN time stamp */
+    uint32_t                   reserved:29;
+    uint32_t                   ext_timer_id:2; /* time stamp timer to use */
+    uintptr_t                  monitorAddr;    
+#endif /* (DPAA_VERSION >= 11) */
+#endif // 0
 } t_FmPcdCcKeyParams;
 
 /**************************************************************************//**
@@ -1979,8 +1990,7 @@ typedef struct t_FmPcdHashTableParams {
     uint16_t                    maxNumOfKeys;               /**< Maximum Number Of Keys that will (ever) be used in this Hash-table */
     e_FmPcdCcStatsMode          statisticsMode;             /**< If not e_FM_PCD_CC_STATS_MODE_NONE, the required structures for the
                                                                  requested statistics mode will be allocated according to maxNumOfKeys. */
-    uint8_t                     kgHashShift;                /**< KG-Hash-shift as it was configured in the KG-scheme
-                                                                 that leads to this hash-table. */
+    uint8_t                     kgHashShift;                /**< Obsolete; will be considered as '0'. */
     uint16_t                    hashResMask;                /**< Mask that will be used on the hash-result;
                                                                  The number-of-sets for this hash will be calculated
                                                                  as (2^(number of bits set in 'hashResMask'));
@@ -1990,7 +2000,34 @@ typedef struct t_FmPcdHashTableParams {
     uint8_t                     matchKeySize;               /**< Size of the exact match keys held by the hash buckets */
 
     t_FmPcdCcNextEngineParams   ccNextEngineParamsForMiss;  /**< Parameters for defining the next engine when a key is not matched */
-
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+    uint32_t    table_type;     /* ip reassembly table */
+    //valid for reassembly tables only
+    struct {
+        uint32_t timeout_val;   //reassembly timeout
+        uint32_t timeout_fqid;  //fqid for reassmebly failures
+        uint32_t max_frags;     //max allowed fragments
+        uint32_t min_frag_size; //min allowed frag size except last frag
+        uint32_t max_sessions;  //max conn reassembly sessions
+    };
+#endif
+#if 0 // not reqd 
+
+    bool                        agingSupport;               /**< TRUE to enable aging support for all keys of this hash table;
+                                                                 Aging status of a key enables the application to monitor if the
+                                                                 key was accessed for a certain period of time, meaning if a
+                                                                 packet that matches this key was received since this bit was last
+                                                                 set by the application */
+#if (DPAA_VERSION >= 11)
+    bool                        externalHash;
+    struct {
+    	uint8_t                 dataMemId;                  /**< Memory partition ID for the external hash table buckets and contexts;
+    	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 Must not cross the 4GB boundaries*/
+        uint16_t                dataLiodnOffset;            /**< LIODN offset for access the external hash table buckets and contexts */
+        uintptr_t               missMonitorAddr;            /**< TODO */
+    } externalHashParams;
+#endif /* (DPAA_VERSION >= 11) */
+#endif // 0
 } t_FmPcdHashTableParams;
 
 /**************************************************************************//**
@@ -3551,8 +3588,7 @@ t_Error FM_PCD_MatchTableGetNextEngine(t_Handle                     h_CcNode,
  @Param[in]     p_KgKey                 Pointer to the key; must be like the key
                                         that the KG is generated, i.e. the same
                                         extraction and with mask if exist.
- @Param[in]     kgHashShift             Hash-shift as it was configured in the KG
-                                        scheme that leads to this hash.
+ @Param[in]     kgHashShift             Obsolete; will be considered as '0'
  @Param[out]    p_CcNodeBucketHandle    Pointer to the bucket of the provided key.
  @Param[out]    p_BucketIndex           Index to the bucket of the provided key
  @Param[out]    p_LastIndex             Pointer to last index in the bucket of the
@@ -3634,6 +3670,7 @@ t_Error FM_PCD_HashTableAddKey(t_Handle            h_HashTbl,
                                uint8_t             keySize,
                                t_FmPcdCcKeyParams  *p_KeyParams);
 
+#ifndef USE_ENHANCED_EHASH
 /**************************************************************************//**
  @Function      FM_PCD_HashTableRemoveKey
 
@@ -3651,7 +3688,6 @@ t_Error FM_PCD_HashTableAddKey(t_Handle            h_HashTbl,
 t_Error FM_PCD_HashTableRemoveKey(t_Handle h_HashTbl,
                                   uint8_t  keySize,
                                   uint8_t  *p_Key);
-
 /**************************************************************************//**
  @Function      FM_PCD_HashTableModifyNextEngine
 
@@ -3675,6 +3711,7 @@ t_Error FM_PCD_HashTableModifyNextEngine(t_Handle                  h_HashTbl,
                                          uint8_t                   keySize,
                                          uint8_t                   *p_Key,
                                          t_FmPcdCcNextEngineParams *p_FmPcdCcNextEngineParams);
+#endif  // USE_ENHANCED_EHASH
 
 /**************************************************************************//**
  @Function      FM_PCD_HashTableModifyMissNextEngine
@@ -3711,6 +3748,21 @@ t_Error FM_PCD_HashTableModifyMissNextEngine(t_Handle                  h_HashTbl
 t_Error FM_PCD_HashTableGetMissNextEngine(t_Handle                     h_HashTbl,
                                           t_FmPcdCcNextEngineParams    *p_FmPcdCcNextEngineParams);
 
+/**************************************************************************//*
+ @Function      FM_PCD_HashTableModifyMissMonitorAddr
+
+ @Description   Modifies the miss monitor address.
+
+ @Param[in]     h_HashTbl                   A handle to a hash table
+ @Param[out]    monitorAddr   				Miss monitor address to be modified
+
+ @Return        E_OK on success; Error code otherwise.
+
+ @Cautions      Allowed only following FM_PCD_HashTableSet().
+*//***************************************************************************/
+t_Error FM_PCD_HashTableModifyMissMonitorAddr(t_Handle h_HashTbl,
+        									  uintptr_t monitorAddr);
+
 /**************************************************************************//**
  @Function      FM_PCD_HashTableFindNGetKeyStatistics
 
@@ -3764,6 +3816,75 @@ t_Error FM_PCD_HashTableFindNGetKeyStatistics(t_Handle                 h_HashTbl
 t_Error FM_PCD_HashTableGetMissStatistics(t_Handle                 h_HashTbl,
                                           t_FmPcdCcKeyStatistics   *p_MissStatistics);
 
+/**************************************************************************//**
+@Function      FM_PCD_HashTableGetKeyAging
+
+@Description   This routine may be used to retrieve the aging status for the
+               provided key.
+
+@Param[in]     h_HashTbl       A handle to a hash table
+@Param[in]     p_Key           Pointer to a key
+@Param[in]     keySize         Size of provided key
+@Param[in]     reset           TRUE if the user wishes to reset the aging
+                               status of this key to 1 after reading it;
+                               FALSE otherwise (key aging status will be
+                               read and not changed);
+@Param[out]    p_KeyAging      FALSE if the provided key was accessed since
+                               it's status was last set, TRUE otherwise.
+
+@Return        E_OK on success; Error code otherwise.
+
+@Cautions      Allowed only following FM_PCD_HashTableSet() with aging support
+               enabled.
+*//***************************************************************************/
+t_Error FM_PCD_HashTableGetKeyAging(t_Handle h_HashTbl,
+                                    uint8_t *p_Key,
+                                    uint8_t keySize,
+                                    bool reset,
+                                    bool *p_KeyAging);
+
+/**************************************************************************//**
+@Function      FM_PCD_HashTableGetBucketAging
+
+@Description   This routine may be used to retrieve the aging status for the
+               hash table bucket.
+
+@Param[in]     h_HashTbl            A handle to a hash table
+@Param[in]     bucketId             Id of the requested bucket
+@Param[in]     reset                TRUE if the user wishes to reset the aging
+                                    status of this bucket to all 1-s after reading;
+                                    FALSE otherwise (aging mask will be read
+                                    and not changed)
+@Param[out]    p_BucketAgingMask    Aging mask of the requested bucket;
+                                    A zero bit in the mask means that the key
+                                    represented by that bit was accessed since the
+                                    bit was last set, otherwise the bit remains
+                                    set to 1;
+                                    The MSB bit represents the first key in the
+                                    bucket, the 2nd MSB bit represents the second
+                                    key, etc..
+@Param[out]    agedKeysArray        If the user will provide a handle to a
+                                    preallocated array, this routine will copy
+                                    into that array all the keys from the requested
+                                    bucket for which the aging status is non-zero,
+                                    meaning all the keys that were not accessed since
+                                    their aging mask was last set;
+                                    The user may set this parameters to NULL to
+                                    disable this option
+
+@Return        E_OK on success; Error code otherwise
+
+@Cautions      Allowed only following FM_PCD_HashTableSet() with aging support
+               Enabled;
+               If 'agedKeysArray' is provided, it must have 31 entries large enough
+               to hold the entire keys
+*//***************************************************************************/
+t_Error FM_PCD_HashTableGetBucketAging(t_Handle h_HashTbl,
+                                       uint16_t bucketId,
+                                       bool reset,
+                                       uint32_t *p_BucketAgingMask,
+                                       uint8_t *agedKeysArray[31]);
+
 /**************************************************************************//**
  @Function      FM_PCD_ManipNodeSet
 
@@ -3970,5 +4091,28 @@ t_Handle FM_PCD_StatisticsSetNode(t_Handle h_FmPcd, t_FmPcdStatsParams *p_FmPcds
     FM_PCD_ManipNodeDelete(__VA_ARGS__)
 #endif /* NCSW_BACKWARD_COMPATIBLE_API */
 
+//external hash table time stamp options
+#define MAX_EXT_TS_TIMERS       4
+#define EXT_TS_TYPE             uint32_t
+#define EXT_TS_SIZE             sizeof(EXT_TS_TYPE)
+struct ext_hash_ts_info {
+        uint32_t max_ext_ts_timers;
+        void *ptr;
+        uint32_t offset;
+};
+#define FM_PCD_UpdateExtTimeStamp(id, val) \
+{\
+        *((EXT_TS_TYPE *)extHashTsInfo.ptr + id) = (EXT_TS_TYPE)val;\
+}
+#define FM_PCD_GetExtTimeStampAddr(id) \
+	(extHashTsInfo.offset + (id * EXT_TS_SIZE))
+
+#define FM_PCD_GetExtTsRef(id)\
+        (extHashTsInfo.offset + (id * EXT_TS_SIZE))
+extern struct ext_hash_ts_info extHashTsInfo;
+
+
+
+
 
 #endif /* __FM_PCD_EXT */
diff --git a/drivers/net/ethernet/freescale/sdk_fman/inc/flib/fsl_fman.h b/drivers/net/ethernet/freescale/sdk_fman/inc/flib/fsl_fman.h
index 96a63fa7f283..96f7ab2745ab 100755
--- a/drivers/net/ethernet/freescale/sdk_fman/inc/flib/fsl_fman.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/inc/flib/fsl_fman.h
@@ -35,6 +35,7 @@
 
 #include "common/general.h"
 
+//#define AUTO_FIRMWARE_LOAD 1  // currently flash the bin file
 struct fman_ext_pool_params {
 	uint8_t                 id;    /**< External buffer pool id */
 	uint16_t                size;  /**< External buffer pool buffer size */
diff --git a/drivers/net/ethernet/freescale/sdk_fman/src/inc/wrapper/lnxwrp_exp_sym.h b/drivers/net/ethernet/freescale/sdk_fman/src/inc/wrapper/lnxwrp_exp_sym.h
index dd0f03acfc9c..cb93821472b1 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/src/inc/wrapper/lnxwrp_exp_sym.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/src/inc/wrapper/lnxwrp_exp_sym.h
@@ -90,15 +90,18 @@ EXPORT_SYMBOL(FM_PCD_MatchTableGetKeyCounter);
 EXPORT_SYMBOL(FM_PCD_MatchTableGetKeyStatistics);
 EXPORT_SYMBOL(FM_PCD_MatchTableFindNGetKeyStatistics);
 EXPORT_SYMBOL(FM_PCD_MatchTableGetMissStatistics);
-EXPORT_SYMBOL(FM_PCD_HashTableGetMissStatistics);
 EXPORT_SYMBOL(FM_PCD_HashTableSet);
-EXPORT_SYMBOL(FM_PCD_HashTableDelete);
 EXPORT_SYMBOL(FM_PCD_HashTableAddKey);
+#ifndef USE_ENHANCED_EHASH
+EXPORT_SYMBOL(FM_PCD_HashTableDelete);
+EXPORT_SYMBOL(FM_PCD_HashTableGetMissStatistics);
 EXPORT_SYMBOL(FM_PCD_HashTableRemoveKey);
+EXPORT_SYMBOL(FM_PCD_HashTableFindNGetKeyStatistics);
 EXPORT_SYMBOL(FM_PCD_HashTableModifyNextEngine);
-EXPORT_SYMBOL(FM_PCD_HashTableModifyMissNextEngine);
 EXPORT_SYMBOL(FM_PCD_HashTableGetMissNextEngine);
-EXPORT_SYMBOL(FM_PCD_HashTableFindNGetKeyStatistics);
+EXPORT_SYMBOL(FM_PCD_HashTableModifyMissMonitorAddr);
+#endif //USE_ENHANCED_EHASH
+EXPORT_SYMBOL(FM_PCD_HashTableModifyMissNextEngine);
 EXPORT_SYMBOL(FM_PCD_PlcrProfileSet);
 EXPORT_SYMBOL(FM_PCD_PlcrProfileDelete);
 EXPORT_SYMBOL(FM_PCD_PlcrProfileGetCounter);
diff --git a/drivers/net/ethernet/freescale/sdk_fman/src/inc/wrapper/lnxwrp_fsl_fman.h b/drivers/net/ethernet/freescale/sdk_fman/src/inc/wrapper/lnxwrp_fsl_fman.h
index c50031cfd032..f98720911251 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/src/inc/wrapper/lnxwrp_fsl_fman.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/src/inc/wrapper/lnxwrp_fsl_fman.h
@@ -769,6 +769,8 @@ int fm_mac_resume(struct fm_mac_dev *fm_mac_dev);
 
 int fm_mac_set_promiscuous(struct fm_mac_dev *fm_mac_dev,
 		bool enable);
+int fm_mac_set_allmulti(struct fm_mac_dev *fm_mac_dev,
+		bool enable);
 
 int fm_mac_remove_hash_mac_addr(struct fm_mac_dev *fm_mac_dev,
 		t_EnetAddr *mac_addr);
diff --git a/drivers/net/ethernet/freescale/sdk_fman/src/system/sys_io.c b/drivers/net/ethernet/freescale/sdk_fman/src/system/sys_io.c
index c106a8b7b208..8d447afb58e8 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/src/system/sys_io.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/src/system/sys_io.c
@@ -156,6 +156,9 @@ uint64_t SYS_PhysToVirt(uint64_t addr)
     }
     return PTR_TO_UINT(phys_to_virt((unsigned long)addr));
 }
+#ifdef CONFIG_DBG_UCODE_INFRA 
+EXPORT_SYMBOL(SYS_PhysToVirt);
+#endif // CONFIG_DBG_UCODE_INFRA
 
 uint64_t SYS_VirtToPhys(uint64_t addr)
 {
@@ -169,3 +172,4 @@ uint64_t SYS_VirtToPhys(uint64_t addr)
         return (uint64_t)(addr - p_IoMap->virtAddr + p_IoMap->physAddr);
     return (uint64_t)virt_to_phys(UINT_TO_PTR(addr));
 }
+EXPORT_SYMBOL(SYS_VirtToPhys);
diff --git a/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_fm.c b/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_fm.c
index 31f654b4c617..0f47eb2bbb60 100755
--- a/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_fm.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_fm.c
@@ -1846,12 +1846,28 @@ int fm_mac_resume(struct fm_mac_dev *fm_mac_dev)
 }
 EXPORT_SYMBOL(fm_mac_resume);
 
+int fm_mac_set_allmulti(struct fm_mac_dev *fm_mac_dev,
+		bool enable)
+{
+	int	_errno;
+	t_Error	err;
+
+	err = FM_MAC_SetAllMulti(fm_mac_dev, enable);
+	_errno = -GET_ERROR_TYPE(err);
+	if (unlikely(_errno < 0))
+		pr_err("FM_MAC_SetPromiscuous() = 0x%08x\n", err);
+
+	return _errno;
+}
+EXPORT_SYMBOL(fm_mac_set_allmulti);
+
 int fm_mac_set_promiscuous(struct fm_mac_dev *fm_mac_dev,
 		bool enable)
 {
 	int	_errno;
 	t_Error	err;
 
+        printk("%s::%d \r\n", __FUNCTION__, __LINE__);
 	err = FM_MAC_SetPromiscuous(fm_mac_dev, enable);
 	_errno = -GET_ERROR_TYPE(err);
 	if (unlikely(_errno < 0))
diff --git a/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_fm_port.c b/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_fm_port.c
index 00ab4bcbb5fb..1c5738ed1612 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_fm_port.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_fm_port.c
@@ -919,11 +919,10 @@ static t_Error InitFmPortDev(t_LnxWrpFmPortDev *p_LnxWrpFmPortDev)
 
 
     if ((p_LnxWrpFmPortDev->settings.param.portType != e_FM_PORT_TYPE_TX) &&
-        (p_LnxWrpFmPortDev->settings.param.portType != e_FM_PORT_TYPE_TX_10G)) {
-            if (FM_PORT_ConfigErrorsToDiscard(p_LnxWrpFmPortDev->h_Dev, (FM_PORT_FRM_ERR_IPRE |
-                                                                         FM_PORT_FRM_ERR_IPR_NCSP |
-                                                                         FM_PORT_FRM_ERR_CLS_DISCARD)) !=E_OK)
-            RETURN_ERROR(MAJOR, E_INVALID_STATE, NO_MSG);
+        (p_LnxWrpFmPortDev->settings.param.portType != e_FM_PORT_TYPE_TX_10G)) { 
+            /*(FM_PORT_FRM_ERR_IPRE | FM_PORT_FRM_ERR_IPR_NCSP | FM_PORT_FRM_ERR_CLS_DISCARD*/
+            if (FM_PORT_ConfigErrorsToDiscard(p_LnxWrpFmPortDev->h_Dev, FM_RFSDM_DEFAULT) != E_OK)
+            	RETURN_ERROR(MAJOR, E_INVALID_STATE, NO_MSG);
     }
 
     if (CheckNConfigFmPortAdvArgs(p_LnxWrpFmPortDev) != E_OK)
diff --git a/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_ioctls_fm.c b/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_ioctls_fm.c
index 06833ba89e05..743582ad2c2e 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_ioctls_fm.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_ioctls_fm.c
@@ -2211,6 +2211,11 @@ Status: feature not supported
 #endif
         case FM_PCD_IOC_HASH_TABLE_GET_MISS_STAT:
         {
+#ifdef USE_ENHANCED_EHASH
+            RETURN_ERROR(MINOR, E_INVALID_SELECTION,
+                ("invalid ioctl: cmd:0x%08x(type:0x%02x, nr: %d.\n",
+                cmd, _IOC_TYPE(cmd), _IOC_NR(cmd)));
+#else
             ioc_fm_pcd_cc_tbl_get_stats_t param;
 
 #if defined(CONFIG_COMPAT)
@@ -2276,7 +2281,7 @@ Status: feature not supported
                                   sizeof(ioc_fm_pcd_cc_tbl_get_stats_t)))
                     RETURN_ERROR(MINOR, E_READ_FAILED, NO_MSG);
             }
-
+#endif //USE_ENHANCED_EHASH
             break;
         }
       
@@ -2384,6 +2389,11 @@ Status: feature not supported
 #endif
         case FM_PCD_IOC_HASH_TABLE_DELETE:
         {
+#ifdef USE_ENHANCED_EHASH
+            RETURN_ERROR(MINOR, E_INVALID_SELECTION,
+                ("invalid ioctl: cmd:0x%08x(type:0x%02x, nr: %d.\n",
+                cmd, _IOC_TYPE(cmd), _IOC_NR(cmd)));
+#else
             ioc_fm_obj_t id;
 
             memset(&id, 0, sizeof(ioc_fm_obj_t));
@@ -2406,6 +2416,7 @@ Status: feature not supported
             }
 
             err = FM_PCD_HashTableDelete(id.obj);
+#endif  // USE_ENHANCED_EHASH
             break;
         }
 
@@ -2535,6 +2546,11 @@ Status: feature not supported
 #endif
         case FM_PCD_IOC_HASH_TABLE_REMOVE_KEY:
         {
+#ifdef USE_ENHANCED_EHASH
+            RETURN_ERROR(MINOR, E_INVALID_SELECTION,
+                ("invalid ioctl: cmd:0x%08x(type:0x%02x, nr: %d.\n",
+                cmd, _IOC_TYPE(cmd), _IOC_NR(cmd)));
+#else
             ioc_fm_pcd_hash_table_remove_key_params_t *param = NULL;
 
             param = (ioc_fm_pcd_hash_table_remove_key_params_t*) XX_Malloc(
@@ -2611,6 +2627,7 @@ Status: feature not supported
             if (param->p_key)
                 XX_Free(param->p_key);
             XX_Free(param);
+#endif // USE_ENHANCED_EHASH
             break;
         }
 
@@ -3705,6 +3722,30 @@ t_Error LnxwrpFmIOCTL(t_LnxWrpFmDev *p_LnxWrpFmDev, unsigned int cmd, unsigned l
         }
         break;
 
+        case FM_IOC_READ_TIMESTAMP:
+        {
+            uint32_t ts;
+
+            ts = FM_ReadTimeStamp(p_LnxWrpFmDev->h_Dev);
+
+            if (copy_to_user((uint32_t *)arg, &ts, sizeof(uint32_t)))
+                err = E_READ_FAILED;
+
+        }
+        break;
+
+        case FM_IOC_GET_TIMESTAMP_INCREMENT:
+        {
+            uint32_t ts_inc;
+
+            ts_inc = FM_GetTimeStampIncrementPerUsec(p_LnxWrpFmDev->h_Dev);
+
+            if (copy_to_user((uint32_t *)arg, &ts_inc, sizeof(uint32_t)))
+                err = E_READ_FAILED;
+
+        }
+        break;
+
         default:
             return LnxwrpFmPcdIOCTL(p_LnxWrpFmDev, cmd, arg, compat);
     }
diff --git a/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_ioctls_fm_compat.h b/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_ioctls_fm_compat.h
index 187011f7ee5a..cf3d26b3cb69 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_ioctls_fm_compat.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_ioctls_fm_compat.h
@@ -265,6 +265,7 @@ typedef struct ioc_compat_fm_pcd_cc_key_params_t {
     compat_uptr_t                              p_key;
     compat_uptr_t                              p_mask;
     ioc_compat_fm_pcd_cc_next_engine_params_t  cc_next_engine_params; /**< compat structure*/
+	compat_uptr_t				monitor_addr;
 } ioc_compat_fm_pcd_cc_key_params_t;
 
 typedef struct ioc_compat_keys_params_t {
@@ -297,6 +298,13 @@ typedef struct ioc_compat_fm_pcd_hash_table_params_t {
     uint8_t                     hash_shift;
     uint8_t                     match_key_size;
     ioc_compat_fm_pcd_cc_next_engine_params_t   cc_next_engine_params_for_miss;
+	bool			aging_support;
+	bool			external_hash;
+	struct {
+		uint8_t		data_mem_id;
+		uint16_t	data_liodn_offs;
+		compat_uptr_t	miss_monitor_addr;
+	} external_hash_params;
     compat_uptr_t               id;
 } ioc_compat_fm_pcd_hash_table_params_t;
 
diff --git a/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_sysfs_fm.c b/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_sysfs_fm.c
index 1badbf984690..df1153a8780e 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_sysfs_fm.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_sysfs_fm.c
@@ -46,7 +46,12 @@
 #include "../../sdk_fman/Peripherals/FM/fm.h"
 #include <linux/delay.h>
 
-
+static ssize_t show_fm_dma_cmd_queue(struct device *dev,
+                                struct device_attribute *attr,
+                                char *buf);
+static ssize_t show_fm_dma_cam_queue(struct device *dev,
+                                struct device_attribute *attr,
+                                char *buf);
 static int fm_get_counter(void *h_fm, e_FmCounters cnt_e, uint32_t *cnt_val);
 
 enum fm_dma_match_stats {
@@ -806,6 +811,23 @@ static DEVICE_ATTR(scheme_29, S_IRUGO, show_fm_schemes, NULL);
 static DEVICE_ATTR(scheme_30, S_IRUGO, show_fm_schemes, NULL);
 static DEVICE_ATTR(scheme_31, S_IRUGO, show_fm_schemes, NULL);
 
+static DEVICE_ATTR(fm_dma_cmdq_0, S_IRUGO, show_fm_dma_cmd_queue, NULL);
+static DEVICE_ATTR(fm_dma_cmdq_8, S_IRUGO, show_fm_dma_cmd_queue, NULL);
+static DEVICE_ATTR(fm_dma_cmdq_16, S_IRUGO, show_fm_dma_cmd_queue, NULL);
+static DEVICE_ATTR(fm_dma_cmdq_24, S_IRUGO, show_fm_dma_cmd_queue, NULL);
+static DEVICE_ATTR(fm_dma_cmdq_32, S_IRUGO, show_fm_dma_cmd_queue, NULL);
+static DEVICE_ATTR(fm_dma_cmdq_40, S_IRUGO, show_fm_dma_cmd_queue, NULL);
+static DEVICE_ATTR(fm_dma_cmdq_48, S_IRUGO, show_fm_dma_cmd_queue, NULL);
+static DEVICE_ATTR(fm_dma_cmdq_56, S_IRUGO, show_fm_dma_cmd_queue, NULL);
+
+static DEVICE_ATTR(fm_dma_camq_0, S_IRUGO, show_fm_dma_cam_queue, NULL);
+static DEVICE_ATTR(fm_dma_camq_8, S_IRUGO, show_fm_dma_cam_queue, NULL);
+static DEVICE_ATTR(fm_dma_camq_16, S_IRUGO, show_fm_dma_cam_queue, NULL);
+static DEVICE_ATTR(fm_dma_camq_24, S_IRUGO, show_fm_dma_cam_queue, NULL);
+static DEVICE_ATTR(fm_dma_camq_32, S_IRUGO, show_fm_dma_cam_queue, NULL);
+static DEVICE_ATTR(fm_dma_camq_40, S_IRUGO, show_fm_dma_cam_queue, NULL);
+static DEVICE_ATTR(fm_dma_camq_48, S_IRUGO, show_fm_dma_cam_queue, NULL);
+static DEVICE_ATTR(fm_dma_camq_56, S_IRUGO, show_fm_dma_cam_queue, NULL);
 
 static struct attribute *fm_dev_stats_attributes[] = {
 	&dev_attr_enq_total_frame.attr,
@@ -970,6 +992,43 @@ static struct attribute *fm_dev_schemes_attributes[] = {
 	NULL
 };
 
+static struct attribute *fm_dma_cmdq_attributes[] = {
+	&dev_attr_fm_dma_cmdq_0.attr,
+	&dev_attr_fm_dma_cmdq_8.attr,
+	&dev_attr_fm_dma_cmdq_16.attr,
+	&dev_attr_fm_dma_cmdq_24.attr,
+	&dev_attr_fm_dma_cmdq_32.attr,
+	&dev_attr_fm_dma_cmdq_40.attr,
+	&dev_attr_fm_dma_cmdq_48.attr,
+	&dev_attr_fm_dma_cmdq_56.attr,
+	NULL
+};
+
+
+static struct attribute *fm_dma_camq_attributes[] = {
+        &dev_attr_fm_dma_camq_0.attr,
+        &dev_attr_fm_dma_camq_8.attr,
+        &dev_attr_fm_dma_camq_16.attr,
+        &dev_attr_fm_dma_camq_24.attr,
+        &dev_attr_fm_dma_camq_32.attr,
+        &dev_attr_fm_dma_camq_40.attr,
+        &dev_attr_fm_dma_camq_48.attr,
+        &dev_attr_fm_dma_camq_56.attr,
+        NULL
+};
+
+
+
+static const struct attribute_group fm_dev_fm_dma_cmdq_grp = {
+	.name = "fm_dma_cmdq",
+	.attrs = fm_dma_cmdq_attributes
+};
+
+static const struct attribute_group fm_dev_fm_dma_camq_grp = {
+	.name = "fm_dma_camq",
+	.attrs = fm_dma_camq_attributes
+};
+
 static const struct attribute_group fm_dev_stats_attr_grp = {
 	.name = "statistics",
 	.attrs = fm_dev_stats_attributes
@@ -995,6 +1054,130 @@ static const struct attribute_group fm_dev_profiles_attr_grp = {
 	.attrs = fm_dev_profiles_attributes
 };
 
+#define MAX_CMD_QUE_DMP_COUNT        8
+#define QT_CMD_QUEUE_ENTRY           (1 << 16)
+#define QT_CAM_QUEUE_ENTRY           (2 << 16)
+int fm_dump_ccqueue(void *h_fm, char *buf, int nn, uint32_t start, uint32_t type)
+{
+	t_Fm            *p_Fm = (t_Fm *)h_fm;
+        uint8_t         i = 0;
+        int             n = nn;
+
+	FM_DMP_SUBTITLE(buf, n, "\n");
+	if (type == QT_CMD_QUEUE_ENTRY) {
+		FM_DMP_TITLE(buf, n, NULL, "FMDM cmd queue %d - %d", start, (start + MAX_CMD_QUE_DMP_COUNT - 1));
+	} else {
+		FM_DMP_TITLE(buf, n, NULL, "FMDM cam queue %d - %d", start, (start + MAX_CMD_QUE_DMP_COUNT - 1));
+	}
+	for (i = start; i < (start + MAX_CMD_QUE_DMP_COUNT); i++) {
+                uint32_t tmp;
+                tmp = (type | i);
+                iowrite32be(tmp, &p_Fm->p_FmDmaRegs->fmdmccqdr);
+                FM_DMP_V32(buf, n, p_Fm->p_FmDmaRegs, fmdmccqdr);
+                FM_DMP_V32(buf, n, p_Fm->p_FmDmaRegs, fmdmccqvr1);
+                FM_DMP_V32(buf, n, p_Fm->p_FmDmaRegs, fmdmccqvr2);
+                FM_DMP_V32(buf, n, p_Fm->p_FmDmaRegs, fmdmcqvr3);
+                FM_DMP_V32(buf, n, p_Fm->p_FmDmaRegs, fmdmcqvr4);
+                FM_DMP_V32(buf, n, p_Fm->p_FmDmaRegs, fmdmcqvr5);
+                FM_DMP_LN(buf, n, "\n");
+        }
+        FM_DMP_LN(buf, n, "\n");
+	return n;
+}
+
+
+static ssize_t show_fm_dma_cam_queue(struct device *dev,
+                                struct device_attribute *attr,
+                                char *buf)
+{
+	unsigned long flags;
+	unsigned n = 0;	
+	int start;
+
+#if (defined(DEBUG_ERRORS) && (DEBUG_ERRORS > 0))
+	t_LnxWrpFmDev *p_wrp_fm_dev = NULL;
+#endif
+	if (attr == NULL || buf == NULL || dev == NULL)
+		return -EINVAL;
+
+#if (defined(DEBUG_ERRORS) && (DEBUG_ERRORS > 0))
+
+	p_wrp_fm_dev = (t_LnxWrpFmDev *) dev_get_drvdata(dev);
+	if (WARN_ON(p_wrp_fm_dev == NULL))
+		return -EINVAL;
+
+	local_irq_save(flags);
+
+	n = snprintf(buf, PAGE_SIZE, "FM DMA CAM queue dump.\n");
+
+	if (!p_wrp_fm_dev->active || !p_wrp_fm_dev->h_Dev)
+		return -EIO;
+
+	if (!sscanf(attr->attr.name, "fm_dma_camq_%d", &start))
+                        return -EINVAL;
+
+	n = fm_dump_ccqueue(p_wrp_fm_dev->h_Dev, buf, n,
+			start, QT_CAM_QUEUE_ENTRY);
+
+	local_irq_restore(flags);
+#else
+
+	local_irq_save(flags);
+	n = snprintf(buf, PAGE_SIZE,
+			"Debug level is too low to dump registers!!!\n");
+	local_irq_restore(flags);
+#endif /* (defined(DEBUG_ERRORS) && ... */
+
+	return n;
+}
+
+static ssize_t show_fm_dma_cmd_queue(struct device *dev,
+                                struct device_attribute *attr,
+                                char *buf)
+{
+	unsigned long flags;
+	unsigned n = 0;	
+	int start;
+
+#if (defined(DEBUG_ERRORS) && (DEBUG_ERRORS > 0))
+	t_LnxWrpFmDev *p_wrp_fm_dev = NULL;
+#endif
+	if (attr == NULL || buf == NULL || dev == NULL)
+		return -EINVAL;
+
+#if (defined(DEBUG_ERRORS) && (DEBUG_ERRORS > 0))
+
+	p_wrp_fm_dev = (t_LnxWrpFmDev *) dev_get_drvdata(dev);
+	if (WARN_ON(p_wrp_fm_dev == NULL))
+		return -EINVAL;
+
+	local_irq_save(flags);
+
+	n = snprintf(buf, PAGE_SIZE, "FM DMA CMD queue dump.\n");
+
+	if (!p_wrp_fm_dev->active || !p_wrp_fm_dev->h_Dev)
+		return -EIO;
+
+	if (!sscanf(attr->attr.name, "fm_dma_cmdq_%d", &start))
+                        return -EINVAL;
+
+	n = fm_dump_ccqueue(p_wrp_fm_dev->h_Dev, buf, n,
+			start, QT_CMD_QUEUE_ENTRY);
+
+	local_irq_restore(flags);
+#else
+
+	local_irq_save(flags);
+	n = snprintf(buf, PAGE_SIZE,
+			"Debug level is too low to dump registers!!!\n");
+	local_irq_restore(flags);
+#endif /* (defined(DEBUG_ERRORS) && ... */
+
+	return n;
+}
+
+
+
 static ssize_t show_fm_regs(struct device *dev,
 				struct device_attribute *attr,
 				char *buf)
@@ -1278,6 +1461,12 @@ int fm_sysfs_create(struct device *dev)
 	if (sysfs_create_group(&dev->kobj, &fm_dev_cls_plans_attr_grp) != 0)
 		return -EIO;
 
+	if (sysfs_create_group(&dev->kobj, &fm_dev_fm_dma_cmdq_grp) != 0)
+		return -EIO;
+
+	if (sysfs_create_group(&dev->kobj, &fm_dev_fm_dma_camq_grp) != 0)
+		return -EIO;
+
 	/* Registers dump entry - in future will be moved to debugfs */
 	if (device_create_file(dev, &dev_attr_fm_regs) != 0)
 		return -EIO;
diff --git a/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_sysfs_fm_port.c b/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_sysfs_fm_port.c
index db8e824c71e7..9735b87488b8 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_sysfs_fm_port.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_sysfs_fm_port.c
@@ -1130,6 +1130,9 @@ int fm_port_dump_regs_bmi(void *h_dev, char *buf, int nn)
 		FM_DMP_V32(buf, n, &p_bmi->rxPortBmiRegs, fmbm_rfpne);
 		FM_DMP_V32(buf, n, &p_bmi->rxPortBmiRegs, fmbm_rpso);
 		FM_DMP_V32(buf, n, &p_bmi->rxPortBmiRegs, fmbm_rpp);
+#ifdef USE_ENHANCED_EHASH
+		FM_DMP_V32(buf, n, &p_bmi->rxPortBmiRegs, fmbm_rccb); 
+#endif
 		FM_DMP_TITLE(buf, n, &(p_bmi->rxPortBmiRegs.fmbm_rprai),
 			"fmbm_rprai");
 		for (i = 0; i < FM_PORT_PRS_RESULT_NUM_OF_WORDS; ++i) {
diff --git a/drivers/net/ethernet/freescale/sdk_fman/src/xx/xx_arm_linux.c b/drivers/net/ethernet/freescale/sdk_fman/src/xx/xx_arm_linux.c
index dd3e376e96af..0e85689d4571 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/src/xx/xx_arm_linux.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/src/xx/xx_arm_linux.c
@@ -325,11 +325,18 @@ void * XX_MallocSmart(uint32_t size, int memPartitionId, uint32_t alignment)
     return xx_MallocSmart(size,memPartitionId, alignment);
 }
 
+#ifdef CONFIG_DBG_UCODE_INFRA 
+EXPORT_SYMBOL(XX_MallocSmart);
+#endif // CONFIG_DBG_UCODE_INFRA
+
 void XX_FreeSmart(void *p)
 {
     xx_FreeSmart(p);
 }
 
+#ifdef CONFIG_DBG_UCODE_INFRA 
+EXPORT_SYMBOL(XX_FreeSmart);
+#endif // CONFIG_DBG_UCODE_INFRA
 
 void XX_Free(void *p)
 {
diff --git a/drivers/net/ppp/ppp_generic.c b/drivers/net/ppp/ppp_generic.c
index 8c6b8918ec31..b189691133dc 100644
--- a/drivers/net/ppp/ppp_generic.c
+++ b/drivers/net/ppp/ppp_generic.c
@@ -55,6 +55,9 @@
 #include <linux/nsproxy.h>
 #include <net/net_namespace.h>
 #include <net/netns/generic.h>
+#if defined(CONFIG_CPE_FAST_PATH)
+#include <linux/jiffies.h>
+#endif
 
 #define PPP_VERSION	"2.4.2"
 
@@ -588,6 +591,9 @@ static long ppp_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
 	struct ppp *ppp;
 	int err = -EFAULT, val, val2, i;
 	struct ppp_idle idle;
+#if defined(CONFIG_CPE_FAST_PATH)
+        struct ppp_idle fppidle;
+#endif
 	struct npioctl npi;
 	int unit, cflags;
 	struct slcompress *vj;
@@ -772,6 +778,30 @@ static long ppp_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
 		err = 0;
 		break;
 
+#if defined(CONFIG_CPE_FAST_PATH)
+	case PPPIOCSFPPIDLE:
+		if (copy_from_user(&fppidle, argp, sizeof(fppidle)))
+			break;
+
+		ppp_xmit_lock(ppp);
+
+		if (time_after((jiffies - (fppidle.xmit_idle * HZ)) , ppp->last_xmit))
+			ppp->last_xmit = (jiffies - fppidle.xmit_idle * HZ);
+
+		ppp_xmit_unlock(ppp);
+
+		ppp_recv_lock(ppp);
+
+		if (time_after((jiffies - (fppidle.recv_idle * HZ)) , ppp->last_recv))
+			ppp->last_recv = (jiffies - fppidle.recv_idle * HZ);
+
+		ppp_recv_unlock(ppp);
+
+		err = 0;
+		break;
+#endif
+
+
 #ifdef CONFIG_PPP_FILTER
 	case PPPIOCSPASS:
 	{
@@ -3154,8 +3184,15 @@ ppp_connect_channel(struct channel *pch, int unit)
 		goto out;
 	write_lock_bh(&pch->upl);
 	ret = -EINVAL;
+#if defined(CONFIG_CPE_FAST_PATH)
+	if (pch->ppp) {
+		write_unlock_bh(&pch->upl);
+		goto out;
+	}
+#else
 	if (pch->ppp)
 		goto outl;
+#endif
 
 	ppp_lock(ppp);
 	if (pch->file.hdrlen > ppp->file.hdrlen)
@@ -3170,8 +3207,18 @@ ppp_connect_channel(struct channel *pch, int unit)
 	ppp_unlock(ppp);
 	ret = 0;
 
+#ifndef CONFIG_CPE_FAST_PATH
  outl:
+#endif
 	write_unlock_bh(&pch->upl);
+#if defined(CONFIG_CPE_FAST_PATH)
+	if ((ppp->dev) && (!ppp->closing)) {
+		rtnl_lock();
+		rtmsg_ifinfo(RTM_NEWLINK, ppp->dev, 0, GFP_KERNEL);
+		rtnl_unlock();
+	}
+#endif
+
  out:
 	mutex_unlock(&pn->all_ppp_mutex);
 	return ret;
@@ -3197,6 +3244,16 @@ ppp_disconnect_channel(struct channel *pch)
 		if (--ppp->n_channels == 0)
 			wake_up_interruptible(&ppp->file.rwait);
 		ppp_unlock(ppp);
+
+#if defined(CONFIG_CPE_FAST_PATH)
+		if ((ppp->dev) && (!ppp->closing)) {
+			int lock_flag = rtnl_trylock();
+			rtmsg_ifinfo(RTM_NEWLINK, ppp->dev, 0, GFP_KERNEL);
+			if (lock_flag)
+				rtnl_unlock();
+		}
+#endif
+
 		if (atomic_dec_and_test(&ppp->file.refcnt))
 			ppp_destroy_interface(ppp);
 		err = 0;
diff --git a/drivers/net/ppp/pppoe.c b/drivers/net/ppp/pppoe.c
index 5aa59f41bf8c..c6a8e0826490 100644
--- a/drivers/net/ppp/pppoe.c
+++ b/drivers/net/ppp/pppoe.c
@@ -946,7 +946,15 @@ static int __pppoe_xmit(struct sock *sk, struct sk_buff *skb)
 
 	skb->protocol = cpu_to_be16(ETH_P_PPP_SES);
 	skb->dev = dev;
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)	
+	if((skb->ipsec_offload == 1) && (!skb->sp))
+	{
+		  dev_hard_header(skb, dev, ETH_P_PPP_SES,
+			 dev->dev_addr, po->pppoe_pa.remote, data_len);
 
+	}
+	else
+#endif
 	dev_hard_header(skb, dev, ETH_P_PPP_SES,
 			po->pppoe_pa.remote, NULL, data_len);
 
@@ -1010,17 +1018,32 @@ static int pppoe_seq_show(struct seq_file *seq, void *v)
 {
 	struct pppox_sock *po;
 	char *dev_name;
+#if defined(CONFIG_CPE_FAST_PATH)
+	char *ppp_name;
+#endif
 
 	if (v == SEQ_START_TOKEN) {
+#if defined(CONFIG_CPE_FAST_PATH)
+		seq_puts(seq, "Id   Address           Device     PPPDevice  Unit\n");
+#else
 		seq_puts(seq, "Id       Address              Device\n");
+#endif
 		goto out;
 	}
 
 	po = v;
 	dev_name = po->pppoe_pa.dev;
+#if defined(CONFIG_CPE_FAST_PATH)
+	ppp_name = ppp_dev_name(&po->chan);
+	if (!ppp_name)
+		goto out;
 
+	seq_printf(seq, "%04X %pM %-10s %-10s %d\n",
+		ntohs(po->pppoe_pa.sid), po->pppoe_pa.remote, dev_name, ppp_name, ppp_unit_number(&po->chan));
+#else
 	seq_printf(seq, "%08X %pM %8s\n",
 		po->pppoe_pa.sid, po->pppoe_pa.remote, dev_name);
+#endif
 out:
 	return 0;
 }
diff --git a/drivers/net/usb/usbnet.c b/drivers/net/usb/usbnet.c
index 42baad125a7d..7179edc88b13 100644
--- a/drivers/net/usb/usbnet.c
+++ b/drivers/net/usb/usbnet.c
@@ -48,6 +48,14 @@
 
 #define DRIVER_VERSION		"22-Aug-2005"
 
+#ifdef CONFIG_CPE_FAST_PATH
+/* 
+ * We alllocate extra 64 Bytes to reserve headroom in the sk_buff 
+ * To be used by Fast Path (Head Room must be 4 Byte aligned 
+ * because USB 2.0 controller doesn't support 2 byte alignment
+ */
+#define C2K_USBNET_SKB_HEADROOM_FAST_PATH 64
+#endif
 
 /*-------------------------------------------------------------------------*/
 
@@ -484,10 +492,19 @@ static int rx_submit (struct usbnet *dev, struct urb *urb, gfp_t flags)
 		return -ENOLINK;
 	}
 
+#ifdef CONFIG_CPE_FAST_PATH
+	/* 
+	 * We alllocate extra 64 Bytes to reserve headroom in the sk_buff 
+	 * To be used by Fast Path (Head Room must be 4 Byte aligned 
+	 * because USB 2.0 controller doesn't support 2 byte alignment
+	 */
+	skb = __netdev_alloc_skb(dev->net, size + C2K_USBNET_SKB_HEADROOM_FAST_PATH, GFP_ATOMIC);
+#else
 	if (test_bit(EVENT_NO_IP_ALIGN, &dev->flags))
 		skb = __netdev_alloc_skb(dev->net, size, flags);
 	else
 		skb = __netdev_alloc_skb_ip_align(dev->net, size, flags);
+#endif
 	if (!skb) {
 		netif_dbg(dev, rx_err, dev->net, "no rx skb\n");
 		usbnet_defer_kevent (dev, EVENT_RX_MEMORY);
@@ -495,6 +512,10 @@ static int rx_submit (struct usbnet *dev, struct urb *urb, gfp_t flags)
 		return -ENOMEM;
 	}
 
+#ifdef CONFIG_CPE_FAST_PATH
+	skb_reserve (skb, C2K_USBNET_SKB_HEADROOM_FAST_PATH);
+#endif    
+
 	entry = (struct skb_data *) skb->cb;
 	entry->urb = urb;
 	entry->dev = dev;
diff --git a/drivers/nfc/Kconfig b/drivers/nfc/Kconfig
index b065eb605215..8a0df0526a53 100644
--- a/drivers/nfc/Kconfig
+++ b/drivers/nfc/Kconfig
@@ -50,6 +50,7 @@ config NFC_PORT100
 
 source "drivers/nfc/fdp/Kconfig"
 source "drivers/nfc/pn544/Kconfig"
+source "drivers/nfc/pn7150/Kconfig"
 source "drivers/nfc/pn533/Kconfig"
 source "drivers/nfc/microread/Kconfig"
 source "drivers/nfc/nfcmrvl/Kconfig"
diff --git a/drivers/nfc/Makefile b/drivers/nfc/Makefile
index 5393ba59b17d..4278d186debf 100644
--- a/drivers/nfc/Makefile
+++ b/drivers/nfc/Makefile
@@ -5,6 +5,7 @@
 
 obj-$(CONFIG_NFC_FDP)		+= fdp/
 obj-$(CONFIG_NFC_PN544)		+= pn544/
+obj-$(CONFIG_NFC_PN7150)	+= pn7150/
 obj-$(CONFIG_NFC_MICROREAD)	+= microread/
 obj-$(CONFIG_NFC_PN533)		+= pn533/
 obj-$(CONFIG_NFC_MEI_PHY)	+= mei_phy.o
diff --git a/drivers/nfc/pn7150/Kconfig b/drivers/nfc/pn7150/Kconfig
new file mode 100644
index 000000000000..1b63e0035feb
--- /dev/null
+++ b/drivers/nfc/pn7150/Kconfig
@@ -0,0 +1,12 @@
+config NFC_PN7150
+	tristate "NXP PN7150 based driver"
+	depends on I2C
+	select CRC_CCITT
+	default n
+	---help---
+	  NXP PN7150 driver based on I2C.
+	  This is a driver to provides I2C access to PN5xx NFC Controller devices
+
+	  To compile this driver as a module, choose m here. The module will
+	  be called pn5xx_i2c.
+	  Say N if unsure.
diff --git a/drivers/nfc/pn7150/LICENSE b/drivers/nfc/pn7150/LICENSE
new file mode 100644
index 000000000000..23cb790338e1
--- /dev/null
+++ b/drivers/nfc/pn7150/LICENSE
@@ -0,0 +1,339 @@
+                    GNU GENERAL PUBLIC LICENSE
+                       Version 2, June 1991
+
+ Copyright (C) 1989, 1991 Free Software Foundation, Inc., <http://fsf.org/>
+ 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ Everyone is permitted to copy and distribute verbatim copies
+ of this license document, but changing it is not allowed.
+
+                            Preamble
+
+  The licenses for most software are designed to take away your
+freedom to share and change it.  By contrast, the GNU General Public
+License is intended to guarantee your freedom to share and change free
+software--to make sure the software is free for all its users.  This
+General Public License applies to most of the Free Software
+Foundation's software and to any other program whose authors commit to
+using it.  (Some other Free Software Foundation software is covered by
+the GNU Lesser General Public License instead.)  You can apply it to
+your programs, too.
+
+  When we speak of free software, we are referring to freedom, not
+price.  Our General Public Licenses are designed to make sure that you
+have the freedom to distribute copies of free software (and charge for
+this service if you wish), that you receive source code or can get it
+if you want it, that you can change the software or use pieces of it
+in new free programs; and that you know you can do these things.
+
+  To protect your rights, we need to make restrictions that forbid
+anyone to deny you these rights or to ask you to surrender the rights.
+These restrictions translate to certain responsibilities for you if you
+distribute copies of the software, or if you modify it.
+
+  For example, if you distribute copies of such a program, whether
+gratis or for a fee, you must give the recipients all the rights that
+you have.  You must make sure that they, too, receive or can get the
+source code.  And you must show them these terms so they know their
+rights.
+
+  We protect your rights with two steps: (1) copyright the software, and
+(2) offer you this license which gives you legal permission to copy,
+distribute and/or modify the software.
+
+  Also, for each author's protection and ours, we want to make certain
+that everyone understands that there is no warranty for this free
+software.  If the software is modified by someone else and passed on, we
+want its recipients to know that what they have is not the original, so
+that any problems introduced by others will not reflect on the original
+authors' reputations.
+
+  Finally, any free program is threatened constantly by software
+patents.  We wish to avoid the danger that redistributors of a free
+program will individually obtain patent licenses, in effect making the
+program proprietary.  To prevent this, we have made it clear that any
+patent must be licensed for everyone's free use or not licensed at all.
+
+  The precise terms and conditions for copying, distribution and
+modification follow.
+
+                    GNU GENERAL PUBLIC LICENSE
+   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION
+
+  0. This License applies to any program or other work which contains
+a notice placed by the copyright holder saying it may be distributed
+under the terms of this General Public License.  The "Program", below,
+refers to any such program or work, and a "work based on the Program"
+means either the Program or any derivative work under copyright law:
+that is to say, a work containing the Program or a portion of it,
+either verbatim or with modifications and/or translated into another
+language.  (Hereinafter, translation is included without limitation in
+the term "modification".)  Each licensee is addressed as "you".
+
+Activities other than copying, distribution and modification are not
+covered by this License; they are outside its scope.  The act of
+running the Program is not restricted, and the output from the Program
+is covered only if its contents constitute a work based on the
+Program (independent of having been made by running the Program).
+Whether that is true depends on what the Program does.
+
+  1. You may copy and distribute verbatim copies of the Program's
+source code as you receive it, in any medium, provided that you
+conspicuously and appropriately publish on each copy an appropriate
+copyright notice and disclaimer of warranty; keep intact all the
+notices that refer to this License and to the absence of any warranty;
+and give any other recipients of the Program a copy of this License
+along with the Program.
+
+You may charge a fee for the physical act of transferring a copy, and
+you may at your option offer warranty protection in exchange for a fee.
+
+  2. You may modify your copy or copies of the Program or any portion
+of it, thus forming a work based on the Program, and copy and
+distribute such modifications or work under the terms of Section 1
+above, provided that you also meet all of these conditions:
+
+    a) You must cause the modified files to carry prominent notices
+    stating that you changed the files and the date of any change.
+
+    b) You must cause any work that you distribute or publish, that in
+    whole or in part contains or is derived from the Program or any
+    part thereof, to be licensed as a whole at no charge to all third
+    parties under the terms of this License.
+
+    c) If the modified program normally reads commands interactively
+    when run, you must cause it, when started running for such
+    interactive use in the most ordinary way, to print or display an
+    announcement including an appropriate copyright notice and a
+    notice that there is no warranty (or else, saying that you provide
+    a warranty) and that users may redistribute the program under
+    these conditions, and telling the user how to view a copy of this
+    License.  (Exception: if the Program itself is interactive but
+    does not normally print such an announcement, your work based on
+    the Program is not required to print an announcement.)
+
+These requirements apply to the modified work as a whole.  If
+identifiable sections of that work are not derived from the Program,
+and can be reasonably considered independent and separate works in
+themselves, then this License, and its terms, do not apply to those
+sections when you distribute them as separate works.  But when you
+distribute the same sections as part of a whole which is a work based
+on the Program, the distribution of the whole must be on the terms of
+this License, whose permissions for other licensees extend to the
+entire whole, and thus to each and every part regardless of who wrote it.
+
+Thus, it is not the intent of this section to claim rights or contest
+your rights to work written entirely by you; rather, the intent is to
+exercise the right to control the distribution of derivative or
+collective works based on the Program.
+
+In addition, mere aggregation of another work not based on the Program
+with the Program (or with a work based on the Program) on a volume of
+a storage or distribution medium does not bring the other work under
+the scope of this License.
+
+  3. You may copy and distribute the Program (or a work based on it,
+under Section 2) in object code or executable form under the terms of
+Sections 1 and 2 above provided that you also do one of the following:
+
+    a) Accompany it with the complete corresponding machine-readable
+    source code, which must be distributed under the terms of Sections
+    1 and 2 above on a medium customarily used for software interchange; or,
+
+    b) Accompany it with a written offer, valid for at least three
+    years, to give any third party, for a charge no more than your
+    cost of physically performing source distribution, a complete
+    machine-readable copy of the corresponding source code, to be
+    distributed under the terms of Sections 1 and 2 above on a medium
+    customarily used for software interchange; or,
+
+    c) Accompany it with the information you received as to the offer
+    to distribute corresponding source code.  (This alternative is
+    allowed only for noncommercial distribution and only if you
+    received the program in object code or executable form with such
+    an offer, in accord with Subsection b above.)
+
+The source code for a work means the preferred form of the work for
+making modifications to it.  For an executable work, complete source
+code means all the source code for all modules it contains, plus any
+associated interface definition files, plus the scripts used to
+control compilation and installation of the executable.  However, as a
+special exception, the source code distributed need not include
+anything that is normally distributed (in either source or binary
+form) with the major components (compiler, kernel, and so on) of the
+operating system on which the executable runs, unless that component
+itself accompanies the executable.
+
+If distribution of executable or object code is made by offering
+access to copy from a designated place, then offering equivalent
+access to copy the source code from the same place counts as
+distribution of the source code, even though third parties are not
+compelled to copy the source along with the object code.
+
+  4. You may not copy, modify, sublicense, or distribute the Program
+except as expressly provided under this License.  Any attempt
+otherwise to copy, modify, sublicense or distribute the Program is
+void, and will automatically terminate your rights under this License.
+However, parties who have received copies, or rights, from you under
+this License will not have their licenses terminated so long as such
+parties remain in full compliance.
+
+  5. You are not required to accept this License, since you have not
+signed it.  However, nothing else grants you permission to modify or
+distribute the Program or its derivative works.  These actions are
+prohibited by law if you do not accept this License.  Therefore, by
+modifying or distributing the Program (or any work based on the
+Program), you indicate your acceptance of this License to do so, and
+all its terms and conditions for copying, distributing or modifying
+the Program or works based on it.
+
+  6. Each time you redistribute the Program (or any work based on the
+Program), the recipient automatically receives a license from the
+original licensor to copy, distribute or modify the Program subject to
+these terms and conditions.  You may not impose any further
+restrictions on the recipients' exercise of the rights granted herein.
+You are not responsible for enforcing compliance by third parties to
+this License.
+
+  7. If, as a consequence of a court judgment or allegation of patent
+infringement or for any other reason (not limited to patent issues),
+conditions are imposed on you (whether by court order, agreement or
+otherwise) that contradict the conditions of this License, they do not
+excuse you from the conditions of this License.  If you cannot
+distribute so as to satisfy simultaneously your obligations under this
+License and any other pertinent obligations, then as a consequence you
+may not distribute the Program at all.  For example, if a patent
+license would not permit royalty-free redistribution of the Program by
+all those who receive copies directly or indirectly through you, then
+the only way you could satisfy both it and this License would be to
+refrain entirely from distribution of the Program.
+
+If any portion of this section is held invalid or unenforceable under
+any particular circumstance, the balance of the section is intended to
+apply and the section as a whole is intended to apply in other
+circumstances.
+
+It is not the purpose of this section to induce you to infringe any
+patents or other property right claims or to contest validity of any
+such claims; this section has the sole purpose of protecting the
+integrity of the free software distribution system, which is
+implemented by public license practices.  Many people have made
+generous contributions to the wide range of software distributed
+through that system in reliance on consistent application of that
+system; it is up to the author/donor to decide if he or she is willing
+to distribute software through any other system and a licensee cannot
+impose that choice.
+
+This section is intended to make thoroughly clear what is believed to
+be a consequence of the rest of this License.
+
+  8. If the distribution and/or use of the Program is restricted in
+certain countries either by patents or by copyrighted interfaces, the
+original copyright holder who places the Program under this License
+may add an explicit geographical distribution limitation excluding
+those countries, so that distribution is permitted only in or among
+countries not thus excluded.  In such case, this License incorporates
+the limitation as if written in the body of this License.
+
+  9. The Free Software Foundation may publish revised and/or new versions
+of the General Public License from time to time.  Such new versions will
+be similar in spirit to the present version, but may differ in detail to
+address new problems or concerns.
+
+Each version is given a distinguishing version number.  If the Program
+specifies a version number of this License which applies to it and "any
+later version", you have the option of following the terms and conditions
+either of that version or of any later version published by the Free
+Software Foundation.  If the Program does not specify a version number of
+this License, you may choose any version ever published by the Free Software
+Foundation.
+
+  10. If you wish to incorporate parts of the Program into other free
+programs whose distribution conditions are different, write to the author
+to ask for permission.  For software which is copyrighted by the Free
+Software Foundation, write to the Free Software Foundation; we sometimes
+make exceptions for this.  Our decision will be guided by the two goals
+of preserving the free status of all derivatives of our free software and
+of promoting the sharing and reuse of software generally.
+
+                            NO WARRANTY
+
+  11. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY
+FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN
+OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES
+PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED
+OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS
+TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE
+PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING,
+REPAIR OR CORRECTION.
+
+  12. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
+WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR
+REDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,
+INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING
+OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED
+TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY
+YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER
+PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE
+POSSIBILITY OF SUCH DAMAGES.
+
+                     END OF TERMS AND CONDITIONS
+
+            How to Apply These Terms to Your New Programs
+
+  If you develop a new program, and you want it to be of the greatest
+possible use to the public, the best way to achieve this is to make it
+free software which everyone can redistribute and change under these terms.
+
+  To do so, attach the following notices to the program.  It is safest
+to attach them to the start of each source file to most effectively
+convey the exclusion of warranty; and each file should have at least
+the "copyright" line and a pointer to where the full notice is found.
+
+    {description}
+    Copyright (C) {year}  {fullname}
+
+    This program is free software; you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation; either version 2 of the License, or
+    (at your option) any later version.
+
+    This program is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License along
+    with this program; if not, write to the Free Software Foundation, Inc.,
+    51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
+
+Also add information on how to contact you by electronic and paper mail.
+
+If the program is interactive, make it output a short notice like this
+when it starts in an interactive mode:
+
+    Gnomovision version 69, Copyright (C) year name of author
+    Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
+    This is free software, and you are welcome to redistribute it
+    under certain conditions; type `show c' for details.
+
+The hypothetical commands `show w' and `show c' should show the appropriate
+parts of the General Public License.  Of course, the commands you use may
+be called something other than `show w' and `show c'; they could even be
+mouse-clicks or menu items--whatever suits your program.
+
+You should also get your employer (if you work as a programmer) or your
+school, if any, to sign a "copyright disclaimer" for the program, if
+necessary.  Here is a sample; alter the names:
+
+  Yoyodyne, Inc., hereby disclaims all copyright interest in the program
+  `Gnomovision' (which makes passes at compilers) written by James Hacker.
+
+  {signature of Ty Coon}, 1 April 1989
+  Ty Coon, President of Vice
+
+This General Public License does not permit incorporating your program into
+proprietary programs.  If your program is a subroutine library, you may
+consider it more useful to permit linking proprietary applications with the
+library.  If this is what you want to do, use the GNU Lesser General
+Public License instead of this License.
diff --git a/drivers/nfc/pn7150/Makefile b/drivers/nfc/pn7150/Makefile
new file mode 100644
index 000000000000..2bfe7bfaf129
--- /dev/null
+++ b/drivers/nfc/pn7150/Makefile
@@ -0,0 +1 @@
+obj-$(CONFIG_NFC_PN7150):= pn5xx_i2c.o
diff --git a/drivers/nfc/pn7150/README.md b/drivers/nfc/pn7150/README.md
new file mode 100644
index 000000000000..c0c8d5c73757
--- /dev/null
+++ b/drivers/nfc/pn7150/README.md
@@ -0,0 +1,2 @@
+# nxp-pn5xx
+NXP's NFC Open Source Kernel mode driver
diff --git a/drivers/nfc/pn7150/pn5xx_i2c.c b/drivers/nfc/pn7150/pn5xx_i2c.c
new file mode 100644
index 000000000000..44c1f3210a3f
--- /dev/null
+++ b/drivers/nfc/pn7150/pn5xx_i2c.c
@@ -0,0 +1,869 @@
+/*
+* Copyright (C) 2010 Trusted Logic S.A.
+* modifications copyright (C) 2015 NXP B.V.
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License as published by
+* the Free Software Foundation; either version 2 of the License, or
+* (at your option) any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+*/
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/fs.h>
+#include <linux/slab.h>
+#include <linux/init.h>
+#include <linux/list.h>
+#include <linux/i2c.h>
+#include <linux/irq.h>
+#include <linux/jiffies.h>
+#include <linux/uaccess.h>
+#include <linux/delay.h>
+#include <linux/interrupt.h>
+#include <linux/io.h>
+#include <linux/platform_device.h>
+#include <linux/gpio.h>
+#include <linux/miscdevice.h>
+#include <linux/spinlock.h>
+#include "pn5xx_i2c.h"
+#include <linux/of_gpio.h>
+#include <linux/regulator/consumer.h>
+#include <linux/of.h>
+
+#define MAX_BUFFER_SIZE	512
+
+#define MODE_OFF    0
+#define MODE_RUN    1
+#define MODE_FW     2
+
+/* Only pn548, pn547 and pn544 are supported */
+#define CHIP "pn544"
+#define DRIVER_CARD "PN54x NFC"
+#define DRIVER_DESC "NFC driver for PN54x Family"
+
+
+#ifndef CONFIG_OF
+#define CONFIG_OF
+#endif
+
+
+struct pn54x_dev	{
+	wait_queue_head_t read_wq;
+	struct mutex read_mutex;
+	struct i2c_client *client;
+	struct miscdevice pn54x_device;
+	int ven_gpio;
+	int firm_gpio;
+	int irq_gpio;
+	int clkreq_gpio;
+	struct regulator *pvdd_reg;
+	struct regulator *vbat_reg;
+	struct regulator *pmuvcc_reg;
+	struct regulator *sevdd_reg;
+	bool irq_enabled;
+	spinlock_t irq_enabled_lock;
+};
+
+
+/**********************************************************
+ * Interrupt control and handler
+ **********************************************************/
+static void pn54x_disable_irq(struct pn54x_dev *pn54x_dev)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&pn54x_dev->irq_enabled_lock, flags);
+	if (pn54x_dev->irq_enabled) {
+		disable_irq_nosync(pn54x_dev->client->irq);
+		pn54x_dev->irq_enabled = false;
+	}
+	spin_unlock_irqrestore(&pn54x_dev->irq_enabled_lock, flags);
+}
+int reset = 0;
+
+static irqreturn_t pn54x_dev_irq_handler(int irq, void *dev_id)
+{
+	struct pn54x_dev *pn54x_dev = dev_id;
+
+
+	pn54x_disable_irq(pn54x_dev);
+
+
+	/* Wake up waiting readers */
+	wake_up(&pn54x_dev->read_wq);
+
+
+	return IRQ_HANDLED;
+}
+
+
+/**********************************************************
+ * private functions
+ **********************************************************/
+static int pn544_enable(struct pn54x_dev *dev, int mode)
+{
+	int r, ret = 0;
+
+
+	/* turn on the regulators */
+	/* -- if the regulators were specified, they're required */
+	if(dev->pvdd_reg != NULL)
+	{
+		r = regulator_enable(dev->pvdd_reg);
+		if (r < 0){
+			pr_err("%s: not able to enable pvdd\n", __func__);
+			return r;
+		}
+	}
+	if(dev->vbat_reg != NULL)
+	{
+		r = regulator_enable(dev->vbat_reg);
+		if (r < 0){
+			pr_err("%s: not able to enable vbat\n", __func__);
+			goto enable_exit0;
+		}
+	}
+	if(dev->pmuvcc_reg != NULL)
+	{
+		r = regulator_enable(dev->pmuvcc_reg);
+		if (r < 0){
+			pr_err("%s: not able to enable pmuvcc\n", __func__);
+			goto enable_exit1;
+		}
+	}
+	if(dev->sevdd_reg != NULL)
+	{
+		r = regulator_enable(dev->sevdd_reg);
+		if (r < 0){
+			pr_err("%s: not able to enable sevdd\n", __func__);
+			goto enable_exit2;
+		}
+	}
+
+	if (MODE_RUN == mode) {
+		pr_info("%s power on\n", __func__);
+		if (gpio_is_valid(dev->firm_gpio))
+			gpio_set_value(dev->firm_gpio, 0);
+		gpio_set_value(dev->ven_gpio, 1);
+		msleep(100);
+	}
+	else if (MODE_FW == mode) {
+		/* power on with firmware download (requires hw reset)
+		 */
+		pr_info("%s power on with firmware\n", __func__);
+		gpio_set_value(dev->ven_gpio, 1);
+		msleep(20);
+		if (gpio_is_valid(dev->firm_gpio)) {
+			gpio_set_value(dev->firm_gpio, 1);
+		}
+		else {
+			pr_err("%s Unused Firm GPIO %d\n", __func__, mode);
+			return GPIO_UNUSED;
+		}
+		msleep(20);
+		gpio_set_value(dev->ven_gpio, 0);
+		msleep(100);
+		gpio_set_value(dev->ven_gpio, 1);
+		msleep(20);
+	}
+	else {
+		pr_err("%s bad arg %d\n", __func__, mode);
+		return -EINVAL;
+	}
+
+
+	return 0;
+
+
+enable_exit2:
+	if(dev->pmuvcc_reg) regulator_disable(dev->pmuvcc_reg);
+enable_exit1:
+	if(dev->vbat_reg) regulator_disable(dev->vbat_reg);
+enable_exit0:
+	if(dev->pvdd_reg) regulator_disable(dev->pvdd_reg);
+
+
+	return r;
+}
+
+
+static void pn544_disable(struct pn54x_dev *dev)
+{
+	/* power off */
+	pr_info("%s power off\n", __func__);
+	if (gpio_is_valid(dev->firm_gpio))
+		gpio_set_value(dev->firm_gpio, 0);
+	gpio_set_value(dev->ven_gpio, 0);
+	msleep(100);
+
+
+	if(dev->sevdd_reg) regulator_disable(dev->sevdd_reg);
+	if(dev->pmuvcc_reg) regulator_disable(dev->pmuvcc_reg);
+	if(dev->vbat_reg) regulator_disable(dev->vbat_reg);
+	if(dev->pvdd_reg) regulator_disable(dev->pvdd_reg);
+
+
+}
+
+
+/**********************************************************
+ * driver functions
+ **********************************************************/
+static ssize_t pn54x_dev_read(struct file *filp, char __user *buf,
+		size_t count, loff_t *offset)
+{
+	struct pn54x_dev *pn54x_dev = filp->private_data;
+	char tmp[MAX_BUFFER_SIZE];
+	int ret;
+
+
+	if (count > MAX_BUFFER_SIZE)
+		count = MAX_BUFFER_SIZE;
+
+
+	//pr_info("%s : READING %zu bytes.\n", __func__, count);
+
+
+	mutex_lock(&pn54x_dev->read_mutex);
+
+
+	if (!gpio_get_value(pn54x_dev->irq_gpio)) {
+		if (filp->f_flags & O_NONBLOCK) {
+			ret = -EAGAIN;
+			goto fail;
+		}
+
+
+		while (1) {
+			pn54x_dev->irq_enabled = true;
+			enable_irq(pn54x_dev->client->irq);
+			ret = wait_event_interruptible(
+					pn54x_dev->read_wq,
+					!pn54x_dev->irq_enabled);
+
+
+			pn54x_disable_irq(pn54x_dev);
+
+
+			if (ret)
+				goto fail;
+
+			if (gpio_get_value(pn54x_dev->irq_gpio))
+				break;
+
+			pr_warning("%s: SPURIOUS INTERRUPTS DETECTED for irq %d \n", __func__, pn54x_dev->irq_gpio);
+		}
+	}
+
+
+	/* Read data */
+	ret = i2c_master_recv(pn54x_dev->client, tmp, count);
+
+
+	mutex_unlock(&pn54x_dev->read_mutex);
+
+
+	/* pn54x seems to be slow in handling I2C read requests
+	 * so add 1ms delay after recv operation */
+	udelay(1000);
+
+
+	if (ret < 0) {
+		pr_err("%s: i2c_master_recv returned %d\n", __func__, ret);
+		return ret;
+	}
+	if (ret > count) {
+		pr_err("%s: received too many bytes from i2c (%d)\n",
+			__func__, ret);
+		return -EIO;
+	}
+	if (copy_to_user(buf, tmp, ret)) {
+		pr_warning("%s : failed to copy to user space\n", __func__);
+		return -EFAULT;
+	}
+	return ret;
+
+
+fail:
+	mutex_unlock(&pn54x_dev->read_mutex);
+	return ret;
+}
+
+
+static ssize_t pn54x_dev_write(struct file *filp, const char __user *buf,
+		size_t count, loff_t *offset)
+{
+	struct pn54x_dev  *pn54x_dev;
+	char tmp[MAX_BUFFER_SIZE];
+	int ret;
+
+
+	pn54x_dev = filp->private_data;
+
+
+	if (count > MAX_BUFFER_SIZE)
+		count = MAX_BUFFER_SIZE;
+
+
+	if (copy_from_user(tmp, buf, count)) {
+		pr_err("%s : failed to copy from user space\n", __func__);
+		return -EFAULT;
+	}
+
+
+	//pr_info("%s : ####### WRITING %zu bytes.\n", __func__, count);
+	/* Write data */
+	ret = i2c_master_send(pn54x_dev->client, tmp, count);
+	if (ret != count) {
+		pr_err("%s : i2c_master_send returned %d\n", __func__, ret);
+		ret = -EIO;
+	}
+
+	/* pn54x seems to be slow in handling I2C write requests
+	 * so add 1ms delay after I2C send oparation */
+	udelay(2000);
+
+
+	return ret;
+}
+
+
+static int pn54x_dev_open(struct inode *inode, struct file *filp)
+{
+	struct pn54x_dev *pn54x_dev = container_of(filp->private_data,
+											   struct pn54x_dev,
+											   pn54x_device);
+
+
+	filp->private_data = pn54x_dev;
+
+
+	pr_info("%s : %d,%d\n", __func__, imajor(inode), iminor(inode));
+
+
+	// pn544_enable(pn54x_dev, MODE_RUN);
+
+
+	return 0;
+}
+
+
+static int pn54x_dev_release(struct inode *inode, struct file *filp)
+{
+	// struct pn54x_dev *pn54x_dev = container_of(filp->private_data,
+	//										   struct pn54x_dev,
+	//										   pn54x_device);
+
+
+	pr_info("%s : closing %d,%d\n", __func__, imajor(inode), iminor(inode));
+
+
+	// pn544_disable(pn54x_dev);
+
+
+	return 0;
+}
+
+
+static long  pn54x_dev_ioctl(struct file *filp, unsigned int cmd,
+				unsigned long arg)
+{
+	struct pn54x_dev *pn54x_dev = filp->private_data;
+
+
+	pr_info("%s, cmd=%d, arg=%lu\n", __func__, cmd, arg);
+	switch (cmd) {
+	case PN544_SET_PWR:
+		if (arg == 2) {
+			/* power on w/FW */
+			pn544_enable(pn54x_dev, arg);
+		} else if (arg == 1) {
+			/* power on */
+			pn544_enable(pn54x_dev, arg);
+		} else  if (arg == 0) {
+			/* power off */
+			pn544_disable(pn54x_dev);
+		} else {
+			pr_err("%s bad SET_PWR arg %lu\n", __func__, arg);
+			return -EINVAL;
+		}
+		break;
+	case PN54X_CLK_REQ:
+		if(1 == arg){
+			if(gpio_is_valid(pn54x_dev->clkreq_gpio)){
+				gpio_set_value(pn54x_dev->clkreq_gpio, 1);
+			}
+		}
+		else if(0 == arg) {
+			if(gpio_is_valid(pn54x_dev->clkreq_gpio)){
+				gpio_set_value(pn54x_dev->clkreq_gpio, 0);
+			}
+		} else {
+			pr_err("%s bad CLK_REQ arg %lu\n", __func__, arg);
+			return -EINVAL;
+		}
+		break;
+	default:
+		pr_err("%s bad ioctl %u\n", __func__, cmd);
+		return -EINVAL;
+	}
+
+
+	return 0;
+}
+
+
+static const struct file_operations pn54x_dev_fops = {
+	.owner	= THIS_MODULE,
+	.llseek	= no_llseek,
+	.read	= pn54x_dev_read,
+	.write	= pn54x_dev_write,
+	.open	= pn54x_dev_open,
+	.release  = pn54x_dev_release,
+	.unlocked_ioctl  = pn54x_dev_ioctl,
+};
+
+
+
+
+/*
+ * Handlers for alternative sources of platform_data
+ */
+#ifdef CONFIG_OF
+/*
+ * Translate OpenFirmware node properties into platform_data
+ */
+static int pn54x_get_pdata(struct device *dev,
+							struct pn544_i2c_platform_data *pdata)
+{
+	struct device_node *node;
+	u32 flags;
+	int val;
+
+
+	/* make sure there is actually a device tree node */
+	node = dev->of_node;
+	if (!node)
+		return -ENODEV;
+
+
+	memset(pdata, 0, sizeof(*pdata));
+
+
+	/* read the dev tree data */
+
+
+	/* ven pin - enable's power to the chip - REQUIRED */
+	val = of_get_named_gpio_flags(node, "enable-gpios", 0, &flags);
+	if (val >= 0) {
+		pdata->ven_gpio = val;
+	}
+	else {
+		dev_err(dev, "VEN GPIO error getting from OF node\n");
+		return val;
+	}
+
+
+	/* firm pin - controls firmware download - OPTIONAL */
+	val = of_get_named_gpio_flags(node, "firmware-gpios", 0, &flags);
+	if (val >= 0) {
+		pdata->firm_gpio = val;
+	}
+	else {
+		pdata->firm_gpio = -EINVAL;
+		dev_warn(dev, "FIRM GPIO <OPTIONAL> error getting from OF node\n");
+	}
+
+
+	/* irq pin - data available irq - REQUIRED */
+	val = of_get_named_gpio_flags(node, "interrupt-gpios", 0, &flags);
+	if (!gpio_is_valid(val)){
+	}
+
+	if (val >= 0) {
+		pdata->irq_gpio = val;
+	}
+	else {
+		dev_err(dev, "IRQ GPIO error getting from OF node\n");
+		return val;
+	}
+
+
+	/* clkreq pin - controls the clock to the PN547 - OPTIONAL */
+	val = of_get_named_gpio_flags(node, "nxp,pn54x-clkreq", 0, &flags);
+	if (val >= 0) {
+		pdata->clkreq_gpio = val;
+	}
+	else {
+		pdata->clkreq_gpio = -EINVAL;
+		dev_warn(dev, "CLKREQ GPIO <OPTIONAL> error getting from OF node\n");
+	}
+
+
+	/* handle the regulator lines - these are optional
+	 * PVdd - pad Vdd (544, 547)
+	 * Vbat - Battery (544, 547)
+	 * PMUVcc - UICC Power (544, 547)
+	 * SEVdd - SE Power (544)
+	 *
+	 * Will attempt to load a matching Regulator Resource for each
+	 * If no resource is provided, then the input will not be controlled
+	 * Example: if only PVdd is provided, it is the only one that will be
+	 *  turned on/off.
+	 */
+	pdata->pvdd_reg = regulator_get(dev, "nxp,pn54x-pvdd");
+	if(IS_ERR(pdata->pvdd_reg)) {
+		pr_err("%s: could not get nxp,pn54x-pvdd, rc=%ld\n", __func__, PTR_ERR(pdata->pvdd_reg));
+		pdata->pvdd_reg = NULL;
+	}
+
+
+	pdata->vbat_reg = regulator_get(dev, "nxp,pn54x-vbat");
+	if (IS_ERR(pdata->vbat_reg)) {
+		pr_err("%s: could not get nxp,pn54x-vbat, rc=%ld\n", __func__, PTR_ERR(pdata->vbat_reg));
+		pdata->vbat_reg = NULL;
+	}
+
+
+	pdata->pmuvcc_reg = regulator_get(dev, "nxp,pn54x-pmuvcc");
+	if (IS_ERR(pdata->pmuvcc_reg)) {
+		pr_err("%s: could not get nxp,pn54x-pmuvcc, rc=%ld\n", __func__, PTR_ERR(pdata->pmuvcc_reg));
+		pdata->pmuvcc_reg = NULL;
+	}
+
+
+	pdata->sevdd_reg = regulator_get(dev, "nxp,pn54x-sevdd");
+	if (IS_ERR(pdata->sevdd_reg)) {
+		pr_err("%s: could not get nxp,pn54x-sevdd, rc=%ld\n", __func__, PTR_ERR(pdata->sevdd_reg));
+		pdata->sevdd_reg = NULL;
+	}
+
+
+	return 0;
+}
+#else
+static int pn54x_get_pdata(struct device *dev,
+							struct pn544_i2c_platform_data *pdata)
+{
+	pdata = dev->platform_data;
+	return 0;
+}
+#endif
+
+
+
+
+/*
+ * pn54x_probe
+ */
+#ifdef KERNEL_3_4_AND_OLDER
+ static int __devinit pn54x_probe(struct i2c_client *client,
+		const struct i2c_device_id *id)
+#else
+static int pn54x_probe(struct i2c_client *client,
+		const struct i2c_device_id *id)
+#endif
+{
+	int ret;
+	struct pn544_i2c_platform_data *pdata; // gpio values, from board file or DT
+	struct pn544_i2c_platform_data tmp_pdata;
+	struct pn54x_dev *pn54x_dev; // internal device specific data
+
+
+
+
+	/* ---- retrieve the platform data ---- */
+	/* If the dev.platform_data is NULL, then */
+	/* attempt to read from the device tree */
+	if(!client->dev.platform_data)
+	{
+		ret = pn54x_get_pdata(&(client->dev), &tmp_pdata);
+		if(ret){
+			return ret;
+		}
+
+
+		pdata = &tmp_pdata;
+	}
+	else
+	{
+		pdata = client->dev.platform_data;
+	}
+
+
+	if (pdata == NULL) {
+		pr_err("%s : nfc probe fail\n", __func__);
+		return  -ENODEV;
+	}
+
+
+	/* validate the the adapter has basic I2C functionality */
+	if (!i2c_check_functionality(client->adapter, I2C_FUNC_I2C)) {
+		pr_err("%s : need I2C_FUNC_I2C\n", __func__);
+		return  -ENODEV;
+	}
+
+
+	/* reserve the GPIO pins */
+	pr_info("%s: request irq_gpio %d\n", __func__, pdata->irq_gpio);
+	ret = gpio_request(pdata->irq_gpio, "nfc_int");
+	if (ret){
+		pr_err("%s :not able to get GPIO irq_gpio\n", __func__);
+		return  -ENODEV;
+	}
+	ret = gpio_to_irq(pdata->irq_gpio);
+	if (ret < 0){
+		pr_err("%s :not able to map GPIO irq_gpio to an IRQ\n", __func__);
+		goto err_ven;
+	}
+	else{
+		client->irq = ret;
+	}
+
+
+	pr_info("%s: request ven_gpio %d\n", __func__, pdata->ven_gpio);
+	ret = gpio_request(pdata->ven_gpio, "nfc_ven");
+	if (ret){
+		pr_err("%s :not able to get GPIO ven_gpio\n", __func__);
+		goto err_ven;
+	}
+
+
+	if (gpio_is_valid(pdata->firm_gpio)) {
+		pr_info("%s: request firm_gpio %d\n", __func__, pdata->firm_gpio);
+		ret = gpio_request(pdata->firm_gpio, "nfc_firm");
+		if (ret){
+			pr_err("%s :not able to get GPIO firm_gpio\n", __func__);
+			goto err_firm;
+		}
+	}
+
+
+	if (gpio_is_valid(pdata->clkreq_gpio)) {
+		pr_info("%s: request clkreq_gpio %d\n", __func__, pdata->clkreq_gpio);
+		ret = gpio_request(pdata->clkreq_gpio, "nfc_clkreq");
+		if (ret){
+			pr_err("%s :not able to get GPIO clkreq_gpio\n", __func__);
+			goto err_clkreq;
+		}
+	}
+
+
+	/* allocate the pn54x driver information structure */
+	pn54x_dev = kzalloc(sizeof(*pn54x_dev), GFP_KERNEL);
+	if (pn54x_dev == NULL) {
+		dev_err(&client->dev, "failed to allocate memory for module data\n");
+		ret = -ENOMEM;
+		goto err_exit;
+	}
+
+
+	/* store the platform data in the driver info struct */
+	pn54x_dev->irq_gpio = pdata->irq_gpio;
+	pn54x_dev->ven_gpio = pdata->ven_gpio;
+	pn54x_dev->firm_gpio = pdata->firm_gpio;
+	pn54x_dev->clkreq_gpio = pdata->clkreq_gpio;
+	pn54x_dev->pvdd_reg = pdata->pvdd_reg;
+	pn54x_dev->vbat_reg = pdata->vbat_reg;
+	pn54x_dev->pmuvcc_reg = pdata->pmuvcc_reg;
+	pn54x_dev->sevdd_reg = pdata->sevdd_reg;
+
+
+	pn54x_dev->client = client;
+
+
+	/* finish configuring the I/O */
+	ret = gpio_direction_input(pn54x_dev->irq_gpio);
+	if (ret < 0) {
+		pr_err("%s :not able to set irq_gpio as input\n", __func__);
+		goto err_exit;
+	}
+
+	ret = gpio_direction_output(pn54x_dev->ven_gpio, 0);
+	if (ret < 0) {
+		pr_err("%s : not able to set ven_gpio as output\n", __func__);
+		goto err_exit;
+	}
+
+	if (gpio_is_valid(pn54x_dev->firm_gpio)) {
+		ret = gpio_direction_output(pn54x_dev->firm_gpio, 0);
+		if (ret < 0) {
+			pr_err("%s : not able to set firm_gpio as output\n",
+				 __func__);
+			goto err_exit;
+		}
+	}
+
+
+	if (gpio_is_valid(pn54x_dev->clkreq_gpio)) {
+		ret = gpio_direction_output(pn54x_dev->clkreq_gpio, 0);
+		if (ret < 0) {
+			pr_err("%s : not able to set clkreq_gpio as output\n",
+				   __func__);
+			goto err_exit;
+		}
+	}
+
+
+	/* init mutex and queues */
+	init_waitqueue_head(&pn54x_dev->read_wq);
+	mutex_init(&pn54x_dev->read_mutex);
+	spin_lock_init(&pn54x_dev->irq_enabled_lock);
+
+
+	/* register as a misc device - character based with one entry point */
+	pn54x_dev->pn54x_device.minor = MISC_DYNAMIC_MINOR;
+	pn54x_dev->pn54x_device.name = CHIP;
+	pn54x_dev->pn54x_device.fops = &pn54x_dev_fops;
+	ret = misc_register(&pn54x_dev->pn54x_device);
+	if (ret) {
+		pr_err("%s : misc_register failed\n", __FILE__);
+		goto err_misc_register;
+	}
+
+
+	/* request irq.  the irq is set whenever the chip has data available
+	 * for reading.  it is cleared when all data has been read.
+	 */
+	pr_info("%s : requesting IRQ %d \n", __func__, client->irq);
+	pn54x_dev->irq_enabled = true;
+	ret = request_irq(client->irq, pn54x_dev_irq_handler,
+				3, client->name, pn54x_dev);
+	if (ret) {
+		dev_err(&client->dev, "request_irq failed\n");
+		goto err_request_irq_failed;
+	}
+	pn54x_disable_irq(pn54x_dev);
+
+
+	i2c_set_clientdata(client, pn54x_dev);
+
+
+	return 0;
+
+
+err_request_irq_failed:
+	misc_deregister(&pn54x_dev->pn54x_device);
+err_misc_register:
+err_exit:
+	if (gpio_is_valid(pdata->clkreq_gpio))
+		gpio_free(pdata->clkreq_gpio);
+err_clkreq:
+	if (gpio_is_valid(pdata->firm_gpio))
+		gpio_free(pdata->firm_gpio);
+err_firm:
+	gpio_free(pdata->ven_gpio);
+err_ven:
+	gpio_free(pdata->irq_gpio);
+	return ret;
+}
+
+
+#ifdef KERNEL_3_4_AND_OLDER
+static int __devexit pn54x_remove(struct i2c_client *client)
+#else
+static int pn54x_remove(struct i2c_client *client)
+#endif
+{
+	struct pn54x_dev *pn54x_dev;
+
+
+	pr_info("%s\n", __func__);
+
+
+	pn54x_dev = i2c_get_clientdata(client);
+	free_irq(client->irq, pn54x_dev);
+	misc_deregister(&pn54x_dev->pn54x_device);
+	mutex_destroy(&pn54x_dev->read_mutex);
+	gpio_free(pn54x_dev->irq_gpio);
+	gpio_free(pn54x_dev->ven_gpio);
+	if (gpio_is_valid(pn54x_dev->firm_gpio))
+		gpio_free(pn54x_dev->firm_gpio);
+	if (gpio_is_valid(pn54x_dev->clkreq_gpio))
+		gpio_free(pn54x_dev->clkreq_gpio);
+	regulator_put(pn54x_dev->pvdd_reg);
+	regulator_put(pn54x_dev->vbat_reg);
+	regulator_put(pn54x_dev->pmuvcc_reg);
+	regulator_put(pn54x_dev->sevdd_reg);
+
+
+	kfree(pn54x_dev);
+
+
+	return 0;
+}
+
+
+/*
+ *
+ */
+#ifdef CONFIG_OF
+static struct of_device_id pn54x_dt_match[] = {
+	{ .compatible = "nxp,pn547", },
+	{ .compatible = "nxp,pn544", },
+	{ .compatible = "nxp,pn7150", },
+	{},
+};
+MODULE_DEVICE_TABLE(of, pn54x_dt_match);
+#endif
+
+
+static const struct i2c_device_id pn54x_id[] = {
+	{ "pn547", 0 },
+	{ },
+};
+MODULE_DEVICE_TABLE(i2c, pn54x_id);
+
+
+static struct i2c_driver pn54x_driver = {
+	.id_table	= pn54x_id,
+	.probe		= pn54x_probe,
+#ifdef KERNEL_3_4_AND_OLDER
+	.remove		= __devexit_p(pn54x_remove),
+#else
+	.remove		= pn54x_remove,
+#endif
+	.driver		= {
+		.owner	= THIS_MODULE,
+		.name	= "pn544",
+		.of_match_table = pn54x_dt_match,
+	},
+};
+
+
+/*
+ * module load/unload record keeping
+ */
+
+
+static int __init pn54x_dev_init(void)
+{
+	pr_info("%s\n", __func__);
+	return i2c_add_driver(&pn54x_driver);
+}
+
+
+static void __exit pn54x_dev_exit(void)
+{
+	pr_info("%s\n", __func__);
+	i2c_del_driver(&pn54x_driver);
+}
+
+
+module_init(pn54x_dev_init);
+module_exit(pn54x_dev_exit);
+
+
+MODULE_AUTHOR("Sylvain Fonteneau");
+MODULE_DESCRIPTION(DRIVER_DESC);
+MODULE_LICENSE("GPL");
diff --git a/drivers/nfc/pn7150/pn5xx_i2c.h b/drivers/nfc/pn7150/pn5xx_i2c.h
new file mode 100644
index 000000000000..fce4edafc6a4
--- /dev/null
+++ b/drivers/nfc/pn7150/pn5xx_i2c.h
@@ -0,0 +1,50 @@
+/*
+ * Copyright (C) 2010 Trusted Logic S.A.
+ * modifications copyright (C) 2015 NXP B.V.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#define PN544_MAGIC	0xE9
+
+/*
+ * PN544 power control via ioctl
+ * PN544_SET_PWR(0): power off
+ * PN544_SET_PWR(1): power on
+ * PN544_SET_PWR(2): reset and power on with firmware download enabled
+ */
+
+#define PWR_OFF 0
+#define PWR_ON  1
+#define PWR_FW  2
+
+#define CLK_OFF 0
+#define CLK_ON  1
+
+#define GPIO_UNUSED -1
+
+#define PN544_SET_PWR	_IOW(PN544_MAGIC, 0x01, unsigned int)
+#define PN54X_CLK_REQ	_IOW(PN544_MAGIC, 0x02, unsigned int)
+
+struct pn544_i2c_platform_data {
+	unsigned int irq_gpio;
+	unsigned int ven_gpio;
+	unsigned int firm_gpio;
+	unsigned int clkreq_gpio;
+	struct regulator *pvdd_reg;
+	struct regulator *vbat_reg;
+	struct regulator *pmuvcc_reg;
+	struct regulator *sevdd_reg;
+};
diff --git a/drivers/nfc/pn7150/sample_devicetree.txt b/drivers/nfc/pn7150/sample_devicetree.txt
new file mode 100644
index 000000000000..0e81959052fc
--- /dev/null
+++ b/drivers/nfc/pn7150/sample_devicetree.txt
@@ -0,0 +1,17 @@
+Example:
+
+&i2c{
+
+	status = "okay";
+
+	pn547: pn547@29 {
+
+		compatible = "nxp,pn547";
+
+		reg = <0x29>;
+		clock-frequency = <400000>;
+
+		interrupt-gpios = <&gpio2 17 0>;
+		enable-gpios = <&gpio4 21 0>;
+	};
+};
diff --git a/drivers/staging/fsl_qbman/fsl_usdpaa.c b/drivers/staging/fsl_qbman/fsl_usdpaa.c
index bd91190f3aad..1a89ff0c747e 100644
--- a/drivers/staging/fsl_qbman/fsl_usdpaa.c
+++ b/drivers/staging/fsl_qbman/fsl_usdpaa.c
@@ -1959,7 +1959,7 @@ static int __init usdpaa_init(void)
 	u64 tmp_start = phys_start;
 	u64 tmp_pfn_size = pfn_size;
 	u64 tmp_pfn_start = pfn_start;
-
+	printk(KERN_CRIT "Freescale USDPAA process driver\n");
 	pr_info("Freescale USDPAA process driver\n");
 	if (!phys_start) {
 		pr_warn("fsl-usdpaa: no region found\n");
diff --git a/drivers/tty/serial/sc16is7xx.c b/drivers/tty/serial/sc16is7xx.c
index ca54ce074a5f..fe7bc03f14d6 100644
--- a/drivers/tty/serial/sc16is7xx.c
+++ b/drivers/tty/serial/sc16is7xx.c
@@ -1264,9 +1264,9 @@ static int sc16is7xx_probe(struct device *dev,
 	}
 
 	/* Setup interrupt */
-	ret = devm_request_irq(dev, irq, sc16is7xx_irq,
-			       flags, dev_name(dev), s);
-	if (!ret)
+	ret = devm_request_any_context_irq(dev, irq, sc16is7xx_irq,
+			      IRQF_ONESHOT | flags, dev_name(dev), s);
+	if (ret > 0)
 		return 0;
 
 out_ports:
diff --git a/include/linux/fsl_oh_port.h b/include/linux/fsl_oh_port.h
new file mode 100644
index 000000000000..9f7eb1ebdf5f
--- /dev/null
+++ b/include/linux/fsl_oh_port.h
@@ -0,0 +1,28 @@
+/*
+ * include/linux/fsl_oh_port.h
+ *
+ * Definitions for offline parsing port device related flags or structures i
+ *
+ * Copyright 2004,2012 Freescale Semiconductor, Inc
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ */
+
+#ifndef _FSL_OH_PORT_H_
+#define _FSL_OH_PORT_H_
+
+#define MAX_FMANS               1
+#define MAX_OFFLINE_PORTS       4
+
+struct fman_offline_port_info {
+        char port_name[32];
+        uint32_t channel_id;
+        uint32_t err_fqid;
+        uint32_t default_fqid;
+};
+int oh_port_driver_get_port_info(struct fman_offline_port_info *info);
+
+#endif
diff --git a/include/linux/fsl_qman.h b/include/linux/fsl_qman.h
index 4e4b21d55169..cf7103e77c0b 100644
--- a/include/linux/fsl_qman.h
+++ b/include/linux/fsl_qman.h
@@ -3881,6 +3881,11 @@ int qman_p_enqueue_orp(struct qman_portal *p, struct qman_fq *fq,
 int qman_p_enqueue_precommit(struct qman_portal *p, struct qman_fq *fq,
 				const struct qm_fd *fd, u32 flags,
 				qman_cb_precommit cb, void *cb_arg);
+
+#define QOS_DEFAULT_QUEUE 7 
+ //Macro used to configure queue for control traffic, 7 is the highest
+ //  priority queue as per the ASK application
+#define QOS_LEAST_PRIORITY_QUEUE 0
 #ifdef __cplusplus
 }
 #endif
diff --git a/include/linux/if_bridge.h b/include/linux/if_bridge.h
index 3cd18ac0697f..51b1d1416290 100644
--- a/include/linux/if_bridge.h
+++ b/include/linux/if_bridge.h
@@ -57,6 +57,22 @@ extern void brioctl_set(int (*ioctl_hook)(struct net *, unsigned int, void __use
 typedef int br_should_route_hook_t(struct sk_buff *skb);
 extern br_should_route_hook_t __rcu *br_should_route_hook;
 
+#if defined(CONFIG_CPE_FAST_PATH)
+struct brevent_fdb_update{
+	char * mac_addr;
+	struct net_device * dev;
+};
+
+enum brevent_notif_type {
+	BREVENT_PORT_DOWN = 1,	/* arg is struct net_device ptr */
+	BREVENT_FDB_UPDATE	/* arg is struct brevent_fdb_update ptr */
+};
+
+int register_brevent_notifier(struct notifier_block *nb);
+int unregister_brevent_notifier(struct notifier_block *nb);
+int call_brevent_notifiers(unsigned long val, void *v);
+#endif
+
 #if IS_ENABLED(CONFIG_BRIDGE) && IS_ENABLED(CONFIG_BRIDGE_IGMP_SNOOPING)
 int br_multicast_list_adjacent(struct net_device *dev,
 			       struct list_head *br_ip_list);
diff --git a/include/linux/netdevice.h b/include/linux/netdevice.h
index e64c0879409c..58644548ce13 100644
--- a/include/linux/netdevice.h
+++ b/include/linux/netdevice.h
@@ -1673,6 +1673,10 @@ struct net_device {
 	netdev_features_t	mpls_features;
 	netdev_features_t	gso_partial_features;
 
+#if defined(CONFIG_CPE_FAST_PATH)
+	/* This is pointing to network device that offload WiFi data to PFE */
+	struct net_device 	*wifi_offload_dev;
+#endif
 	int			ifindex;
 	int			group;
 
@@ -2427,6 +2431,10 @@ void dev_close_many(struct list_head *head, bool unlink);
 void dev_disable_lro(struct net_device *dev);
 int dev_loopback_xmit(struct net *net, struct sock *sk, struct sk_buff *newskb);
 int dev_queue_xmit(struct sk_buff *skb);
+#if defined(CONFIG_CPE_FAST_PATH)
+int original_dev_queue_xmit(struct sk_buff *skb);
+#endif
+
 int dev_queue_xmit_accel(struct sk_buff *skb, void *accel_priv);
 int register_netdevice(struct net_device *dev);
 void unregister_netdevice_queue(struct net_device *dev, struct list_head *head);
@@ -3255,6 +3263,11 @@ int do_xdp_generic(struct bpf_prog *xdp_prog, struct sk_buff *skb);
 int netif_rx(struct sk_buff *skb);
 int netif_rx_ni(struct sk_buff *skb);
 int netif_receive_skb(struct sk_buff *skb);
+
+#if defined(CONFIG_CPE_FAST_PATH)
+int capture_receive_skb(struct sk_buff *skb);
+#endif
+
 gro_result_t napi_gro_receive(struct napi_struct *napi, struct sk_buff *skb);
 void napi_gro_flush(struct napi_struct *napi, bool flush_old);
 struct sk_buff *napi_get_frags(struct napi_struct *napi);
@@ -4446,4 +4459,7 @@ do {								\
 #define PTYPE_HASH_SIZE	(16)
 #define PTYPE_HASH_MASK	(PTYPE_HASH_SIZE - 1)
 
+//hook function for getting statistics from offloaded interfaces
+typedef void (*fp_iface_stats_get)(struct net_device *device, struct rtnl_link_stats64 *tot);
+
 #endif	/* _LINUX_NETDEVICE_H */
diff --git a/include/linux/skbuff.h b/include/linux/skbuff.h
index de3e7e5ff6df..94e807924a56 100644
--- a/include/linux/skbuff.h
+++ b/include/linux/skbuff.h
@@ -620,7 +620,10 @@ typedef unsigned char *sk_buff_data_t;
  *	@destructor: Destruct function
  *	@_nfct: Associated connection, if any (with nfctinfo bits)
  *	@nf_bridge: Saved data about a bridged frame - see br_netfilter.c
+ *	@abm_ff: sets 1 to process auto bridge module, otherwise ignore.
  *	@skb_iif: ifindex of device we arrived on
+ *	@iif_index: ifindex of device we arrived on,now skb->skb_iif
+ *	            always tracks skb->dev
  *	@tc_index: Traffic control index
  *	@hash: the packet hash
  *	@queue_mapping: Queue mapping for multiqueue devices
@@ -727,6 +730,11 @@ struct sk_buff {
 				__unused:1; /* one bit hole */
 	kmemcheck_bitfield_end(flags1);
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	__u16			ipsec_offload;
+	__u16			ipsec_xfrm_dir;
+#endif
+
 	/* fields enclosed in headers_start/headers_end are copied
 	 * using a single memcpy() in __copy_skb_header()
 	 */
@@ -794,6 +802,21 @@ struct sk_buff {
 	};
 	__u32			priority;
 	int			skb_iif;
+#ifdef CONFIG_CPE_FAST_PATH
+
+	/* This field is used to check bridge fast path in auto bridge module.
+	Instead of verifying the cb[] index, adding this new variable to the
+	structure. In some cases the cb[] index is not working. */
+	unsigned char		abm_ff;
+	/* skb->skb_iif always tracks skb->dev, so a new variable is introduced 
+           to keep incoming interface intact */
+	int			iif_index;
+	/* This field tracks bridge's incoming device when routing is done
+	through bridge and  also similarly tracks the iif just before the final logical interface,
+	when the final logical interface is a tunnel interface(4o6/6o4)
+	In all other cases iif_index and underlying_iif point to the same ifindex */
+	int			underlying_iif;
+#endif
 	__u32			hash;
 	__be16			vlan_proto;
 	__u16			vlan_tci;
@@ -835,6 +858,11 @@ struct sk_buff {
 	sk_buff_data_t		end;
 	unsigned char		*head,
 				*data;
+#if defined(CONFIG_COMCERTO_CUSTOM_SKB_LAYOUT)
+	unsigned char 		*mspd_data;
+	__u32 			mspd_len;
+	__u32 			mspd_ofst;
+#endif
 	unsigned int		truesize;
 	refcount_t		users;
 };
diff --git a/include/net/ip.h b/include/net/ip.h
index af8addbaa3c1..45954f07a692 100644
--- a/include/net/ip.h
+++ b/include/net/ip.h
@@ -542,6 +542,9 @@ enum ip_defrag_users {
 	IP_DEFRAG_VS_FWD,
 	IP_DEFRAG_AF_PACKET,
 	IP_DEFRAG_MACVLAN,
+#ifdef CONFIG_CPE_TNL_4RD
+	IP_DEFRAG_IP6_TNL_4RD /* Used to support Post Fragmentation for 4o6 tunnels */
+#endif
 };
 
 /* Return true if the value of 'user' is between 'lower_bond'
diff --git a/include/net/ip6_tunnel.h b/include/net/ip6_tunnel.h
index d66f70f63734..ef3201c24305 100644
--- a/include/net/ip6_tunnel.h
+++ b/include/net/ip6_tunnel.h
@@ -48,6 +48,12 @@ struct ip6_tnl {
 	struct dst_cache dst_cache;	/* cached dst */
 	struct gro_cells gro_cells;
 
+#if defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	u32 genid;
+#endif
+#ifdef	CONFIG_CPE_4RD_TUNNEL 
+	struct ip6_tnl_4rd_parm ip4rd; /* 4rd parameters for the tunnel */ 
+#endif
 	int err_count;
 	unsigned long err_time;
 
diff --git a/include/net/netfilter/nf_conntrack.h b/include/net/netfilter/nf_conntrack.h
index 792c3f6d30ce..5ea5df0f972a 100644
--- a/include/net/netfilter/nf_conntrack.h
+++ b/include/net/netfilter/nf_conntrack.h
@@ -26,6 +26,9 @@
 #include <net/netfilter/ipv6/nf_conntrack_icmpv6.h>
 
 #include <net/netfilter/nf_conntrack_tuple.h>
+#ifdef CONFIG_CPE_FAST_PATH
+#define COMCERTO_PERMANENT_TIMEOUT  1000
+#endif
 
 /* per conntrack: protocol private data */
 union nf_conntrack_proto {
@@ -47,6 +50,15 @@ union nf_conntrack_expect_proto {
 #include <net/netfilter/ipv4/nf_conntrack_ipv4.h>
 #include <net/netfilter/ipv6/nf_conntrack_ipv6.h>
 
+#if defined(CONFIG_CPE_FAST_PATH)
+struct comcerto_fp_info {
+	int ifindex;
+	int iif;
+	int underlying_iif;
+	u32 mark;
+};
+#endif
+
 struct nf_conn {
 	/* Usage count in here is 1 for hash table, 1 per skb,
 	 * plus 1 for any connection(s) we are `master' for
@@ -93,6 +105,9 @@ struct nf_conn {
 	u_int32_t secmark;
 #endif
 
+#if defined(CONFIG_CPE_FAST_PATH)
+    struct comcerto_fp_info fp_info[IP_CT_DIR_MAX];
+#endif
 	/* Extensions */
 	struct nf_ct_ext *ext;
 
@@ -255,6 +270,18 @@ static inline int nf_ct_is_dying(const struct nf_conn *ct)
 	return test_bit(IPS_DYING_BIT, &ct->status);
 }
 
+#ifdef CONFIG_CPE_FAST_PATH
+static inline int nf_ct_is_permanent(const struct nf_conn *ct)
+{
+	return test_bit(IPS_PERMANENT_BIT, &ct->status);
+}
+#endif
+
+static inline int nf_ct_is_untracked(const struct nf_conn *ct)
+{
+	return test_bit(IPS_UNTRACKED_BIT, &ct->status);
+}
+
 /* Packet is received from loopback */
 static inline bool nf_is_loopback_packet(const struct sk_buff *skb)
 {
@@ -268,10 +295,20 @@ static inline unsigned long nf_ct_expires(const struct nf_conn *ct)
 {
 	s32 timeout = ct->timeout - nfct_time_stamp;
 
+#ifdef CONFIG_CPE_FAST_PATH
+	return (nf_ct_is_permanent(ct))? COMCERTO_PERMANENT_TIMEOUT : ((timeout > 0) ? timeout : 0);
+#else
 	return timeout > 0 ? timeout : 0;
+#endif
 }
 
+
+#ifdef CONFIG_CPE_FAST_PATH
+bool nf_ct_is_expired(const struct nf_conn *ct);
+static inline bool __nf_ct_is_expired(const struct nf_conn *ct)
+#else
 static inline bool nf_ct_is_expired(const struct nf_conn *ct)
+#endif
 {
 	return (__s32)(ct->timeout - nfct_time_stamp) <= 0;
 }
@@ -285,6 +322,10 @@ static inline bool nf_ct_should_gc(const struct nf_conn *ct)
 
 struct kernel_param;
 
+#if defined(CONFIG_CPE_FAST_PATH)
+extern int nf_conntrack_set_dpi_allow_report(struct sk_buff *skb);
+extern int nf_conntrack_set_dpi_allow_and_mark(struct sk_buff *skb, int mark);
+#endif
 int nf_conntrack_set_hashsize(const char *val, struct kernel_param *kp);
 int nf_conntrack_hash_resize(unsigned int hashsize);
 
diff --git a/include/net/netns/xfrm.h b/include/net/netns/xfrm.h
index 9991e5ef52cc..eebe8542dddd 100644
--- a/include/net/netns/xfrm.h
+++ b/include/net/netns/xfrm.h
@@ -41,6 +41,9 @@ struct netns_xfrm {
 	struct hlist_head	__rcu *state_bydst;
 	struct hlist_head	__rcu *state_bysrc;
 	struct hlist_head	__rcu *state_byspi;
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	struct hlist_head	__rcu *state_byh;
+#endif
 	unsigned int		state_hmask;
 	unsigned int		state_num;
 	struct work_struct	state_hash_work;
diff --git a/include/net/tcp.h b/include/net/tcp.h
index 0a13574134b8..6d10a77c61e2 100644
--- a/include/net/tcp.h
+++ b/include/net/tcp.h
@@ -130,6 +130,10 @@ void tcp_time_wait(struct sock *sk, int state, int timeo);
 				  */
 
 #define TCP_DELACK_MAX	((unsigned)(HZ/5))	/* maximal time to delay before sending an ACK */
+#ifdef CONFIG_COMCERTO_TCP_DELACK_MIN
+#define TCP_DELACK_MIN	((unsigned)(HZ/100))
+#define TCP_ATO_MIN	((unsigned)(HZ/100))
+#else
 #if HZ >= 100
 #define TCP_DELACK_MIN	((unsigned)(HZ/25))	/* minimal time to delay before sending an ACK */
 #define TCP_ATO_MIN	((unsigned)(HZ/25))
@@ -137,6 +141,7 @@ void tcp_time_wait(struct sock *sk, int state, int timeo);
 #define TCP_DELACK_MIN	4U
 #define TCP_ATO_MIN	4U
 #endif
+#endif
 #define TCP_RTO_MAX	((unsigned)(120*HZ))
 #define TCP_RTO_MIN	((unsigned)(HZ/5))
 #define TCP_TIMEOUT_MIN	(2U) /* Min timeout for TCP timers in jiffies */
diff --git a/include/net/udp.h b/include/net/udp.h
index 6c759c8594e2..d421fbfb1475 100644
--- a/include/net/udp.h
+++ b/include/net/udp.h
@@ -284,6 +284,11 @@ int udp_lib_getsockopt(struct sock *sk, int level, int optname,
 int udp_lib_setsockopt(struct sock *sk, int level, int optname,
 		       char __user *optval, unsigned int optlen,
 		       int (*push_pending_frames)(struct sock *));
+#ifdef CONFIG_CPE_NATT
+int 	udp6_lib_setsockopt(struct sock *sk, int level, int optname,
+				   char __user *optval, unsigned int optlen,
+				   int (*push_pending_frames)(struct sock *));
+#endif
 struct sock *udp4_lib_lookup(struct net *net, __be32 saddr, __be16 sport,
 			     __be32 daddr, __be16 dport, int dif);
 struct sock *__udp4_lib_lookup(struct net *net, __be32 saddr, __be16 sport,
diff --git a/include/net/xfrm.h b/include/net/xfrm.h
index e015e164bac0..e13108e91cbb 100644
--- a/include/net/xfrm.h
+++ b/include/net/xfrm.h
@@ -140,6 +140,11 @@ struct xfrm_state {
 	};
 	struct hlist_node	bysrc;
 	struct hlist_node	byspi;
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	struct hlist_node 	byh;
+	u16			handle;
+	u16			in_byh_hash;
+#endif
 
 	refcount_t		refcnt;
 	spinlock_t		lock;
@@ -244,6 +249,11 @@ struct xfrm_state {
 	/* Private data of this transformer, format is opaque,
 	 * interpreted by xfrm_type methods. */
 	void			*data;
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	 /* Intended direction of this state, used for offloading */
+	int	dir;
+	int	offloaded;	
+#endif
 };
 
 static inline struct net *xs_net(struct xfrm_state *x)
@@ -263,6 +273,13 @@ enum {
 	XFRM_STATE_EXPIRED,
 	XFRM_STATE_DEAD
 };
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+enum {
+	 XFRM_STATE_DIR_UNKNOWN,
+	 XFRM_STATE_DIR_IN,
+	 XFRM_STATE_DIR_OUT,
+};
+#endif
 
 /* callback structure passed from either netlink or pfkey */
 struct km_event {
@@ -321,8 +338,12 @@ struct xfrm_policy_afinfo {
 
 int xfrm_policy_register_afinfo(const struct xfrm_policy_afinfo *afinfo, int family);
 void xfrm_policy_unregister_afinfo(const struct xfrm_policy_afinfo *afinfo);
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+struct xfrm_policy_afinfo *xfrm_policy_get_afinfo(unsigned short family);
+#endif
 void km_policy_notify(struct xfrm_policy *xp, int dir,
 		      const struct km_event *c);
+
 void xfrm_policy_cache_flush(void);
 void km_state_notify(struct xfrm_state *x, const struct km_event *c);
 
@@ -1044,6 +1065,35 @@ struct sec_path {
 	struct xfrm_offload	ovec[XFRM_MAX_OFFLOAD_DEPTH];
 };
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+struct xfrm_input_shared
+{
+	struct sk_buff 		*skb;
+	int 			xfrm_nr, first, xfrm_encap;
+	struct xfrm_state 	*xfrm_vec[XFRM_MAX_DEPTH];
+	__u16 			encap_type;
+	int 			decaps;
+	u32			seq, spi;
+	unsigned int   nhoff;
+	int 			nexthdr;
+	int 			(*callback)(struct xfrm_input_shared *sh);
+	atomic_t		refcnt;
+};
+
+
+static inline void xfrm_shared_get(struct xfrm_input_shared *sh)
+{
+	atomic_inc(&sh->refcnt);
+}
+
+static inline void xfrm_shared_put(struct xfrm_input_shared *sh)
+{
+	if (atomic_dec_and_test(&sh->refcnt)) {
+		kfree(sh);
+	}
+}
+#endif
+
 static inline int secpath_exists(struct sk_buff *skb)
 {
 #ifdef CONFIG_XFRM
@@ -1602,6 +1652,13 @@ int xfrm4_tunnel_deregister(struct xfrm_tunnel *handler, unsigned short family);
 void xfrm4_local_error(struct sk_buff *skb, u32 mtu);
 int xfrm6_extract_header(struct sk_buff *skb);
 int xfrm6_extract_input(struct xfrm_state *x, struct sk_buff *skb);
+
+#ifdef CONFIG_CPE_NATT
+/* NAT-T changes Start */
+int xfrm6_rcv_encap(struct sk_buff *skb, int nexthdr, __be32 spi,
+			   int encap_type);
+/* NAT-T changes End */
+#endif
 int xfrm6_rcv_spi(struct sk_buff *skb, int nexthdr, __be32 spi,
 		  struct ip6_tnl *t);
 int xfrm6_transport_finish(struct sk_buff *skb, int async);
@@ -1626,6 +1683,9 @@ int xfrm6_find_1stfragopt(struct xfrm_state *x, struct sk_buff *skb,
 
 #ifdef CONFIG_XFRM
 int xfrm4_udp_encap_rcv(struct sock *sk, struct sk_buff *skb);
+#ifdef CONFIG_CPE_NATT
+int xfrm6_udp_encap_rcv(struct sock *sk, struct sk_buff *skb);
+#endif
 int xfrm_user_policy(struct sock *sk, int optname,
 		     u8 __user *optval, int optlen);
 #else
@@ -1633,6 +1693,16 @@ static inline int xfrm_user_policy(struct sock *sk, int optname, u8 __user *optv
 {
  	return -ENOPROTOOPT;
 } 
+#ifdef CONFIG_CPE_NATT
+/* NAT-T changes Start */
+static inline int xfrm6_udp_encap_rcv(struct sock *sk, struct sk_buff *skb)
+{
+	/* should not happen */
+	kfree_skb(skb);
+	return 0;
+}
+/* NAT-T changes End */
+#endif
 
 static inline int xfrm4_udp_encap_rcv(struct sock *sk, struct sk_buff *skb)
 {
diff --git a/include/uapi/linux/fmd/Peripherals/fm_ioctls.h b/include/uapi/linux/fmd/Peripherals/fm_ioctls.h
index e0c2dd31363a..0f151470b0ac 100644
--- a/include/uapi/linux/fmd/Peripherals/fm_ioctls.h
+++ b/include/uapi/linux/fmd/Peripherals/fm_ioctls.h
@@ -617,6 +617,34 @@ typedef struct ioc_fm_ctrl_mon_counters_params_t {
 #endif
 #define FM_IOC_CTRL_MON_GET_COUNTERS                       _IOW(FM_IOC_TYPE_BASE, FM_IOC_NUM(17), ioc_fm_ctrl_mon_counters_params_t)
 
+/**************************************************************************//**
+ @Function      FM_ReadTimeStamp
+
+ @Description   Reads the FMan engine's timestamp.
+
+ @Param[out]    uint32_t                   The indicated engine's timestamp
+
+ @Return        E_OK on success; Error code otherwise.
+
+ @Cautions      Allowed only following FM_Init().
+*//***************************************************************************/
+#define FM_IOC_READ_TIMESTAMP                              _IOWR(FM_IOC_TYPE_BASE, FM_IOC_NUM(18), uint32_t)
+
+/**************************************************************************//**
+ @Function      FM_GetTimeStampIncrementPerUsec
+
+ @Description   Provides the value of the FMan engine's timestamp increment
+                per microsecond.
+
+ @Param[out]    uint32_t                   The value the timestamp is
+                                           incremented with each microsecond
+
+ @Return        E_OK on success; Error code otherwise.
+
+ @Cautions      Allowed only following FM_Init().
+*//***************************************************************************/
+#define FM_IOC_GET_TIMESTAMP_INCREMENT                     _IOWR(FM_IOC_TYPE_BASE, FM_IOC_NUM(19), uint32_t)
+
 /** @} */ /* end of lnx_ioctl_FM_runtime_control_grp group */
 /** @} */ /* end of lnx_ioctl_FM_lib_grp group */
 /** @} */ /* end of lnx_ioctl_FM_grp */
diff --git a/include/uapi/linux/fmd/Peripherals/fm_pcd_ioctls.h b/include/uapi/linux/fmd/Peripherals/fm_pcd_ioctls.h
index d13e878d5566..4aacaf3db462 100644
--- a/include/uapi/linux/fmd/Peripherals/fm_pcd_ioctls.h
+++ b/include/uapi/linux/fmd/Peripherals/fm_pcd_ioctls.h
@@ -1,4 +1,5 @@
 /* Copyright (c) 2008-2012 Freescale Semiconductor, Inc.
+ * Copyright 2017-2018 NXP
  * All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -1412,6 +1413,14 @@ typedef struct ioc_fm_pcd_cc_key_params_t {
                                                  of the same size defined in the key_size */
     ioc_fm_pcd_cc_next_engine_params_t  cc_next_engine_params;
                                             /**< parameters for the next for the defined Key in p_key */
+#if 0 // following fields not defined in ioc_fm_pcd_cc_key_params_t 
+#if (DPAA_VERSION >= 11)
+    uint32_t                   internal_tstamp:1; /* set to use internal FMAN time stamp */
+    uint32_t                   reserved:29;
+    uint32_t                   ext_timer_id:2; /* time stamp timer to use */
+    uintptr_t	monitor_addr;
+#endif /* (DPAA_VERSION >= 11) */
+#endif // 0
 
 } ioc_fm_pcd_cc_key_params_t;
 
@@ -1510,6 +1519,37 @@ typedef struct ioc_fm_pcd_hash_table_params_t {
 
     ioc_fm_pcd_cc_next_engine_params_t   cc_next_engine_params_for_miss;
                                                             /**< Parameters for defining the next engine when a key is not matched */
+
+    bool			aging_support;							/**< TRUE to enable aging support for all keys of this hash table;
+                                                                 Aging status of a key enables the application to monitor if the
+                                                                 key was accessed for a certain period of time, meaning if a
+                                                                 packet that matches this key was received since this bit was last
+                                                                 set by the application */
+
+#if (DPAA_VERSION >= 11)
+    bool			external_hash;
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+    uint32_t    table_type;    /* ip reassembly table */
+    //valid for reassembly tables only
+    struct {
+        uint32_t timeout_val;   //reassembly timeout
+        uint32_t timeout_fqid;  //fqid for reassmebly failures
+        uint32_t max_frags;     //max allowed fragments
+        uint32_t min_frag_size; //min allowed frag size except last frag
+        uint32_t max_sessions;  //max conn reassembly sessions
+    };
+#endif
+
+    struct {
+    	uint8_t		data_mem_id;							/**< Memory partition ID for the external hash table buckets and contexts;
+    	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 Must not cross the 4GB boundaries*/
+
+    	uint16_t	data_liodn_offs;						/**< LIODN offset for access the external hash table buckets and contexts */
+
+    	uintptr_t	miss_monitor_addr;						/**< user allocated miss monitor address */
+    } external_hash_params;
+#endif /* (DPAA_VERSION >= 11) */
+
     void                        *id;
 } ioc_fm_pcd_hash_table_params_t;
 
diff --git a/include/uapi/linux/if.h b/include/uapi/linux/if.h
index 7fea0fd7d6f5..9bf350437bd0 100644
--- a/include/uapi/linux/if.h
+++ b/include/uapi/linux/if.h
@@ -103,6 +103,9 @@ enum net_device_flags {
 	IFF_DORMANT			= 1<<17, /* volatile */
 	IFF_ECHO			= 1<<18, /* volatile */
 #endif /* __UAPI_DEF_IF_NET_DEVICE_FLAGS_LOWER_UP_DORMANT_ECHO */
+#if defined(CONFIG_CPE_FAST_PATH)
+	IFF_WIFI_OFLD		= 1<<19, /*Offload interface */
+#endif
 };
 #endif /* __UAPI_DEF_IF_NET_DEVICE_FLAGS_LOWER_UP_DORMANT_ECHO != 0 || __UAPI_DEF_IF_NET_DEVICE_FLAGS != 0 */
 
@@ -131,6 +134,9 @@ enum net_device_flags {
 #define IFF_DORMANT			IFF_DORMANT
 #define IFF_ECHO			IFF_ECHO
 #endif /* __UAPI_DEF_IF_NET_DEVICE_FLAGS_LOWER_UP_DORMANT_ECHO */
+#if defined(CONFIG_CPE_FAST_PATH)
+#define IFF_WIFI_OFLD		IFF_WIFI_OFLD
+#endif
 
 #define IFF_VOLATILE	(IFF_LOOPBACK|IFF_POINTOPOINT|IFF_BROADCAST|IFF_ECHO|\
 		IFF_MASTER|IFF_SLAVE|IFF_RUNNING|IFF_LOWER_UP|IFF_DORMANT)
diff --git a/include/uapi/linux/if_arp.h b/include/uapi/linux/if_arp.h
index 4605527ca41b..f66830900288 100644
--- a/include/uapi/linux/if_arp.h
+++ b/include/uapi/linux/if_arp.h
@@ -98,7 +98,9 @@
 #define ARPHRD_NETLINK	824		/* Netlink header		*/
 #define ARPHRD_6LOWPAN	825		/* IPv6 over LoWPAN             */
 #define ARPHRD_VSOCKMON	826		/* Vsock monitor header		*/
-
+#if defined(CONFIG_CPE_FAST_PATH)
+#define ARPHRD_IPV6_IPV6_TUNNEL   ARPHRD_ETHER 
+#endif
 #define ARPHRD_VOID	  0xFFFF	/* Void type, nothing is known */
 #define ARPHRD_NONE	  0xFFFE	/* zero header length */
 
diff --git a/include/uapi/linux/if_ether.h b/include/uapi/linux/if_ether.h
index 3ee3bf7c8526..77e7d70453e1 100644
--- a/include/uapi/linux/if_ether.h
+++ b/include/uapi/linux/if_ether.h
@@ -39,6 +39,9 @@
 #define ETH_MIN_MTU	68		/* Min IPv4 MTU per RFC791	*/
 #define ETH_MAX_MTU	0xFFFFU		/* 65535, same as IP_MAX_MTU	*/
 
+#ifdef CONFIG_CPE_ETHERIP
+#define ETH_IPHLEN      2               /* EtherIP header length         */
+#endif
 /*
  *	These are the defined Ethernet Protocol ID's.
  */
diff --git a/include/uapi/linux/if_tunnel.h b/include/uapi/linux/if_tunnel.h
index 383b850aeb88..c28acd235171 100644
--- a/include/uapi/linux/if_tunnel.h
+++ b/include/uapi/linux/if_tunnel.h
@@ -21,6 +21,18 @@
 #define SIOCADD6RD      (SIOCDEVPRIVATE + 9)
 #define SIOCDEL6RD      (SIOCDEVPRIVATE + 10)
 #define SIOCCHG6RD      (SIOCDEVPRIVATE + 11)
+#ifdef CONFIG_CPE_4RD_TUNNEL
+#define SIOCGET4RD      (SIOCDEVPRIVATE + 12)
+#define SIOCADD4RD      (SIOCDEVPRIVATE + 13)
+#define SIOCDEL4RD      (SIOCDEVPRIVATE + 14)
+#define SIOCCHG4RD      (SIOCDEVPRIVATE + 15)
+#endif
+//#define COMCERTO_ETHERIPV4
+#ifdef CONFIG_CPE_ETHERIP
+/* SIOCCHG4RD is currently not used and even if it were, these two tunnels would never co-inside*/
+/* MSPD Added */
+#define SIOCISETHIPV4TUNNEL  (SIOCDEVPRIVATE + 15)
+#endif
 
 #define GRE_CSUM	__cpu_to_be16(0x8000)
 #define GRE_ROUTING	__cpu_to_be16(0x4000)
@@ -113,6 +125,22 @@ struct ip_tunnel_6rd {
 	__u16			relay_prefixlen;
 };
 
+#ifdef CONFIG_CPE_4RD_TUNNEL
+/* ip6 tnl 4rd parm -start  */ 
+struct ip6_tnl_4rd {
+       __be32                  prefix;
+       struct in6_addr         relay_prefix;
+       struct in6_addr         relay_suffix;
+       __u16                   prefixlen;
+       __u16                   relay_prefixlen;
+       __u16                   relay_suffixlen;
+       __u16                   psid_offsetlen;
+       __u16                   eabit_len;
+       __u16                   entry_num;
+};
+/* ip6 tnl 4rd parm -end  */ 
+#endif
+
 enum {
 	IFLA_GRE_UNSPEC,
 	IFLA_GRE_LINK,
diff --git a/include/uapi/linux/in.h b/include/uapi/linux/in.h
index 48e8a225b985..ab508b3a55db 100644
--- a/include/uapi/linux/in.h
+++ b/include/uapi/linux/in.h
@@ -62,6 +62,10 @@ enum {
 #define IPPROTO_MTP		IPPROTO_MTP
   IPPROTO_BEETPH = 94,		/* IP option pseudo header for BEET	*/
 #define IPPROTO_BEETPH		IPPROTO_BEETPH
+#ifdef CONFIG_CPE_ETHERIP
+  IPPROTO_ETHERIP = 97,        /* IP option for EtherIP tunnel (rfc 3378) */
+#define IPPROTO_ETHERIP		IPPROTO_ETHERIP
+#endif
   IPPROTO_ENCAP = 98,		/* Encapsulation Header			*/
 #define IPPROTO_ENCAP		IPPROTO_ENCAP
   IPPROTO_PIM = 103,		/* Protocol Independent Multicast	*/
diff --git a/include/uapi/linux/ip6_tunnel.h b/include/uapi/linux/ip6_tunnel.h
index 51f29308ac6d..1c757b15dddc 100644
--- a/include/uapi/linux/ip6_tunnel.h
+++ b/include/uapi/linux/ip6_tunnel.h
@@ -51,4 +51,52 @@ struct ip6_tnl_parm2 {
 	__be32			o_key;
 };
 
+#ifdef CONFIG_CPE_4RD_TUNNEL 
+struct ip6_4rd_map_msg {
+       __u32 reset;
+       __u32 ifindex;
+       __be32 prefix;
+       __u16 prefixlen;
+       struct in6_addr relay_prefix;
+       struct in6_addr relay_suffix;
+       __u16 relay_prefixlen;
+       __u16 relay_suffixlen;
+       __u16 psid_offsetlen;
+       __u16 eabit_len;
+       __u16 entry_num;
+};
+
+struct ip6_tnl_4rd_map_rule {
+       __be32 prefix;
+       __u16 prefixlen;
+       struct in6_addr relay_prefix;
+       struct in6_addr relay_suffix;
+       __u16 relay_prefixlen;
+       __u16 relay_suffixlen;
+       __u16 psid_offsetlen;
+       __u16 eabit_len;
+       __u16 entry_num;
+       struct list_head mr_list;
+};
+
+#ifdef __KERNEL__
+struct ip6_tnl_4rd_parm {
+       __be32 prefix;
+       struct in6_addr relay_prefix;
+       struct in6_addr relay_suffix;
+       __u16 prefixlen;
+       __u16 relay_prefixlen;
+       __u16 relay_suffixlen;
+       __be32 laddr4;
+       __u16 port_set_id;
+       __u16 port_set_id_len;
+       __u16 psid_offsetlen;
+       __u16 eabit_len;
+
+       struct list_head map_list;
+       rwlock_t map_lock;
+};
+#endif
+#endif
+
 #endif
diff --git a/include/uapi/linux/netfilter/nf_conntrack_common.h b/include/uapi/linux/netfilter/nf_conntrack_common.h
index 3fea7709a441..7fd03c8384d4 100644
--- a/include/uapi/linux/netfilter/nf_conntrack_common.h
+++ b/include/uapi/linux/netfilter/nf_conntrack_common.h
@@ -101,14 +101,29 @@ enum ip_conntrack_status {
 	IPS_HELPER_BIT = 13,
 	IPS_HELPER = (1 << IPS_HELPER_BIT),
 
+
+#ifdef CONFIG_CPE_FAST_PATH
+	/* Connection  cannot expire */
+	IPS_PERMANENT_BIT = 14,
+	IPS_PERMANENT = (1 << IPS_PERMANENT_BIT),
+
+	/* Connection is assured by DPI application */
+	IPS_DPI_ALLOWED_BIT = 15,
+	IPS_DPI_ALLOWED = (1 << IPS_DPI_ALLOWED_BIT),
+#endif
+#if 1 //harish
+
 	/* Be careful here, modifying these bits can make things messy,
 	 * so don't let users modify them directly.
 	 */
+
 	IPS_UNCHANGEABLE_MASK = (IPS_NAT_DONE_MASK | IPS_NAT_MASK |
-				 IPS_EXPECTED | IPS_CONFIRMED | IPS_DYING |
-				 IPS_SEQ_ADJUST | IPS_TEMPLATE),
+			IPS_EXPECTED | IPS_CONFIRMED | IPS_DYING |
+			IPS_SEQ_ADJUST | IPS_TEMPLATE),
+	__IPS_MAX_BIT = 16,
+#endif
+
 
-	__IPS_MAX_BIT = 14,
 };
 
 /* Connection tracking event types */
diff --git a/include/uapi/linux/netfilter/nf_conntrack_tuple_common.h b/include/uapi/linux/netfilter/nf_conntrack_tuple_common.h
index 64390fac6f7e..819b166adcb4 100644
--- a/include/uapi/linux/netfilter/nf_conntrack_tuple_common.h
+++ b/include/uapi/linux/netfilter/nf_conntrack_tuple_common.h
@@ -13,6 +13,9 @@ enum ip_conntrack_dir {
 	IP_CT_DIR_REPLY,
 	IP_CT_DIR_MAX
 };
+#ifdef CONFIG_CPE_4RD_TUNNEL
+#define IP_NAT_RANGE_4RD_NAPT 16
+#endif
 
 /* The protocol-specific manipulable parts of the tuple: always in
  * network order
diff --git a/include/uapi/linux/netfilter/nfnetlink_conntrack.h b/include/uapi/linux/netfilter/nfnetlink_conntrack.h
index 7397e022ce6e..4161b3be3a6b 100644
--- a/include/uapi/linux/netfilter/nfnetlink_conntrack.h
+++ b/include/uapi/linux/netfilter/nfnetlink_conntrack.h
@@ -54,6 +54,10 @@ enum ctattr_type {
 	CTA_MARK_MASK,
 	CTA_LABELS,
 	CTA_LABELS_MASK,
+#if defined(CONFIG_CPE_FAST_PATH)
+    CTA_COMCERTO_FP_ORIG,
+    CTA_COMCERTO_FP_REPLY,
+#endif
 	__CTA_MAX
 };
 #define CTA_MAX (__CTA_MAX - 1)
@@ -230,6 +234,18 @@ enum ctattr_secctx {
 };
 #define CTA_SECCTX_MAX (__CTA_SECCTX_MAX - 1)
 
+#if defined(CONFIG_CPE_FAST_PATH)
+enum ctattr_comcerto_fp {
+    CTA_COMCERTO_FP_UNSPEC,
+    CTA_COMCERTO_FP_MARK,
+    CTA_COMCERTO_FP_IFINDEX,
+    CTA_COMCERTO_FP_IIF,
+    CTA_COMCERTO_FP_UNDERLYING_IIF,
+    __CTA_COMCERTO_FP_MAX
+};
+#define CTA_COMCERTO_FP_MAX (__CTA_COMCERTO_FP_MAX - 1)
+#endif
+
 enum ctattr_stats_cpu {
 	CTA_STATS_UNSPEC,
 	CTA_STATS_SEARCHED,	/* no longer used */
diff --git a/include/uapi/linux/netlink.h b/include/uapi/linux/netlink.h
index 776bc92e9118..17240ad44b23 100644
--- a/include/uapi/linux/netlink.h
+++ b/include/uapi/linux/netlink.h
@@ -30,9 +30,17 @@
 #define NETLINK_CRYPTO		21	/* Crypto layer */
 #define NETLINK_SMC		22	/* SMC monitoring */
 
+#ifdef CONFIG_CPE_FAST_PATH
+#define NETLINK_FF              30
+#define NETLINK_KEY             32
+#define NETLINK_L2FLOW          33
+#define MAX_LINKS 64		
+#else
+#define MAX_LINKS 32		
+#endif
+
 #define NETLINK_INET_DIAG	NETLINK_SOCK_DIAG
 
-#define MAX_LINKS 32		
 
 struct sockaddr_nl {
 	__kernel_sa_family_t	nl_family;	/* AF_NETLINK	*/
diff --git a/include/uapi/linux/pfkeyv2.h b/include/uapi/linux/pfkeyv2.h
index d65b11785260..f463081e4655 100644
--- a/include/uapi/linux/pfkeyv2.h
+++ b/include/uapi/linux/pfkeyv2.h
@@ -281,6 +281,9 @@ struct sadb_x_filter {
 #define SADB_SAFLAGS_NOPMTUDISC	0x20000000
 #define SADB_SAFLAGS_DECAP_DSCP	0x40000000
 #define SADB_SAFLAGS_NOECN	0x80000000
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+#define SADB_SAFLAGS_ESN    0x01000000
+#endif
 
 /* Security Association states */
 #define SADB_SASTATE_LARVAL	0
diff --git a/include/uapi/linux/ppp-ioctl.h b/include/uapi/linux/ppp-ioctl.h
index b19a9c249b15..563d7a9e3d02 100644
--- a/include/uapi/linux/ppp-ioctl.h
+++ b/include/uapi/linux/ppp-ioctl.h
@@ -113,6 +113,9 @@ struct pppol2tp_ioc_stats {
 #define PPPIOCATTCHAN	_IOW('t', 56, int)	/* attach to ppp channel */
 #define PPPIOCGCHAN	_IOR('t', 55, int)	/* get ppp channel number */
 #define PPPIOCGL2TPSTATS _IOR('t', 54, struct pppol2tp_ioc_stats)
+#if defined(CONFIG_CPE_FAST_PATH)
+#define PPPIOCSFPPIDLE	_IOW('t', 53, struct ppp_idle)	/* Set the FPP stats */
+#endif
 
 #define SIOCGPPPSTATS   (SIOCDEVPRIVATE + 0)
 #define SIOCGPPPVER     (SIOCDEVPRIVATE + 1)	/* NEVER change this!! */
diff --git a/include/uapi/linux/rtnetlink.h b/include/uapi/linux/rtnetlink.h
index a6d37c2ea355..5687a08dea73 100644
--- a/include/uapi/linux/rtnetlink.h
+++ b/include/uapi/linux/rtnetlink.h
@@ -150,6 +150,14 @@ enum {
 	RTM_NEWCACHEREPORT = 96,
 #define RTM_NEWCACHEREPORT RTM_NEWCACHEREPORT
 
+#ifdef CONFIG_CPE_4RD_TUNNEL
+       RTM_NEW4RD = 96,
+#define RTM_NEW4RD      RTM_NEW4RD
+       RTM_DEL4RD,
+#define RTM_DEL4RD      RTM_DEL4RD
+       RTM_GET4RD,
+#define RTM_GET4RD      RTM_GET4RD
+#endif
 	__RTM_MAX,
 #define RTM_MAX		(((__RTM_MAX + 3) & ~3) - 1)
 };
diff --git a/net/Kconfig b/net/Kconfig
index 9dba2715919d..e50039993d3f 100644
--- a/net/Kconfig
+++ b/net/Kconfig
@@ -85,6 +85,14 @@ config INET
 	  Short answer: say Y.
 
 if INET
+
+config CPE_FAST_PATH
+        bool "Fast Path Processing offload"
+	default y
+        depends on ARCH_LAYERSCAPE 
+                ---help---
+          Support for Fast Path offload.
+
 source "net/ipv4/Kconfig"
 source "net/ipv6/Kconfig"
 source "net/netlabel/Kconfig"
diff --git a/net/bridge/br.c b/net/bridge/br.c
index 1407d1ba7577..468922db1bbe 100644
--- a/net/bridge/br.c
+++ b/net/bridge/br.c
@@ -277,6 +277,60 @@ static void __exit br_deinit(void)
 	br_fdb_fini();
 }
 
+#if defined(CONFIG_CPE_FAST_PATH)
+static ATOMIC_NOTIFIER_HEAD(brevent_notif_chain);
+
+/**
+ *	register_brevent_notifier - register a netevent notifier block
+ *	@nb: notifier
+ *
+ *	Register a notifier to be called when a bridge event occurs.
+ *	The notifier passed is linked into the kernel structures and must
+ *	not be reused until it has been unregistered. A negative errno code
+ *	is returned on a failure.
+ */
+int register_brevent_notifier(struct notifier_block *nb)
+{
+	int err;
+
+	err = atomic_notifier_chain_register(&brevent_notif_chain, nb);
+	return err;
+}
+
+/**
+ *	unregister_brevent_notifier - unregister a netevent notifier block
+ *	@nb: notifier
+ *
+ *	Unregister a notifier previously registered by
+ *	register_neigh_notifier(). The notifier is unlinked into the
+ *	kernel structures and may then be reused. A negative errno code
+ *	is returned on a failure.
+ */
+
+int unregister_brevent_notifier(struct notifier_block *nb)
+{
+	return atomic_notifier_chain_unregister(&brevent_notif_chain, nb);
+}
+
+/**
+ *	call_brevent_notifiers - call all netevent notifier blocks
+ *      @val: value passed unmodified to notifier function
+ *      @v:   pointer passed unmodified to notifier function
+ *
+ *	Call all neighbour notifier blocks.  Parameters and return value
+ *	are as for notifier_call_chain().
+ */
+
+int call_brevent_notifiers(unsigned long val, void *v)
+{
+	return atomic_notifier_call_chain(&brevent_notif_chain, val, v);
+}
+
+EXPORT_SYMBOL_GPL(register_brevent_notifier);
+EXPORT_SYMBOL_GPL(unregister_brevent_notifier);
+EXPORT_SYMBOL_GPL(call_brevent_notifiers);
+#endif
+
 module_init(br_init)
 module_exit(br_deinit)
 MODULE_LICENSE("GPL");
diff --git a/net/bridge/br_fdb.c b/net/bridge/br_fdb.c
index 4ea5c8bbe286..0d9d6d7c9294 100644
--- a/net/bridge/br_fdb.c
+++ b/net/bridge/br_fdb.c
@@ -18,6 +18,10 @@
 #include <linux/times.h>
 #include <linux/netdevice.h>
 #include <linux/etherdevice.h>
+#if defined(CONFIG_CPE_FAST_PATH)
+#include <linux/rtnetlink.h>
+#include <linux/module.h>
+#endif
 #include <linux/jhash.h>
 #include <linux/random.h>
 #include <linux/slab.h>
@@ -36,6 +40,11 @@ static void fdb_notify(struct net_bridge *br,
 
 static u32 fdb_salt __read_mostly;
 
+#if defined(CONFIG_CPE_FAST_PATH)
+	int(*br_fdb_can_expire)(unsigned char *mac_addr, struct net_device *dev) = NULL;
+	DEFINE_SPINLOCK(br_fdb_cb_lock);
+#endif
+
 int __init br_fdb_init(void)
 {
 	br_fdb_cache = kmem_cache_create("bridge_fdb_cache",
@@ -46,6 +55,9 @@ int __init br_fdb_init(void)
 		return -ENOMEM;
 
 	get_random_bytes(&fdb_salt, sizeof(fdb_salt));
+#if defined(CONFIG_CPE_FAST_PATH)
+	spin_lock_init(&br_fdb_cb_lock);
+#endif
 	return 0;
 }
 
@@ -172,6 +184,21 @@ static void fdb_del_hw_addr(struct net_bridge *br, const unsigned char *addr)
 
 static void fdb_delete(struct net_bridge *br, struct net_bridge_fdb_entry *f)
 {
+#if defined(CONFIG_CPE_FAST_PATH)
+	struct net_bridge_port *this_port = f->dst, *p;
+	
+	if (f->is_local) {
+		list_for_each_entry(p, &br->port_list, list) {
+			if (this_port == p)
+				continue;
+			//ensure port is not NULL before using dev member from it
+			if (this_port) {
+				dev_uc_del(this_port->dev, p->dev->dev_addr);
+			}
+			dev_uc_del(p->dev, f->addr.addr);
+		}
+	}
+#endif
 	trace_fdb_delete(br, f);
 
 	if (f->is_static)
@@ -198,8 +225,22 @@ static void fdb_delete_local(struct net_bridge *br,
 		vg = nbp_vlan_group(op);
 		if (op != p && ether_addr_equal(op->dev->dev_addr, addr) &&
 		    (!vid || br_vlan_find(vg, vid))) {
+#if defined(CONFIG_CPE_FAST_PATH)
+			struct net_bridge_port *this_port = f->dst, *p1;
+#endif
 			f->dst = op;
 			f->added_by_user = 0;
+#if defined(CONFIG_CPE_FAST_PATH)
+			/*
+			* dev_uc_del()can not be called in fdb_delete() as f->dst may be NULL there.
+			*  so calling dev_uc_del here itself. refer DNCPE-31 for fix on LS1024
+			*/
+			list_for_each_entry(p1, &br->port_list, list) {
+				if (this_port == p1)
+					continue;
+				dev_uc_del(this_port->dev, p1->dev->dev_addr);
+			}
+#endif
 			return;
 		}
 	}
@@ -336,6 +377,15 @@ void br_fdb_cleanup(struct work_struct *work)
 				continue;
 			if (f->added_by_external_learn)
 				continue;
+#if defined(CONFIG_CPE_FAST_PATH)
+				spin_lock(&br_fdb_cb_lock);
+				if(br_fdb_can_expire && !(*br_fdb_can_expire)(f->addr.addr, f->dst->dev)){
+					f->updated = jiffies;
+					spin_unlock(&br_fdb_cb_lock);
+					continue;
+				}
+				spin_unlock(&br_fdb_cb_lock);
+#endif
 			this_timer = f->updated + delay;
 			if (time_after(this_timer, now))
 				work_delay = min(work_delay, this_timer - now);
@@ -508,6 +558,9 @@ static int fdb_insert(struct net_bridge *br, struct net_bridge_port *source,
 {
 	struct hlist_head *head = &br->hash[br_mac_hash(addr, vid)];
 	struct net_bridge_fdb_entry *fdb;
+#if defined(CONFIG_CPE_FAST_PATH)
+	struct net_bridge_port *p;
+#endif
 
 	if (!is_valid_ether_addr(addr))
 		return -EINVAL;
@@ -528,6 +581,15 @@ static int fdb_insert(struct net_bridge *br, struct net_bridge_port *source,
 	if (!fdb)
 		return -ENOMEM;
 
+#if defined(CONFIG_CPE_FAST_PATH)
+	list_for_each_entry(p, &br->port_list, list) {
+		if (source == p)
+			continue;
+
+		dev_uc_add(source->dev, p->dev->dev_addr);
+		dev_uc_add(p->dev, addr);
+	}
+#endif
 	fdb_add_hw_addr(br, addr);
 	fdb_notify(br, fdb, RTM_NEWNEIGH);
 	return 0;
@@ -573,6 +635,16 @@ void br_fdb_update(struct net_bridge *br, struct net_bridge_port *source,
 
 			/* fastpath: update of existing entry */
 			if (unlikely(source != fdb->dst)) {
+#if defined(CONFIG_CPE_FAST_PATH)
+				struct brevent_fdb_update fdb_update;
+
+				fdb_update.dev = source->dev;
+				fdb_update.mac_addr = fdb->addr.addr;
+				//FIXME
+				//__rtmsg_ifinfo(RTM_NEWLINK, br->dev, 0, GFP_ATOMIC);
+				//FIXME
+				call_brevent_notifiers(BREVENT_FDB_UPDATE, &fdb_update);
+#endif
 				fdb->dst = source;
 				fdb_modified = true;
 				/* Take over HW learned entry */
@@ -606,6 +678,24 @@ void br_fdb_update(struct net_bridge *br, struct net_bridge_port *source,
 	}
 }
 
+#if defined(CONFIG_CPE_FAST_PATH)
+void br_fdb_register_can_expire_cb(int(*cb)(unsigned char *mac_addr, struct net_device *dev))
+{
+        spin_lock_bh(&br_fdb_cb_lock);
+        br_fdb_can_expire = cb;
+        spin_unlock_bh(&br_fdb_cb_lock);
+}
+EXPORT_SYMBOL(br_fdb_register_can_expire_cb);
+
+void br_fdb_deregister_can_expire_cb()
+{
+        spin_lock_bh(&br_fdb_cb_lock);
+        br_fdb_can_expire = NULL;
+        spin_unlock_bh(&br_fdb_cb_lock);
+}
+EXPORT_SYMBOL(br_fdb_deregister_can_expire_cb);
+#endif
+
 static int fdb_to_nud(const struct net_bridge *br,
 		      const struct net_bridge_fdb_entry *fdb)
 {
diff --git a/net/bridge/br_forward.c b/net/bridge/br_forward.c
index 48fb17417fac..fea2e9ce6621 100644
--- a/net/bridge/br_forward.c
+++ b/net/bridge/br_forward.c
@@ -35,7 +35,11 @@ static inline int should_deliver(const struct net_bridge_port *p,
 
 int br_dev_queue_push_xmit(struct net *net, struct sock *sk, struct sk_buff *skb)
 {
-	if (!is_skb_forwardable(skb->dev, skb))
+	if (
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	    (!skb->ipsec_offload) && 
+#endif
+	    !is_skb_forwardable(skb->dev, skb))
 		goto drop;
 
 	skb_push(skb, ETH_HLEN);
diff --git a/net/bridge/br_input.c b/net/bridge/br_input.c
index 7637f58c1226..33c7486ed90f 100644
--- a/net/bridge/br_input.c
+++ b/net/bridge/br_input.c
@@ -66,6 +66,10 @@ static int br_pass_frame_up(struct sk_buff *skb)
 	br_multicast_count(br, NULL, skb, br_multicast_igmp_type(skb),
 			   BR_MCAST_DIR_TX);
 
+#if defined(CONFIG_CPE_FAST_PATH)
+	skb->underlying_iif = indev->ifindex;
+#endif
+
 	return NF_HOOK(NFPROTO_BRIDGE, NF_BR_LOCAL_IN,
 		       dev_net(indev), NULL, skb, indev, NULL,
 		       br_netif_receive_skb);
@@ -169,6 +173,10 @@ int br_handle_frame_finish(struct net *net, struct sock *sk, struct sk_buff *skb
 	if (p->state == BR_STATE_LEARNING)
 		goto drop;
 
+#if defined(CONFIG_CPE_FAST_PATH)
+	skb->abm_ff = 0;
+#endif
+
 	BR_INPUT_SKB_CB(skb)->brdev = br->dev;
 
 	if (IS_ENABLED(CONFIG_INET) && skb->protocol == htons(ETH_P_ARP))
@@ -204,6 +212,10 @@ int br_handle_frame_finish(struct net *net, struct sock *sk, struct sk_buff *skb
 
 		if (now != dst->used)
 			dst->used = now;
+#if defined(CONFIG_CPE_FAST_PATH)
+			/* Used by ABM module */
+			skb->abm_ff = 1;
+#endif
 		br_forward(dst->dst, skb, local_rcv, false);
 	} else {
 		if (!mcast_hit)
diff --git a/net/bridge/br_private.h b/net/bridge/br_private.h
index e870cfc85b14..ab8960ec5fb4 100644
--- a/net/bridge/br_private.h
+++ b/net/bridge/br_private.h
@@ -526,6 +526,11 @@ int br_fdb_insert(struct net_bridge *br, struct net_bridge_port *source,
 void br_fdb_update(struct net_bridge *br, struct net_bridge_port *source,
 		   const unsigned char *addr, u16 vid, bool added_by_user);
 
+#if defined(CONFIG_CPE_FAST_PATH)
+extern void br_fdb_register_can_expire_cb(int(*cb)(unsigned char *mac_addr, struct net_device *dev)); 
+extern void br_fdb_deregister_can_expire_cb(void);
+#endif
+
 int br_fdb_delete(struct ndmsg *ndm, struct nlattr *tb[],
 		  struct net_device *dev, const unsigned char *addr, u16 vid);
 int br_fdb_add(struct ndmsg *nlh, struct nlattr *tb[], struct net_device *dev,
diff --git a/net/bridge/br_stp_if.c b/net/bridge/br_stp_if.c
index 89110319ef0f..d9433f310467 100644
--- a/net/bridge/br_stp_if.c
+++ b/net/bridge/br_stp_if.c
@@ -126,6 +126,10 @@ void br_stp_disable_port(struct net_bridge_port *p)
 
 	if (br_is_root_bridge(br) && !wasroot)
 		br_become_root_bridge(br);
+
+#if defined(CONFIG_CPE_FAST_PATH)
+	call_brevent_notifiers(BREVENT_PORT_DOWN, p->dev);
+#endif
 }
 
 static int br_stp_call_user(struct net_bridge *br, char *arg)
diff --git a/net/core/dev.c b/net/core/dev.c
index 2d7aa7dec718..5cc85e751b78 100644
--- a/net/core/dev.c
+++ b/net/core/dev.c
@@ -164,7 +164,7 @@ static int netif_rx_internal(struct sk_buff *skb);
 static int call_netdevice_notifiers_info(unsigned long val,
 					 struct netdev_notifier_info *info);
 static struct napi_struct *napi_by_id(unsigned int napi_id);
-
+static fp_iface_stats_get fast_path_stats_get;
 /*
  * The @dev_base_head list is protected by @dev_base_lock and the rtnl
  * semaphore.
@@ -3519,10 +3519,24 @@ static int __dev_queue_xmit(struct sk_buff *skb, void *accel_priv)
 
 int dev_queue_xmit(struct sk_buff *skb)
 {
+#if defined(CONFIG_CPE_FAST_PATH)
+	if (skb->dev->flags & IFF_WIFI_OFLD)
+		skb->dev = skb->dev->wifi_offload_dev;
+
+	return original_dev_queue_xmit(skb);
+}
+
+int original_dev_queue_xmit(struct sk_buff *skb)
+{
+#endif
 	return __dev_queue_xmit(skb, NULL);
 }
 EXPORT_SYMBOL(dev_queue_xmit);
 
+#if defined(CONFIG_CPE_FAST_PATH)
+EXPORT_SYMBOL(original_dev_queue_xmit);
+#endif
+
 int dev_queue_xmit_accel(struct sk_buff *skb, void *accel_priv)
 {
 	return __dev_queue_xmit(skb, accel_priv);
@@ -4320,6 +4334,15 @@ static int __netif_receive_skb_core(struct sk_buff *skb, bool pfmemalloc)
 
 	trace_netif_receive_skb(skb);
 
+#ifdef CONFIG_CPE_FAST_PATH
+	/* ifindex of device we arrived on,now skb->skb_iif
+	   always tracks skb->dev */	
+	if (!skb->iif_index)
+		skb->iif_index = skb->dev->ifindex;
+	if(!skb->underlying_iif)
+		skb->underlying_iif = skb->dev->ifindex;
+	
+#endif
 	orig_dev = skb->dev;
 
 	skb_reset_network_header(skb);
@@ -4957,6 +4980,10 @@ static void napi_reuse_skb(struct napi_struct *napi, struct sk_buff *skb)
 	skb->vlan_tci = 0;
 	skb->dev = napi->dev;
 	skb->skb_iif = 0;
+#ifdef CONFIG_CPE_FAST_PATH
+	skb->iif_index = 0;
+	skb->underlying_iif = 0;
+#endif
 	skb->encapsulation = 0;
 	skb_shinfo(skb)->gso_type = 0;
 	skb->truesize = SKB_TRUESIZE(skb_end_offset(skb));
@@ -7968,10 +7995,24 @@ struct rtnl_link_stats64 *dev_get_stats(struct net_device *dev,
 	storage->rx_dropped += (unsigned long)atomic_long_read(&dev->rx_dropped);
 	storage->tx_dropped += (unsigned long)atomic_long_read(&dev->tx_dropped);
 	storage->rx_nohandler += (unsigned long)atomic_long_read(&dev->rx_nohandler);
+	if (fast_path_stats_get)
+        	fast_path_stats_get(dev, storage); 
 	return storage;
 }
 EXPORT_SYMBOL(dev_get_stats);
 
+void dev_fp_stats_get_register(fp_iface_stats_get func)
+{
+  fast_path_stats_get = func;
+}
+EXPORT_SYMBOL(dev_fp_stats_get_register);
+
+void dev_fp_stats_get_deregister(fp_iface_stats_get func)
+{
+  fast_path_stats_get = NULL;
+}
+EXPORT_SYMBOL(dev_fp_stats_get_deregister);
+
 struct netdev_queue *dev_ingress_queue_create(struct net_device *dev)
 {
 	struct netdev_queue *queue = dev_ingress_queue(dev);
diff --git a/net/core/rtnetlink.c b/net/core/rtnetlink.c
index d4a82fa889fc..d0040a1c3ccd 100644
--- a/net/core/rtnetlink.c
+++ b/net/core/rtnetlink.c
@@ -695,6 +695,17 @@ int rtnetlink_put_metrics(struct sk_buff *skb, u32 *metrics)
 			}
 			valid++;
 		}
+#ifdef CONFIG_CPE_FAST_PATH
+                else if (i  == RTAX_MTU - 1){
+                        struct dst_entry *dst = skb_dst(skb);
+                        if(dst)
+                        {
+                                if (nla_put_u32(skb, i + 1, dst_mtu(dst)))
+                                        goto nla_put_failure;
+                                valid++;
+                        }
+                }
+#endif	
 	}
 
 	if (!valid) {
diff --git a/net/core/skbuff.c b/net/core/skbuff.c
index 25bec1e774bc..bb2286714b83 100644
--- a/net/core/skbuff.c
+++ b/net/core/skbuff.c
@@ -230,6 +230,10 @@ struct sk_buff *__alloc_skb(unsigned int size, gfp_t gfp_mask,
 	skb->mac_header = (typeof(skb->mac_header))~0U;
 	skb->transport_header = (typeof(skb->transport_header))~0U;
 
+#if defined(CONFIG_COMCERTO_CUSTOM_SKB_LAYOUT)
+	skb->mspd_data = NULL;
+	skb->mspd_len = 0;
+#endif
 	/* make sure we initialize shinfo sequentially */
 	shinfo = skb_shinfo(skb);
 	memset(shinfo, 0, offsetof(struct skb_shared_info, dataref));
@@ -572,6 +576,13 @@ static void skb_release_data(struct sk_buff *skb)
 
 	skb_zcopy_clear(skb, true);
 	skb_free_head(skb);
+#if defined(CONFIG_COMCERTO_CUSTOM_SKB_LAYOUT)
+	if (skb->mspd_data) {
+		kfree(skb->mspd_data);
+		skb->mspd_data = NULL;
+	}
+#endif
+
 }
 
 /*
@@ -836,6 +847,10 @@ static void __copy_skb_header(struct sk_buff *new, const struct sk_buff *old)
 	 */
 	new->queue_mapping = old->queue_mapping;
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+        new->ipsec_offload       = old->ipsec_offload;
+        new->ipsec_xfrm_dir      = old->ipsec_xfrm_dir;
+#endif
 	memcpy(&new->headers_start, &old->headers_start,
 	       offsetof(struct sk_buff, headers_end) -
 	       offsetof(struct sk_buff, headers_start));
@@ -844,6 +859,11 @@ static void __copy_skb_header(struct sk_buff *new, const struct sk_buff *old)
 	CHECK_SKB_FIELD(hash);
 	CHECK_SKB_FIELD(priority);
 	CHECK_SKB_FIELD(skb_iif);
+#ifdef CONFIG_CPE_FAST_PATH
+	CHECK_SKB_FIELD(abm_ff);
+	CHECK_SKB_FIELD(iif_index);
+	CHECK_SKB_FIELD(underlying_iif);
+#endif
 	CHECK_SKB_FIELD(vlan_proto);
 	CHECK_SKB_FIELD(vlan_tci);
 	CHECK_SKB_FIELD(transport_header);
@@ -877,6 +897,24 @@ static struct sk_buff *__skb_clone(struct sk_buff *n, struct sk_buff *skb)
 {
 #define C(x) n->x = skb->x
 
+#if defined(CONFIG_COMCERTO_CUSTOM_SKB_LAYOUT)
+	if (skb->mspd_data) {
+		if (skb->mspd_len) {
+			int ofst = skb->len - skb->mspd_len;
+
+			memcpy(skb->data + ofst, skb->mspd_data + skb->mspd_ofst, skb->mspd_len);
+			skb->mspd_len = 0;
+		}
+
+		WARN_ON(skb_shared(skb));
+
+		if (!skb_shared(skb)) {
+			kfree(skb->mspd_data);
+			skb->mspd_data = NULL;
+		}
+	}
+#endif
+
 	n->next = n->prev = NULL;
 	n->sk = NULL;
 	__copy_skb_header(n, skb);
@@ -896,6 +934,13 @@ static struct sk_buff *__skb_clone(struct sk_buff *n, struct sk_buff *skb)
 	C(truesize);
 	refcount_set(&n->users, 1);
 
+#if defined(CONFIG_COMCERTO_CUSTOM_SKB_LAYOUT)
+	WARN_ON(skb->mspd_data);
+	C(mspd_data);
+	C(mspd_len);
+	C(mspd_ofst);
+#endif
+
 	atomic_inc(&(skb_shinfo(skb)->dataref));
 	skb->cloned = 1;
 
@@ -1377,6 +1422,24 @@ struct sk_buff *skb_copy(const struct sk_buff *skb, gfp_t gfp_mask)
 	if (!n)
 		return NULL;
 
+#if defined(CONFIG_COMCERTO_CUSTOM_SKB_LAYOUT)
+	if (skb->mspd_data) {
+		if (skb->mspd_len) {
+			int ofst = skb->len - skb->mspd_len;
+
+			memcpy(skb->data + ofst, skb->mspd_data + skb->mspd_ofst, skb->mspd_len);
+			((struct sk_buff *)skb)->mspd_len = 0;
+		}
+
+		WARN_ON(skb_shared(skb));
+
+		if (!skb_shared(skb)) {
+			kfree(skb->mspd_data);
+			((struct sk_buff *)skb)->mspd_data = NULL;
+		}
+	}
+#endif
+
 	/* Set the data pointer */
 	skb_reserve(n, headerlen);
 	/* Set the tail pointer and length */
@@ -1414,6 +1477,9 @@ struct sk_buff *__pskb_copy_fclone(struct sk_buff *skb, int headroom,
 	int flags = skb_alloc_rx_flag(skb) | (fclone ? SKB_ALLOC_FCLONE : 0);
 	struct sk_buff *n = __alloc_skb(size, gfp_mask, flags, NUMA_NO_NODE);
 
+#if defined(CONFIG_COMCERTO_CUSTOM_SKB_LAYOUT)
+	WARN_ON(skb->mspd_len);
+#endif
 	if (!n)
 		goto out;
 
diff --git a/net/ipv4/Kconfig b/net/ipv4/Kconfig
index f48fe6fc7e8c..913b94a6cdfc 100644
--- a/net/ipv4/Kconfig
+++ b/net/ipv4/Kconfig
@@ -176,6 +176,13 @@ config NET_IPIP
 	  be inserted in and removed from the running kernel whenever you
 	  want). Most people won't need this and can say N.
 
+
+config NET_ETHERIP
+	tristate "Ethernet over IP: tunneling"
+	default y
+	help
+	 Ethernet over IPv4 tunneling support.
+
 config NET_IPGRE_DEMUX
 	tristate "IP: GRE demultiplexer"
 	help
@@ -372,6 +379,12 @@ config INET_ESP_OFFLOAD
 
 	  If unsure, say N.
 
+config INET_IPSEC_OFFLOAD
+	bool "IPsec Fast Path Processing offload"
+	depends on (INET_ESP || INET_AH) && CPE_FAST_PATH
+		---help---
+	  Support for IPsec Fast Path offload.
+
 config INET_IPCOMP
 	tristate "IP: IPComp transformation"
 	select INET_XFRM_TUNNEL
diff --git a/net/ipv4/Makefile b/net/ipv4/Makefile
index c6c8ad1d4b6d..ce1d9220846f 100644
--- a/net/ipv4/Makefile
+++ b/net/ipv4/Makefile
@@ -35,6 +35,7 @@ obj-$(CONFIG_INET_IPCOMP) += ipcomp.o
 obj-$(CONFIG_INET_XFRM_TUNNEL) += xfrm4_tunnel.o
 obj-$(CONFIG_INET_XFRM_MODE_BEET) += xfrm4_mode_beet.o
 obj-$(CONFIG_INET_TUNNEL) += tunnel4.o
+#obj-$(CONFIG_NET_ETHERIP) += etherip.o
 obj-$(CONFIG_INET_XFRM_MODE_TRANSPORT) += xfrm4_mode_transport.o
 obj-$(CONFIG_INET_XFRM_MODE_TUNNEL) += xfrm4_mode_tunnel.o
 obj-$(CONFIG_IP_PNP) += ipconfig.o
diff --git a/net/ipv4/etherip.c b/net/ipv4/etherip.c
new file mode 100644
index 000000000000..fad3d465cf6c
--- /dev/null
+++ b/net/ipv4/etherip.c
@@ -0,0 +1,626 @@
+/*
+ * etherip.c: Ethernet over IPv4 tunnel driver (according to RFC3378)
+ *
+ * This driver could be used to tunnel Ethernet packets through IPv4
+ * networks. This is especially usefull together with the bridging
+ * code in Linux.
+ *
+ * This code was written with an eye on the IPIP driver in linux from
+ * Sam Lantinga. Thanks for the great work.
+ *
+ *      This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      version 2 (no later version) as published by the
+ *      Free Software Foundation.
+ *
+ */
+
+#include <linux/version.h>
+#include <linux/capability.h>
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/mutex.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <linux/ip.h>
+#include <linux/if_tunnel.h>
+#include <linux/list.h>
+#include <linux/string.h>
+#include <linux/netfilter_ipv4.h>
+#include <net/ip.h>
+#include <net/protocol.h>
+#include <net/route.h>
+#include <net/ip_tunnels.h>
+#include <net/xfrm.h>
+#include <net/inet_ecn.h>
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Joerg Roedel <joro@8bytes.org>");
+MODULE_DESCRIPTION("Ethernet over IPv4 tunnel driver");
+
+#ifndef IPPROTO_ETHERIP
+#define IPPROTO_ETHERIP 97
+#endif
+
+
+#define __IPTUNNEL_XMIT(stats1, stats2) do {				\
+	int err;							\
+	int pkt_len = skb->len - skb_transport_offset(skb);		\
+									\
+	skb->ip_summed = CHECKSUM_NONE;					\
+	ip_select_ident(skb, NULL);				\
+									\
+	err = ip_local_out(skb);					\
+	if (likely(net_xmit_eval(err) == 0)) {				\
+		(stats1)->tx_bytes += pkt_len;				\
+		(stats1)->tx_packets++;					\
+	} else {							\
+		(stats2)->tx_errors++;					\
+		(stats2)->tx_aborted_errors++;				\
+	}								\
+} while (0)
+
+/*
+ * These 2 defines are taken from ipip.c - if it's good enough for them
+ * it's good enough for me.
+ */
+#define ETHER_IP_HASH_SIZE        16
+#define HASH(addr)       ((addr^(addr>>4))&0xF)
+
+//#define ETHERIP_HEADER   ((u16)0x0300) /* There seems to be some difference here, This should ideally be 0x3000
+//					http://lists.freebsd.org/pipermail/freebsd-bugs/2008-June/031385.html */
+
+#define ETHERIP_HEADER     ((u16)0x3000)
+
+#define ETHERIP_HLEN     2
+#define ETHERIP_MAX_MTU  (65535 - 20 - ETHERIP_HLEN)
+
+#define BANNER1 "etherip: Ethernet over IPv4 tunneling driver\n"
+#if 1
+struct pcpu_tstats {
+	unsigned long rx_packets;
+	unsigned long rx_bytes;
+	unsigned long tx_packets;
+	unsigned long tx_bytes;
+};
+#endif
+struct etherip_tunnel {
+	struct list_head list;
+	struct net_device *dev;
+	struct net_device_stats stats;
+	struct ip_tunnel_parm parms;
+	unsigned int recursion;
+};
+
+static struct net_device *etherip_tunnel_dev;
+static struct list_head tunnels[ETHER_IP_HASH_SIZE];
+
+static DEFINE_RWLOCK(etherip_lock);
+
+static void etherip_tunnel_setup(struct net_device *dev);
+
+static struct net_device_stats *etherip_get_stats(struct net_device *dev)
+{
+	struct pcpu_sw_netstats sum = { 0 };
+	int i;
+
+	for_each_possible_cpu(i) {
+		const struct pcpu_sw_netstats *tstats = per_cpu_ptr(dev->tstats, i);
+		
+		sum.rx_packets += tstats->rx_packets;
+		sum.rx_bytes   += tstats->rx_bytes;
+		sum.tx_packets += tstats->tx_packets;
+		sum.tx_bytes   += tstats->tx_bytes;
+	}
+	dev->stats.rx_packets = sum.rx_packets;
+	dev->stats.rx_bytes   = sum.rx_bytes;
+	dev->stats.tx_packets = sum.tx_packets;
+	dev->stats.tx_bytes   = sum.tx_bytes;
+	return &dev->stats;
+}
+
+/* add a tunnel to the hash */
+static void etherip_tunnel_add(struct etherip_tunnel *tun)
+{
+	unsigned h = HASH(tun->parms.iph.daddr);
+	list_add_tail(&tun->list, &tunnels[h]);
+}
+
+/* delete a tunnel from the hash*/
+static void etherip_tunnel_del(struct etherip_tunnel *tun)
+{
+	list_del(&tun->list);
+}
+
+/* find a tunnel in the hash by parameters from userspace */
+static struct etherip_tunnel* etherip_tunnel_find(struct ip_tunnel_parm *p)
+{
+	struct etherip_tunnel *ret;
+	unsigned h = HASH(p->iph.daddr);
+
+	list_for_each_entry(ret, &tunnels[h], list)
+		if (ret->parms.iph.daddr == p->iph.daddr)
+			return ret;
+
+	return NULL;
+}
+
+/* find a tunnel by its destination address */
+static struct etherip_tunnel* etherip_tunnel_locate(u32 remote)
+{
+	struct etherip_tunnel *ret;
+	unsigned h = HASH(remote);
+
+	list_for_each_entry(ret, &tunnels[h], list)
+		if (ret->parms.iph.daddr == remote)
+			return ret;
+
+	return NULL;
+}
+
+static int etherip_change_mtu(struct net_device *dev, int new_mtu)
+{
+	if (new_mtu < 68 || new_mtu > ETHERIP_MAX_MTU)
+		return -EINVAL;
+	dev->mtu = new_mtu;
+
+	return 0;
+}
+
+/* netdevice hard_start_xmit function
+ * it gets an Ethernet packet in skb and encapsulates it in another IP
+ * packet */
+static int etherip_tunnel_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	struct etherip_tunnel *tunnel = netdev_priv(dev);
+	struct rtable *rt;
+	struct iphdr *iph;
+	struct net_device *tdev;
+	int max_headroom;
+	struct pcpu_sw_netstats *tstats;
+	struct flowi4 fl4;
+
+	if (tunnel->recursion++) {
+		tunnel->stats.collisions++;
+		goto tx_error;
+	}
+
+
+	rt = ip_route_output_ports(dev_net(dev), &fl4, NULL,
+				   tunnel->parms.iph.daddr,
+				   tunnel->parms.iph.saddr,
+				   0, 0, IPPROTO_ETHERIP,
+				   RT_TOS(tunnel->parms.iph.tos),
+				   tunnel->parms.link);
+	if (IS_ERR(rt)) {
+		dev->stats.tx_carrier_errors++;
+		goto tx_error_icmp;
+	}
+
+	tdev = rt->dst.dev;
+	if (tdev == dev) {
+		ip_rt_put(rt);
+		tunnel->stats.collisions++;
+		goto tx_error;
+	}
+
+	max_headroom = (LL_RESERVED_SPACE(tdev)+sizeof(struct iphdr)
+			+ ETHERIP_HLEN);
+
+	if (skb_headroom(skb) < max_headroom || skb_shared(skb) ||
+	    (skb_cloned(skb) && !skb_clone_writable(skb, 0))) {
+		struct sk_buff *skn = skb_realloc_headroom(skb, max_headroom);
+		if (!skn) {
+			ip_rt_put(rt);
+			dev->stats.tx_dropped++;
+			dev_kfree_skb(skb);
+			tunnel->recursion--;
+			tunnel->stats.tx_dropped++;
+			return 0;
+		}
+		if (skb->sk)
+			skb_set_owner_w(skn, skb->sk);
+		dev_kfree_skb(skb);
+		skb = skn;
+	}
+
+	skb->transport_header = skb->mac_header;
+	skb_push(skb, sizeof(struct iphdr)+ETHERIP_HLEN);
+	skb_reset_network_header(skb);
+	memset(&(IPCB(skb)->opt), 0, sizeof(IPCB(skb)->opt));
+	IPCB(skb)->flags &= ~(IPSKB_XFRM_TUNNEL_SIZE | IPSKB_XFRM_TRANSFORMED |
+			IPSKB_REROUTED);
+
+	skb_dst_drop(skb);
+	skb_dst_set(skb, &rt->dst);
+
+	/* Build the IP header for the outgoing packet
+	 *
+	 * Note: This driver never sets the DF flag on outgoing packets
+	 *       to ensure that the tunnel provides the full Ethernet MTU.
+	 *       This behavior guarantees that protocols can be
+	 *       encapsulated within the Ethernet packet which do not
+	 *       know the concept of a path MTU
+	 */
+	iph = ip_hdr(skb);
+	iph->version = 4;
+	iph->ihl = sizeof(struct iphdr)>>2;
+	iph->frag_off = 0;
+	iph->protocol = IPPROTO_ETHERIP;
+	iph->tos = tunnel->parms.iph.tos & INET_ECN_MASK;
+	iph->daddr = fl4.daddr;
+	iph->saddr = fl4.saddr;
+	iph->ttl = tunnel->parms.iph.ttl;
+	if (iph->ttl == 0)
+		iph->ttl = 64;
+
+	/* add the 16bit etherip header after the ip header */
+	((u16*)(iph+1))[0]=htons(ETHERIP_HEADER);
+	nf_reset(skb);
+	tstats = this_cpu_ptr(dev->tstats);
+	__IPTUNNEL_XMIT(tstats, &dev->stats);
+//	tunnel->dev->trans_start = jiffies;
+	tunnel->recursion--;
+
+	return NETDEV_TX_OK;
+
+tx_error_icmp:
+	dst_link_failure(skb);
+
+tx_error:
+	tunnel->stats.tx_errors++;
+	dev_kfree_skb(skb);
+	tunnel->recursion--;
+	return NETDEV_TX_OK;
+}
+
+/* checks parameters the driver gets from userspace */
+static int etherip_param_check(struct ip_tunnel_parm *p)
+{
+	if (p->iph.version != 4 ||
+	    p->iph.protocol != IPPROTO_ETHERIP ||
+	    p->iph.ihl != 5 ||
+	    p->iph.daddr == INADDR_ANY ||
+	    IN_MULTICAST(p->iph.daddr))
+		return -EINVAL;
+
+	return 0;
+}
+
+/* central ioctl function for all netdevices this driver manages
+ * it allows to create, delete, modify a tunnel and fetch tunnel
+ * information */
+static int etherip_tunnel_ioctl(struct net_device *dev, struct ifreq *ifr,
+		int cmd)
+{
+	int err = 0;
+	struct ip_tunnel_parm p;
+	struct net_device *tmp_dev;
+	char *dev_name;
+	struct etherip_tunnel *t;
+
+
+	switch (cmd) {
+	case SIOCGETTUNNEL:
+		t = netdev_priv(dev);
+		if (copy_to_user(ifr->ifr_ifru.ifru_data, &t->parms,
+				sizeof(t->parms)))
+			err = -EFAULT;
+		break;
+	case SIOCADDTUNNEL:
+		err = -EINVAL;
+		if (dev != etherip_tunnel_dev)
+			goto out;
+
+	case SIOCCHGTUNNEL:
+		err = -EPERM;
+		if (!capable(CAP_NET_ADMIN))
+			goto out;
+
+		err = -EFAULT;
+		if (copy_from_user(&p, ifr->ifr_ifru.ifru_data,
+					sizeof(p)))
+			goto out;
+		p.i_flags = p.o_flags = 0;
+
+		if ((err = etherip_param_check(&p)) < 0)
+			goto out;
+
+		t = etherip_tunnel_find(&p);
+
+		err = -EEXIST;
+		if (t != NULL && t->dev != dev)
+			goto out;
+
+		if (cmd == SIOCADDTUNNEL) {
+
+			p.name[IFNAMSIZ-1] = 0;
+			dev_name = p.name;
+			if (dev_name[0] == 0)
+				dev_name = "ethip%d";
+
+			err = -ENOMEM;
+			tmp_dev = alloc_netdev(
+					sizeof(struct etherip_tunnel),
+					dev_name, NET_NAME_UNKNOWN,
+					etherip_tunnel_setup);
+
+			if (tmp_dev == NULL)
+				goto out;
+
+			if (strchr(tmp_dev->name, '%')) {
+				err = dev_alloc_name(tmp_dev, tmp_dev->name);
+				if (err < 0)
+					goto add_err;
+			}
+
+			t = netdev_priv(tmp_dev);
+			t->dev = tmp_dev;
+			strncpy(p.name, tmp_dev->name, IFNAMSIZ);
+			memcpy(&(t->parms), &p, sizeof(p));
+
+			err = -EFAULT;
+			if (copy_to_user(ifr->ifr_ifru.ifru_data, &p,
+						sizeof(p)))
+				goto add_err;
+
+			err = -ENOMEM;
+			tmp_dev->tstats = alloc_percpu(struct pcpu_sw_netstats);
+			if (!tmp_dev->tstats)
+				goto add_err;
+
+			err = register_netdevice(tmp_dev);
+			if (err < 0)
+				goto add_err;
+
+#ifdef  COMCERTO_ETHERIPV4
+			t->dev->iflink  = t->parms.link; // MSPD Added
+#endif
+			dev_hold(tmp_dev);
+
+			write_lock_bh(&etherip_lock);
+			etherip_tunnel_add(t);
+			write_unlock_bh(&etherip_lock);
+
+		} else {
+			err = -EINVAL;
+			if ((t = netdev_priv(dev)) == NULL)
+				goto out;
+			if (dev == etherip_tunnel_dev)
+				goto out;
+			write_lock_bh(&etherip_lock);
+			memcpy(&(t->parms), &p, sizeof(p));
+			write_unlock_bh(&etherip_lock);
+		}
+
+		err = 0;
+		break;
+add_err:
+		free_percpu(tmp_dev->tstats);
+		free_netdev(tmp_dev);
+		goto out;
+
+	case SIOCDELTUNNEL:
+		err = -EPERM;
+		if (!capable(CAP_NET_ADMIN))
+			goto out;
+
+		err = -EFAULT;
+		if (copy_from_user(&p, ifr->ifr_ifru.ifru_data,
+					sizeof(p)))
+			goto out;
+
+		err = -EINVAL;
+		if (dev == etherip_tunnel_dev) {
+			t = etherip_tunnel_find(&p);
+			if (t == NULL) {
+				goto out;
+			}
+		} else
+			t = netdev_priv(dev);
+
+		write_lock_bh(&etherip_lock);
+		etherip_tunnel_del(t);
+		write_unlock_bh(&etherip_lock);
+
+#ifdef COMCERTO_ETHERIPV4
+		dev_put(t->dev);
+#endif
+		unregister_netdevice(t->dev);
+		err = 0;
+
+		break;
+#ifdef COMCERTO_ETHERIPV4
+	// MSPD added
+	/* Returns Okay for EtherIP-over-IPv4 */
+	case SIOCISETHIPV4TUNNEL:
+		err = 0;
+		break;
+#endif
+	default:
+		err = -EINVAL;
+	}
+
+out:
+	return err;
+}
+
+static const struct net_device_ops etherip_netdev_ops = {
+	.ndo_start_xmit = etherip_tunnel_xmit,
+	.ndo_do_ioctl   = etherip_tunnel_ioctl,
+	.ndo_change_mtu = etherip_change_mtu,
+	.ndo_get_stats  = etherip_get_stats,
+};
+
+static void free_etheripdev(struct net_device *dev)
+{
+	free_percpu(dev->tstats);
+	free_netdev(dev);
+}
+
+/* device init function - called via register_netdevice
+ * The tunnel is registered as an Ethernet device. This allows
+ * the tunnel to be added to a bridge */
+static void etherip_tunnel_setup(struct net_device *dev)
+{
+	ether_setup(dev);
+	dev->netdev_ops      = &etherip_netdev_ops;
+	dev->destructor      = free_etheripdev;
+	dev->mtu             = ETH_DATA_LEN;
+	dev->hard_header_len = LL_MAX_HEADER + sizeof(struct iphdr) + ETHERIP_HLEN;
+#ifdef COMCERTO_ETHERIPV4
+	dev->tx_queue_len	= 0; /* Being a virtual device set queue len to zero.
+                                        Packets should only be queued on real interfaces */
+	dev->flags	     |= IFF_POINTOPOINT;//MSPD Added
+#endif
+	random_ether_addr(dev->dev_addr);
+}
+
+/* receive function for EtherIP packets
+ * Does some basic checks on the MAC addresses and
+ * interface modes */
+static int etherip_rcv(struct sk_buff *skb)
+{
+	struct iphdr *iph;
+	struct etherip_tunnel *tunnel;
+	struct net_device *dev;
+
+	iph = ip_hdr(skb);
+
+	read_lock_bh(&etherip_lock);
+	tunnel = etherip_tunnel_locate(iph->saddr);
+	if (tunnel == NULL)
+		goto drop;
+
+	dev = tunnel->dev;
+	secpath_reset(skb);
+	skb_pull(skb, (skb_network_header(skb)-skb->data) +
+			sizeof(struct iphdr)+ETHERIP_HLEN);
+
+	skb->dev = dev;
+	skb->pkt_type = PACKET_HOST;
+	skb->protocol = eth_type_trans(skb, tunnel->dev);
+	skb->ip_summed = CHECKSUM_UNNECESSARY;
+	skb_dst_drop(skb);
+
+	/* do some checks */
+	if (skb->pkt_type == PACKET_HOST || skb->pkt_type == PACKET_BROADCAST)
+		goto accept;
+
+	if (skb->pkt_type == PACKET_MULTICAST &&
+			(dev->mc.count > 0 || dev->flags & IFF_ALLMULTI))
+		goto accept;
+
+	if (skb->pkt_type == PACKET_OTHERHOST && dev->flags & IFF_PROMISC)
+		goto accept;
+
+drop:
+	read_unlock_bh(&etherip_lock);
+	kfree_skb(skb);
+	return 0;
+
+accept:
+	tunnel->dev->last_rx = jiffies;
+	tunnel->stats.rx_packets++;
+	tunnel->stats.rx_bytes += skb->len;
+	nf_reset(skb);
+	netif_rx(skb);
+	read_unlock_bh(&etherip_lock);
+	return 0;
+
+}
+
+static struct net_protocol etherip_protocol = {
+	.handler      = etherip_rcv,
+	.err_handler  = 0,
+	.no_policy    = 0,
+	.netns_ok     = 1,
+};
+
+/* module init function
+ * initializes the EtherIP protocol (97) and registers the initial
+ * device */
+static int __init etherip_init(void)
+{
+	int err, i;
+	struct etherip_tunnel *p;
+
+	printk(KERN_INFO BANNER1);
+
+	for (i = 0; i < ETHER_IP_HASH_SIZE; ++i)
+		INIT_LIST_HEAD(&tunnels[i]);
+
+	printk(KERN_INFO"etherip  ----- is functional");
+
+	if (inet_add_protocol(&etherip_protocol, IPPROTO_ETHERIP)) {
+		printk(KERN_ERR "etherip: can't add protocol\n");
+		return -EBUSY;
+	}
+
+	etherip_tunnel_dev = alloc_netdev(sizeof(struct etherip_tunnel),
+			"ethip0", NET_NAME_UNKNOWN,
+			etherip_tunnel_setup);
+
+	if (!etherip_tunnel_dev) {
+		err = -ENOMEM;
+		goto err2;
+	}
+
+	err = -ENOMEM;
+	etherip_tunnel_dev->tstats = alloc_percpu(struct pcpu_sw_netstats);
+	if (!etherip_tunnel_dev->tstats)
+		goto err1;
+
+	p = netdev_priv(etherip_tunnel_dev);
+	p->dev = etherip_tunnel_dev;
+	/* set some params for iproute2 */
+	strcpy(p->parms.name, "ethip0");
+	p->parms.iph.protocol = IPPROTO_ETHERIP;
+
+	if ((err = register_netdev(etherip_tunnel_dev)))
+		goto err1;
+
+out:
+	return err;
+err1:
+	free_percpu(etherip_tunnel_dev->tstats);
+	free_netdev(etherip_tunnel_dev);
+err2:
+	inet_del_protocol(&etherip_protocol, IPPROTO_ETHERIP);
+	goto out;
+}
+
+/* destroy all tunnels */
+static void __exit etherip_destroy_tunnels(void)
+{
+	int i;
+	struct list_head *ptr;
+	struct etherip_tunnel *tun;
+
+	for (i = 0; i < ETHER_IP_HASH_SIZE; ++i) {
+		list_for_each(ptr, &tunnels[i]) {
+			tun = list_entry(ptr, struct etherip_tunnel, list);
+			ptr = ptr->prev;
+			etherip_tunnel_del(tun);
+			dev_put(tun->dev);
+			unregister_netdevice(tun->dev);
+		}
+	}
+}
+
+/* module cleanup function */
+static void __exit etherip_exit(void)
+{
+	rtnl_lock();
+	etherip_destroy_tunnels();
+	unregister_netdevice(etherip_tunnel_dev);
+	rtnl_unlock();
+	if (inet_del_protocol(&etherip_protocol, IPPROTO_ETHERIP))
+		printk(KERN_ERR "etherip: can't remove protocol\n");
+}
+
+module_init(etherip_init);
+module_exit(etherip_exit);
diff --git a/net/ipv4/ip_output.c b/net/ipv4/ip_output.c
index e8e675be60ec..24590fd4d23f 100644
--- a/net/ipv4/ip_output.c
+++ b/net/ipv4/ip_output.c
@@ -110,6 +110,14 @@ int __ip_local_out(struct net *net, struct sock *sk, struct sk_buff *skb)
 
 	skb->protocol = htons(ETH_P_IP);
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD)
+	if(skb->ipsec_offload)
+	{	
+		dst_output(net, sk, skb);	
+		return 0;
+	}	
+	else
+#endif
 	return nf_hook(NFPROTO_IPV4, NF_INET_LOCAL_OUT,
 		       net, sk, skb, NULL, skb_dst(skb)->dev,
 		       dst_output);
@@ -311,7 +319,11 @@ static int ip_finish_output(struct net *net, struct sock *sk, struct sk_buff *sk
 	if (skb_is_gso(skb))
 		return ip_finish_output_gso(net, sk, skb, mtu);
 
-	if (skb->len > mtu || (IPCB(skb)->flags & IPSKB_FRAG_PMTU))
+	if (
+#if defined(CONFIG_INET_IPSEC_OFFLOAD)
+		(skb->ipsec_offload == 0) &&
+#endif
+		((skb->len > mtu) || (IPCB(skb)->flags & IPSKB_FRAG_PMTU)))
 		return ip_fragment(net, sk, skb, mtu, ip_finish_output2);
 
 	return ip_finish_output2(net, sk, skb);
diff --git a/net/ipv4/ip_tunnel.c b/net/ipv4/ip_tunnel.c
index 4e90082b23a6..e385662fbc9b 100644
--- a/net/ipv4/ip_tunnel.c
+++ b/net/ipv4/ip_tunnel.c
@@ -436,6 +436,9 @@ int ip_tunnel_rcv(struct ip_tunnel *tunnel, struct sk_buff *skb,
 		skb->protocol = eth_type_trans(skb, tunnel->dev);
 		skb_postpull_rcsum(skb, eth_hdr(skb), ETH_HLEN);
 	} else {
+#ifdef CONFIG_CPE_FAST_PATH
+		skb->underlying_iif = skb->dev->ifindex;
+#endif
 		skb->dev = tunnel->dev;
 	}
 
diff --git a/net/ipv4/xfrm4_policy.c b/net/ipv4/xfrm4_policy.c
index 05017e2c849c..e08294824dad 100644
--- a/net/ipv4/xfrm4_policy.c
+++ b/net/ipv4/xfrm4_policy.c
@@ -28,13 +28,32 @@ static struct dst_entry *__xfrm4_dst_lookup(struct net *net, struct flowi4 *fl4,
 
 	memset(fl4, 0, sizeof(*fl4));
 	fl4->daddr = daddr->a4;
+
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+/*
+In 3.19 kernel, "rt_gateway" in IPv4 route is not set if the src and dst are directly connected.  If set,
+rt->rt_gateway else destination in IPv4 header of the packet is used as nexthop during neighbor resolution.
+
+For IPsec packets with directly connected IPv4 tunnel end points, neighbor resolution is done for inner
+destination since we do not add tunnel headers in slow path to IPsec packets. To fix this issue, flag
+"FLOWI_FLAG_KNOWN_NH" is passed during tunnel route lookup. This flag will ensure that if the src and dst
+are directly connected then a new route entry is created with "rt_gateway" set to dst address (in this case
+tunnel dst address).This new route is not cached, will not be used by any other packet, and will be deleted
+during the release of sk_buff structure.
+*/
+	fl4->flowi4_flags = FLOWI_FLAG_KNOWN_NH;
+#endif
 	fl4->flowi4_tos = tos;
 	fl4->flowi4_oif = l3mdev_master_ifindex_by_index(net, oif);
 	fl4->flowi4_mark = mark;
 	if (saddr)
 		fl4->saddr = saddr->a4;
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	fl4->flowi4_flags |= FLOWI_FLAG_SKIP_NH_OIF;
+#else
 	fl4->flowi4_flags = FLOWI_FLAG_SKIP_NH_OIF;
+#endif
 
 	rt = __ip_route_output_key(net, fl4);
 	if (!IS_ERR(rt))
diff --git a/net/ipv6/Kconfig b/net/ipv6/Kconfig
index ea71e4b0ab7a..bf15f649bf5d 100644
--- a/net/ipv6/Kconfig
+++ b/net/ipv6/Kconfig
@@ -88,6 +88,12 @@ config INET6_ESP_OFFLOAD
 
 	  If unsure, say N.
 
+config INET6_IPSEC_OFFLOAD
+	bool "IPsec IPv6 Fast Path Processing offload"
+	depends on (INET6_ESP && CPE_FAST_PATH)
+		---help---
+	  Support for IPsec IPv6 Fast Path offload.
+
 config INET6_IPCOMP
 	tristate "IPv6: IPComp transformation"
 	select INET6_XFRM_TUNNEL
@@ -275,6 +281,15 @@ config IPV6_SUBTREES
 
 	  If unsure, say N.
 
+config IPV6_ETHERIP
+	tristate "EtherIP over IPv6: EtherIP-in-IPv6 tunnel"
+	depends on IPV6
+	select INET6_TUNNEL
+	---help---
+	  Support for EtherIP-in-IPv6 tunnels described in RFC 3378.
+
+	  If unsure, say N.
+
 config IPV6_MROUTE
 	bool "IPv6: multicast routing"
 	depends on IPV6
diff --git a/net/ipv6/Makefile b/net/ipv6/Makefile
index e0026fa1261b..79d964ad01de 100644
--- a/net/ipv6/Makefile
+++ b/net/ipv6/Makefile
@@ -48,6 +48,7 @@ obj-$(CONFIG_IPV6_SIT) += sit.o
 obj-$(CONFIG_IPV6_TUNNEL) += ip6_tunnel.o
 obj-$(CONFIG_IPV6_GRE) += ip6_gre.o
 obj-$(CONFIG_IPV6_FOU) += fou6.o
+obj-$(CONFIG_IPV6_ETHERIP) += ethipip6.o
 
 obj-y += addrconf_core.o exthdrs_core.o ip6_checksum.o ip6_icmp.o
 obj-$(CONFIG_INET) += output_core.o protocol.o $(ipv6-offload)
diff --git a/net/ipv6/esp6.c b/net/ipv6/esp6.c
index 89910e2c10f4..2553aa0dd496 100644
--- a/net/ipv6/esp6.c
+++ b/net/ipv6/esp6.c
@@ -454,6 +454,39 @@ static int esp6_output(struct xfrm_state *x, struct sk_buff *skb)
 	esph = ip_esp_hdr(skb);
 	esph->spi = x->id.spi;
 
+#ifdef CONFIG_CPE_NATT
+	/* NAT-T changes Start */
+	/* this is non-NULL only with UDP Encapsulation */
+	if (x->encap) {
+		struct xfrm_encap_tmpl *encap = x->encap;
+		__be32 *udpdata32;
+		__be16 sport, dport;
+		int encap_type;
+		spin_lock_bh(&x->lock);
+		sport = encap->encap_sport;
+		dport = encap->encap_dport;
+		encap_type = encap->encap_type;
+		spin_unlock_bh(&x->lock);
+		uh = (struct udphdr *)esph;
+		uh->source = sport;
+		uh->dest = dport;
+		uh->len = htons(skb->len - skb_transport_offset(skb));
+		uh->check = 0;
+
+		switch (encap_type) {
+			default:
+			case UDP_ENCAP_ESPINUDP:
+				esph = (struct ip_esp_hdr *)(uh + 1);
+				break;
+			case UDP_ENCAP_ESPINUDP_NON_IKE:
+				udpdata32 = (__be32 *)(uh + 1);
+				udpdata32[0] = udpdata32[1] = 0;
+				esph = (struct ip_esp_hdr *)(udpdata32 + 2);
+				break;
+		}
+		*skb_mac_header(skb) = IPPROTO_UDP;
+	}
+#endif
 	esph->seq_no = htonl(XFRM_SKB_CB(skb)->seq.output.low);
 	esp.seqno = cpu_to_be64(XFRM_SKB_CB(skb)->seq.output.low +
 			    ((u64)XFRM_SKB_CB(skb)->seq.output.hi << 32));
@@ -510,6 +543,9 @@ static inline int esp_remove_trailer(struct sk_buff *skb)
 
 int esp6_input_done2(struct sk_buff *skb, int err)
 {
+#ifdef CONFIG_CPE_NATT
+	struct ipv6hdr *ipv6h;
+#endif
 	struct xfrm_state *x = xfrm_input_state(skb);
 	struct xfrm_offload *xo = xfrm_offload(skb);
 	struct crypto_aead *aead = x->data;
@@ -867,8 +903,10 @@ static int esp6_init_state(struct xfrm_state *x)
 	u32 align;
 	int err;
 
+#ifndef CONFIG_CPE_NATT
 	if (x->encap)
 		return -EINVAL;
+#endif
 
 	x->data = NULL;
 
@@ -899,6 +937,24 @@ static int esp6_init_state(struct xfrm_state *x)
 		goto error;
 	}
 
+#ifdef CONFIG_CPE_NATT
+	/* NAT-T  changes Start */
+	if (x->encap) {
+		struct xfrm_encap_tmpl *encap = x->encap;
+		switch (encap->encap_type) {
+		default:
+			goto error;
+		case UDP_ENCAP_ESPINUDP:
+			x->props.header_len += sizeof(struct udphdr);
+			break;
+		case UDP_ENCAP_ESPINUDP_NON_IKE:
+			x->props.header_len += sizeof(struct udphdr) + 2 * sizeof(u32) * 4;
+			break;
+		}
+	}
+	/* NAT-T changes End */
+#endif
+
 	align = ALIGN(crypto_aead_blocksize(aead), 4);
 	x->props.trailer_len = align + 1 + crypto_aead_authsize(aead);
 
diff --git a/net/ipv6/ethipip6.c b/net/ipv6/ethipip6.c
new file mode 100644
index 000000000000..37dd677d5959
--- /dev/null
+++ b/net/ipv6/ethipip6.c
@@ -0,0 +1,1614 @@
+/*
+ * 	EtherIP tunnel over IPv6 link
+ *	IPv6 tunneling device
+ *	Linux INET6 implementation
+ *
+ *	Authors:
+ *	Ville Nuorvala		<vnuorval@tcs.hut.fi>
+ *	Yasuyuki Kozakai	<kozakai@linux-ipv6.org>
+ *
+ *      Based on:
+ *      linux/net/ipv6/ip6_tunnel.c, linux/net/ipv6/sit.c and linux/net/ipv4/ipip.c
+ *
+ *      RFC 3378
+ *
+ *	This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/capability.h>
+#include <linux/errno.h>
+#include <linux/types.h>
+#include <linux/sockios.h>
+#include <linux/icmp.h>
+#include <linux/if.h>
+#include <linux/in.h>
+#include <linux/ip.h>
+#include <linux/if_tunnel.h>
+#include <linux/net.h>
+#include <linux/in6.h>
+#include <linux/netdevice.h>
+#include <linux/if_arp.h>
+#include <linux/icmpv6.h>
+#include <linux/init.h>
+#include <linux/route.h>
+#include <linux/rtnetlink.h>
+#include <linux/netfilter_ipv6.h>
+#include <linux/etherdevice.h>
+
+#include <asm/uaccess.h>
+#include <asm/atomic.h>
+
+#include <net/icmp.h>
+#include <net/ip.h>
+#include <net/ipv6.h>
+#include <net/ip6_route.h>
+#include <net/addrconf.h>
+#include <net/ip6_tunnel.h>
+#include <net/xfrm.h>
+#include <net/dsfield.h>
+#include <net/inet_ecn.h>
+#include <net/net_namespace.h>
+#include <net/netns/generic.h>
+#include <net/protocol.h>
+
+MODULE_AUTHOR("Ville Nuorvala");
+MODULE_DESCRIPTION("EtherIP-in-IPv6 tunneling device");
+MODULE_LICENSE("GPL");
+
+#define ETHERIP_VERSION       0x3000
+
+#define IPV6_TNL_F_TOS_TO_TC  128
+#define IPV6_TLV_TEL_DST_SIZE 8
+
+#ifdef ETHIPIP6_TNL_DEBUG
+#define ETHIPIP6_TNL_TRACE(x...) printk(KERN_DEBUG "%s:" x "\n", __func__)
+#else
+#define ETHIPIP6_TNL_TRACE(x...) do {;} while(0)
+#endif
+
+#define IPV6_TCLASS_MASK (IPV6_FLOWINFO_MASK & ~IPV6_FLOWLABEL_MASK)
+#define IPV6_TCLASS_SHIFT 20
+
+#define HASH_SIZE  32
+
+#define HASH(addr) ((__force u32)((addr)->s6_addr32[0] ^ (addr)->s6_addr32[1] ^ \
+		     (addr)->s6_addr32[2] ^ (addr)->s6_addr32[3]) & \
+		    (HASH_SIZE - 1))
+
+static void ethipip6_fb_tnl_dev_init(struct net_device *dev);
+static int ethipip6_tnl_dev_init(struct net_device *dev);
+static void ethipip6_tnl_dev_setup(struct net_device *dev);
+
+static int ethipip6_tnl_net_id __read_mostly;
+struct ip6_tnl_net {
+	/* the IPv6 tunnel fallback device */
+	struct net_device *fb_tnl_dev;
+	/* lists for storing tunnels in use */
+	struct ip6_tnl *tnls_r_l[HASH_SIZE];
+	struct ip6_tnl *tnls_wc[1];
+	struct ip6_tnl **tnls[2];
+};
+
+/*
+ * Locking : hash tables are protected by RCU and a spinlock
+ */
+static DEFINE_SPINLOCK(ethipip6_tnl_lock);
+
+/**
+ * ethipip6_tnl_lookup - fetch tunnel matching the end-point addresses
+ *   @remote: the address of the tunnel exit-point
+ *   @local: the address of the tunnel entry-point
+ *
+ * Return:
+ *   tunnel matching given end-points if found,
+ *   else fallback tunnel if its device is up,
+ *   else %NULL
+ **/
+
+#define for_each_ethip6_tunnel_rcu(start) \
+	for (t = rcu_dereference(start); t; t = rcu_dereference(t->next))
+
+static struct ip6_tnl *
+ethipip6_tnl_lookup(struct net *net, struct in6_addr *remote, struct in6_addr *local)
+{
+	unsigned h0 = HASH(remote);
+	unsigned h1 = HASH(local);
+	struct ip6_tnl *t;
+	struct ip6_tnl_net *ip6n = net_generic(net, ethipip6_tnl_net_id);
+
+	for_each_ethip6_tunnel_rcu(ip6n->tnls_r_l[h0 ^ h1]) {
+		if (ipv6_addr_equal(local, &t->parms.laddr) &&
+		    ipv6_addr_equal(remote, &t->parms.raddr) &&
+		    (t->dev->flags & IFF_UP))
+			return t;
+	}
+	t = rcu_dereference(ip6n->tnls_wc[0]);
+	if (t && (t->dev->flags & IFF_UP))
+		return t;
+
+	return NULL;
+}
+
+/**
+ * ethipip6_tnl_bucket - get head of list matching given tunnel parameters
+ *   @p: parameters containing tunnel end-points
+ *
+ * Description:
+ *   ethipip6_tnl_bucket() returns the head of the list matching the
+ *   &struct in6_addr entries laddr and raddr in @p.
+ *
+ * Return: head of IPv6 tunnel list
+ **/
+
+static struct ip6_tnl **
+ethipip6_tnl_bucket(struct ip6_tnl_net *ip6n, struct __ip6_tnl_parm *p)
+{
+	struct in6_addr *remote = &p->raddr;
+	struct in6_addr *local = &p->laddr;
+	unsigned h = 0;
+	int prio = 0;
+
+	if (!ipv6_addr_any(remote) || !ipv6_addr_any(local)) {
+		prio = 1;
+		h = HASH(remote) ^ HASH(local);
+	}
+	return &ip6n->tnls[prio][h];
+}
+
+/**
+ * ethipip6_tnl_link - add tunnel to hash table
+ *   @t: tunnel to be added
+ **/
+
+static void
+ethipip6_tnl_link(struct ip6_tnl_net *ip6n, struct ip6_tnl *t)
+{
+	struct ip6_tnl **tp = ethipip6_tnl_bucket(ip6n, &t->parms);
+
+	spin_lock_bh(&ethipip6_tnl_lock);
+	t->next = *tp;
+	rcu_assign_pointer(*tp, t);
+	spin_unlock_bh(&ethipip6_tnl_lock);
+}
+
+/**
+ * ethipip6_tnl_unlink - remove tunnel from hash table
+ *   @t: tunnel to be removed
+ **/
+
+static void
+ethipip6_tnl_unlink(struct ip6_tnl_net *ip6n, struct ip6_tnl *t)
+{
+	struct ip6_tnl **tp;
+
+	for (tp = ethipip6_tnl_bucket(ip6n, &t->parms); *tp; tp = &(*tp)->next) {
+		if (t == *tp) {
+			spin_lock_bh(&ethipip6_tnl_lock);
+			*tp = t->next;
+			spin_unlock_bh(&ethipip6_tnl_lock);
+			break;
+		}
+	}
+}
+
+/**
+ * ip6_tnl_create() - create a new tunnel
+ *   @p: tunnel parameters
+ *   @pt: pointer to new tunnel
+ *
+ * Description:
+ *   Create tunnel matching given parameters.
+ *
+ * Return:
+ *   created tunnel or NULL
+ **/
+
+static struct ip6_tnl *ip6_tnl_create(struct net *net, struct __ip6_tnl_parm *p)
+{
+	struct net_device *dev;
+	struct ip6_tnl *t;
+	char name[IFNAMSIZ];
+	int err;
+	struct ip6_tnl_net *ip6n = net_generic(net, ethipip6_tnl_net_id);
+
+	if (p->name[0])
+		strlcpy(name, p->name, IFNAMSIZ);
+	else
+		sprintf(name, "ethipip6tnl%%d");
+
+	dev = alloc_netdev(sizeof (*t), name, NET_NAME_UNKNOWN, ethipip6_tnl_dev_setup);
+	if (dev == NULL)
+		goto failed;
+
+	dev_net_set(dev, net);
+
+	if (strchr(name, '%')) {
+		if (dev_alloc_name(dev, name) < 0)
+			goto failed_free;
+	}
+
+	t = netdev_priv(dev);
+	t->parms = *p;
+
+	if ((err = register_netdevice(dev)) < 0)
+		goto failed_free;
+
+	dev_hold(dev);
+	ethipip6_tnl_link(ip6n, t);
+	return t;
+
+failed_free:
+	free_netdev(dev);
+failed:
+	return NULL;
+}
+
+/**
+ * ethipip6_tnl_locate - find or create tunnel matching given parameters
+ *   @p: tunnel parameters
+ *   @create: != 0 if allowed to create new tunnel if no match found
+ *
+ * Description:
+ *   ethipip6_tnl_locate() first tries to locate an existing tunnel
+ *   based on @parms. If this is unsuccessful, but @create is set a new
+ *   tunnel device is created and registered for use.
+ *
+ * Return:
+ *   matching tunnel or NULL
+ **/
+
+static struct ip6_tnl *ethipip6_tnl_locate(struct net *net,
+		struct __ip6_tnl_parm *p, int create)
+{
+	struct in6_addr *remote = &p->raddr;
+	struct in6_addr *local = &p->laddr;
+	struct ip6_tnl *t;
+	struct ip6_tnl_net *ip6n = net_generic(net, ethipip6_tnl_net_id);
+
+	for (t = *ethipip6_tnl_bucket(ip6n, p); t; t = t->next) {
+		if (ipv6_addr_equal(local, &t->parms.laddr) &&
+		    ipv6_addr_equal(remote, &t->parms.raddr)) {
+			if (create)
+				return NULL;
+
+			return t;
+		}
+	}
+	if (!create)
+		return NULL;
+	return ip6_tnl_create(net, p);
+}
+
+/**
+ * ethipip6_tnl_dev_uninit - tunnel device uninitializer
+ *   @dev: the device to be destroyed
+ *
+ * Description:
+ *   ethipip6_tnl_dev_uninit() removes tunnel from its list
+ **/
+
+static void
+ethipip6_tnl_dev_uninit(struct net_device *dev)
+{
+	struct ip6_tnl *t = netdev_priv(dev);
+	struct net *net = dev_net(dev);
+	struct ip6_tnl_net *ip6n = net_generic(net, ethipip6_tnl_net_id);
+
+	if (dev == ip6n->fb_tnl_dev) {
+		spin_lock_bh(&ethipip6_tnl_lock);
+		ip6n->tnls_wc[0] = NULL;
+		spin_unlock_bh(&ethipip6_tnl_lock);
+	} else {
+		ethipip6_tnl_unlink(ip6n, t);
+	}
+	ip6_tnl_dst_reset(t);
+	dev_put(dev);
+}
+
+/**
+ * parse_tvl_tnl_enc_lim - handle encapsulation limit option
+ *   @skb: received socket buffer
+ *
+ * Return:
+ *   0 if none was found,
+ *   else index to encapsulation limit
+ **/
+
+static __u16
+parse_tlv_tnl_enc_lim(struct sk_buff *skb, __u8 * raw)
+{
+	struct ipv6hdr *ipv6h = (struct ipv6hdr *) raw;
+	__u8 nexthdr = ipv6h->nexthdr;
+	__u16 off = sizeof(*ipv6h);
+
+	while (ipv6_ext_hdr(nexthdr) && nexthdr != NEXTHDR_NONE) {
+		__u16 optlen = 0;
+		struct ipv6_opt_hdr *hdr;
+		if (raw + off + sizeof(*hdr) > skb->data &&
+		    !pskb_may_pull(skb, raw - skb->data + off + sizeof (*hdr)))
+			break;
+
+		hdr = (struct ipv6_opt_hdr *) (raw + off);
+		if (nexthdr == NEXTHDR_FRAGMENT) {
+			struct frag_hdr *frag_hdr = (struct frag_hdr *) hdr;
+			if (frag_hdr->frag_off)
+				break;
+			optlen = 8;
+		} else if (nexthdr == NEXTHDR_AUTH) {
+			optlen = (hdr->hdrlen + 2) << 2;
+		} else {
+			optlen = ipv6_optlen(hdr);
+		}
+		if (nexthdr == NEXTHDR_DEST) {
+			__u16 i = off + 2;
+			while (1) {
+				struct ipv6_tlv_tnl_enc_lim *tel;
+
+				/* No more room for encapsulation limit */
+				if (i + sizeof (*tel) > off + optlen)
+					break;
+
+				tel = (struct ipv6_tlv_tnl_enc_lim *) &raw[i];
+				/* return index of option if found and valid */
+				if (tel->type == IPV6_TLV_TNL_ENCAP_LIMIT &&
+				    tel->length == 1)
+					return i;
+				/* else jump to next option */
+				if (tel->type)
+					i += tel->length + 2;
+				else
+					i++;
+			}
+		}
+		nexthdr = hdr->nexthdr;
+		off += optlen;
+	}
+	return 0;
+}
+
+/**
+ * ethipip6_tnl_err - tunnel error handler
+ *
+ * Description:
+ *   ethipip6_tnl_err() should handle errors in the tunnel according
+ *   to the specifications in RFC 2473.
+ **/
+
+static int
+ethipip6_tnl_err(struct sk_buff *skb, __u8 ipproto, struct inet6_skb_parm *opt,
+	    u8 *type, u8 *code, int *msg, __u32 *info, int offset)
+{
+	struct ipv6hdr *ipv6h = (struct ipv6hdr *) skb->data;
+	struct ip6_tnl *t;
+	int rel_msg = 0;
+	u8 rel_type = ICMPV6_DEST_UNREACH;
+	u8 rel_code = ICMPV6_ADDR_UNREACH;
+	__u32 rel_info = 0;
+	__u16 len;
+	int err = -ENOENT;
+
+	/* If the packet doesn't contain the original IPv6 header we are
+	   in trouble since we might need the source address for further
+	   processing of the error. */
+
+	rcu_read_lock();
+	if ((t = ethipip6_tnl_lookup(dev_net(skb->dev), &ipv6h->daddr,
+					&ipv6h->saddr)) == NULL)
+		goto out;
+
+	if (t->parms.proto != ipproto && t->parms.proto != 0)
+		goto out;
+
+	err = 0;
+
+	switch (*type) {
+		__u32 teli;
+		struct ipv6_tlv_tnl_enc_lim *tel;
+		__u32 mtu;
+	case ICMPV6_DEST_UNREACH:
+		if (net_ratelimit())
+			printk(KERN_WARNING
+			       "%s: Path to destination invalid "
+			       "or inactive!\n", t->parms.name);
+		rel_msg = 1;
+		break;
+	case ICMPV6_TIME_EXCEED:
+		if ((*code) == ICMPV6_EXC_HOPLIMIT) {
+			if (net_ratelimit())
+				printk(KERN_WARNING
+				       "%s: Too small hop limit or "
+				       "routing loop in tunnel!\n",
+				       t->parms.name);
+			rel_msg = 1;
+		}
+		break;
+	case ICMPV6_PARAMPROB:
+		teli = 0;
+		if ((*code) == ICMPV6_HDR_FIELD)
+			teli = parse_tlv_tnl_enc_lim(skb, skb->data);
+
+		if (teli && teli == *info - 2) {
+			tel = (struct ipv6_tlv_tnl_enc_lim *) &skb->data[teli];
+			if (tel->encap_limit == 0) {
+				if (net_ratelimit())
+					printk(KERN_WARNING
+					       "%s: Too small encapsulation "
+					       "limit or routing loop in "
+					       "tunnel!\n", t->parms.name);
+				rel_msg = 1;
+			}
+		} else if (net_ratelimit()) {
+			printk(KERN_WARNING
+			       "%s: Recipient unable to parse tunneled "
+			       "packet!\n ", t->parms.name);
+		}
+		break;
+	case ICMPV6_PKT_TOOBIG:
+		mtu = *info - offset;
+		if (mtu < IPV6_MIN_MTU)
+			mtu = IPV6_MIN_MTU;
+		t->dev->mtu = mtu;
+
+		if ((len = sizeof (*ipv6h) + ntohs(ipv6h->payload_len)) > mtu) {
+			rel_type = ICMPV6_PKT_TOOBIG;
+			rel_code = 0;
+			rel_info = mtu;
+			rel_msg = 1;
+		}
+		break;
+	}
+
+	*type = rel_type;
+	*code = rel_code;
+	*info = rel_info;
+	*msg = rel_msg;
+
+out:
+	rcu_read_unlock();
+	return err;
+}
+
+static void 
+ip4ethipip6_err(struct sk_buff *skb, struct inet6_skb_parm *opt,
+	   u8 type, u8 code, int offset, __be32 info)
+{
+	int rel_msg = 0;
+	u8 rel_type = type;
+	u8 rel_code = code;
+	__u32 rel_info = ntohl(info);
+	int err;
+	struct sk_buff *skb2;
+	struct iphdr *eiph;
+	struct flowi fl;
+	struct rtable *rt;
+
+	err = ethipip6_tnl_err(skb, IPPROTO_IPIP, opt, &rel_type, &rel_code,
+			  &rel_msg, &rel_info, offset);
+	if (err < 0)
+		return;
+
+	if (rel_msg == 0)
+		return;
+
+	switch (rel_type) {
+	case ICMPV6_DEST_UNREACH:
+		if (rel_code != ICMPV6_ADDR_UNREACH)
+			return;
+		rel_type = ICMP_DEST_UNREACH;
+		rel_code = ICMP_HOST_UNREACH;
+		break;
+	case ICMPV6_PKT_TOOBIG:
+		if (rel_code != 0)
+			return;
+		rel_type = ICMP_DEST_UNREACH;
+		rel_code = ICMP_FRAG_NEEDED;
+		break;
+	default:
+		return;
+	}
+
+	if (!pskb_may_pull(skb, offset + sizeof(struct iphdr)))
+		return;
+
+	skb2 = skb_clone(skb, GFP_ATOMIC);
+	if (!skb2)
+		return;
+
+	skb_dst_drop(skb2);
+
+	skb_pull(skb2, offset);
+	skb_reset_network_header(skb2);
+	eiph = ip_hdr(skb2);
+
+	/* Try to guess incoming interface */
+	memset(&fl, 0, sizeof(fl));
+	fl.u.ip4.daddr = eiph->saddr;
+	fl.flowi_tos = RT_TOS(eiph->tos);
+	fl.flowi_proto = IPPROTO_IPIP;
+	rt = ip_route_output_key(dev_net(skb->dev), &fl.u.ip4);
+	if (IS_ERR(rt))
+		goto out;
+
+	skb2->dev = rt->dst.dev;
+
+	/* route "incoming" packet */
+	if (rt->rt_flags & RTCF_LOCAL) {
+		ip_rt_put(rt);
+		fl.u.ip4.daddr = eiph->daddr;
+		fl.u.ip4.saddr = eiph->saddr;
+		fl.flowi_tos = eiph->tos;
+		rt = ip_route_output_key(dev_net(skb->dev), &fl.u.ip4);
+		if (IS_ERR(rt))
+			goto out;
+		if (rt->dst.dev->type != ARPHRD_TUNNEL) {
+			ip_rt_put(rt);
+			goto out;
+		}
+		skb_dst_set(skb2, (struct dst_entry *)rt);
+	} else {
+		ip_rt_put(rt);
+		if (ip_route_input(skb2, eiph->daddr, eiph->saddr, eiph->tos,
+				   skb2->dev) ||
+		    skb_dst(skb2)->dev->type != ARPHRD_TUNNEL)
+			goto out;
+	}
+
+	/* change mtu on this route */
+	if (rel_type == ICMP_DEST_UNREACH && rel_code == ICMP_FRAG_NEEDED) {
+		if (rel_info > dst_mtu(skb_dst(skb2)))
+			goto out;
+
+		skb_dst(skb2)->ops->update_pmtu(skb_dst(skb2), NULL, skb2, rel_info);
+	}
+
+	icmp_send(skb2, rel_type, rel_code, htonl(rel_info));
+
+out:
+	kfree_skb(skb2);
+	return;
+}
+
+static int
+ip6ethipip6_err(struct sk_buff *skb, struct inet6_skb_parm *opt,
+	   u8 type, u8 code, int offset, __be32 info)
+{
+	int rel_msg = 0;
+	u8 rel_type = type;
+	u8 rel_code = code;
+	__u32 rel_info = ntohl(info);
+	int err;
+
+	err = ethipip6_tnl_err(skb, IPPROTO_IPV6, opt, &rel_type, &rel_code,
+			  &rel_msg, &rel_info, offset);
+	if (err < 0)
+		return err;
+
+	if (rel_msg && pskb_may_pull(skb, offset + sizeof(struct ipv6hdr))) {
+		struct rt6_info *rt;
+		struct sk_buff *skb2 = skb_clone(skb, GFP_ATOMIC);
+
+		if (!skb2)
+			return 0;
+
+		skb_dst_drop(skb2);
+		skb_pull(skb2, offset);
+		skb_reset_network_header(skb2);
+
+		/* Try to guess incoming interface */
+		rt = rt6_lookup(dev_net(skb->dev), &ipv6_hdr(skb2)->saddr,
+				NULL, 0, 0);
+
+		if (rt && rt->dst.dev)
+			skb2->dev = rt->dst.dev;
+
+		icmpv6_send(skb2, rel_type, rel_code, rel_info);
+
+		if (rt)
+			dst_release(&rt->dst);
+
+		kfree_skb(skb2);
+	}
+
+	return 0;
+}
+
+static void ip4ethipip6_dscp_ecn_decapsulate(struct ip6_tnl *t,
+					struct ipv6hdr *ipv6h,
+					struct sk_buff *skb)
+{
+	__u8 dsfield = ipv6_get_dsfield(ipv6h) & ~INET_ECN_MASK;
+
+	if (t->parms.flags & IP6_TNL_F_RCV_DSCP_COPY)
+		ipv4_change_dsfield(ip_hdr(skb), INET_ECN_MASK, dsfield);
+
+	if (INET_ECN_is_ce(dsfield))
+		IP_ECN_set_ce(ip_hdr(skb));
+}
+
+static void ip6ethipip6_dscp_ecn_decapsulate(struct ip6_tnl *t,
+					struct ipv6hdr *ipv6h,
+					struct sk_buff *skb)
+{
+	if (t->parms.flags & IP6_TNL_F_RCV_DSCP_COPY)
+		ipv6_copy_dscp(ipv6_get_dsfield(ipv6h), ipv6_hdr(skb));
+
+	if (INET_ECN_is_ce(ipv6_get_dsfield(ipv6h)))
+		IP6_ECN_set_ce(ipv6_hdr(skb));
+}
+
+/* called with rcu_read_lock() */
+static inline int __ethipip6_tnl_rcv_ctl(struct ip6_tnl *t)
+{
+	struct ip6_tnl_parm *p = &t->parms;
+	int ret = 0;
+	struct net *net = dev_net(t->dev);
+ 
+	if (p->flags & IP6_TNL_F_CAP_RCV) {
+		struct net_device *ldev = NULL;
+
+		if (p->link)
+			ldev = dev_get_by_index_rcu(net, p->link);
+
+		if ((ipv6_addr_is_multicast(&p->laddr) ||
+		     likely(ipv6_chk_addr(net, &p->laddr, ldev, 0))) &&
+		    likely(!ipv6_chk_addr(net, &p->raddr, NULL, 0)))
+			ret = 1;
+
+	}
+	return ret;
+}
+
+/**
+ * ethipip6_tnl_rcv - decapsulate IPv6 packet and retransmit it locally
+ *   @skb: received socket buffer
+ *   @protocol: ethernet protocol ID
+ *   @dscp_ecn_decapsulate: the function to decapsulate DSCP code and ECN
+ *
+ * Return: 0
+ **/
+static int ethipip6_tnl_rcv(struct sk_buff *skb, __u16 protocol,
+		       __u8 ipproto,
+		       void (*dscp_ecn_decapsulate)(struct ip6_tnl *t,
+						    struct ipv6hdr *ipv6h,
+						    struct sk_buff *skb))
+{
+	struct ip6_tnl *t;
+	struct ipv6hdr *ipv6h = ipv6_hdr(skb);
+
+	__u16 *etherip_ver;
+
+	if (!pskb_may_pull(skb, ETH_IPHLEN+ETH_HLEN))
+		goto discard;
+	
+	etherip_ver = (__u16 *)skb->data;
+	if (*etherip_ver != htons(ETHERIP_VERSION)) 
+		goto discard;
+	
+	rcu_read_lock();
+
+	if ((t = ethipip6_tnl_lookup(dev_net(skb->dev), &ipv6h->saddr,
+					&ipv6h->daddr)) != NULL) {
+		if (t->parms.proto != ipproto && t->parms.proto != 0) {
+			rcu_read_unlock();
+			goto discard;
+		}
+
+		/* Check the xfrm policy for decrypted packets */
+		if (skb->sp && !xfrm6_policy_check(NULL, XFRM_POLICY_IN, skb)) {
+			rcu_read_unlock();
+			goto discard;
+		}
+
+		if (!__ethipip6_tnl_rcv_ctl(t)) {
+			t->dev->stats.rx_dropped++;
+			rcu_read_unlock();
+			goto discard;
+		}
+		/*
+		 * ip6_tunnel.c ip6_tnl_rcv() function, the below steps are removed and 
+		 * they are covered under __skb_tunnel_rx(). But in earlier version also
+		 * this function we did not ported. So, here __skb_tunnel_rx() funcation
+		 * call not present, so the below steps are not removed.
+  		 *	secpath_reset(skb);
+		 *	skb->pkt_type = PACKET_HOST;
+		 */
+		secpath_reset(skb);
+		skb_pull(skb, ETH_IPHLEN);
+		skb->pkt_type = PACKET_HOST;
+		skb->protocol = eth_type_trans(skb, skb->dev);
+		skb_reset_network_header(skb);
+
+
+		memset(skb->cb, 0, sizeof(struct inet6_skb_parm));
+		skb->dev = t->dev;
+		skb_dst_drop(skb);
+		nf_reset(skb);
+
+		dscp_ecn_decapsulate(t, ipv6h, skb);
+
+		t->dev->stats.rx_packets++;
+		t->dev->stats.rx_bytes += skb->len;
+		netif_rx(skb);
+		rcu_read_unlock();
+		return 0;
+	}
+	rcu_read_unlock();
+
+discard:
+	kfree_skb(skb);
+	return 0;
+}
+
+static int ip4ethipip6_rcv(struct sk_buff *skb)
+{
+	return ethipip6_tnl_rcv(skb, ETH_P_IP, IPPROTO_ETHERIP,
+			   ip4ethipip6_dscp_ecn_decapsulate);
+}
+
+static int ip6ethipip6_rcv(struct sk_buff *skb)
+{
+	return ethipip6_tnl_rcv(skb, ETH_P_IPV6, IPPROTO_ETHERIP,
+			   ip6ethipip6_dscp_ecn_decapsulate);
+}
+
+struct ipv6_tel_txoption {
+	struct ipv6_txoptions ops;
+	__u8 dst_opt[8];
+};
+
+static void init_tel_txopt(struct ipv6_tel_txoption *opt, __u8 encap_limit)
+{
+	memset(opt, 0, sizeof(struct ipv6_tel_txoption));
+
+	opt->dst_opt[2] = IPV6_TLV_TNL_ENCAP_LIMIT;
+	opt->dst_opt[3] = 1;
+	opt->dst_opt[4] = encap_limit;
+	opt->dst_opt[5] = IPV6_TLV_PADN;
+	opt->dst_opt[6] = 1;
+
+	opt->ops.dst0opt = (struct ipv6_opt_hdr *) opt->dst_opt;
+	opt->ops.opt_nflen = 8;
+}
+
+/**
+ * ethipip6_tnl_addr_conflict - compare packet addresses to tunnel's own
+ *   @t: the outgoing tunnel device
+ *   @hdr: IPv6 header from the incoming packet
+ *
+ * Description:
+ *   Avoid trivial tunneling loop by checking that tunnel exit-point
+ *   doesn't match source of incoming packet.
+ *
+ * Return:
+ *   1 if conflict,
+ *   0 else
+ **/
+
+static inline int
+ethipip6_tnl_addr_conflict(struct ip6_tnl *t, struct ipv6hdr *hdr)
+{
+	return ipv6_addr_equal(&t->parms.raddr, &hdr->saddr);
+}
+
+static inline int ethipip6_tnl_xmit_ctl(struct ip6_tnl *t)
+{
+	struct __ip6_tnl_parm *p = &t->parms;
+	int ret = 0;
+	struct net *net = dev_net(t->dev);
+
+	if (p->flags & IP6_TNL_F_CAP_XMIT) {
+		struct net_device *ldev = NULL;
+
+		rcu_read_lock();
+		if (p->link)
+			ldev = dev_get_by_index_rcu(net, p->link);
+
+		if (unlikely(!ipv6_chk_addr(net, &p->laddr, ldev, 0)))
+			printk(KERN_WARNING
+			       "%s xmit: Local address not yet configured!\n",
+			       p->name);
+		else if (!ipv6_addr_is_multicast(&p->raddr) &&
+			 unlikely(ipv6_chk_addr(net, &p->raddr, NULL, 0)))
+			printk(KERN_WARNING
+			       "%s xmit: Routing loop! "
+			       "Remote address found on this node!\n",
+			       p->name);
+		else
+			ret = 1;
+		rcu_read_unlock();
+	}
+	return ret;
+}
+/**
+ * ethipip6_tnl_xmit2 - encapsulate packet and send
+ *   @skb: the outgoing socket buffer
+ *   @dev: the outgoing tunnel device
+ *   @dsfield: dscp code for outer header
+ *   @fl: flow of tunneled packet
+ *   @encap_limit: encapsulation limit
+ *   @pmtu: Path MTU is stored if packet is too big
+ *
+ * Description:
+ *   Build new header and do some sanity checks on the packet before sending
+ *   it.
+ *
+ * Return:
+ *   0 on success
+ *   -1 fail
+ *   %-EMSGSIZE message too big. return mtu in this case.
+ **/
+
+static int ethipip6_tnl_xmit2(struct sk_buff *skb,
+			 struct net_device *dev,
+			 __u8 dsfield,
+			 struct flowi *fl,
+			 int encap_limit,
+			 __u32 *pmtu)
+{
+	struct net *net = dev_net(dev);
+	struct ip6_tnl *t = netdev_priv(dev);
+	struct net_device_stats *stats = &t->dev->stats;
+	struct ipv6hdr *ipv6h = ipv6_hdr(skb);
+	struct ipv6_tel_txoption opt;
+	struct dst_entry *dst;
+	struct net_device *tdev;
+	int mtu;
+	unsigned int max_headroom = sizeof(struct ipv6hdr);
+	u8 proto;
+	int err = -1;
+	int pkt_len;
+	__u16 *etherip_ver;
+
+	if (((dst = ip6_tnl_dst_check(t)) != NULL) 
+#if defined(CONFIG_INET6_IPSEC_OFFLOAD)            
+                && (t->genid == atomic_read(&net->xfrm.flow_cache_genid))
+#endif
+            ) {
+		dst_hold(dst);
+        } else {
+		dst = ip6_route_output(net, NULL, &fl->u.ip6);
+
+		if(dst->error)
+			goto tx_err_link_failure;
+		dst = xfrm_lookup(net, dst, fl, NULL, 0);
+		if(IS_ERR(dst))
+		{
+			err = PTR_ERR(dst);
+			dst = NULL;
+			goto tx_err_link_failure;
+		}
+#if defined(CONFIG_INET6_IPSEC_OFFLOAD)
+		t->genid = atomic_read(&net->xfrm.flow_cache_genid);
+#endif
+        }
+
+	/* donot allow wifi specific pkts to be bridged,
+         * is there any better why to identify this condition!!! 
+         * if (skb->len < 42) some thing like this... 
+         * For regular ethernet pkts, iphdr is always aligned to 4bytes,
+         * so one way is to check the address alignment */
+	if (!((unsigned int)skb->data & 0x3)) {
+		stats->rx_length_errors++;
+	 	goto tx_err_dst_release;
+	}
+
+	tdev = dst->dev;
+
+	if (tdev == dev) {
+		stats->collisions++;
+		if (net_ratelimit())
+			printk(KERN_WARNING
+			       "%s: Local routing loop detected!\n",
+			       t->parms.name);
+		goto tx_err_dst_release;
+	}
+	mtu = dst_mtu(dst) - (sizeof (*ipv6h) + ETH_IPHLEN + ETH_HLEN);
+	if (encap_limit >= 0) {
+		max_headroom += 8;
+		mtu -= 8;
+	}
+	if (mtu < IPV6_MIN_MTU)
+		mtu = IPV6_MIN_MTU;
+	if (skb_dst(skb))
+		skb_dst(skb)->ops->update_pmtu(skb_dst(skb), NULL, skb, mtu);
+
+	/*
+	 * Okay, now see if we can stuff it in the buffer as-is.
+	 */
+	max_headroom += LL_RESERVED_SPACE(tdev);
+
+	if (skb_headroom(skb) < max_headroom || skb_shared(skb) ||
+	    (skb_cloned(skb) && !skb_clone_writable(skb, 0))) {
+		struct sk_buff *new_skb;
+
+		if (!(new_skb = skb_realloc_headroom(skb, max_headroom)))
+			goto tx_err_dst_release;
+
+		if (skb->sk)
+			skb_set_owner_w(new_skb, skb->sk);
+		kfree_skb(skb);
+		skb = new_skb;
+	}
+	skb_dst_drop(skb);
+	skb_dst_set(skb, dst_clone(dst));
+
+	skb->transport_header = skb->network_header;
+	IP6CB(skb)->nhoff = offsetof(struct ipv6hdr, nexthdr);
+
+	etherip_ver  = (__u16 *)skb_push(skb, ETH_IPHLEN);
+	*etherip_ver = htons(ETHERIP_VERSION);
+
+	proto = fl->flowi_proto;
+	if (encap_limit >= 0) {
+		init_tel_txopt(&opt, encap_limit);
+		ipv6_push_nfrag_opts(skb, &opt.ops, &proto, NULL);
+	}
+	skb_push(skb, sizeof(struct ipv6hdr));
+	skb_reset_network_header(skb);
+	ipv6h = ipv6_hdr(skb);
+	*(__be32*)ipv6h = fl->u.ip6.flowlabel | htonl(0x60000000);
+	//dsfield = INET_ECN_encapsulate(0, dsfield);
+	//ipv6_change_dsfield(ipv6h, ~INET_ECN_MASK, dsfield);
+	ipv6h->hop_limit = t->parms.hop_limit;
+	ipv6h->nexthdr = proto;
+	ipv6h->saddr = fl->u.ip6.saddr;
+	ipv6h->daddr = fl->u.ip6.daddr;
+	nf_reset(skb);
+	pkt_len = skb->len;
+	skb->ignore_df = 1;
+	err = ip6_local_out(skb);
+
+	if (net_xmit_eval(err) == 0) {
+		stats->tx_bytes += pkt_len;
+		stats->tx_packets++;
+	} else {
+		stats->tx_errors++;
+		stats->tx_aborted_errors++;
+	}
+	ip6_tnl_dst_store(t, dst);
+	return 0;
+tx_err_link_failure:
+	stats->tx_carrier_errors++;
+	dst_link_failure(skb);
+tx_err_dst_release:
+	dst_release(dst);
+	return err;
+}
+
+static inline int
+__ethipip6_tnl_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	struct ip6_tnl *t = netdev_priv(dev);
+	struct flowi fl;
+	__u32 mtu = 0;
+	int err;
+
+	memcpy(&fl, &t->fl, sizeof (fl));
+	fl.flowi_proto = IPPROTO_ETHERIP;
+
+	err = ethipip6_tnl_xmit2(skb, dev, 0, &fl, -1, &mtu);
+	if (err != 0) {
+		/* XXX: send ICMP error even if DF is not set. */
+		if (err == -EMSGSIZE) {
+			icmp_send(skb, ICMP_DEST_UNREACH, ICMP_FRAG_NEEDED, htonl(mtu));
+		}
+		return -1;
+	}
+
+	return 0;
+}
+
+static inline int
+ip4ethipip6_tnl_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	struct ip6_tnl *t = netdev_priv(dev);
+	struct iphdr  *iph = ip_hdr(skb);
+	int encap_limit = -1;
+	struct flowi fl;
+	__u8 dsfield;
+	__u32 mtu = 0;
+	int err;
+
+
+	memcpy(&fl, &t->fl, sizeof (fl));
+	fl.flowi_proto = IPPROTO_ETHERIP;
+
+	dsfield = ipv4_get_dsfield(iph);
+
+
+	err = ethipip6_tnl_xmit2(skb, dev, dsfield, &fl, encap_limit, &mtu);
+	if (err != 0) {
+		/* XXX: send ICMP error even if DF is not set. */
+		if (err == -EMSGSIZE)
+			icmp_send(skb, ICMP_DEST_UNREACH, ICMP_FRAG_NEEDED, 
+				htonl(mtu));
+		return -1;
+	}
+
+	return 0;
+}
+
+static inline int
+ip6ethipip6_tnl_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	struct ip6_tnl *t = netdev_priv(dev);
+	struct ipv6hdr *ipv6h = ipv6_hdr(skb);
+	int encap_limit = -1;
+	//__u16 offset;
+	struct flowi fl;
+	__u8 dsfield;
+	__u32 mtu = 0;
+	int err;
+
+	memcpy(&fl, &t->fl, sizeof (fl));
+	fl.flowi_proto = IPPROTO_ETHERIP;
+
+	dsfield = ipv6_get_dsfield(ipv6h);
+
+	err = ethipip6_tnl_xmit2(skb, dev, dsfield, &fl, encap_limit, &mtu);
+	if (err != 0) {
+		if (err == -EMSGSIZE)
+			icmpv6_send(skb, ICMPV6_PKT_TOOBIG, 0, mtu);
+		return -1;
+	}
+
+	return 0;
+}
+
+static netdev_tx_t
+ethipip6_tnl_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	struct ip6_tnl *t = netdev_priv(dev);
+	struct net_device_stats *stats = &t->dev->stats;
+	int ret;
+
+	switch (skb->protocol) {
+	case htons(ETH_P_IP):
+		ret = ip4ethipip6_tnl_xmit(skb, dev);
+		break;
+	case htons(ETH_P_IPV6):
+		ret = ip6ethipip6_tnl_xmit(skb, dev);
+		break;
+	default:
+		ret = __ethipip6_tnl_xmit(skb, dev);
+		break;
+	}
+
+	if (ret < 0)
+		goto tx_err;
+
+	return NETDEV_TX_OK;
+
+tx_err:
+	stats->tx_errors++;
+	stats->tx_dropped++;
+	kfree_skb(skb);
+	return NETDEV_TX_OK;
+}
+
+static void ip6_tnl_set_cap(struct ip6_tnl *t)
+{
+	struct __ip6_tnl_parm *p = &t->parms;
+	int ltype = ipv6_addr_type(&p->laddr);
+	int rtype = ipv6_addr_type(&p->raddr);
+
+	p->flags &= ~(IP6_TNL_F_CAP_XMIT|IP6_TNL_F_CAP_RCV);
+
+	if (ltype & (IPV6_ADDR_UNICAST|IPV6_ADDR_MULTICAST) &&
+	    rtype & (IPV6_ADDR_UNICAST|IPV6_ADDR_MULTICAST) &&
+	    !((ltype|rtype) & IPV6_ADDR_LOOPBACK) &&
+	    (!((ltype|rtype) & IPV6_ADDR_LINKLOCAL) || p->link)) {
+		if (ltype&IPV6_ADDR_UNICAST)
+			p->flags |= IP6_TNL_F_CAP_XMIT;
+		if (rtype&IPV6_ADDR_UNICAST)
+			p->flags |= IP6_TNL_F_CAP_RCV;
+	}
+}
+
+static void ethipip6_tnl_link_config(struct ip6_tnl *t)
+{
+	struct net_device *dev = t->dev;
+	struct __ip6_tnl_parm *p = &t->parms;
+	struct flowi *fl = &t->fl;
+	struct net_device *ldev = NULL;
+	struct net *net = dev_net(t->dev);
+
+	memcpy(dev->dev_addr, &p->laddr, dev->addr_len);
+	/* Make sure that dev_addr is nither mcast nor all zeros */
+	dev->dev_addr[0] &= 0xfe;
+	dev->dev_addr[0] |= 0x2;
+
+	memcpy(dev->broadcast, &p->raddr, sizeof(struct in6_addr));
+
+	/* Set up flowi template */
+	fl->u.ip6.saddr = p->laddr;
+	fl->u.ip6.daddr = p->raddr;
+	fl->flowi_oif = p->link;
+	//fl->u.ip6.flowlabel = 0; 
+
+	if (!(p->flags&IP6_TNL_F_USE_ORIG_TCLASS))
+		fl->u.ip6.flowlabel |= IPV6_TCLASS_MASK & p->flowinfo;
+	if (!(p->flags&IP6_TNL_F_USE_ORIG_FLOWLABEL))
+		fl->u.ip6.flowlabel |= IPV6_FLOWLABEL_MASK & p->flowinfo;
+
+	ip6_tnl_set_cap(t);
+
+	if (p->flags&IP6_TNL_F_CAP_XMIT && p->flags&IP6_TNL_F_CAP_RCV)
+		dev->flags |= IFF_POINTOPOINT;
+	else
+		dev->flags &= ~IFF_POINTOPOINT;
+
+	dev->iflink = p->link;
+
+	/* Initialize the default mtu  of tunnel with it's parent interface
+	mtu */
+	rcu_read_lock();
+	if (p->link)
+	{
+		ldev = dev_get_by_index_rcu(net, p->link);
+		if (ldev)
+			dev->mtu = ldev->mtu;
+	}
+	rcu_read_unlock();
+
+	if (p->flags & IP6_TNL_F_CAP_XMIT) {
+		int strict = (ipv6_addr_type(&p->raddr) &
+			      (IPV6_ADDR_MULTICAST|IPV6_ADDR_LINKLOCAL));
+
+		struct rt6_info *rt = rt6_lookup(dev_net(dev),
+						 &p->raddr, &p->laddr,
+						 p->link, strict);
+
+		if (rt == NULL)
+			return;
+
+		if (rt->dst.dev) {
+			dev->hard_header_len = rt->dst.dev->hard_header_len +
+				sizeof(struct ipv6hdr);
+
+			dev->mtu = rt->dst.dev->mtu; //To make bridge happy
+
+			if (dev->mtu < IPV6_MIN_MTU)
+				dev->mtu = IPV6_MIN_MTU;
+		}
+		ip6_rt_put(rt);
+	}
+}
+
+/**
+ * ethipip6_tnl_change - update the tunnel parameters
+ *   @t: tunnel to be changed
+ *   @p: tunnel configuration parameters
+ *
+ * Description:
+ *   ethipip6_tnl_change() updates the tunnel parameters
+ **/
+
+static int
+ethipip6_tnl_change(struct ip6_tnl *t, struct __ip6_tnl_parm *p)
+{
+	t->parms.laddr = p->laddr;
+	t->parms.raddr = p->raddr;
+	t->parms.flags = p->flags;
+	t->parms.hop_limit = p->hop_limit;
+	t->parms.encap_limit = p->encap_limit;
+	t->parms.flowinfo = p->flowinfo;
+	t->parms.link = p->link;
+	t->parms.proto = p->proto;
+	ip6_tnl_dst_reset(t);
+	ethipip6_tnl_link_config(t);
+	return 0;
+}
+
+static void
+ip6_tnl_parm_from_user(struct __ip6_tnl_parm *p, const struct ip6_tnl_parm *u)
+{
+	p->laddr = u->laddr;
+	p->raddr = u->raddr;
+	p->flags = u->flags;
+	p->hop_limit = u->hop_limit;
+	p->encap_limit = u->encap_limit;
+	p->flowinfo = u->flowinfo;
+	p->link = u->link;
+	p->proto = u->proto;
+	memcpy(p->name, u->name, sizeof(u->name));
+}
+
+static void
+ip6_tnl_parm_to_user(struct ip6_tnl_parm *u, const struct __ip6_tnl_parm *p)
+{
+	u->laddr = p->laddr;
+	u->raddr = p->raddr;
+	u->flags = p->flags;
+	u->hop_limit = p->hop_limit;
+	u->encap_limit = p->encap_limit;
+	u->flowinfo = p->flowinfo;
+	u->link = p->link;
+	u->proto = p->proto;
+	memcpy(u->name, p->name, sizeof(u->name));
+}
+
+/**
+ * ehtipip6_tnl_ioctl - configure ipv6 tunnels from userspace
+ *   @dev: virtual device associated with tunnel
+ *   @ifr: parameters passed from userspace
+ *   @cmd: command to be performed
+ *
+ * Description:
+ *   ethipip6_tnl_ioctl() is used for managing IPv6 tunnels
+ *   from userspace.
+ *
+ *   The possible commands are the following:
+ *     %SIOCGETTUNNEL: get tunnel parameters for device
+ *     %SIOCADDTUNNEL: add tunnel matching given tunnel parameters
+ *     %SIOCCHGTUNNEL: change tunnel parameters to those given
+ *     %SIOCDELTUNNEL: delete tunnel
+ *
+ *   The fallback device "ethipip6tnl0", created during module
+ *   initialization, can be used for creating other tunnel devices.
+ *
+ * Return:
+ *   0 on success,
+ *   %-EFAULT if unable to copy data to or from userspace,
+ *   %-EPERM if current process hasn't %CAP_NET_ADMIN set
+ *   %-EINVAL if passed tunnel parameters are invalid,
+ *   %-EEXIST if changing a tunnel's parameters would cause a conflict
+ *   %-ENODEV if attempting to change or delete a nonexisting device
+ **/
+
+static int
+ethipip6_tnl_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)
+{
+	int err = 0;
+	struct ip6_tnl_parm p;
+	struct __ip6_tnl_parm p1;
+	struct ip6_tnl *t = NULL;
+	struct net *net = dev_net(dev);
+	struct ip6_tnl_net *ip6n = net_generic(net, ethipip6_tnl_net_id);
+
+	switch (cmd) {
+	case SIOCGETTUNNEL:
+		if (dev == ip6n->fb_tnl_dev) {
+			if (copy_from_user(&p, ifr->ifr_ifru.ifru_data, sizeof(p))) {
+				err = -EFAULT;
+				break;
+			}
+			ip6_tnl_parm_from_user(&p1, &p);
+			t = ethipip6_tnl_locate(net, &p1, 0);
+		} else {
+			memset(&p, 0, sizeof(p));
+		}
+		if (t == NULL)
+			t = netdev_priv(dev);
+			
+		ip6_tnl_parm_to_user(&p, &t->parms);
+		if (copy_to_user(ifr->ifr_ifru.ifru_data, &p, sizeof(p))) {
+			err = -EFAULT;
+		}
+		break;
+	case SIOCADDTUNNEL:
+	case SIOCCHGTUNNEL:
+		err = -EPERM;
+		if (!capable(CAP_NET_ADMIN))
+			break;
+		err = -EFAULT;
+		if (copy_from_user(&p, ifr->ifr_ifru.ifru_data, sizeof(p)))
+			break;
+		err = -EINVAL;
+		if (p.proto != IPPROTO_ETHERIP && p.proto != 0)
+			break;
+		ip6_tnl_parm_from_user(&p1, &p);
+		t = ethipip6_tnl_locate(net, &p1, cmd == SIOCADDTUNNEL);
+		if (dev != ip6n->fb_tnl_dev && cmd == SIOCCHGTUNNEL) {
+			if (t != NULL) {
+				if (t->dev != dev) {
+					err = -EEXIST;
+					break;
+				}
+			} else
+				t = netdev_priv(dev);
+
+			ethipip6_tnl_unlink(ip6n, t);
+			err = ethipip6_tnl_change(t, &p1);
+			ethipip6_tnl_link(ip6n, t);
+			netdev_state_change(dev);
+		}
+		if (t) {
+			err = 0;
+			ip6_tnl_parm_to_user(&p, &t->parms);
+			if (copy_to_user(ifr->ifr_ifru.ifru_data, &p, sizeof(p)))
+				err = -EFAULT;
+
+		} else
+			err = (cmd == SIOCADDTUNNEL ? -ENOBUFS : -ENOENT);
+		break;
+	case SIOCDELTUNNEL:
+		err = -EPERM;
+		if (!capable(CAP_NET_ADMIN))
+			break;
+
+		if (dev == ip6n->fb_tnl_dev) {
+			err = -EFAULT;
+			if (copy_from_user(&p, ifr->ifr_ifru.ifru_data, sizeof(p)))
+				break;
+			err = -ENOENT;
+			ip6_tnl_parm_from_user(&p1, &p);
+			if ((t = ethipip6_tnl_locate(net, &p1, 0)) == NULL)
+				break;
+			err = -EPERM;
+			if (t->dev == ip6n->fb_tnl_dev)
+				break;
+			dev = t->dev;
+		}
+		err = 0;
+		unregister_netdevice(dev);
+		break;
+	default:
+		err = -EINVAL;
+	}
+	return err;
+}
+
+/**
+ * ethipip6_tnl_change_mtu - change mtu manually for tunnel device
+ *   @dev: virtual device associated with tunnel
+ *   @new_mtu: the new mtu
+ *
+ * Return:
+ *   0 on success,
+ *   %-EINVAL if mtu too small
+ **/
+
+static int
+ethipip6_tnl_change_mtu(struct net_device *dev, int new_mtu)
+{
+	if (new_mtu < IPV6_MIN_MTU) {
+		return -EINVAL;
+	}
+	dev->mtu = new_mtu;
+	return 0;
+}
+
+static int ethipip6_open(struct net_device *dev)
+{
+	return 0;
+}
+
+static int ethipip6_stop(struct net_device *dev)
+{
+	return 0;
+}
+
+static const struct net_device_ops ip6_tnl_netdev_ops = {
+	.ndo_init = ethipip6_tnl_dev_init,
+	.ndo_uninit = ethipip6_tnl_dev_uninit,
+	.ndo_start_xmit = ethipip6_tnl_xmit,
+	.ndo_do_ioctl = ethipip6_tnl_ioctl,
+	.ndo_change_mtu = ethipip6_tnl_change_mtu,
+	.ndo_open = ethipip6_open,
+	.ndo_stop = ethipip6_stop, 
+};
+
+/**
+ * ethipip6_tnl_dev_setup - setup virtual tunnel device
+ *   @dev: virtual device associated with tunnel
+ *
+ * Description:
+ *   Initialize function pointers and device parameters
+ **/
+
+static void ethipip6_tnl_dev_setup(struct net_device *dev)
+{
+	struct ip6_tnl *t = netdev_priv(dev);
+
+	dev->netdev_ops = &ip6_tnl_netdev_ops;
+	dev->destructor = free_netdev;
+
+	dev->type = ARPHRD_IPV6_IPV6_TUNNEL;
+	dev->hard_header_len = LL_MAX_HEADER + sizeof(struct ipv6hdr);
+	dev->mtu = ETH_DATA_LEN - sizeof(struct ipv6hdr) - ETH_IPHLEN - ETH_HLEN;
+	dev->flags |= IFF_NOARP;
+
+	if (ipv6_addr_type(&t->parms.raddr) & IPV6_ADDR_UNICAST)
+		dev->flags |= IFF_POINTOPOINT;
+	dev->iflink = 0; 
+
+	dev->addr_len = ETH_ALEN; //To make bridge happy while adding etherip iface to bridge
+	dev->features |= NETIF_F_NETNS_LOCAL;
+}
+
+
+/**
+ * ethipip6_tnl_dev_init_gen - general initializer for all tunnel devices
+ *   @dev: virtual device associated with tunnel
+ **/
+
+static inline void
+ethipip6_tnl_dev_init_gen(struct net_device *dev)
+{
+	struct ip6_tnl *t = netdev_priv(dev);
+	t->dev = dev;
+	strcpy(t->parms.name, dev->name);
+}
+
+/**
+ * ethipip6_tnl_dev_init - initializer for all non fallback tunnel devices
+ *   @dev: virtual device associated with tunnel
+ **/
+
+static int ethipip6_tnl_dev_init(struct net_device *dev)
+{
+	struct ip6_tnl *t = netdev_priv(dev);
+	ethipip6_tnl_dev_init_gen(dev);
+	ethipip6_tnl_link_config(t);
+
+	return 0;
+}
+
+/**
+ * ethipip6_fb_tnl_dev_init - initializer for fallback tunnel device
+ *   @dev: fallback device
+ *
+ * Return: 0
+ **/
+
+static void ethipip6_fb_tnl_dev_init(struct net_device *dev)
+{
+	struct ip6_tnl *t = netdev_priv(dev);
+	struct net *net = dev_net(dev);
+	struct ip6_tnl_net *ip6n = net_generic(net, ethipip6_tnl_net_id);
+
+	ethipip6_tnl_dev_init_gen(dev);
+	t->parms.proto = IPPROTO_ETHERIP;
+	dev_hold(dev);
+	ip6n->tnls_wc[0] = t;
+}
+
+static struct xfrm6_tunnel ip4ethipip6_handler = {
+	.handler	= ip4ethipip6_rcv,
+	.err_handler	= ip4ethipip6_err,
+	.priority	=	3,
+};
+
+static struct xfrm6_tunnel ip6ethipip6_handler = {
+	.handler	= ip6ethipip6_rcv,
+	.err_handler	= ip6ethipip6_err,
+	.priority	=	3,
+};
+
+static void ethipip6_tnl_destroy_tunnels(struct ip6_tnl_net *ip6n)
+{
+	int h;
+	struct ip6_tnl *t;
+	LIST_HEAD(list);
+
+	for (h = 0; h < HASH_SIZE; h++) {
+		t = ip6n->tnls_r_l[h];
+		while (t != NULL) {
+			unregister_netdevice_queue(t->dev, &list);
+			t = t->next;
+		}
+	}
+
+	t = ip6n->tnls_wc[0];
+	unregister_netdevice_queue(t->dev, &list);
+	unregister_netdevice_many(&list);
+}
+
+static int ethipip6_tnl_init_net(struct net *net)
+{
+	struct ip6_tnl_net *ip6n = net_generic(net, ethipip6_tnl_net_id);
+	int err;
+
+	ip6n->tnls[0] = ip6n->tnls_wc;
+	ip6n->tnls[1] = ip6n->tnls_r_l;
+
+	err = -ENOMEM;
+	ip6n->fb_tnl_dev = alloc_netdev(sizeof(struct ip6_tnl), "ethipip6tnl0",
+				      NET_NAME_UNKNOWN, ethipip6_tnl_dev_setup);
+
+	if (!ip6n->fb_tnl_dev)
+		goto err_alloc_dev;
+	dev_net_set(ip6n->fb_tnl_dev, net);
+
+	ethipip6_fb_tnl_dev_init(ip6n->fb_tnl_dev);
+
+	err = register_netdev(ip6n->fb_tnl_dev);
+	if (err < 0)
+		goto err_register;
+	return 0;
+
+err_register:
+	free_netdev(ip6n->fb_tnl_dev);
+err_alloc_dev:
+	return err;
+}
+
+static void ethipip6_tnl_exit_net(struct net *net)
+{
+	struct ip6_tnl_net *ip6n = net_generic(net, ethipip6_tnl_net_id);
+
+	rtnl_lock();
+	ethipip6_tnl_destroy_tunnels(ip6n);
+	rtnl_unlock();
+}
+
+static struct pernet_operations ethipip6_tnl_net_ops = {
+	.init = ethipip6_tnl_init_net,
+	.exit = ethipip6_tnl_exit_net,
+	.id   = &ethipip6_tnl_net_id,
+	.size = sizeof(struct ip6_tnl_net),
+};
+
+static const struct inet6_protocol ethipip6_protocol = {
+ 	.handler        =       ip4ethipip6_rcv,
+        .err_handler    =       ip4ethipip6_err,
+	.flags		= 	IPPROTO_ETHERIP,
+};
+
+/**
+ * ethipip6_tunnel_init - register protocol and reserve needed resources
+ *
+ * Return: 0 on success
+ **/
+
+static int __init ethipip6_tunnel_init(void)
+{
+	int  err;
+
+	if (xfrm6_tunnel_register(&ip4ethipip6_handler, AF_INET)) {
+		printk(KERN_ERR "ip6_tunnel init: can't register ip4ethipip6\n");
+		err = -EAGAIN;
+		goto out;
+	}
+
+	if (xfrm6_tunnel_register(&ip6ethipip6_handler, AF_INET6)) {
+		printk(KERN_ERR "ip6_tunnel init: can't register ip6ethipip6\n");
+		err = -EAGAIN;
+		goto unreg_ip4ip6;
+	}
+
+	err = register_pernet_device(&ethipip6_tnl_net_ops);
+	if (err < 0)
+		goto err_pernet;
+
+	if (inet6_add_protocol(&ethipip6_protocol, IPPROTO_ETHERIP)) { 
+                return -EAGAIN;
+	}
+	return 0;
+
+err_pernet:
+	xfrm6_tunnel_deregister(&ip6ethipip6_handler, AF_INET6);
+unreg_ip4ip6:
+	xfrm6_tunnel_deregister(&ip4ethipip6_handler, AF_INET);
+out:
+	return err;
+}
+
+/**
+ * ethipip6_tunnel_cleanup - free resources and unregister protocol
+ **/
+
+static void __exit ethipip6_tunnel_cleanup(void)
+{
+
+	if (inet6_del_protocol(&ethipip6_protocol, IPPROTO_ETHERIP)) { 
+                printk(KERN_ERR "ethipip6: can't del protocol IPPROTO_ETHERIP\n");
+        }
+
+	if (xfrm6_tunnel_deregister(&ip4ethipip6_handler, AF_INET))
+		printk(KERN_INFO "ip6_tunnel close: can't deregister ip4ethipip6\n");
+
+	if (xfrm6_tunnel_deregister(&ip6ethipip6_handler, AF_INET6))
+		printk(KERN_INFO "ip6_tunnel close: can't deregister ip6ethipip6\n");
+
+	unregister_pernet_device(&ethipip6_tnl_net_ops);
+}
+
+module_init(ethipip6_tunnel_init);
+module_exit(ethipip6_tunnel_cleanup);
diff --git a/net/ipv6/ip6_tunnel.c b/net/ipv6/ip6_tunnel.c
index 3f46121ad139..50820cf2e04a 100644
--- a/net/ipv6/ip6_tunnel.c
+++ b/net/ipv6/ip6_tunnel.c
@@ -24,6 +24,7 @@
 #include <linux/capability.h>
 #include <linux/errno.h>
 #include <linux/types.h>
+#include <linux/version.h>
 #include <linux/sockios.h>
 #include <linux/icmp.h>
 #include <linux/if.h>
@@ -79,6 +80,11 @@ static u32 HASH(const struct in6_addr *addr1, const struct in6_addr *addr2)
 	return hash_32(hash, IP6_TUNNEL_HASH_SIZE_SHIFT);
 }
 
+#ifdef CONFIG_CPE_4RD_TUNNEL
+#define for_each_ip6_tunnel_rcu(start) \
+	for (t = rcu_dereference(start); t; t = rcu_dereference(t->next))
+#endif
+
 static int ip6_tnl_dev_init(struct net_device *dev);
 static void ip6_tnl_dev_setup(struct net_device *dev);
 static struct rtnl_link_ops ip6_link_ops __read_mostly;
@@ -124,6 +130,571 @@ static struct net_device_stats *ip6_get_stats(struct net_device *dev)
 	return &dev->stats;
 }
 
+/*
+ * Locking : hash tables are protected by RCU and RTNL
+ */
+
+#ifdef CONFIG_CPE_4RD_TUNNEL
+static struct kmem_cache *mr_kmem __read_mostly;
+int mr_kmem_alloced = 0;
+
+static inline size_t  ip6_4rd_nlmsg_size(void)
+{
+	return NLMSG_ALIGN(sizeof(struct ip6_4rd_map_msg));
+}
+
+static int ip6_4rd_fill_node( struct sk_buff *skb, struct ip6_tnl_4rd_map_rule *mr,
+			u32 pid, u32 seq,int type, unsigned int flags, int reset, unsigned int ifindex)
+{
+	struct ip6_4rd_map_msg *mr_msg;
+	struct nlmsghdr *nlh;
+
+	nlh = nlmsg_put(skb, pid , seq, type, sizeof(*mr_msg), flags);
+	if (nlh == NULL)
+		return -EMSGSIZE;
+
+	mr_msg = nlmsg_data(nlh);
+	if(reset)
+	{
+		memset(mr_msg,0,sizeof(*mr_msg));
+		mr_msg->reset = 1;
+		mr_msg->ifindex = ifindex;
+		
+	}
+	else
+	{
+		//	memcpy(mr_msg,mr, sizeof(*mr_msg));
+		memset(mr_msg,0,sizeof(*mr_msg));
+		mr_msg->prefix = mr->prefix;
+		mr_msg->prefixlen = mr->prefixlen ;
+		mr_msg->relay_prefix = mr->relay_prefix;
+		mr_msg->relay_suffix = mr->relay_suffix;
+		mr_msg->relay_prefixlen = mr->relay_prefixlen ;
+		mr_msg->relay_suffixlen = mr->relay_suffixlen ;
+		mr_msg->psid_offsetlen = mr->psid_offsetlen ;
+		mr_msg->eabit_len = mr->eabit_len ;
+		mr_msg->entry_num = mr->entry_num ;
+		mr_msg->ifindex = ifindex;
+	}
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,19,0)
+	nlmsg_end(skb, nlh);
+	return nlh->nlmsg_len;
+#else
+	return nlmsg_end(skb, nlh);
+#endif
+
+
+}
+
+
+static int inet6_dump4rd_mrule(struct sk_buff *skb, struct netlink_callback *cb)
+{
+	struct net *net = sock_net(skb->sk);
+	unsigned int h, s_h;
+	int s_idx, s_ip_idx;
+	int idx, ip_idx;
+	struct ip6_tnl_4rd_map_rule *mr ;
+	int err = 0;
+
+
+	struct ip6_tnl *t;
+	struct ip6_tnl_net *ip6n = net_generic(net, ip6_tnl_net_id);
+
+	s_h = cb->args[0];
+	s_idx = idx = cb->args[1];
+	s_ip_idx = ip_idx = cb->args[2];
+
+	rcu_read_lock();
+
+	for (h = s_h; h < HASH_SIZE ; h++, s_idx = 0) {
+		idx = 0;
+		for_each_ip6_tunnel_rcu(ip6n->tnls_r_l[h])
+		{
+			if (idx < s_idx)
+				goto cont_tunnel;
+			if (idx > s_idx)
+				s_ip_idx = 0;
+			ip_idx = 0;
+			read_lock(&t->ip4rd.map_lock);
+			list_for_each_entry (mr, &t->ip4rd.map_list, mr_list){
+				if (ip_idx < s_ip_idx)
+					goto cont_mr;
+
+				err = ip6_4rd_fill_node(skb, mr,NETLINK_CB(cb->skb).portid,
+						cb->nlh->nlmsg_seq,RTM_NEW4RD, NLM_F_MULTI , 0, t->dev->ifindex);
+				if (err < 0) {
+					WARN_ON(err == -EMSGSIZE);
+					kfree_skb(skb);
+					read_unlock(&t->ip4rd.map_lock);
+					goto out;
+				}
+cont_mr:
+				ip_idx++;
+			}
+			read_unlock(&t->ip4rd.map_lock);
+cont_tunnel:
+			idx++;	
+		}
+	}
+out:
+	rcu_read_unlock();
+
+	cb->args[0] = h;
+	cb->args[1] = idx;
+	cb->args[2] = ip_idx;
+	
+	return skb->len;
+}
+
+
+void ip6_4rd_notify(int event, struct ip6_tnl_4rd_map_rule *mr ,struct net_device *dev, int reset)
+{
+	struct sk_buff *skb;
+	struct net *net = dev_net(dev);
+	int err;
+
+	err = -ENOBUFS;
+
+	skb = nlmsg_new(ip6_4rd_nlmsg_size(), gfp_any());
+	if (skb == NULL)
+		goto errout;
+
+	err = ip6_4rd_fill_node(skb, mr,0,0,event,  0, reset, dev->ifindex);
+	if (err < 0) {
+		/* -EMSGSIZE implies BUG in rt6_nlmsg_size() */
+		WARN_ON(err == -EMSGSIZE);
+		kfree_skb(skb);
+		goto errout;
+	}
+	rtnl_notify(skb, net, 0, RTNLGRP_IPV6_IFADDR,
+		    NULL, gfp_any());
+	return;
+errout:
+	if (err < 0)
+		rtnl_set_sk_err(net, RTNLGRP_IPV6_IFADDR, err);
+}
+
+static inline void
+ip6_tnl_4rd_mr_destroy(char *f, struct ip6_tnl_4rd_map_rule *mr)
+{
+	list_del(&mr->mr_list);
+	kmem_cache_free(mr_kmem, mr);
+	--mr_kmem_alloced;
+}
+
+static int
+ip6_tnl_4rd_mr_create(struct ip6_tnl_4rd *ip4rd, struct ip6_tnl_4rd_parm *parm, struct net_device *dev)
+{
+	struct ip6_tnl_4rd_map_rule *mr ;
+	int err = 0;
+
+       write_lock_bh(&parm->map_lock);
+       list_for_each_entry (mr, &parm->map_list, mr_list){
+               if( mr->entry_num == ip4rd->entry_num ){
+                       printk(KERN_DEBUG "ip6_tnl_4rd_mr_create: map rule found update");
+                       mr->prefix = ip4rd->prefix ;
+                       mr->relay_prefix = ip4rd->relay_prefix;
+                       mr->relay_suffix = ip4rd->relay_suffix;
+                       mr->prefixlen = ip4rd->prefixlen ;
+                       mr->relay_prefixlen = ip4rd->relay_prefixlen ;
+                       mr->relay_suffixlen = ip4rd->relay_suffixlen ;
+                       mr->psid_offsetlen = ip4rd->psid_offsetlen ;
+                       mr->eabit_len = ip4rd->eabit_len ;
+                       mr->entry_num = ip4rd->entry_num ;
+                       goto out;
+               }
+       }
+
+       mr = kmem_cache_alloc(mr_kmem, GFP_KERNEL);
+
+       if (!mr) {
+               printk(KERN_INFO "ip6_tnl_4rd_mr_create: kmem_cache_alloc fail");
+               err = -1 ;
+               goto out;
+       }
+
+       mr->prefix = ip4rd->prefix ;
+       mr->relay_prefix = ip4rd->relay_prefix;
+       mr->relay_suffix = ip4rd->relay_suffix;
+       mr->prefixlen = ip4rd->prefixlen ;
+       mr->relay_prefixlen = ip4rd->relay_prefixlen ;
+       mr->relay_suffixlen = ip4rd->relay_suffixlen ;
+       mr->psid_offsetlen = ip4rd->psid_offsetlen ;
+       mr->eabit_len = ip4rd->eabit_len ;
+       mr->entry_num = ip4rd->entry_num ;
+
+       ++mr_kmem_alloced;
+       list_add_tail(&mr->mr_list, &parm->map_list);
+
+out:
+	ip6_4rd_notify(RTM_NEW4RD,mr, dev,0); /* modified by MSPD */
+	write_unlock_bh(&parm->map_lock);
+	return err;
+}
+
+static void
+ip6_tnl_4rd_mr_delete_all(struct ip6_tnl_4rd_parm *parm, struct net_device *dev)
+{
+	struct ip6_tnl_4rd_map_rule *mr, *mr_rule;
+
+	write_lock_bh(&parm->map_lock);
+	list_for_each_entry_safe (mr, mr_rule, &parm->map_list, mr_list){
+		ip6_tnl_4rd_mr_destroy("all", mr);
+	}
+	ip6_4rd_notify(RTM_DEL4RD,mr, dev ,1);
+	write_unlock_bh(&parm->map_lock);
+
+}
+
+static int
+ip6_tnl_4rd_mr_delete(__u16 entry_num , struct ip6_tnl_4rd_parm *parm, struct net_device *dev)
+{
+	struct ip6_tnl_4rd_map_rule *mr, *mr_rule;
+	int err = -1 ;
+
+	write_lock_bh(&parm->map_lock);
+	list_for_each_entry_safe (mr, mr_rule, &parm->map_list, mr_list){
+		if( mr->entry_num == entry_num ){
+			printk(KERN_DEBUG "ip6_tnl_4rd_mr_delete: map rule found delete");
+			ip6_tnl_4rd_mr_destroy("one", mr);
+			err = 0 ;
+			break;
+		}
+	}
+	ip6_4rd_notify(RTM_DEL4RD,mr,dev,0);
+	write_unlock_bh(&parm->map_lock);
+	return err ;
+}
+
+static void
+ip6_tnl_4rd_mr_show(struct ip6_tnl_4rd_parm *parm)
+{
+	struct ip6_tnl_4rd_map_rule *mr;
+
+       printk(KERN_DEBUG "-- 4rd mapping rule list\n");
+       printk(KERN_DEBUG "-- entry num = %d \n",mr_kmem_alloced);
+
+	read_lock(&parm->map_lock);
+	list_for_each_entry(mr, &parm->map_list, mr_list){
+		printk(KERN_DEBUG "%03d : %03d.%03d.%03d.%03d/%02d %02x%02x:%02x%02x:%02x%02x:%02x%02x:%02x%02x:%02x%02x:%02x%02x:%02x%02x/%03d %02x%02x:%02x%02x:%02x%02x:%02x%02x:%02x%02x:%02x%02x:%02x%02x:%02x%02x/%03d eabit:%03d offset:%03d \n",
+			mr->entry_num,
+			(ntohl(mr->prefix) >> 24) & 0xff,
+			(ntohl(mr->prefix) >> 16) & 0xff,
+			(ntohl(mr->prefix) >>  8) & 0xff,
+			ntohl(mr->prefix) & 0xff,
+			mr->prefixlen,
+			mr->relay_prefix.s6_addr[0],
+			mr->relay_prefix.s6_addr[1],
+			mr->relay_prefix.s6_addr[2],
+			mr->relay_prefix.s6_addr[3],
+			mr->relay_prefix.s6_addr[4],
+			mr->relay_prefix.s6_addr[5],
+			mr->relay_prefix.s6_addr[6],
+			mr->relay_prefix.s6_addr[7],
+			mr->relay_prefix.s6_addr[8],
+			mr->relay_prefix.s6_addr[9],
+			mr->relay_prefix.s6_addr[10],
+			mr->relay_prefix.s6_addr[11],
+			mr->relay_prefix.s6_addr[12],
+			mr->relay_prefix.s6_addr[13],
+			mr->relay_prefix.s6_addr[14],
+			mr->relay_prefix.s6_addr[15],
+			mr->relay_prefixlen,
+			mr->relay_suffix.s6_addr[0],
+			mr->relay_suffix.s6_addr[1],
+			mr->relay_suffix.s6_addr[2],
+			mr->relay_suffix.s6_addr[3],
+			mr->relay_suffix.s6_addr[4],
+			mr->relay_suffix.s6_addr[5],
+			mr->relay_suffix.s6_addr[6],
+			mr->relay_suffix.s6_addr[7],
+			mr->relay_suffix.s6_addr[8],
+			mr->relay_suffix.s6_addr[9],
+			mr->relay_suffix.s6_addr[10],
+			mr->relay_suffix.s6_addr[11],
+			mr->relay_suffix.s6_addr[12],
+			mr->relay_suffix.s6_addr[13],
+			mr->relay_suffix.s6_addr[14],
+			mr->relay_suffix.s6_addr[15],
+			mr->relay_suffixlen,
+			mr->eabit_len,
+			mr->psid_offsetlen );
+	}
+	read_unlock(&parm->map_lock);
+}
+
+static int
+ip6_tnl_4rd_modify_daddr(struct in6_addr *daddr6, __be32 daddr4, __be16 dport4,
+		struct ip6_tnl_4rd_map_rule *mr)
+{
+       int i, pbw0, pbi0, pbi1;
+       __u32 daddr[4];
+       __u32 port_set_id = 0;
+       __u32 mask;
+       __u32 da = ntohl(daddr4);
+       __u16 dp = ntohs(dport4);
+       __u32 diaddr[4];
+       int port_set_id_len = ( mr->eabit_len ) - ( 32 - mr->prefixlen ) ;
+
+       if ( port_set_id_len < 0) {
+               printk(KERN_DEBUG "ip6_tnl_4rd_modify_daddr: PSID length ERROR %d\n", port_set_id_len);
+               return -1;
+       }
+
+       if ( port_set_id_len > 0) {
+               mask = 0xffffffff >> (32 - port_set_id_len);
+               port_set_id = ( dp >> (16 - mr->psid_offsetlen - port_set_id_len ) & mask ) ;
+       }
+
+       for (i = 0; i < 4; ++i)
+               daddr[i] = ntohl(mr->relay_prefix.s6_addr32[i])
+                       | ntohl(mr->relay_suffix.s6_addr32[i]);
+
+       if( mr->prefixlen < 32 ) {
+               pbw0 = mr->relay_prefixlen >> 5;
+               pbi0 = mr->relay_prefixlen & 0x1f;
+               daddr[pbw0] |= (da << mr->prefixlen) >> pbi0;
+               pbi1 = pbi0 - mr->prefixlen;
+               if (pbi1 > 0)
+                       daddr[pbw0+1] |= da << (32 - pbi1);
+	}
+       if ( port_set_id_len > 0) {
+	       pbw0 = (mr->relay_prefixlen + 32 - mr->prefixlen) >> 5;
+	       pbi0 = (mr->relay_prefixlen + 32 - mr->prefixlen) & 0x1f;
+	       daddr[pbw0] |= (port_set_id << (32 - port_set_id_len)) >> pbi0;
+	       pbi1 = pbi0 - (32 - port_set_id_len);
+	       if (pbi1 > 0)
+		       daddr[pbw0+1] |= port_set_id << (32 - pbi1);
+       }
+
+       memset(diaddr, 0, sizeof(diaddr));
+
+       diaddr[2] = ( da >> 8 ) ;
+       diaddr[3] = ( da << 24 ) ;
+       diaddr[3] |= ( port_set_id << 8 ) ;
+
+       for (i = 0; i < 4; ++i)
+               daddr[i] = daddr[i] | diaddr[i] ;
+
+       for (i = 0; i < 4; ++i)
+               daddr6->s6_addr32[i] = htonl(daddr[i]);
+
+       /* DBG */
+       printk(KERN_DEBUG "ip6_tnl_4rd_modify_daddr: %08x %08x %08x %08x  PSID:%04x\n",
+               daddr[0], daddr[1], daddr[2], daddr[3], port_set_id);
+
+       return 0;
+}
+
+/**
+ * ip6_tnl_4rd_rcv_helper - 
+ *   @skb: received socket buffer
+ *   @t: tunnel device
+ **/
+
+static int
+ip6_tnl_4rd_rcv_helper(struct sk_buff *skb, struct ip6_tnl *t)
+{
+       int err = 0;
+       struct iphdr *iph;
+
+       iph = ip_hdr(skb);
+
+       switch (iph->protocol) {
+       case IPPROTO_TCP:
+       case IPPROTO_UDP:
+       case IPPROTO_ICMP:
+       case IPPROTO_GRE:
+               break;
+       default:
+               err = -1;
+               break;
+       }
+
+       return err;
+}
+
+static int
+ip6_tnl_4rd_xmit_helper(struct sk_buff *skb, struct flowi6 *fl6,
+		struct ip6_tnl *t)
+{
+       int err = 0;
+       struct iphdr *iph, *icmpiph;
+       __be16  *idp;
+       struct tcphdr *tcph, *icmptcph;
+       struct udphdr *udph, *icmpudph;
+       struct icmphdr *icmph;
+#if 0
+       struct gre_hdr *greh;
+#endif
+       __u32 mask;
+       __be16 *sportp = NULL;
+       __be32 daddr;
+       __be16 dport;
+       u8 *ptr;
+       int no_dst_chg = 0;
+       struct ip6_tnl_4rd_map_rule *mr,*mr_tmp;
+       int mr_prefixlen ;
+       int count ;
+
+       iph = ip_hdr(skb);
+
+       daddr = iph->daddr;
+       idp = &iph->id;
+
+       ptr = (u8 *)iph;
+       ptr += iph->ihl * 4;
+       switch (iph->protocol) {
+       case IPPROTO_TCP:
+               tcph = (struct tcphdr *)ptr;
+               sportp = &tcph->source;
+               dport = tcph->dest;
+               break;
+       case IPPROTO_UDP:
+               udph = (struct udphdr *)ptr;
+               sportp = &udph->source;
+               dport = udph->dest;
+               break;
+       case IPPROTO_ICMP:
+               icmph = (struct icmphdr *)ptr;
+               switch (icmph->type) {
+               case ICMP_DEST_UNREACH:
+               case ICMP_SOURCE_QUENCH:
+               case ICMP_REDIRECT:
+               case ICMP_TIME_EXCEEDED:
+               case ICMP_PARAMETERPROB:
+                       ptr = (u8 *)icmph;
+                       ptr += sizeof(struct icmphdr);
+                       icmpiph = (struct iphdr*)ptr;
+                       if (ntohs(iph->tot_len) < icmpiph->ihl * 4 + 12) {
+                               err = -1;
+                               goto out;
+                       }
+                       daddr = icmpiph->saddr;
+                       ptr += icmpiph->ihl * 4;
+                       switch (icmpiph->protocol) {
+                       case IPPROTO_TCP:
+                               icmptcph = (struct tcphdr *)ptr;
+                               sportp = &icmptcph->dest;
+                               dport = icmptcph->source;
+                               break;
+                       case IPPROTO_UDP:
+                               icmpudph = (struct udphdr *)ptr;
+                               sportp = &icmpudph->dest;
+                               dport = icmpudph->source;
+                               break;
+                       default:
+                               err = -1;
+                               goto out;
+                       }
+                       break;
+               default:
+                       no_dst_chg = 1;
+                       break;
+               }
+               break;
+#if 0
+	//FIXME this is a GRE related change, should be enabled after porting it
+       case IPPROTO_GRE:
+               greh = (struct gre_hdr *)ptr;
+               if(greh->protocol != GRE_PROTOCOL_PPTP){
+                       err = -1;
+                       goto out;
+               }
+               no_dst_chg = 1;
+               break;
+#endif
+       default:
+               err = -1;
+               goto out;
+       }
+
+       if ( no_dst_chg == 0 ){
+
+               count = 0;
+               mr_prefixlen = 0;
+
+               read_lock(&t->ip4rd.map_lock);
+               list_for_each_entry (mr, &t->ip4rd.map_list, mr_list){
+                       mask = 0xffffffff << (32 - mr->prefixlen) ;
+                       if( (htonl(daddr) & mask ) == htonl( mr->prefix) ) {
+                               if ( mr->prefixlen >= mr_prefixlen ){
+                                       mr_prefixlen = mr->prefixlen ;
+                                       mr_tmp = mr;
+                                       count++;
+                               }
+                       }
+               }
+
+               if (count){
+                       err = ip6_tnl_4rd_modify_daddr(&fl6->daddr, daddr, dport, mr_tmp );
+                       if (err){
+                                       read_unlock(&t->ip4rd.map_lock);
+                                       goto out;
+                       }
+               }
+               read_unlock(&t->ip4rd.map_lock);
+
+               if(sportp && idp){
+                       *idp=*sportp;
+               }
+       }
+
+       iph->check = 0;
+       iph->check = ip_fast_csum((unsigned char *)iph, iph->ihl);
+
+       /* XXX: */ //FIXME this feild is not present, this shold be fixed
+       //skb->local_df = 1;
+
+out:
+	return err;
+}
+
+/**
+ * ip6_tnl_4rd_update_parms - update 4rd parameters
+ *   @t: tunnel to be updated
+ *
+ * Description:
+ *   ip6_tnl_4rd_update_parms() updates 4rd parameters
+ **/
+static void
+ip6_tnl_4rd_update_parms(struct ip6_tnl *t)
+{
+	int pbw0, pbi0, pbi1;
+	__u32 d;
+
+	t->ip4rd.port_set_id_len = t->ip4rd.relay_suffixlen
+				- t->ip4rd.relay_prefixlen
+				- (32 - t->ip4rd.prefixlen);
+	pbw0 = (t->ip4rd.relay_suffixlen - t->ip4rd.port_set_id_len) >> 5;
+	pbi0 = (t->ip4rd.relay_suffixlen - t->ip4rd.port_set_id_len) & 0x1f;
+	d = (ntohl(t->parms.laddr.s6_addr32[pbw0]) << pbi0)
+		>> (32 - t->ip4rd.port_set_id_len);
+	pbi1 = pbi0 - (32 - t->ip4rd.port_set_id_len);
+
+	if (pbi1 > 0)
+		d |= ntohl(t->parms.laddr.s6_addr32[pbw0+1]) >> (32 - pbi1);
+	t->ip4rd.port_set_id = d;
+
+	/* local v4 address */
+	t->ip4rd.laddr4 = t->ip4rd.prefix;
+	pbw0 = t->ip4rd.relay_prefixlen >> 5;
+	pbi0 = t->ip4rd.relay_prefixlen & 0x1f;
+	d = (ntohl(t->parms.laddr.s6_addr32[pbw0]) << pbi0)
+		>> t->ip4rd.prefixlen;
+	pbi1 = pbi0 - t->ip4rd.prefixlen;
+	if (pbi1 > 0)
+		d |= ntohl(t->parms.laddr.s6_addr32[pbw0+1]) >> (32 - pbi1);
+	t->ip4rd.laddr4 |= htonl(d);
+	if (t->ip4rd.port_set_id_len < 0) {
+		d = ntohl(t->ip4rd.laddr4);
+		d &= 0xffffffff << -t->ip4rd.port_set_id_len;
+		t->ip4rd.laddr4 = htonl(d);
+	}
+
+}
+#endif
+
 /**
  * ip6_tnl_lookup - fetch tunnel matching the end-point addresses
  *   @remote: the address of the tunnel exit-point
@@ -135,8 +706,10 @@ static struct net_device_stats *ip6_get_stats(struct net_device *dev)
  *   else %NULL
  **/
 
+#ifndef CONFIG_CPE_4RD_TUNNEL
 #define for_each_ip6_tunnel_rcu(start) \
 	for (t = rcu_dereference(start); t; t = rcu_dereference(t->next))
+#endif
 
 static struct ip6_tnl *
 ip6_tnl_lookup(struct net *net, const struct in6_addr *remote, const struct in6_addr *local)
@@ -153,6 +726,15 @@ ip6_tnl_lookup(struct net *net, const struct in6_addr *remote, const struct in6_
 			return t;
 	}
 
+#ifdef CONFIG_CPE_4RD_TUNNEL
+                if (t->ip4rd.prefix &&
+                   ipv6_addr_equal(local, &t->parms.laddr) &&
+                /* ipv6_prefix_equal(remote, &t->ip4rd.relay_prefix,
+                       t->ip4rd.relay_prefixlen) && 4RD D  */
+                   (t->dev->flags & IFF_UP))
+                       return t;
+#endif
+
 	memset(&any, 0, sizeof(any));
 	hash = HASH(&any, local);
 	for_each_ip6_tunnel_rcu(ip6n->tnls_r_l[hash]) {
@@ -272,6 +854,11 @@ static int ip6_tnl_create2(struct net_device *dev)
 
 	strcpy(t->parms.name, dev->name);
 
+#ifdef CONFIG_CPE_4RD_TUNNEL
+	rwlock_init(&t->ip4rd.map_lock);
+	INIT_LIST_HEAD(&t->ip4rd.map_list); 
+#endif
+
 	dev_hold(dev);
 	ip6_tnl_link(ip6n, t);
 	return 0;
@@ -822,6 +1409,9 @@ static int __ip6_tnl_rcv(struct ip6_tnl *tunnel, struct sk_buff *skb,
 		skb->protocol = eth_type_trans(skb, tunnel->dev);
 		skb_postpull_rcsum(skb, eth_hdr(skb), ETH_HLEN);
 	} else {
+#ifdef CONFIG_CPE_FAST_PATH
+		skb->underlying_iif = skb->dev->ifindex;
+#endif
 		skb->dev = tunnel->dev;
 	}
 
@@ -843,6 +1433,13 @@ static int __ip6_tnl_rcv(struct ip6_tnl *tunnel, struct sk_buff *skb,
 		}
 	}
 
+#ifdef CONFIG_CPE_4RD_TUNNEL
+                if (ip6_tnl_4rd_rcv_helper(skb, tunnel)) {
+                        rcu_read_unlock();
+                        goto drop;
+                }
+#endif
+
 	tstats = this_cpu_ptr(tunnel->dev->tstats);
 	u64_stats_update_begin(&tstats->syncp);
 	tstats->rx_packets++;
@@ -1096,7 +1693,16 @@ int ip6_tnl_xmit(struct sk_buff *skb, struct net_device *dev, __u8 dsfield,
 	if (!ip6_tnl_xmit_ctl(t, &fl6->saddr, &fl6->daddr))
 		goto tx_err_link_failure;
 
+#if defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	if ((dst)
+	&& (t->genid  == atomic_read(&net->xfrm.flow_cache_genid))
+		) {
+			dst_hold(dst);
+	}
+	else {
+#else
 	if (!dst) {
+#endif
 route_lookup:
 		/* add dsfield to flowlabel for route lookup */
 		fl6->flowlabel = ip6_make_flowinfo(dsfield, fl6->flowlabel);
@@ -1116,6 +1722,9 @@ int ip6_tnl_xmit(struct sk_buff *skb, struct net_device *dev, __u8 dsfield,
 				       &fl6->daddr, 0, &fl6->saddr))
 			goto tx_err_link_failure;
 		ndst = dst;
+#if defined(CONFIG_INET6_IPSEC_OFFLOAD)
+		t->genid = atomic_read(&net->xfrm.flow_cache_genid);
+#endif
 	}
 
 	tdev = dst->dev;
@@ -1135,10 +1744,26 @@ int ip6_tnl_xmit(struct sk_buff *skb, struct net_device *dev, __u8 dsfield,
 		mtu = IPV6_MIN_MTU;
 	if (skb_dst(skb) && !t->parms.collect_md)
 		skb_dst(skb)->ops->update_pmtu(skb_dst(skb), NULL, skb, mtu);
-	if (skb->len - t->tun_hlen - eth_hlen > mtu && !skb_is_gso(skb)) {
-		*pmtu = mtu;
-		err = -EMSGSIZE;
-		goto tx_err_dst_release;
+#ifdef CONFIG_CPE_4RD_TUNNEL
+        if (!t->ip4rd.prefix) {   /* 4rd support requires Post Fragmentation, so skb->len could be greater than MTU */ 
+#endif
+		if (skb->len - t->tun_hlen - eth_hlen > mtu && !skb_is_gso(skb)) {
+			*pmtu = mtu;
+			err = -EMSGSIZE;
+			goto tx_err_dst_release;
+		}
+#ifdef CONFIG_CPE_4RD_TUNNEL
+        }                         
+
+	if (t->ip4rd.prefix) {
+		struct iphdr *iph;
+		iph = ip_hdr(skb);
+		hop_limit = iph->ttl;
+	}
+	else
+#endif
+	{
+		hop_limit = t->parms.hop_limit;
 	}
 
 	if (t->err_count > 0) {
@@ -1278,6 +1903,11 @@ ip4ip6_tnl_xmit(struct sk_buff *skb, struct net_device *dev)
 
 	skb_set_inner_ipproto(skb, IPPROTO_IPIP);
 
+#ifdef CONFIG_CPE_4RD_TUNNEL
+        if (t->ip4rd.prefix && ip6_tnl_4rd_xmit_helper(skb, &fl6, t))
+                return -1;
+#endif
+
 	err = ip6_tnl_xmit(skb, dev, dsfield, &fl6, encap_limit, &mtu,
 			   IPPROTO_IPIP);
 	if (err != 0) {
@@ -1385,6 +2015,10 @@ ip6_tnl_start_xmit(struct sk_buff *skb, struct net_device *dev)
 
 	switch (skb->protocol) {
 	case htons(ETH_P_IP):
+#ifdef CONFIG_CPE_4RD_TUNNEL
+                if (t->ip4rd.prefix && ip_defrag(skb, IP_DEFRAG_IP6_TNL_4RD))
+                        return NETDEV_TX_OK;
+#endif
 		ret = ip4ip6_tnl_xmit(skb, dev);
 		break;
 	case htons(ETH_P_IPV6):
@@ -1463,6 +2097,13 @@ static void ip6_tnl_link_config(struct ip6_tnl *t)
 		}
 		ip6_rt_put(rt);
 	}
+
+#ifdef CONFIG_CPE_4RD_TUNNEL
+        if (t->ip4rd.prefix) {
+                p->flags |= IP6_TNL_F_CAP_XMIT;
+                p->flags |= IP6_TNL_F_CAP_RCV;
+        }
+#endif
 }
 
 /**
@@ -1486,6 +2127,9 @@ ip6_tnl_change(struct ip6_tnl *t, const struct __ip6_tnl_parm *p)
 	t->parms.link = p->link;
 	t->parms.proto = p->proto;
 	t->parms.fwmark = p->fwmark;
+#ifdef CONFIG_CPE_4RD_TUNNEL
+        ip6_tnl_4rd_update_parms(t);
+#endif
 	dst_cache_reset(&t->dst_cache);
 	ip6_tnl_link_config(t);
 	return 0;
@@ -1578,6 +2222,10 @@ ip6_tnl_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)
 	struct ip6_tnl *t = netdev_priv(dev);
 	struct net *net = t->net;
 	struct ip6_tnl_net *ip6n = net_generic(net, ip6_tnl_net_id);
+#ifdef CONFIG_CPE_4RD_TUNNEL
+        struct ip6_tnl_4rd ip4rd, *ip4rdp;  
+        struct ip6_tnl_4rd_map_rule *mr;   
+#endif
 
 	memset(&p1, 0, sizeof(p1));
 
@@ -1659,9 +2307,119 @@ ip6_tnl_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)
 		err = 0;
 		unregister_netdevice(dev);
 		break;
+#ifdef CONFIG_CPE_4RD_TUNNEL
+	case SIOCADD4RD:
+	case SIOCDEL4RD:
+		err = -EPERM;
+		if (!capable(CAP_NET_ADMIN))
+			goto done;
+
+		err = -EFAULT;
+		if (copy_from_user(&ip4rd, ifr->ifr_ifru.ifru_data, sizeof(ip4rd)))
+			goto done;
+
+		t = netdev_priv(dev);
+
+		if (cmd == SIOCADD4RD) {
+
+			__be32 prefix;
+			struct in6_addr relay_prefix, relay_suffix;
+
+			err = -EINVAL;
+
+			if (ip4rd.relay_suffixlen > 64)
+				goto done;
+
+			if (ip4rd.relay_suffixlen <= ip4rd.relay_prefixlen)
+				goto done;
+
+			prefix = ip4rd.prefix & htonl(0xffffffffUL << (32 - ip4rd.prefixlen));
+			if (prefix != ip4rd.prefix)
+				goto done;
+
+			ipv6_addr_prefix(&relay_prefix, &ip4rd.relay_prefix, ip4rd.relay_prefixlen);
+			if (!ipv6_addr_equal(&relay_prefix, &ip4rd.relay_prefix))
+				goto done;
+
+			ipv6_addr_prefix(&relay_suffix, &ip4rd.relay_suffix, ip4rd.relay_suffixlen);
+			if (!ipv6_addr_equal(&relay_suffix, &ip4rd.relay_suffix))
+				goto done;
+
+
+			err = ip6_tnl_4rd_mr_create(&ip4rd, &t->ip4rd, t->dev); /* modified by MSPD */
+
+			if ( ip4rd.entry_num == 0 ){
+
+				t->ip4rd.prefix = prefix;
+				t->ip4rd.relay_prefix = relay_prefix;
+				t->ip4rd.relay_suffix = relay_suffix;
+				t->ip4rd.prefixlen = ip4rd.prefixlen;
+				t->ip4rd.relay_prefixlen = ip4rd.relay_prefixlen;
+				t->ip4rd.relay_suffixlen = ip4rd.relay_suffixlen;
+				t->ip4rd.psid_offsetlen = ip4rd.psid_offsetlen;
+
+				ip6_tnl_4rd_update_parms(t);
+				ip6_tnl_dst_reset(t);
+				ip6_tnl_link_config(t);
+			}
+			/* DBG */
+			ip6_tnl_4rd_mr_show(&t->ip4rd);
+		}else if(cmd == SIOCDEL4RD){
+			if ( ip4rd.entry_num == 0 ){
+				ip6_tnl_4rd_mr_delete_all(&t->ip4rd, t->dev);
+				t->ip4rd.prefix = 0;
+				memset(&t->ip4rd.relay_prefix, 0, sizeof(t->ip4rd.relay_prefix));
+				memset(&t->ip4rd.relay_suffix, 0, sizeof(t->ip4rd.relay_suffix));
+				t->ip4rd.prefixlen = 0;
+				t->ip4rd.relay_prefixlen = 0;
+				t->ip4rd.relay_suffixlen = 0;
+				t->ip4rd.psid_offsetlen = 0;
+				t->ip4rd.laddr4 = 0;
+				t->ip4rd.port_set_id = t->ip4rd.port_set_id_len = 0;
+
+				ip6_tnl_dst_reset(t);
+				ip6_tnl_link_config(t);
+			}else{
+				err = ip6_tnl_4rd_mr_delete( ip4rd.entry_num , &t->ip4rd, t->dev);  /* modified by MSPD */
+			}
+			/* DBG */
+			ip6_tnl_4rd_mr_show(&t->ip4rd);
+		}else{
+			printk(KERN_ERR "=== ioctl_cmd 0x%x \n",cmd );
+		}
+		err = 0;
+		break;
+        case SIOCGET4RD:
+                t = netdev_priv(dev);
+                ip4rdp = (struct ip6_tnl_4rd *)ifr->ifr_ifru.ifru_data;
+ 
+                read_lock(&t->ip4rd.map_lock);
+                list_for_each_entry (mr, &t->ip4rd.map_list, mr_list){
+                        ip4rd.relay_prefix = mr->relay_prefix;
+                        ip4rd.relay_suffix = mr->relay_suffix;
+                        ip4rd.prefix = mr->prefix;
+                        ip4rd.relay_prefixlen = mr->relay_prefixlen;
+                        ip4rd.relay_suffixlen = mr->relay_suffixlen;
+                        ip4rd.prefixlen = mr->prefixlen;
+                        ip4rd.eabit_len = mr->eabit_len;
+                        ip4rd.psid_offsetlen = mr->psid_offsetlen;
+                        ip4rd.entry_num = mr->entry_num;
+ 
+                        if (copy_to_user(ip4rdp, &ip4rd, sizeof(ip4rd))) {
+                                read_unlock(&t->ip4rd.map_lock);
+                                err = -EFAULT;
+                        }
+                        ip4rdp++;
+                }
+                read_unlock(&t->ip4rd.map_lock);
+                break;
+#endif
 	default:
 		err = -EINVAL;
 	}
+#ifdef CONFIG_CPE_4RD_TUNNEL
+done:
+#endif
 	return err;
 }
 
@@ -2264,9 +3022,23 @@ static int __init ip6_tunnel_init(void)
 	if (!ipv6_mod_enabled())
 		return -EOPNOTSUPP;
 
+#ifdef CONFIG_CPE_4RD_TUNNEL
+        mr_kmem = kmem_cache_create("ip6_tnl_4rd_map_rule",
+                sizeof(struct ip6_tnl_4rd_map_rule), 0, SLAB_HWCACHE_ALIGN,
+                NULL);
+        if (!mr_kmem)
+	{
+		err= -ENOMEM; 
+                goto out_pernet;
+	}
+#endif
 	err = register_pernet_device(&ip6_tnl_net_ops);
 	if (err < 0)
+#ifdef CONFIG_CPE_4RD_TUNNEL
+		goto out_kmem;
+#else
 		goto out_pernet;
+#endif
 
 	err = xfrm6_tunnel_register(&ip4ip6_handler, AF_INET);
 	if (err < 0) {
@@ -2279,6 +3051,13 @@ static int __init ip6_tunnel_init(void)
 		pr_err("%s: can't register ip6ip6\n", __func__);
 		goto out_ip6ip6;
 	}
+
+#ifdef CONFIG_CPE_4RD_TUNNEL
+	err =__rtnl_register(PF_UNSPEC, RTM_GET4RD, NULL , inet6_dump4rd_mrule, NULL);
+	if(err < 0)
+		goto rtnl_link_failed;
+#endif
+
 	err = rtnl_link_register(&ip6_link_ops);
 	if (err < 0)
 		goto rtnl_link_failed;
@@ -2291,6 +3070,10 @@ static int __init ip6_tunnel_init(void)
 	xfrm6_tunnel_deregister(&ip4ip6_handler, AF_INET);
 out_ip4ip6:
 	unregister_pernet_device(&ip6_tnl_net_ops);
+#ifdef CONFIG_CPE_4RD_TUNNEL
+out_kmem:
+	kmem_cache_destroy(mr_kmem);
+#endif
 out_pernet:
 	return err;
 }
@@ -2308,7 +3091,16 @@ static void __exit ip6_tunnel_cleanup(void)
 	if (xfrm6_tunnel_deregister(&ip6ip6_handler, AF_INET6))
 		pr_info("%s: can't deregister ip6ip6\n", __func__);
 
+#ifdef CONFIG_CPE_4RD_TUNNEL
+        kmem_cache_destroy(mr_kmem);     
+#endif
+ 
 	unregister_pernet_device(&ip6_tnl_net_ops);
+
+#ifdef CONFIG_CPE_4RD_TUNNEL
+        rtnl_unregister(PF_UNSPEC, RTM_GET4RD);
+#endif
+ 
 }
 
 module_init(ip6_tunnel_init);
diff --git a/net/ipv6/netfilter/ip6t_NPT.c b/net/ipv6/netfilter/ip6t_NPT.c
index a379d2f79b19..31e5b4e0a0eb 100644
--- a/net/ipv6/netfilter/ip6t_NPT.c
+++ b/net/ipv6/netfilter/ip6t_NPT.c
@@ -14,6 +14,9 @@
 #include <linux/netfilter_ipv6.h>
 #include <linux/netfilter_ipv6/ip6t_NPT.h>
 #include <linux/netfilter/x_tables.h>
+#ifdef CONFIG_CPE_FAST_PATH
+#include <net/netfilter/nf_conntrack.h>
+#endif
 
 static int ip6t_npt_checkentry(const struct xt_tgchk_param *par)
 {
@@ -90,6 +93,18 @@ ip6t_snpt_tg(struct sk_buff *skb, const struct xt_action_param *par)
 			    offsetof(struct ipv6hdr, saddr));
 		return NF_DROP;
 	}
+#ifdef CONFIG_CPE_FAST_PATH
+	if (1) {
+		struct nf_conn *ct;
+		enum ip_conntrack_info ctinfo;
+		rcu_read_lock();
+		ct = nf_ct_get(skb, &ctinfo);
+		if (ct && ((ctinfo == IP_CT_NEW) || (ctinfo == IP_CT_RELATED))) {
+			memcpy(&ct->tuplehash[IP_CT_DIR_REPLY].tuple.dst.u3.in6, &ipv6_hdr(skb)->saddr, sizeof(struct in6_addr));
+		}
+		rcu_read_unlock();
+	}
+#endif
 	return XT_CONTINUE;
 }
 
@@ -103,6 +118,18 @@ ip6t_dnpt_tg(struct sk_buff *skb, const struct xt_action_param *par)
 			    offsetof(struct ipv6hdr, daddr));
 		return NF_DROP;
 	}
+#ifdef CONFIG_CPE_FAST_PATH
+	if (1) {
+		struct nf_conn *ct;
+		enum ip_conntrack_info ctinfo;
+		rcu_read_lock();
+		ct = nf_ct_get(skb, &ctinfo);
+		if (ct && ((ctinfo == IP_CT_NEW) || (ctinfo == IP_CT_RELATED))) {
+			memcpy(&ct->tuplehash[IP_CT_DIR_REPLY].tuple.src.u3.in6, &ipv6_hdr(skb)->daddr, sizeof(struct in6_addr));
+		}
+		rcu_read_unlock();
+	}
+#endif
 	return XT_CONTINUE;
 }
 
diff --git a/net/ipv6/output_core.c b/net/ipv6/output_core.c
index 4fe7c90962dd..e85935d9b18f 100644
--- a/net/ipv6/output_core.c
+++ b/net/ipv6/output_core.c
@@ -161,6 +161,14 @@ int __ip6_local_out(struct net *net, struct sock *sk, struct sk_buff *skb)
 
 	skb->protocol = htons(ETH_P_IPV6);
 
+#if defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	if(skb->ipsec_offload)
+	{	
+		dst_output(net, sk, skb);	
+		return 0;
+	}	
+	else
+#endif
 	return nf_hook(NFPROTO_IPV6, NF_INET_LOCAL_OUT,
 		       net, sk, skb, NULL, skb_dst(skb)->dev,
 		       dst_output);
diff --git a/net/ipv6/udp.c b/net/ipv6/udp.c
index 40d7234c27b9..ee40a75b0068 100644
--- a/net/ipv6/udp.c
+++ b/net/ipv6/udp.c
@@ -625,6 +625,9 @@ static int udpv6_queue_rcv_skb(struct sock *sk, struct sk_buff *skb)
 
 		/* FALLTHROUGH -- it's a UDP Packet */
 	}
+	/* CONFIG_CPE_NATT change
+	 * kernel had this support changes above. So not adding
+	 * change from 4.1 kernel to here. */
 
 	/*
 	 * UDP-Lite specific tests, ignored on UDP sockets (see net/ipv4/udp.c).
@@ -1440,6 +1443,107 @@ void udpv6_destroy_sock(struct sock *sk)
 	inet6_destroy_sock(sk);
 }
 
+#ifdef CONFIG_CPE_NATT
+/*
+*	Socket option code for UDP for IPV6
+*/
+int udp6_lib_setsockopt(struct sock *sk, int level, int optname,
+		       char __user *optval, unsigned int optlen,
+		       int (*push_pending_frames)(struct sock *))
+{
+	struct udp_sock *up = udp_sk(sk);
+	int val;
+	int err = 0;
+	int is_udplite = IS_UDPLITE(sk);
+
+	if (optlen < sizeof(int))
+		return -EINVAL;
+
+	if (get_user(val, (int __user *)optval))
+		return -EFAULT;
+
+	switch (optname) {
+		case UDP_CORK:
+			if (val != 0) {
+				up->corkflag = 1;
+			} else {
+				up->corkflag = 0;
+				lock_sock(sk);
+				(*push_pending_frames)(sk);
+				release_sock(sk);
+			}
+			break;
+
+		case UDP_ENCAP:
+			switch (val) {
+				case 0:
+				case UDP_ENCAP_ESPINUDP:
+				case UDP_ENCAP_ESPINUDP_NON_IKE:
+					up->encap_rcv = xfrm6_udp_encap_rcv;
+					/* FALLTHROUGH */
+				case UDP_ENCAP_L2TPINUDP:
+					up->encap_type = val;
+					break;
+				default:
+					err = -ENOPROTOOPT;
+					break;
+			}
+			break;
+
+		/* BEGIN --- The below two cases support brought from net/ipv4/udp.c udp_lib_setsockopt(). *
+		 * These two cases added later in kernel, compares with when initially it ported on first kernel. */
+		case UDP_NO_CHECK6_TX:
+			up->no_check6_tx = valbool;
+			break;
+
+		case UDP_NO_CHECK6_RX:
+			up->no_check6_rx = valbool;
+			break;
+
+		/* END --- The below two cases support brought from net/ipv4/udp.c udp_lib_setsockopt(). */
+
+			/*
+			 * 	UDP-Lite's partial checksum coverage (RFC 3828).
+			 */
+			/* The sender sets actual checksum coverage length via this option.
+			 * The case coverage > packet length is handled by send module. */
+		case UDPLITE_SEND_CSCOV:
+			if (!is_udplite)         /* Disable the option on UDP sockets */
+				return -ENOPROTOOPT;
+			if (val != 0 && val < 8) /* Illegal coverage: use default (8) */
+				val = 8;
+			else if (val > USHRT_MAX)
+				val = USHRT_MAX;
+			up->pcslen = val;
+			up->pcflag |= UDPLITE_SEND_CC;
+			break;
+
+			/* The receiver specifies a minimum checksum coverage value. To make
+			 * sense, this should be set to at least 8 (as done below). If zero is
+			 * used, this again means full checksum coverage.                     */
+		case UDPLITE_RECV_CSCOV:
+			if (!is_udplite)         /* Disable the option on UDP sockets */
+				return -ENOPROTOOPT;
+			if (val != 0 && val < 8) /* Avoid silly minimal values.       */
+				val = 8;
+			else if (val > USHRT_MAX)
+				val = USHRT_MAX;
+			up->pcrlen = val;
+			up->pcflag |= UDPLITE_RECV_CC;
+			break;
+
+		default:
+			err = -ENOPROTOOPT;
+			break;
+	}
+
+	return err;
+}
+
+EXPORT_SYMBOL(udp6_lib_setsockopt);
+#endif
+
+
 /*
  *	Socket option code for UDP
  */
@@ -1447,8 +1551,13 @@ int udpv6_setsockopt(struct sock *sk, int level, int optname,
 		     char __user *optval, unsigned int optlen)
 {
 	if (level == SOL_UDP  ||  level == SOL_UDPLITE)
+#ifdef CONFIG_CPE_NATT
+		return udp6_lib_setsockopt(sk, level, optname, optval, optlen,
+					  udp_v6_push_pending_frames);
+#else
 		return udp_lib_setsockopt(sk, level, optname, optval, optlen,
 					  udp_v6_push_pending_frames);
+#endif
 	return ipv6_setsockopt(sk, level, optname, optval, optlen);
 }
 
@@ -1457,8 +1566,13 @@ int compat_udpv6_setsockopt(struct sock *sk, int level, int optname,
 			    char __user *optval, unsigned int optlen)
 {
 	if (level == SOL_UDP  ||  level == SOL_UDPLITE)
+#ifdef CONFIG_CPE_NATT
+		return udp6_lib_setsockopt(sk, level, optname, optval, optlen,
+					  udp_v6_push_pending_frames);
+#else
 		return udp_lib_setsockopt(sk, level, optname, optval, optlen,
 					  udp_v6_push_pending_frames);
+#endif
 	return compat_ipv6_setsockopt(sk, level, optname, optval, optlen);
 }
 #endif
diff --git a/net/ipv6/xfrm6_input.c b/net/ipv6/xfrm6_input.c
index fe04e23af986..82289480ada6 100644
--- a/net/ipv6/xfrm6_input.c
+++ b/net/ipv6/xfrm6_input.c
@@ -22,6 +22,17 @@ int xfrm6_extract_input(struct xfrm_state *x, struct sk_buff *skb)
 	return xfrm6_extract_header(skb);
 }
 
+#ifdef CONFIG_CPE_NATT
+int xfrm6_rcv_encap(struct sk_buff *skb, int nexthdr, __be32 spi,
+		    int encap_type)
+{
+	XFRM_SPI_SKB_CB(skb)->family = AF_INET6;
+	XFRM_SPI_SKB_CB(skb)->daddroff = offsetof(struct ipv6hdr, daddr);
+	return xfrm_input(skb, nexthdr, spi, encap_type);
+}
+EXPORT_SYMBOL(xfrm6_rcv_encap);
+#endif
+
 int xfrm6_rcv_spi(struct sk_buff *skb, int nexthdr, __be32 spi,
 		  struct ip6_tnl *t)
 {
@@ -60,6 +71,108 @@ int xfrm6_transport_finish(struct sk_buff *skb, int async)
 	return -1;
 }
 
+#ifdef CONFIG_CPE_NATT
+/* If it's a keepalive packet, then just eat it.
+ * If it's an encapsulated packet, then pass it to the
+ * IPsec xfrm input.
+ * Returns 0 if skb passed to xfrm or was dropped.
+ * Returns >0 if skb should be passed to UDP.
+ * Returns <0 if skb should be resubmitted (-ret is protocol)
+ */
+int xfrm6_udp_encap_rcv(struct sock *sk, struct sk_buff *skb)
+{
+
+#ifndef CONFIG_XFRM
+	return 1;
+#else
+	struct udp_sock *up = udp_sk(sk);
+	struct udphdr *uh;
+	struct ipv6hdr *iph;
+	int iphlen, len;
+
+	__u8 *udpdata;
+	__be32 *udpdata32;
+	__u16 encap_type = up->encap_type;
+
+
+
+	/* if this is not encapsulated socket, then just return now */
+	if (!encap_type)
+		return 1;
+
+	/* If this is a paged skb, make sure we pull up
+	 * whatever data we need to look at. */
+	len = skb->len - sizeof(struct udphdr);
+	if (!pskb_may_pull(skb, sizeof(struct udphdr) + min(len, 8)))
+		return 1;
+
+	/* Now we can get the pointers */
+	uh = udp_hdr(skb);
+	udpdata = (__u8 *)uh + sizeof(struct udphdr);
+	udpdata32 = (__be32 *)udpdata;
+
+	switch (encap_type) {
+	default:
+	case UDP_ENCAP_ESPINUDP:
+		/* Check if this is a keepalive packet.  If so, eat it. */
+		if (len == 1 && udpdata[0] == 0xff) {
+			goto drop;
+		} else if (len > sizeof(struct ip_esp_hdr) && udpdata32[0] != 0) {
+			/* ESP Packet without Non-ESP header */
+			len = sizeof(struct udphdr);
+		} else
+			/* Must be an IKE packet.. pass it through */
+			return 1;
+		break;
+	case UDP_ENCAP_ESPINUDP_NON_IKE:
+		/* Check if this is a keepalive packet.  If so, eat it. */
+		if (len == 1 && udpdata[0] == 0xff) {
+			goto drop;
+		} else if (len > 2 * sizeof(u32) + sizeof(struct ip_esp_hdr) &&
+			   udpdata32[0] == 0 && udpdata32[1] == 0) {
+
+			/* ESP Packet with Non-IKE marker */
+			len = sizeof(struct udphdr) + 2 * (sizeof(u32) * 4);
+		} else
+			/* Must be an IKE packet.. pass it through */
+			return 1;
+		break;
+	}
+
+	/* At this point we are sure that this is an ESPinUDP packet,
+	 * so we need to remove 'len' bytes from the packet (the UDP
+	 * header and optional ESP marker bytes) and then modify the
+	 * protocol to ESP, and then call into the transform receiver.
+	 */
+	if (skb_cloned(skb) && pskb_expand_head(skb, 0, 0, GFP_ATOMIC)){
+		goto drop;
+	}
+
+	/* Now we can update and verify the packet length... */
+	iph = ipv6_hdr(skb);
+	iphlen = ntohs(iph->payload_len);
+	if (skb->len < iphlen) {
+		/* packet is too small!?! */
+		goto drop;
+	}
+
+	/* pull the data buffer up to the ESP header and set the
+	 * transport header to point to ESP.  Keep UDP on the stack
+	 * for later.
+	 */
+	__skb_pull(skb, len);
+	skb_reset_transport_header(skb);
+
+	/* process ESP */
+	return xfrm6_rcv_encap(skb, IPPROTO_ESP, 0, encap_type);
+
+drop:
+	kfree_skb(skb);
+	return 0;
+#endif
+}
+#endif
+
 int xfrm6_rcv_tnl(struct sk_buff *skb, struct ip6_tnl *t)
 {
 	return xfrm6_rcv_spi(skb, skb_network_header(skb)[IP6CB(skb)->nhoff],
diff --git a/net/ipv6/xfrm6_policy.c b/net/ipv6/xfrm6_policy.c
index 17e95a0386b3..fde6b7833ad2 100644
--- a/net/ipv6/xfrm6_policy.c
+++ b/net/ipv6/xfrm6_policy.c
@@ -122,11 +122,27 @@ _decode_session6(struct sk_buff *skb, struct flowi *fl, int reverse)
 {
 	struct flowi6 *fl6 = &fl->u.ip6;
 	int onlyproto = 0;
+#ifdef NET_SKBUFF_NF_DEFRAG_NEEDED
+#ifdef CONFIG_CPE_FAST_PATH 
+	struct sk_buff *whole_skb = (skb->nfct_reasm) ? skb->nfct_reasm : skb;
+#else
+	struct sk_buff *whole_skb = skb;
+#endif
+#else
+	struct sk_buff *whole_skb = skb;
+#endif
 	const struct ipv6hdr *hdr = ipv6_hdr(skb);
 	u16 offset = sizeof(*hdr);
 	struct ipv6_opt_hdr *exthdr;
+#ifdef CONFIG_CPE_FAST_PATH 
+/* This is not fast path related patch, but a bug-fix which is taken from patch in the internet
+*/
+	const unsigned char *nh = skb_network_header(whole_skb);
+	u16 nhoff = IP6CB(whole_skb)->nhoff;
+#else
 	const unsigned char *nh = skb_network_header(skb);
 	u16 nhoff = IP6CB(skb)->nhoff;
+#endif
 	int oif = 0;
 	u8 nexthdr;
 
@@ -145,9 +161,15 @@ _decode_session6(struct sk_buff *skb, struct flowi *fl, int reverse)
 	fl6->daddr = reverse ? hdr->saddr : hdr->daddr;
 	fl6->saddr = reverse ? hdr->daddr : hdr->saddr;
 
+#ifdef CONFIG_CPE_FAST_PATH 
+	while (nh + offset + 1 < whole_skb->data ||
+	       pskb_may_pull(whole_skb, nh + offset + 1 - whole_skb->data)) {
+		nh = skb_network_header(whole_skb);
+#else
 	while (nh + offset + 1 < skb->data ||
 	       pskb_may_pull(skb, nh + offset + 1 - skb->data)) {
 		nh = skb_network_header(skb);
+#endif
 		exthdr = (struct ipv6_opt_hdr *)(nh + offset);
 
 		switch (nexthdr) {
@@ -166,8 +188,13 @@ _decode_session6(struct sk_buff *skb, struct flowi *fl, int reverse)
 		case IPPROTO_TCP:
 		case IPPROTO_SCTP:
 		case IPPROTO_DCCP:
+#ifdef CONFIG_CPE_NATT
+			if (!onlyproto && (nh + offset + 4 < whole_skb->data ||
+			     pskb_may_pull(whole_skb, nh + offset + 4 - whole_skb->data))) {
+#else
 			if (!onlyproto && (nh + offset + 4 < skb->data ||
 			     pskb_may_pull(skb, nh + offset + 4 - skb->data))) {
+#endif
 				__be16 *ports;
 
 				nh = skb_network_header(skb);
diff --git a/net/key/af_key.c b/net/key/af_key.c
index 2ad693232f74..1d9db4762b07 100644
--- a/net/key/af_key.c
+++ b/net/key/af_key.c
@@ -30,8 +30,180 @@
 #include <net/net_namespace.h>
 #include <net/netns/generic.h>
 #include <net/xfrm.h>
+#if defined(CONFIG_INET_IPSEC_OFFLOAD)|| defined(CONFIG_INET6_IPSEC_OFFLOAD)
+#include <net/netlink.h>
+#endif
 
 #include <net/sock.h>
+#if defined(CONFIG_INET_IPSEC_OFFLOAD)|| defined(CONFIG_INET6_IPSEC_OFFLOAD)
+#include <net/ip6_route.h>
+#define NLKEY_SUPPORT 1
+#else 
+#undef NLKEY_SUPPORT
+#endif 
+
+#ifdef NLKEY_SUPPORT
+#include <net/dsfield.h>
+#include <net/inet_ecn.h>
+#include <net/ipv6.h>
+
+
+extern int xfrm_get_tos(struct flowi *fl, int family);
+
+
+#define	NLKEY_SA_CREATE		0x0A01
+#define NLKEY_SA_DELETE		0x0A02
+#define NLKEY_SA_FLUSH 		0x0A03
+#define NLKEY_SA_SET_KEYS	0x0A04
+#define NLKEY_SA_SET_TUNNEL	0x0A05
+#define NLKEY_SA_SET_NATT	0x0A06
+#define	NLKEY_SA_SET_STATE	0x0A07
+#define	NLKEY_SA_SET_LIFETIME	0x0A08
+#define	NLKEY_SA_NOTIFY		0x0A09
+#define NLKEY_SA_INFO_UPDATE	0x0A0C
+#define	NLKEY_FLOW_ADD		0x0A11
+#define NLKEY_FLOW_REMOVE	0x0A12
+#define NLKEY_FLOW_NOTIFY	0x0A13
+#define NLKEY_NULL_MSG		0x0000
+
+#define NLKEY_HDR_LEN		4
+#define NLKEY_MSG_LEN 		256
+
+#define NLKEY_MAX_NUM_KEYS	2
+#define NLKEY_MAX_KEY_LEN	(256 / 8)
+
+struct nlkey_msg {
+	/* message data */
+	unsigned short fcode;
+	unsigned short length;
+	unsigned short payload[(NLKEY_MSG_LEN /sizeof(unsigned short))];
+};
+/* sizeof(nlkey_msg) = 4 + 256 */
+
+struct nlkey_sa_id {
+	unsigned int spi;
+	unsigned char sa_type;
+	unsigned char proto_family;
+	unsigned char replay_window;
+#define NLKEY_SAFLAGS_ESN	0x1
+#define NLKEY_SAFLAGS_INBOUND	0x2
+	unsigned char flags;
+	unsigned int dst_ip[4];
+	unsigned int src_ip[4];
+	unsigned short mtu;
+	unsigned short dev_mtu;
+
+};
+/* sizeof(nlkey_sa_id) = 24 */
+
+struct nlkey_sa_create {
+	unsigned short sagd;
+	unsigned short rsvd;
+	struct nlkey_sa_id said;
+};
+/* sizeof(nlkey_sa_delete) = 28 */
+
+struct nlkey_sa_delete {
+	unsigned short sagd;
+	unsigned short rsvd;
+};
+/* sizeof(nlkey_sa_delete) = 4 */
+
+struct nlkey_sa_set_tunnel {
+	unsigned short sagd;
+	unsigned char rsvd;
+	unsigned char proto_family;
+	union {
+		struct iphdr 	 ipv4h;
+		struct ipv6hdr ipv6h;
+	} h;
+};
+/* sizeof(nlkey_sa_set_tunnel) = 36 */
+
+struct nlkey_sa_set_natt {
+	unsigned short sagd;
+	unsigned short sport;
+	unsigned short dport;
+	unsigned short rsvd;
+};
+/* sizeof(nlkey_sa_set_natt) = 4 */
+
+struct nlkey_sa_set_state {
+	unsigned short sagd;
+	unsigned short rsvd;
+	unsigned short state;
+	unsigned short rsvd2;
+};
+/* sizeof(nlkey_sa_set_natt) = 8 */
+
+struct nlkey_key_desc {
+	unsigned short key_bits;
+	unsigned char key_alg;
+	unsigned char  key_type;
+	unsigned char key[NLKEY_MAX_KEY_LEN]; 
+};
+/* sizeof(nlkey_key_desc) =  36 */
+
+struct nlkey_sa_set_keys {
+	unsigned short sagd;
+	unsigned short rsvd;	
+	unsigned short num_keys;
+	unsigned short rsvd2;
+	struct nlkey_key_desc keys[NLKEY_MAX_NUM_KEYS];
+};
+/* sizeof(nlkey_sa_set_keys) =  80 */
+
+struct nlkey_lifetime_desc {
+	unsigned int allocations;
+	unsigned int bytes[2];
+};
+/* sizeof(nlkey_sa_set_lifetime) =  12 */
+
+struct nlkey_sa_set_lifetime {
+	unsigned short sagd;
+	unsigned short rsvd;
+	struct nlkey_lifetime_desc hard_time;
+	struct nlkey_lifetime_desc soft_time;
+	struct nlkey_lifetime_desc current_time;
+};
+/* sizeof(nlkey_sa_set_lifetime) =  40 */
+
+/* SA notifications */
+#define IPSEC_SOFT_EXPIRE 0
+#define IPSEC_HARD_EXPIRE 1
+
+struct nlkey_sa_notify {
+	unsigned short sagd;
+	unsigned short rsvd;
+	unsigned int  action;
+};
+/* sizeof(nlkey_sa_notify) = 8 */
+
+/* SA Info update */
+
+struct nlkey_sa_info {
+        unsigned short sagd;
+        unsigned short rsvd;
+        unsigned long long bytes;
+        unsigned long long packets;
+};
+/* sizeof(nlkey_sa_info) =  */
+
+
+static int ipsec_nlkey_send(struct net *net, struct xfrm_state *x, const struct km_event *c);
+static void ipsec_nlkey_rcv(struct sk_buff *skb);
+static void ipsec_nlkey_init(void);
+static unsigned short ipsec_sacode_to_nlkeycode(unsigned short sa_code);
+static struct sk_buff * ipsec_xfrm2nlkey (struct net *net, struct xfrm_state *x, 
+					const struct km_event *c, unsigned short *msg_id);
+static int ipsec_nlkey_set_said(struct net *net, struct xfrm_state *x, const struct km_event *c, struct nlkey_sa_id *said);
+
+/* netlink NETLINK_KEY socket */
+struct sock *nlkey_socket = NULL;
+
+#endif
+/************************************************************************************/
+
 
 #define _X2KEY(x) ((x) == XFRM_INF ? 0 : (x))
 #define _KEY2X(x) ((x) == 0 ? XFRM_INF : (x))
@@ -867,6 +1039,10 @@ static struct sk_buff *__pfkey_xfrm_state2msg(const struct xfrm_state *x,
 		sa->sadb_sa_flags |= SADB_SAFLAGS_DECAP_DSCP;
 	if (x->props.flags & XFRM_STATE_NOPMTUDISC)
 		sa->sadb_sa_flags |= SADB_SAFLAGS_NOPMTUDISC;
+#ifdef NLKEY_SUPPORT
+	if (x->props.flags & XFRM_STATE_ESN)
+		sa->sadb_sa_flags |= SADB_SAFLAGS_ESN;
+#endif
 
 	/* hard time */
 	if (hsc & 2) {
@@ -1128,6 +1304,10 @@ static struct xfrm_state * pfkey_msg2xfrm_state(struct net *net,
 		x->props.flags |= XFRM_STATE_DECAP_DSCP;
 	if (sa->sadb_sa_flags & SADB_SAFLAGS_NOPMTUDISC)
 		x->props.flags |= XFRM_STATE_NOPMTUDISC;
+#ifdef NLKEY_SUPPORT
+	if (sa->sadb_sa_flags & SADB_SAFLAGS_ESN)
+		x->props.flags |= XFRM_STATE_ESN;
+#endif
 
 	lifetime = ext_hdrs[SADB_EXT_LIFETIME_HARD - 1];
 	if (lifetime != NULL) {
@@ -3037,6 +3217,12 @@ static int pfkey_send_notify(struct xfrm_state *x, const struct km_event *c)
 	struct net *net = x ? xs_net(x) : c->net;
 	struct netns_pfkey *net_pfkey = net_generic(net, pfkey_net_id);
 
+
+#ifdef NLKEY_SUPPORT
+	/* send message to the user space through NETLINK_KEY socket*/
+	ipsec_nlkey_send(net, x, c);
+#endif
+
 	if (atomic_read(&net_pfkey->socks_nr) == 0)
 		return 0;
 
@@ -3835,6 +4021,628 @@ static struct xfrm_mgr pfkeyv2_mgr =
 	.is_alive	= pfkey_is_alive,
 };
 
+
+#ifdef NLKEY_SUPPORT
+extern struct xfrm_state *xfrm_state_lookup_byhandle(struct net *net, u16 handle);
+
+static unsigned short ipsec_sacode_to_nlkeycode(unsigned short sa_code)
+{
+	unsigned nlkey_code;
+
+	switch (sa_code) 
+	{
+		case XFRM_MSG_DELSA:
+			nlkey_code = NLKEY_SA_DELETE;
+			break;
+		case XFRM_MSG_NEWSA:
+		case XFRM_MSG_UPDSA:
+			nlkey_code = NLKEY_SA_CREATE;
+			break;
+		case XFRM_MSG_FLUSHSA:
+			nlkey_code = NLKEY_SA_FLUSH;
+			break;
+		case XFRM_MSG_EXPIRE:
+			nlkey_code = NLKEY_SA_SET_STATE;
+			break;
+		default:
+			nlkey_code = NLKEY_NULL_MSG;
+			break;
+	}
+
+	return nlkey_code;
+}
+
+static void ipsec_nlkey_rcv(struct sk_buff *skb)
+{
+	struct nlmsghdr *nlh = NULL;
+	struct nlkey_msg *msg = NULL;
+	struct flowi flow;
+	unsigned short *p;
+	unsigned short family, dir;
+	struct xfrm_state *x;
+	struct nlkey_sa_notify sa_notify_msg;
+	struct nlkey_sa_info sa_info_msg;
+
+	/* extract message from skb */
+	nlh = (struct nlmsghdr *)skb->data;
+
+	msg = (struct nlkey_msg *)NLMSG_DATA(nlh);
+
+	//printk(KERN_INFO "ipsec_nlkey_rcv fcode: 0x%x length: %d bytes\n",msg->fcode,msg->length);
+
+	/* process command received from user space */
+	switch(msg->fcode)
+	{
+		case NLKEY_FLOW_REMOVE:
+			//printk(KERN_INFO "ipsec_nlkey_rcv NLKEY_FLOW_REMOVE\n");
+			p = msg->payload;
+			memcpy(&flow, p, sizeof(struct flowi)); p += sizeof(struct flowi)/2;
+			family = *p; p++;
+			dir = *p; p++;
+			flow_cache_remove(&flow, family, dir);
+			break;
+
+		case NLKEY_SA_NOTIFY:
+			//printk(KERN_INFO "ipsec_nlkey_rcv NLKEY_SA_NOTIFY\n");
+			memcpy(&sa_notify_msg, msg->payload, sizeof(struct nlkey_sa_notify));
+			x = xfrm_state_lookup_byhandle(&init_net, sa_notify_msg.sagd);
+			if (x) {
+				spin_lock(&x->lock);
+
+				if (sa_notify_msg.action) { 
+					// hard expired
+					x->km.state = XFRM_STATE_EXPIRED;
+					tasklet_hrtimer_start(&x->mtimer, ktime_set(0,0), HRTIMER_MODE_REL);
+				}
+				else if (!x->km.dying) {
+					 x->km.dying = 1;
+					 km_state_expired(x, 0, 0);
+				}
+
+				spin_unlock(&x->lock);
+				xfrm_state_put(x);
+			}
+			break;
+
+		case NLKEY_SA_INFO_UPDATE:
+			memcpy(&sa_info_msg, msg->payload, sizeof(struct nlkey_sa_info));
+
+			x = xfrm_state_lookup_byhandle(&init_net,sa_info_msg.sagd);
+			if (x) {
+				spin_lock(&x->lock);
+
+				x->curlft.bytes = sa_info_msg.bytes;
+				x->curlft.packets = sa_info_msg.packets;
+
+				spin_unlock(&x->lock);
+				xfrm_state_put(x);
+			}
+			break;
+		default:
+			//printk(KERN_INFO "ipsec_nlkey_rcv fcode 0x%x not supported\n", msg->fcode);
+			break;
+	}
+
+}
+
+extern struct dst_entry *__xfrm_dst_lookup(struct net *net, int tos, int oif,
+						  xfrm_address_t *saddr,
+						  xfrm_address_t *daddr,
+						  int family);
+static int ipsec_nlkey_set_said(struct net *net, struct xfrm_state *x, 
+				const struct km_event *c, struct nlkey_sa_id *said)
+{
+
+	struct flowi fl;
+	int tos;
+	xfrm_address_t saddr, daddr;
+	struct dst_entry *dst;
+	struct rt6_info  *rt;
+	int rc = 0;
+	int oif = 0;
+
+	memset(&fl, 0, sizeof(struct flowi));
+
+	/* SPI */
+	said->spi = x->id.spi;
+	/* SA Type (AH or ESP) */
+	said->sa_type = x->id.proto;
+	/* Protocol Family (IPv4 or IPv6) */
+	said->proto_family = x->props.family;
+	/* Replay window */
+	said->replay_window = x->props.replay_window;
+	/* Destination IP Address */
+	if(x->props.family == AF_INET6) {
+		memcpy(&said->dst_ip, x->id.daddr.a6, sizeof(struct in6_addr));
+		fl.u.ip6.daddr = *(struct in6_addr *)x->id.daddr.a6;
+		memcpy(&said->src_ip, x->props.saddr.a6, sizeof(struct in6_addr));
+	}
+	else {
+		said->dst_ip[0] = x->id.daddr.a4;
+		fl.u.ip4.daddr = x->id.daddr.a4;
+		said->src_ip[0] = x->props.saddr.a4;
+	}
+	said->mtu = 0;
+
+	if(x->props.flags & XFRM_STATE_ESN)
+		said->flags = NLKEY_SAFLAGS_ESN;
+	xfrm_flowi_addr_get(&fl, &saddr, &daddr, x->props.family);
+
+	tos = xfrm_get_tos(&fl, x->props.family);
+	if (tos < 0) {
+		printk(KERN_ERR "%s:%d: FIXME\n",__FUNCTION__,__LINE__);	
+		rc = -1;
+		goto error;
+	}
+	
+	switch (x->props.family)
+	{
+		case AF_INET:
+			if (!__ip_route_output_key(net, &(fl.u.ip4)))
+			{
+				printk(KERN_ERR "%s:%d:  FIXME\n",__FUNCTION__,__LINE__);
+				rc = -1;
+				goto error;
+			}
+			oif = fl.u.ip4.flowi4_oif;
+			break;
+
+		case AF_INET6:
+			rt = rt6_lookup(net, &fl.u.ip6.daddr, NULL, 0, 0);
+			if ((!rt) || (!rt->dst.dev))
+			{
+				printk(KERN_ERR "%s:%d: FIXME\n",__FUNCTION__,__LINE__);
+				rc = -1;
+				goto error;
+			}
+			oif = rt->dst.dev->ifindex;
+			break;
+	}
+
+	dst = __xfrm_dst_lookup(net, tos, oif, NULL, &daddr, x->props.family);
+	if (IS_ERR(dst)) {
+		printk(KERN_ERR "%s:%d: FIXME\n",__FUNCTION__,__LINE__);
+		rc = -1;
+		goto error;
+	}
+
+	if (strcmp(dst->dev->name, "lo") == 0)
+		said->flags |= NLKEY_SAFLAGS_INBOUND;
+
+	said->dev_mtu = dst_mtu(dst);
+	said->mtu = xfrm_state_mtu(x,dst_mtu(dst));	
+
+	dst_release(dst);
+error:
+	return rc;
+}
+
+static struct sk_buff * ipsec_xfrm2nlkey (struct net *net, struct xfrm_state *x, 
+					const struct km_event *c, unsigned short *msg_id)
+{
+	struct nlkey_sa_id sa_id_msg;
+	struct nlkey_sa_create sa_create_msg;
+	struct nlkey_sa_delete sa_delete_msg;
+	struct nlkey_sa_set_keys sa_set_keys_msg;
+	struct nlkey_sa_set_tunnel sa_set_tunnel_msg;
+	struct nlkey_sa_set_natt sa_set_natt_msg;
+	struct nlkey_sa_set_state sa_set_state_msg;
+	struct nlkey_sa_set_lifetime sa_set_lifetime_msg;
+	struct nlkey_msg msg;
+	struct sk_buff *skb = NULL;
+	struct nlmsghdr *nlh = NULL;
+	gfp_t allocation = GFP_ATOMIC; //This may called from atomic context
+	unsigned char tunnel, keys, natt, state, lifetime;
+
+	/* supported SA informations */
+	keys = 1; state = 1; tunnel = 1; lifetime = 1; natt = 1; 
+
+	/* next message to build */
+	memset(&msg, 0, sizeof(struct nlkey_msg));
+	msg.fcode = *msg_id;
+	
+	//printk(KERN_INFO "\n\nipsec_xfrm2nlkey: processing event 0x%x\n", msg.fcode);
+
+	switch (msg.fcode)
+	{
+		case NLKEY_SA_CREATE:
+			//printk(KERN_INFO "ipsec_xfrm2nlkey: NLKEY_SA_CREATE\n");
+			if(x) {
+				/* some check before builing message */
+				if((x->id.proto != IPPROTO_ESP) && (x->id.proto != IPPROTO_AH)) {
+					printk(KERN_ERR "ipsec_xfrm2nlkey: protocol %d not supported\n", x->id.proto);
+					*msg_id = NLKEY_NULL_MSG;
+					goto exit;
+				}	
+				memset(&sa_create_msg, 0, sizeof(struct nlkey_sa_create));	
+
+				/* SA global handler */
+				sa_create_msg.sagd = x->handle;
+
+				/* SA identifier */
+				if(ipsec_nlkey_set_said(net, x, c, &sa_create_msg.said) < 0)
+				{
+					printk(KERN_ERR "%s: set sa ID failed\n", __func__);
+					*msg_id = NLKEY_NULL_MSG; /* next message */
+					goto exit;
+				}
+				memcpy(msg.payload, &sa_create_msg, sizeof(struct nlkey_sa_create));
+				msg.length = sizeof(struct nlkey_sa_create);
+				*msg_id = NLKEY_SA_SET_KEYS; /* next message */
+			} else {
+				*msg_id = NLKEY_NULL_MSG; /* next message */
+				goto exit;
+			}
+			
+			break;
+
+		case NLKEY_SA_SET_KEYS:
+			//printk(KERN_INFO "ipsec_xfrm2nlkey: NLKEY_SA_SET_KEYS\n");
+			if(keys) {
+				memset(&sa_set_keys_msg, 0, sizeof(struct nlkey_sa_set_keys));
+
+				/* SA global handler */
+				sa_set_keys_msg.sagd = x->handle; 
+				
+				/* auth key */
+				if(x->aalg) {
+					if (x->aalg->alg_key_len) {
+						sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_bits = x->aalg->alg_key_len;
+						sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_alg = x->props.aalgo;
+						sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_type = 0;
+						memcpy(sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key, x->aalg->alg_key,(sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_bits / 8));
+						//printk(KERN_INFO "ipsec_xfrm2nlkey: AUTH - algo %d key %d bits\n", sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_alg, sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_bits);
+						sa_set_keys_msg.num_keys++;
+					}
+				}
+				/* encrypt key */
+				if(x->ealg) {
+					if (x->ealg->alg_key_len) {
+
+						sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_bits = x->ealg->alg_key_len;
+						sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_alg = x->props.ealgo;
+						sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_type = 1;
+						memcpy(sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key, x->ealg->alg_key,(sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_bits / 8));
+						//printk(KERN_INFO "ipsec_xfrm2nlkey: ENCRYPT - algo %d key %d bits\n", sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_alg, sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_bits);
+						sa_set_keys_msg.num_keys++;
+					}
+				}
+				memcpy(msg.payload, &sa_set_keys_msg, sizeof(struct nlkey_sa_set_keys));
+				msg.length = sizeof(struct nlkey_sa_set_keys);
+				*msg_id = NLKEY_SA_SET_TUNNEL; /* next message */
+			} else {
+				*msg_id = NLKEY_SA_SET_TUNNEL; /* next message */
+				goto exit;
+			}
+			break;
+
+		case NLKEY_SA_SET_TUNNEL:
+			//printk(KERN_INFO "ipsec_xfrm2nlkey: NLKEY_SA_SET_TUNNEL\n");
+			if(tunnel && (x->props.mode == XFRM_MODE_TUNNEL)) {
+				memset(&sa_set_tunnel_msg, 0, sizeof(struct nlkey_sa_set_tunnel));
+
+				/* SA global handler */
+				sa_set_tunnel_msg.sagd = x->handle; 
+
+				/* Tunnel */
+				sa_set_tunnel_msg.proto_family = x->props.family;
+				if(x->props.family == AF_INET6) {
+					struct ipv6hdr *top_iph = &sa_set_tunnel_msg.h.ipv6h;
+					int dsfield;
+					top_iph->version = 6;
+					top_iph->priority = 0;
+					top_iph->flow_lbl[0] = 0;
+					top_iph->flow_lbl[1] = 0;
+					top_iph->flow_lbl[2] = 0;
+					top_iph->nexthdr = IPPROTO_IPIP;	
+					dsfield = ipv6_get_dsfield(top_iph);
+					dsfield = INET_ECN_encapsulate(dsfield, dsfield);
+					if (x->props.flags & XFRM_STATE_NOECN)
+						dsfield &= ~INET_ECN_MASK;
+					ipv6_change_dsfield(top_iph, 0, dsfield);
+					top_iph->hop_limit = 64;
+					memcpy(&top_iph->daddr, x->id.daddr.a6, sizeof(struct in6_addr));
+					memcpy(&top_iph->saddr, x->props.saddr.a6, sizeof(struct in6_addr));
+					//printk(KERN_INFO "ipsec_xfrm2nlkey: IPv6 tunnel\n");
+					//printk(KERN_INFO "dst: %x %x %x %x\n", x->id.daddr.a6[0], x->id.daddr.a6[1], x->id.daddr.a6[2], x->id.daddr.a6[3]);
+					//(KERN_INFO "src: %x %x %x %x\n", x->props.saddr.a6[0], x->props.saddr.a6[1], x->props.saddr.a6[2], x->props.saddr.a6[3]);
+				}
+				else {
+					struct iphdr *top_iph = &sa_set_tunnel_msg.h.ipv4h;
+					top_iph->ihl = 5;
+					top_iph->version = 4;
+					top_iph->tos = 0;
+					top_iph->frag_off = 0; 
+					top_iph->ttl = 64;
+					top_iph->saddr = x->props.saddr.a4;
+					top_iph->daddr = x->id.daddr.a4;
+					//printk(KERN_INFO "ipsec_xfrm2nlkey: IPv4 tunnel dst:%x - src:%x \n", x->id.daddr.a4, x->props.saddr.a4);
+				}
+				memcpy(msg.payload, &sa_set_tunnel_msg, sizeof(struct nlkey_sa_set_tunnel));
+				msg.length = sizeof(struct nlkey_sa_set_tunnel);
+				*msg_id = NLKEY_SA_SET_NATT; /* next message */
+			} else {
+				*msg_id = NLKEY_SA_SET_NATT; /* next message */
+				goto exit;	
+			} 
+			break;
+
+		case NLKEY_SA_SET_NATT:
+			//printk(KERN_INFO "ipsec_xfrm2nlkey: NLKEY_SA_SET_NATT\n");
+			if((natt) && (x->encap)){
+				memset(&sa_set_natt_msg, 0, sizeof(struct nlkey_sa_set_natt));
+
+				/* SA global handler */
+				sa_set_natt_msg.sagd = x->handle; 
+				sa_set_natt_msg.sport = x->encap->encap_sport;
+				sa_set_natt_msg.dport = x->encap->encap_dport;
+				//printk(KERN_INFO "src port: %d  dst port: %d \n", ntohs(sa_set_natt_msg.sport), ntohs( sa_set_natt_msg.dport));
+				memcpy(msg.payload, &sa_set_natt_msg, sizeof(struct nlkey_sa_set_natt));
+				msg.length = sizeof(struct nlkey_sa_set_natt);
+				*msg_id = NLKEY_SA_SET_LIFETIME; /* next message */
+			} else {
+				*msg_id = NLKEY_SA_SET_LIFETIME; /* next message */
+				goto exit;	
+			}
+			break;
+
+		case NLKEY_SA_SET_LIFETIME:
+			//printk(KERN_INFO "ipsec_xfrm2nlkey: NLKEY_SA_SET_LIFETIME\n");
+			if(lifetime) {
+				memset(&sa_set_lifetime_msg, 0, sizeof(struct nlkey_sa_set_lifetime));
+
+				/* SA global handler */
+				sa_set_lifetime_msg.sagd = x->handle;
+
+				/* hard time */
+				sa_set_lifetime_msg.hard_time.allocations =  _X2KEY(x->lft.hard_packet_limit);
+				if(_X2KEY(x->lft.hard_byte_limit))
+					memcpy(sa_set_lifetime_msg.hard_time.bytes, &x->lft.hard_byte_limit, sizeof(uint64_t));
+
+				/* soft time */
+				sa_set_lifetime_msg.soft_time.allocations =  _X2KEY(x->lft.soft_packet_limit);
+				if(_X2KEY(x->lft.soft_byte_limit))
+					memcpy(sa_set_lifetime_msg.soft_time.bytes, &x->lft.soft_byte_limit, sizeof(uint64_t));
+
+				/* current time */
+				sa_set_lifetime_msg.current_time.allocations = x->curlft.packets;
+				memcpy(sa_set_lifetime_msg.current_time.bytes, &x->curlft.bytes, sizeof(uint64_t));
+
+				memcpy(msg.payload, &sa_set_lifetime_msg, sizeof(struct nlkey_sa_set_lifetime));
+				msg.length = sizeof(struct nlkey_sa_set_lifetime);
+				*msg_id = NLKEY_SA_SET_STATE; /* next message */
+			} else {
+				*msg_id = NLKEY_SA_SET_STATE; /* next message */
+				goto exit;	
+			}
+			break;
+
+		case NLKEY_SA_SET_STATE:
+			//printk(KERN_INFO "ipsec_xfrm2nlkey: NLKEY_SET_STATE\n");
+			if(state) {
+				memset(&sa_set_state_msg, 0, sizeof(struct nlkey_sa_set_state));
+				memset(&sa_id_msg, 0, sizeof(struct nlkey_sa_id));
+
+				/* SA global handler */
+				sa_set_state_msg.sagd = x->handle; 
+				/* State */
+				sa_set_state_msg.state = x->km.state;
+				// TODO: set the offloaded state once ack received !
+				x->offloaded = 1;
+				atomic_inc(&net->xfrm.flow_cache_genid);
+
+				memcpy(msg.payload, &sa_set_state_msg, sizeof(struct nlkey_sa_set_state));
+				msg.length = sizeof(struct nlkey_sa_set_state);
+				*msg_id = NLKEY_NULL_MSG; /* next message */
+			} else {
+				*msg_id = NLKEY_NULL_MSG; /* next message */
+				goto exit;
+			}
+			break;
+		
+		case NLKEY_SA_DELETE:
+			//printk(KERN_INFO "ipsec_xfrm2nlkey: NLKEY_SA_DELETE\n");
+			memset(&sa_delete_msg, 0, sizeof(struct nlkey_sa_delete));
+			
+			/* SA global handler */
+			sa_delete_msg.sagd = x->handle;
+			memcpy(msg.payload, &sa_delete_msg, sizeof(struct nlkey_sa_delete));
+			msg.length = sizeof(struct nlkey_sa_delete);
+			atomic_inc(&net->xfrm.flow_cache_genid);
+
+
+			*msg_id = NLKEY_NULL_MSG; /* next message */
+			break;
+
+		case NLKEY_SA_FLUSH:
+			//printk(KERN_INFO "ipsec_xfrm2nlkey: NLKEY_SA_FLUSH\n");
+			/* No data required for flush SA command */
+			atomic_inc(&net->xfrm.flow_cache_genid);
+
+			*msg_id = NLKEY_NULL_MSG; /* next message */
+			break;
+
+		default:
+			printk(KERN_ERR "ipsec_xfrm2nlkey: event 0x%x not supported\n", c->event);
+			*msg_id = NLKEY_NULL_MSG; /* next message */
+			break;
+	}
+
+	/* prepare netlink message for kernel to user space direction */
+	if(msg.length > NLKEY_MSG_LEN)
+	{
+		printk(KERN_ERR "ipsec_xfrm2nlkey: maximum message size reached (%d bytes)\n", msg.length);
+		goto exit;
+	}
+
+	skb = alloc_skb(NLMSG_SPACE(NLKEY_MSG_LEN + NLKEY_HDR_LEN), allocation);
+	if (skb == NULL)
+		goto exit;
+		
+	nlh = (struct nlmsghdr *)skb_put(skb, NLMSG_SPACE(NLKEY_HDR_LEN + msg.length));
+	memcpy(NLMSG_DATA(nlh), (unsigned char *)&msg, (NLKEY_HDR_LEN + msg.length));
+	
+	/* whole length of the message i.e. header + payload */
+	nlh->nlmsg_len = NLMSG_SPACE(NLKEY_HDR_LEN + msg.length);
+
+	/* from kernel */
+	nlh->nlmsg_pid = 0;
+	nlh->nlmsg_flags = 0;
+        nlh->nlmsg_type = 0;
+	NETLINK_CB(skb).portid = 0;
+	NETLINK_CB(skb).dst_group = 1;
+exit:
+	return skb;
+}
+
+static int ipsec_nlkey_send(struct net *net, struct xfrm_state *x, const struct km_event *c)
+{
+	struct sk_buff *skb;
+	unsigned short msg_type;
+	int rc = 0;
+
+	/* We may generate more than one message when adding new SA (sa_create + sa_set_state + sa_set_tunnel...) */
+	msg_type = ipsec_sacode_to_nlkeycode((unsigned short)c->event);
+
+	while(msg_type != NLKEY_NULL_MSG)
+	{
+		/* build nlkey message */
+		skb = ipsec_xfrm2nlkey(net, x, c, &msg_type);
+
+		if(skb != NULL)
+			if((rc = netlink_broadcast(nlkey_socket, skb, 0, 1, GFP_ATOMIC)) < 0)
+				return rc;
+	}
+
+	return rc;
+}
+
+
+int ipsec_nlkey_flow(u16 xfrm_nr, u16 *xfrm_handle, const struct flowi *fl, u16 family, u16 dir, u16 ignore_neigh)
+{
+	struct sk_buff *skb;
+	struct nlkey_msg msg;
+	struct nlmsghdr *nlh = NULL;
+	unsigned short *p;
+	gfp_t allocation = GFP_ATOMIC; //This may called from atomic context
+
+	//printk(KERN_INFO "ipsec_nlkey_flow \n");
+
+	/* next message to build */
+	memset(&msg, 0, sizeof(struct nlkey_msg));
+	msg.fcode = NLKEY_FLOW_ADD;
+
+	// Number of SA for this flow
+	p = msg.payload;
+	*p++ = xfrm_nr;
+	msg.length += sizeof(unsigned short);
+	// SA handles list
+	memcpy(p, xfrm_handle, xfrm_nr*sizeof(unsigned short));
+	msg.length += xfrm_nr*sizeof(unsigned short);
+	p+=xfrm_nr;
+	// flow family
+	*p++ = family;
+	msg.length += sizeof(unsigned short);
+	// flow family
+	*p++ = dir;
+	msg.length += sizeof(unsigned short);
+	// flow mode
+	*p++ = ignore_neigh;
+	msg.length += sizeof(unsigned short);
+	// flow descriptor
+	memcpy(p, fl, sizeof(struct flowi));
+	msg.length +=sizeof(struct flowi);
+	p+=sizeof(struct flowi) / sizeof(u16);
+
+	skb = alloc_skb(NLMSG_SPACE(NLKEY_MSG_LEN + NLKEY_HDR_LEN), allocation);
+	if (skb == NULL)
+		return -ENOMEM;
+
+	/* prepare netlink message for kernel to user space direction */
+	nlh = (struct nlmsghdr *)skb_put(skb, NLMSG_SPACE(NLKEY_HDR_LEN + msg.length));
+	memcpy(NLMSG_DATA(nlh), (unsigned char *)&msg, (NLKEY_HDR_LEN + msg.length));
+
+	/* whole length of the message i.e. header + payload */
+	nlh->nlmsg_len = NLMSG_SPACE(NLKEY_HDR_LEN + msg.length);
+
+	/* from kernel */
+	nlh->nlmsg_pid = 0; 
+	nlh->nlmsg_flags = 0;
+        nlh->nlmsg_type = 0;
+	NETLINK_CB(skb).portid = 0;
+	NETLINK_CB(skb).dst_group = 1;
+
+	return(netlink_broadcast(nlkey_socket, skb, 0, 1, allocation));
+}
+EXPORT_SYMBOL(ipsec_nlkey_flow);
+
+
+int ipsec_nlkey_flow_remove(struct flowi *fl, u16 family, u16 dir)
+{
+	struct sk_buff *skb;
+	struct nlkey_msg msg;
+	struct nlmsghdr *nlh = NULL;
+	unsigned short *p;
+	gfp_t allocation = GFP_ATOMIC; //This may called from atomic context
+
+	
+	//printk(KERN_INFO "ipsec_nlkey_flow_remove\n");
+
+	/* next message to build */
+	memset(&msg, 0, sizeof(struct nlkey_msg));
+	msg.fcode = NLKEY_FLOW_REMOVE;
+
+	p = msg.payload;
+	// flow family
+	*p++ = family;
+	msg.length += sizeof(unsigned short);
+	// flow family
+	*p++ = dir;
+	msg.length += sizeof(unsigned short);
+	// flow descriptor
+	memcpy(p, fl, sizeof(struct flowi));
+	msg.length +=sizeof(struct flowi);
+	p+=sizeof(struct flowi) / sizeof(u16);
+
+	skb = alloc_skb(NLMSG_SPACE(NLKEY_MSG_LEN + NLKEY_HDR_LEN), allocation);
+	if (skb == NULL)
+		return -ENOMEM;
+
+	/* prepare netlink message for kernel to user space direction */
+	nlh = (struct nlmsghdr *)skb_put(skb, NLMSG_SPACE(NLKEY_HDR_LEN + msg.length));
+	memcpy(NLMSG_DATA(nlh), (unsigned char *)&msg, (NLKEY_HDR_LEN + msg.length));
+	
+	/* whole length of the message i.e. header + payload */
+	nlh->nlmsg_len = NLMSG_SPACE(NLKEY_HDR_LEN + msg.length);
+
+	/* from kernel */
+	nlh->nlmsg_pid = 0; 
+	nlh->nlmsg_flags = 0;
+        nlh->nlmsg_type = 0;
+	NETLINK_CB(skb).portid = 0;
+	NETLINK_CB(skb).dst_group = 1;	
+
+		
+        return(netlink_broadcast(nlkey_socket, skb, 0, 1, allocation));
+
+	
+}
+EXPORT_SYMBOL(ipsec_nlkey_flow_remove);
+
+
+
+static void ipsec_nlkey_init(void)
+{
+	struct netlink_kernel_cfg cfg = {
+		.groups	  = 1,
+		.input	  = ipsec_nlkey_rcv,
+	};
+	printk(KERN_INFO "Initializing NETLINK_KEY socket\n");
+	nlkey_socket = netlink_kernel_create(&init_net, NETLINK_KEY, &cfg);
+}
+#endif
+
+
 static int __net_init pfkey_net_init(struct net *net)
 {
 	struct netns_pfkey *net_pfkey = net_generic(net, pfkey_net_id);
@@ -3869,6 +4677,11 @@ static void __exit ipsec_pfkey_exit(void)
 	sock_unregister(PF_KEY);
 	unregister_pernet_subsys(&pfkey_net_ops);
 	proto_unregister(&key_proto);
+
+#ifdef NLKEY_SUPPORT
+	/* release NETLINK_KEY socket */
+	sock_release(nlkey_socket->sk_socket);
+#endif
 }
 
 static int __init ipsec_pfkey_init(void)
@@ -3887,6 +4700,12 @@ static int __init ipsec_pfkey_init(void)
 	err = xfrm_register_km(&pfkeyv2_mgr);
 	if (err != 0)
 		goto out_sock_unregister;
+
+#ifdef NLKEY_SUPPORT
+	/* create NETLINK_KEY socket for IPSec offload on Comcerto */
+	ipsec_nlkey_init();
+#endif
+
 out:
 	return err;
 
diff --git a/net/netfilter/Makefile b/net/netfilter/Makefile
index f78ed2470831..10268fe0f047 100644
--- a/net/netfilter/Makefile
+++ b/net/netfilter/Makefile
@@ -10,6 +10,7 @@ nf_conntrack-$(CONFIG_NF_CT_PROTO_DCCP) += nf_conntrack_proto_dccp.o
 nf_conntrack-$(CONFIG_NF_CT_PROTO_SCTP) += nf_conntrack_proto_sctp.o
 
 obj-$(CONFIG_NETFILTER) = netfilter.o
+obj-$(CONFIG_CPE_FAST_PATH) += comcerto_fp_netfilter.o
 
 obj-$(CONFIG_NETFILTER_NETLINK) += nfnetlink.o
 obj-$(CONFIG_NETFILTER_NETLINK_ACCT) += nfnetlink_acct.o
diff --git a/net/netfilter/comcerto_fp_netfilter.c b/net/netfilter/comcerto_fp_netfilter.c
new file mode 100644
index 000000000000..ecac6b91fc35
--- /dev/null
+++ b/net/netfilter/comcerto_fp_netfilter.c
@@ -0,0 +1,332 @@
+/* Copyright (C) 2015 Freescale Semiconductor, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include <linux/module.h>
+#include <linux/version.h>
+#include <linux/kernel.h>
+#include <linux/skbuff.h>
+#include <linux/netfilter.h>
+#include <net/netfilter/nf_conntrack.h>
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,4,0)
+static unsigned int fp_netfilter_pre_routing(int family, const struct nf_hook_state *state, struct sk_buff *skb)
+#else
+static unsigned int fp_netfilter_pre_routing(int family, const struct nf_hook_ops *ops, struct sk_buff *skb)
+#endif
+{
+	struct nf_conn *ct;
+	u_int8_t protonum;
+	enum ip_conntrack_info ctinfo;
+	struct comcerto_fp_info *fp_info;
+	int dir;
+
+	ct = nf_ct_get(skb, &ctinfo);
+	if (!ct)
+		goto done;
+
+	protonum = nf_ct_protonum(ct);
+	if ((protonum != IPPROTO_TCP) && (protonum != IPPROTO_UDP) && (protonum != IPPROTO_IPIP) && (protonum != IPPROTO_IPV6) && 
+#ifdef CONFIG_CPE_ETHERIP
+	(protonum != IPPROTO_ETHERIP) && 
+#endif
+	(protonum != IPPROTO_GRE) && (protonum != IPPROTO_ESP) && (protonum != IPPROTO_AH))
+		goto done;
+
+	dir = CTINFO2DIR(ctinfo);
+
+	//	if (printk_ratelimit())
+	//		printk(KERN_INFO "ct: %lx, dir: %x, mark: %x, ifindex: %d iif: %d iif_index:%d\n", (unsigned long)ct, dir, skb->mark, skb->dev->ifindex, skb->skb_iif,skb->iif_index);
+
+	/* We could also check for changes and notify userspace (or print message) */
+	if (dir == IP_CT_DIR_ORIGINAL) {
+		fp_info = &ct->fp_info[IP_CT_DIR_ORIGINAL];
+	} else {
+		fp_info = &ct->fp_info[IP_CT_DIR_REPLY];
+	}
+
+	if (fp_info->mark && (fp_info->mark != skb->mark))
+		if (printk_ratelimit())
+			printk(KERN_INFO "ct: mark changed %x, %x\n", fp_info->mark, skb->mark);
+
+	if (fp_info->ifindex && (fp_info->ifindex != skb->dev->ifindex))
+		if (printk_ratelimit())
+			printk(KERN_INFO "ct: ifindex changed %d, %d\n", fp_info->ifindex, skb->dev->ifindex);
+
+	if (fp_info->iif && (fp_info->iif != skb->iif_index))
+		if (printk_ratelimit())
+			printk(KERN_INFO "ct: iif changed %d, %d\n", fp_info->iif, skb->iif_index);
+/*      // commenting it out as a duplicate print. In most cases iif and underlying iif are the same.
+	if (fp_info->underlying_iif && (fp_info->underlying_iif != skb->underlying_iif))
+		if (printk_ratelimit())
+			printk(KERN_INFO "ct: underlying_iif changed %d, %d\n", fp_info->underlying_iif, skb->underlying_iif);
+*/
+
+	fp_info->mark = skb->mark;
+	fp_info->ifindex = skb->dev->ifindex;
+	/* now skb_iif always tracks dev,so iif_index stores incoming interface */
+	fp_info->iif = skb->iif_index;
+	fp_info->underlying_iif = skb->underlying_iif;
+
+done:
+	return NF_ACCEPT;
+}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,4,0)
+static unsigned int fp_netfilter_local_out(int family, const struct nf_hook_state *state, struct sk_buff *skb)
+#else
+static unsigned int fp_netfilter_local_out(int family, const struct nf_hook_ops *ops, struct sk_buff *skb)
+#endif
+{
+	struct nf_conn *ct;
+	u_int8_t protonum;
+	enum ip_conntrack_info ctinfo;
+	struct comcerto_fp_info *fp_info;
+	int dir;
+
+	ct = nf_ct_get(skb, &ctinfo);
+	if (!ct)
+		goto done;
+
+	protonum = nf_ct_protonum(ct);
+#ifdef CONFIG_CPE_ETHERIP
+	if ((protonum != IPPROTO_ETHERIP) && (protonum != IPPROTO_IPIP) && (protonum != IPPROTO_IPV6) && (protonum != IPPROTO_GRE))
+#else
+	if ((protonum != IPPROTO_IPIP) && (protonum != IPPROTO_IPV6) && (protonum != IPPROTO_GRE))
+		goto done;
+#endif
+
+	dir = CTINFO2DIR(ctinfo);
+
+	/* We could also check for changes and notify userspace (or print message) */
+	if (dir == IP_CT_DIR_ORIGINAL) {
+		fp_info = &ct->fp_info[IP_CT_DIR_ORIGINAL];
+	} else {
+		fp_info = &ct->fp_info[IP_CT_DIR_REPLY];
+	}
+
+	if (fp_info->mark && (fp_info->mark != skb->mark))
+		if (printk_ratelimit())
+			printk(KERN_INFO "ct: mark changed %x, %x\n", fp_info->mark, skb->mark);
+
+	if ((fp_info->ifindex) && (skb->dev) &&(fp_info->ifindex != skb->dev->ifindex))
+		if (printk_ratelimit())
+			printk(KERN_INFO "ct: ifindex changed %d, %d\n", fp_info->ifindex, skb->dev->ifindex);
+
+#if 0
+	if (fp_info->iif && (fp_info->iif != skb->skb_iif))
+		if (printk_ratelimit())
+			printk(KERN_INFO "ct: iif changed %d, %d\n", fp_info->iif, skb->skb_iif);
+#endif
+
+	fp_info->mark = skb->mark;
+	if (skb->dev)
+		fp_info->ifindex = skb->dev->ifindex;
+
+	//printk(KERN_INFO "%s:(DIR-%d, CT-%x):%x:%s:%x\n",__func__,dir, (unsigned int)ct, fp_info->mark,  skb->dev->name, skb->skb_iif);
+	fp_info->iif = 0; /* To identify the connection as local connection */
+
+
+done:
+	return NF_ACCEPT;
+}
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,4,0)
+static unsigned int fp_ipv4_netfilter_pre_routing(void *priv,
+						struct sk_buff *skb,
+						const struct nf_hook_state *state)
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(4,0,0)
+static unsigned int fp_ipv4_netfilter_pre_routing(const struct nf_hook_ops *ops,
+						struct sk_buff *skb,
+						const struct nf_hook_state *state)
+#else
+static unsigned int fp_ipv4_netfilter_pre_routing(const struct nf_hook_ops *ops,
+		struct sk_buff *skb,
+		const struct net_device *in,
+		const struct net_device *out,
+		int (*okfn)(struct sk_buff *))
+#endif
+
+{
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,4,0)
+	return fp_netfilter_pre_routing(PF_INET, state, skb);
+#else
+	return fp_netfilter_pre_routing(PF_INET, ops, skb);
+#endif
+}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,4,0)
+static unsigned int fp_ipv6_netfilter_pre_routing(void *priv,
+						struct sk_buff *skb,
+						const struct nf_hook_state *state)
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(4,0,0)
+static unsigned int fp_ipv6_netfilter_pre_routing(const struct nf_hook_ops *ops,
+						struct sk_buff *skb,
+						const struct nf_hook_state *state)
+#else
+static unsigned int fp_ipv6_netfilter_pre_routing(const struct nf_hook_ops *ops,
+		struct sk_buff *skb,
+		const struct net_device *in,
+		const struct net_device *out,
+		int (*okfn)(struct sk_buff *))
+#endif
+{
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,4,0)
+	return fp_netfilter_pre_routing(PF_INET6, state, skb);
+#else
+	return fp_netfilter_pre_routing(PF_INET6, ops, skb);
+#endif
+}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,4,0)
+static unsigned int fp_ipv4_netfilter_local_out(void *priv,
+						struct sk_buff *skb,
+						const struct nf_hook_state *state)
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(4,0,0)
+static unsigned int fp_ipv4_netfilter_local_out(const struct nf_hook_ops *ops,
+						struct sk_buff *skb,
+						const struct nf_hook_state *state)
+#else
+static unsigned int fp_ipv4_netfilter_local_out(const struct nf_hook_ops *ops,
+		struct sk_buff *skb,
+		const struct net_device *in,
+		const struct net_device *out,
+		int (*okfn)(struct sk_buff *))
+#endif
+{
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,4,0)
+	return fp_netfilter_local_out(PF_INET, state, skb);
+#else
+	return fp_netfilter_local_out(PF_INET, ops, skb);
+#endif
+}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,4,0)
+static unsigned int fp_ipv6_netfilter_local_out(void *priv,
+						struct sk_buff *skb,
+						const struct nf_hook_state *state)
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(4,0,0)
+static unsigned int fp_ipv6_netfilter_local_out(const struct nf_hook_ops *ops,
+						struct sk_buff *skb,
+						const struct nf_hook_state *state)
+#else
+static unsigned int fp_ipv6_netfilter_local_out(const struct nf_hook_ops *ops,
+		struct sk_buff *skb,
+		const struct net_device *in,
+		const struct net_device *out,
+		int (*okfn)(struct sk_buff *))
+#endif
+{
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,4,0)
+	return fp_netfilter_local_out(PF_INET6, state, skb);
+#else
+	return fp_netfilter_local_out(PF_INET6, ops, skb);
+#endif
+}
+
+
+static struct nf_hook_ops fp_netfilter_ops[] __read_mostly = {
+	{
+		.hook		= fp_ipv4_netfilter_pre_routing,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4,4,0)
+		.owner		= THIS_MODULE,
+#endif
+		.pf		= NFPROTO_IPV4,
+		.hooknum	= NF_INET_PRE_ROUTING,
+		.priority	= NF_IP_PRI_LAST,
+	},
+	{
+		.hook		= fp_ipv6_netfilter_pre_routing,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4,4,0)
+		.owner		= THIS_MODULE,
+#endif
+		.pf		= NFPROTO_IPV6,
+		.hooknum	= NF_INET_PRE_ROUTING,
+		.priority	= NF_IP_PRI_LAST,
+	},
+		/* For local_out packets, routing will be done
+			1. before entering the LOCAL_OUT hook
+			2. and at the completion of all mangle rules,
+			if there are changes to the packet like mark etc
+
+			So NF_IP_PRI_LAST priority is used here to receive
+			the mark value of the packet, at the end of all changes.
+		*/
+	{
+		.hook           = fp_ipv4_netfilter_local_out,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4,4,0)
+		.owner          = THIS_MODULE,
+#endif
+		.pf             = NFPROTO_IPV4,
+		.hooknum        = NF_INET_LOCAL_OUT,
+		.priority       = NF_IP_PRI_LAST,
+	},
+	{
+		.hook           = fp_ipv6_netfilter_local_out,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4,4,0)
+		.owner          = THIS_MODULE,
+#endif
+		.pf             = NFPROTO_IPV6,
+		.hooknum        = NF_INET_LOCAL_OUT,
+		.priority       = NF_IP_PRI_LAST,
+	},
+
+};
+
+static int __init fp_netfilter_init(void)
+{
+	int rc;
+
+	printk(KERN_INFO "fp_netfilter_init  **[%s:%d]  \n",__func__,__LINE__);	
+	rc = nf_register_net_hooks(&init_net,fp_netfilter_ops, ARRAY_SIZE(fp_netfilter_ops));
+	if (rc < 0) {
+		printk(KERN_ERR "fp_netfilter_ops: can't register hooks.\n");
+		goto err0;
+	}
+
+	return 0;
+
+err0:
+	return rc;
+}
+
+
+static void __exit fp_netfilter_exit(void)
+{
+	nf_unregister_net_hooks(&init_net,fp_netfilter_ops, ARRAY_SIZE(fp_netfilter_ops));
+}
+
+module_init(fp_netfilter_init);
+module_exit(fp_netfilter_exit);
diff --git a/net/netfilter/nf_conntrack_core.c b/net/netfilter/nf_conntrack_core.c
index 01130392b7c0..c45d6b90d2c9 100644
--- a/net/netfilter/nf_conntrack_core.c
+++ b/net/netfilter/nf_conntrack_core.c
@@ -14,6 +14,7 @@
 
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
 
+#include <linux/version.h>
 #include <linux/types.h>
 #include <linux/netfilter.h>
 #include <linux/module.h>
@@ -466,7 +467,6 @@ static void nf_ct_delete_from_lists(struct nf_conn *ct)
 bool nf_ct_delete(struct nf_conn *ct, u32 portid, int report)
 {
 	struct nf_conn_tstamp *tstamp;
-
 	if (test_and_set_bit(IPS_DYING_BIT, &ct->status))
 		return false;
 
@@ -862,7 +862,6 @@ nf_conntrack_tuple_taken(const struct nf_conntrack_tuple *tuple,
 
 		if (ct == ignored_conntrack)
 			continue;
-
 		if (nf_ct_is_expired(ct)) {
 			nf_ct_gc_expired(ct);
 			continue;
@@ -1883,6 +1882,46 @@ void *nf_ct_alloc_hashtable(unsigned int *sizep, int nulls)
 }
 EXPORT_SYMBOL_GPL(nf_ct_alloc_hashtable);
 
+#ifdef CONFIG_CPE_FAST_PATH
+int nf_conntrack_set_dpi_allow_report(struct sk_buff *skb)
+{
+	int err = 0;
+	struct nf_conn *ct = (struct nf_conn *)skb->_nfct;
+
+	nf_conntrack_get(skb->_nfct);
+
+	set_bit(IPS_DPI_ALLOWED_BIT, &ct->status);
+
+	nf_conntrack_event_cache(IPCT_PROTOINFO, ct);
+
+	nf_conntrack_put(skb->_nfct);
+
+	return err;
+}
+EXPORT_SYMBOL(nf_conntrack_set_dpi_allow_report);
+
+int nf_conntrack_set_dpi_allow_and_mark(struct sk_buff *skb, int mark)
+{
+	int err = 0;
+	struct nf_conn *ct = (struct nf_conn *)skb->_nfct;
+
+	nf_conntrack_get(skb->_nfct);
+
+	set_bit(IPS_DPI_ALLOWED_BIT, &ct->status);
+
+#ifdef CONFIG_NF_CONNTRACK_MARK
+	ct->mark = mark;
+#endif
+
+	nf_conntrack_event_cache(IPCT_PROTOINFO, ct);
+
+	nf_conntrack_put(skb->_nfct);
+
+	return err;
+}
+EXPORT_SYMBOL(nf_conntrack_set_dpi_allow_and_mark);
+#endif
+
 int nf_conntrack_hash_resize(unsigned int hashsize)
 {
 	int i, bucket;
@@ -2186,3 +2225,18 @@ int nf_conntrack_init_net(struct net *net)
 err_stat:
 	return ret;
 }
+
+#ifdef CONFIG_CPE_FAST_PATH
+bool nf_ct_is_expired(const struct nf_conn *ct)
+{
+	struct nf_conntrack_l4proto *l4proto;
+
+        l4proto = __nf_ct_l4proto_find(nf_ct_l3num(ct), nf_ct_protonum(ct));
+        if((!nf_ct_is_permanent(ct)) || ((l4proto->l4proto == IPPROTO_TCP) && (ct->proto.tcp.state != TCP_CONNTRACK_ESTABLISHED))) 
+		return (__nf_ct_is_expired(ct));
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(nf_ct_is_expired);
+#endif
+
diff --git a/net/netfilter/nf_conntrack_netlink.c b/net/netfilter/nf_conntrack_netlink.c
index de4053d84364..5b900cf1e765 100644
--- a/net/netfilter/nf_conntrack_netlink.c
+++ b/net/netfilter/nf_conntrack_netlink.c
@@ -167,9 +167,16 @@ static int ctnetlink_dump_protoinfo(struct sk_buff *skb, struct nf_conn *ct)
 	struct nlattr *nest_proto;
 	int ret;
 
+#ifdef CONFIG_CPE_FAST_PATH
+	rcu_read_lock();
+#endif
 	l4proto = __nf_ct_l4proto_find(nf_ct_l3num(ct), nf_ct_protonum(ct));
-	if (!l4proto->to_nlattr)
+	if (!l4proto->to_nlattr) {
+#ifdef CONFIG_CPE_FAST_PATH
+		rcu_read_unlock();
+#endif
 		return 0;
+	}
 
 	nest_proto = nla_nest_start(skb, CTA_PROTOINFO | NLA_F_NESTED);
 	if (!nest_proto)
@@ -179,9 +186,15 @@ static int ctnetlink_dump_protoinfo(struct sk_buff *skb, struct nf_conn *ct)
 
 	nla_nest_end(skb, nest_proto);
 
+#ifdef CONFIG_CPE_FAST_PATH
+	rcu_read_unlock();
+#endif
 	return ret;
 
 nla_put_failure:
+#ifdef CONFIG_CPE_FAST_PATH
+	rcu_read_unlock();
+#endif
 	return -1;
 }
 
@@ -372,6 +385,43 @@ ctnetlink_dump_labels(struct sk_buff *skb, const struct nf_conn *ct)
 #define ctnetlink_label_size(a)	(0)
 #endif
 
+#if defined(CONFIG_CPE_FAST_PATH)
+static int
+ctnetlink_dump_comcerto_fp(struct sk_buff *skb, const struct nf_conn *ct)
+{
+	struct nlattr *nest_count;
+
+	nest_count = nla_nest_start(skb, CTA_COMCERTO_FP_ORIG | NLA_F_NESTED);
+	if (!nest_count)
+		goto nla_put_failure;
+
+	nla_put_u32(skb, CTA_COMCERTO_FP_MARK, ct->fp_info[IP_CT_DIR_ORIGINAL].mark);
+	nla_put_u32(skb, CTA_COMCERTO_FP_IFINDEX, ct->fp_info[IP_CT_DIR_ORIGINAL].ifindex);
+	nla_put_u32(skb, CTA_COMCERTO_FP_IIF, ct->fp_info[IP_CT_DIR_ORIGINAL].iif);
+	nla_put_u32(skb, CTA_COMCERTO_FP_UNDERLYING_IIF, ct->fp_info[IP_CT_DIR_ORIGINAL].underlying_iif);
+
+	nla_nest_end(skb, nest_count);
+
+	nest_count = nla_nest_start(skb, CTA_COMCERTO_FP_REPLY | NLA_F_NESTED);
+	if (!nest_count)
+		goto nla_put_failure;
+
+	nla_put_u32(skb, CTA_COMCERTO_FP_MARK, ct->fp_info[IP_CT_DIR_REPLY].mark);
+	nla_put_u32(skb, CTA_COMCERTO_FP_IFINDEX, ct->fp_info[IP_CT_DIR_REPLY].ifindex);
+	nla_put_u32(skb, CTA_COMCERTO_FP_IIF, ct->fp_info[IP_CT_DIR_REPLY].iif);
+	nla_put_u32(skb, CTA_COMCERTO_FP_UNDERLYING_IIF, ct->fp_info[IP_CT_DIR_REPLY].underlying_iif);
+
+	nla_nest_end(skb, nest_count);
+
+	return 0;
+
+nla_put_failure:
+	return -1;
+}
+#else
+#define ctnetlink_dump_comcerto_fp(a, b) (0)
+#endif
+
 #define master_tuple(ct) &(ct->master->tuplehash[IP_CT_DIR_ORIGINAL].tuple)
 
 static int ctnetlink_dump_master(struct sk_buff *skb, const struct nf_conn *ct)
@@ -517,6 +567,9 @@ ctnetlink_fill_info(struct sk_buff *skb, u32 portid, u32 seq, u32 type,
 	    ctnetlink_dump_helpinfo(skb, ct) < 0 ||
 	    ctnetlink_dump_mark(skb, ct) < 0 ||
 	    ctnetlink_dump_secctx(skb, ct) < 0 ||
+#ifdef CONFIG_CPE_FAST_PATH
+	    ctnetlink_dump_comcerto_fp(skb, ct) < 0 ||
+#endif
 	    ctnetlink_dump_labels(skb, ct) < 0 ||
 	    ctnetlink_dump_id(skb, ct) < 0 ||
 	    ctnetlink_dump_use(skb, ct) < 0 ||
@@ -603,6 +656,13 @@ static size_t ctnetlink_nlmsg_size(const struct nf_conn *ct)
 	       + nla_total_size(0) /* CTA_HELP */
 	       + nla_total_size(NF_CT_HELPER_NAME_LEN) /* CTA_HELP_NAME */
 	       + ctnetlink_secctx_size(ct)
+#ifdef CONFIG_CPE_FAST_PATH
+	       + 2 * nla_total_size(0) /* CTA_COMCERTO_FP_ORIG|REPL */
+	       + 2 * nla_total_size(sizeof(uint32_t)) /* CTA_COMCERTO_FP_MARK */
+	       + 2 * nla_total_size(sizeof(uint32_t)) /* CTA_COMCERTO_FP_IFINDEX */
+	       + 2 * nla_total_size(sizeof(uint32_t)) /* CTA_COMCERTO_FP_IIF */
+	       + 2 * nla_total_size(sizeof(uint32_t)) /* CTA_COMCERTO_FP_UNDERLYING_IIF */
+#endif
 #ifdef CONFIG_NF_NAT_NEEDED
 	       + 2 * nla_total_size(0) /* CTA_NAT_SEQ_ADJ_ORIG|REPL */
 	       + 6 * nla_total_size(sizeof(u_int32_t)) /* CTA_NAT_SEQ_OFFSET */
@@ -689,6 +749,14 @@ ctnetlink_conntrack_event(unsigned int events, struct nf_ct_event *item)
 				   NF_CT_DEFAULT_ZONE_DIR) < 0)
 		goto nla_put_failure;
 
+#if defined(CONFIG_CPE_FAST_PATH)
+	if (ctnetlink_dump_comcerto_fp(skb, ct) < 0)
+	{	
+		goto nla_put_failure;
+	}
+
+#endif
+
 	if (ctnetlink_dump_id(skb, ct) < 0)
 		goto nla_put_failure;
 
@@ -1466,7 +1534,47 @@ ctnetlink_change_status(struct nf_conn *ct, const struct nlattr * const cda[])
 	__ctnetlink_change_status(ct, status, 0);
 	return 0;
 }
+#if defined(CONFIG_CPE_FAST_PATH)
+/*
+ * This function detects ctnetlink messages that require
+ * to set the conntrack status to IPS_PERMANENT.
+ * It updates only this bit regardless of other possible
+ * changes.
+ * Return 0 if succesfull
+ */
+static int
+ctnetlink_change_permanent(struct nf_conn *ct, const struct nlattr * const cda[])
+{
+	unsigned int status;
+	u_int32_t id;
 
+	if (cda[CTA_STATUS] && cda[CTA_ID]) {
+		status = ntohl(nla_get_be32(cda[CTA_STATUS]));
+		id = ntohl(nla_get_be32(cda[CTA_ID]));
+
+
+		if (status & IPS_PERMANENT) {
+			if ((u32)(unsigned long)ct == id) {
+				ct->status |= IPS_PERMANENT;
+				return 0;
+			}
+			else
+				return -ENOENT;
+		}
+		else if(nf_ct_is_permanent(ct))
+		{
+// Clear the PERMANENT bit.
+			if ((u32)(unsigned long)ct == id) {
+				clear_bit(IPS_PERMANENT_BIT, &ct->status);
+				return 0;
+			}
+			else
+				return -ENOENT;
+		}
+	}
+	return -1;
+}
+#endif
 static int
 ctnetlink_setup_nat(struct nf_conn *ct, const struct nlattr * const cda[])
 {
@@ -1982,6 +2090,15 @@ static int ctnetlink_new_conntrack(struct net *net, struct sock *ctnl,
 	err = -EEXIST;
 	ct = nf_ct_tuplehash_to_ctrack(h);
 	if (!(nlh->nlmsg_flags & NLM_F_EXCL)) {
+#if defined(CONFIG_CPE_FAST_PATH)
+		/* If the permanent status has been set, this is a specific
+		 * message. Don't broadcast the event and don't update the ct */
+		err = ctnetlink_change_permanent(ct, cda);
+		if ((err == 0) || (err == -ENOENT)) {
+			nf_ct_put(ct);
+			return err;
+		}
+#endif
 		err = ctnetlink_change_conntrack(ct, cda);
 		if (err == 0) {
 			nf_conntrack_eventmask_report((1 << IPCT_REPLY) |
diff --git a/net/netfilter/nf_conntrack_proto_tcp.c b/net/netfilter/nf_conntrack_proto_tcp.c
index cba1c6ffe51a..d84ed8a19062 100644
--- a/net/netfilter/nf_conntrack_proto_tcp.c
+++ b/net/netfilter/nf_conntrack_proto_tcp.c
@@ -1081,6 +1081,10 @@ static int tcp_packet(struct nf_conn *ct,
 		   connection. */
 		set_bit(IPS_ASSURED_BIT, &ct->status);
 		nf_conntrack_event_cache(IPCT_ASSURED, ct);
+#ifdef CONFIG_CPE_FAST_PATH
+		if (old_state == TCP_CONNTRACK_ESTABLISHED && new_state == TCP_CONNTRACK_ESTABLISHED)
+			nf_conntrack_event_cache(IPCT_PROTOINFO, ct);
+#endif
 	}
 	nf_ct_refresh_acct(ct, ctinfo, skb, timeout);
 
diff --git a/net/netfilter/nf_conntrack_standalone.c b/net/netfilter/nf_conntrack_standalone.c
index 5a101caa3e12..b3f117033dd9 100644
--- a/net/netfilter/nf_conntrack_standalone.c
+++ b/net/netfilter/nf_conntrack_standalone.c
@@ -344,6 +344,13 @@ static int ct_seq_show(struct seq_file *s, void *v)
 
 	if (seq_has_overflowed(s))
 		goto release;
+#ifdef CONFIG_CPE_FAST_PATH
+	if (test_bit(IPS_PERMANENT_BIT, &ct->status))
+		seq_printf(s, "[PERMANENT] ");
+
+	if(seq_has_overflowed(s))
+		goto release;
+#endif
 
 #if defined(CONFIG_NF_CONNTRACK_MARK)
 	seq_printf(s, "mark=%u ", ct->mark);
diff --git a/net/wireless/db.txt b/net/wireless/db.txt
index a2fc3a09ccdc..df7f7b1df4ce 100644
--- a/net/wireless/db.txt
+++ b/net/wireless/db.txt
@@ -1,17 +1,1215 @@
+# This is the world regulatory domain
+country 00:
+	(2402 - 2472 @ 40), (20)
+	# Channel 12 - 13.
+	(2457 - 2482 @ 40), (20), NO-IR
+	# Channel 14. Only JP enables this and for 802.11b only
+	(2474 - 2494 @ 20), (20), NO-IR, NO-OFDM
+	# Channel 36 - 48
+	(5170 - 5250 @ 80), (20), NO-IR, AUTO-BW
+	# Channel 52 - 64
+	(5250 - 5330 @ 80), (20), NO-IR, DFS, AUTO-BW
+	# Channel 100 - 144
+	(5490 - 5730 @ 160), (20), NO-IR, DFS
+	# Channel 149 - 165
+	(5735 - 5835 @ 80), (20), NO-IR
+	# IEEE 802.11ad (60GHz), channels 1..3
+	(57240 - 63720 @ 2160), (0)
+
+
+country AD:
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20)
+	(5250 - 5330 @ 80), (20), DFS
+	(5490 - 5710 @ 80), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country AE: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country AF: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+# Source:
+# http://pucanguilla.org/Downloads/January2005-Anguilla%20Table%20of%20Allocations.pdf
+country AI: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+country AL: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20.00), AUTO-BW
+	(5250 - 5330 @ 80), (20.00), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27.00), DFS
+
+country AM: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (18)
+	(5250 - 5330 @ 80), (18), DFS
+
+country AN: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+country AR: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country AS: DFS-FCC
+	(2402 - 2472 @ 40), (30)
+	(5170 - 5250 @ 80), (24), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country AT: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country AU:
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country AW: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+country AZ: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (18), AUTO-BW
+	(5250 - 5330 @ 80), (18), DFS, AUTO-BW
+
+country BA: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country BB: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (23), AUTO-BW
+	(5250 - 5330 @ 80), (23), DFS, AUTO-BW
+	(5735 - 5835 @ 80), (30)
+
+country BD: DFS-JP
+	(2402 - 2482 @ 40), (20)
+	(5735 - 5835 @ 80), (30)
+
+country BE: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country BF: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country BG: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country BH: DFS-JP
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20)
+	(5250 - 5330 @ 80), (20), DFS
+	(5735 - 5835 @ 80), (20)
+
+country BL: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+country BM: DFS-FCC
+	(2402 - 2472 @ 40), (30)
+	(5170 - 5250 @ 80), (24), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country BN: DFS-JP
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5735 - 5835 @ 80), (20)
+
+country BO: DFS-JP
+	(2402 - 2482 @ 40), (20)
+	(5250 - 5330 @ 80), (30), DFS
+	(5735 - 5835 @ 80), (30)
+
+country BR: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country BS: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (24), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+# Source:
+# http://www.bicma.gov.bt/paper/publication/nrrpart4.pdf
+country BT: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+country BY: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+country BZ: DFS-JP
+	(2402 - 2482 @ 40), (30)
+	(5735 - 5835 @ 80), (30)
+
+country CA: DFS-FCC
+	(2402 - 2472 @ 40), (30)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+# Source:
+# http://www.art-rca.org
+country CF: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 40), (17)
+	(5250 - 5330 @ 40), (24), DFS
+	(5490 - 5730 @ 40), (24), DFS
+	(5735 - 5835 @ 40), (30)
+
+country CH: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country CI: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country CL: DFS-JP
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5735 - 5835 @ 80), (20)
+
+country CN: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (23), AUTO-BW
+	(5250 - 5330 @ 80), (23), DFS, AUTO-BW
+	(5735 - 5835 @ 80), (30)
+	# 60 gHz band channels 1,4: 28dBm, channels 2,3: 44dBm
+	# ref: http://www.miit.gov.cn/n11293472/n11505629/n11506593/n11960250/n11960606/n11960700/n12330791.files/n12330790.pdf
+	(57240 - 59400 @ 2160), (28)
+	(59400 - 63720 @ 2160), (44)
+	(63720 - 65880 @ 2160), (28)
+
+country CO: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country CR: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17)
+	(5250 - 5330 @ 80), (24), DFS
+	(5490 - 5730 @ 80), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country CX: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (24), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country CY: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+# Data from http://www.ctu.eu/164/download/VOR/VOR-12-08-2005-34.pdf
+# and http://www.ctu.eu/164/download/VOR/VOR-12-05-2007-6-AN.pdf
+# Power at 5250 - 5350 MHz and 5470 - 5725 MHz can be doubled if TPC is
+# implemented.
+country CZ: DFS-ETSI
+	(2400 - 2483.5 @ 40), (100 mW)
+	(5150 - 5250 @ 80), (200 mW), NO-OUTDOOR, AUTO-BW
+	(5250 - 5350 @ 80), (100 mW), NO-OUTDOOR, DFS, AUTO-BW
+	(5470 - 5725 @ 160), (500 mW), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+# Data from "Frequenznutzungsplan" (as published in April 2008), downloaded from
+# http://www.bundesnetzagentur.de/cae/servlet/contentblob/38448/publicationFile/2659/Frequenznutzungsplan2008_Id17448pdf.pdf
+# For the 5GHz range also see
+# http://www.bundesnetzagentur.de/cae/servlet/contentblob/38216/publicationFile/6579/WLAN5GHzVfg7_2010_28042010pdf.pdf
+# The values have been reduced by a factor of 2 (3db) for non TPC devices
+# (in other words: devices with TPC can use twice the tx power of this table).
+# Note that the docs do not require TPC for 5150--5250; the reduction to
+# 100mW thus is not strictly required -- however the conservative 100mW
+# limit is used here as the non-interference with radar and satellite
+# apps relies on the attenuation by the building walls only in the
+# absence of DFS; the neighbour countries have 100mW limit here as well.
+
+country DE: DFS-ETSI
+	# entries 279004 and 280006
+	(2400 - 2483.5 @ 40), (100 mW)
+	# entry 303005
+	(5150 - 5250 @ 80), (100 mW), NO-OUTDOOR, AUTO-BW
+	# entries 304002 and 305002
+	(5250 - 5350 @ 80), (100 mW), NO-OUTDOOR, DFS, AUTO-BW
+	# entries 308002, 309001 and 310003
+	(5470 - 5725 @ 160), (500 mW), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country DK: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+# Source:
+# http://www.ntrcdom.org/index.php?option=com_content&view=category&layout=blog&id=10&Itemid=55
+country DM: DFS-FCC
+	(2402 - 2472 @ 40), (30)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (23), DFS, AUTO-BW
+	(5735 - 5835 @ 80), (30)
+
+country DO: DFS-FCC
+	(2402 - 2472 @ 40), (30)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (23), DFS, AUTO-BW
+	(5735 - 5835 @ 80), (30)
+
+country DZ: DFS-JP
+	(2402 - 2482 @ 40), (20)
+	(5170.000 - 5250.000 @ 80.000), (23.00), AUTO-BW
+	(5250.000 - 5330.000 @ 80.000), (23.00), DFS, AUTO-BW
+	(5490.000 - 5670.000 @ 160.000), (23.00), DFS
+
+country EC: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17)
+	(5250 - 5330 @ 80), (24), DFS
+	(5490 - 5730 @ 80), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country EE: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country EG: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20)
+	(5250 - 5330 @ 80), (20), DFS
+
+# Orden IET/787/2013, de 25 de abril, por la que se aprueba
+# el cuadro nacional de atribución de frecuencias.
+# http://www.boe.es/diario_boe/txt.php?id=BOE-A-2013-4845
 #
-# This file is a placeholder to prevent accidental build breakage if someone
-# enables CONFIG_CFG80211_INTERNAL_REGDB.  Almost no one actually needs to
-# enable that build option.
-#
-# You should be using CRDA instead.  It is even better if you use the CRDA
-# package provided by your distribution, since they will probably keep it
-# up-to-date on your behalf.
-#
-# If you _really_ intend to use CONFIG_CFG80211_INTERNAL_REGDB then you will
-# need to replace this file with one containing appropriately formatted
-# regulatory rules that cover the regulatory domains you will be using.  Your
-# best option is to extract the db.txt file from the wireless-regdb git
-# repository:
-#
-#   git://git.kernel.org/pub/scm/linux/kernel/git/linville/wireless-regdb.git
-#
+# more info at "Cuadro nacional de atribución de frecuencias (CNAF)":
+# http://www.minetur.gob.es/telecomunicaciones/espectro/paginas/cnaf.aspx
+
+country ES: DFS-ETSI
+	(2400 - 2483.5 @ 40), (100 mW)
+	(5150 - 5250 @ 80), (200 mW), NO-OUTDOOR, AUTO-BW
+	(5250 - 5350 @ 80), (100 mW), NO-OUTDOOR, DFS, AUTO-BW
+	(5470 - 5725 @ 160), (500 mW), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country ET: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+country FI: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country FM: DFS-FCC
+	(2402 - 2472 @ 40), (30)
+	(5170 - 5250 @ 80), (24), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country FR: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country GB: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country GD: DFS-FCC
+	(2402 - 2472 @ 40), (30)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country GE: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (18), AUTO-BW
+	(5250 - 5330 @ 80), (18), DFS, AUTO-BW
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country GF: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+country GH: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country GL: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20)
+	(5250 - 5330 @ 80), (20), DFS
+	(5490 - 5710 @ 80), (27), DFS
+
+country GP: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+country GR: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country GT: DFS-FCC
+	(2402 - 2472 @ 40), (30)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (23), DFS, AUTO-BW
+	(5735 - 5835 @ 80), (30)
+
+country GU: DFS-FCC
+	(2402 - 2472 @ 40), (30)
+	(5170 - 5250 @ 80), (17)
+	(5250 - 5330 @ 80), (24), DFS
+	(5490 - 5730 @ 80), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country GY:
+	(2402 - 2482 @ 40), (30)
+	(5735 - 5835 @ 80), (30)
+
+country HK:
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country HN: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country HR: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country HT: DFS-FCC
+	(2402 - 2472 @ 40), (30)
+	(5170 - 5250 @ 80), (24), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country HU: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country ID: DFS-JP
+	# ref: http://www.postel.go.id/content/ID/regulasi/standardisasi/kepdir/bwa%205,8%20ghz.pdf
+	(2402 - 2482 @ 40), (20)
+	(5735 - 5815 @ 80), (23)
+
+country IE: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country IL: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5150 - 5250 @ 80), (200 mW), NO-OUTDOOR, AUTO-BW
+	(5250 - 5350 @ 80), (200 mW), NO-OUTDOOR, DFS, AUTO-BW
+
+country IN: DFS-JP
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5735 - 5835 @ 80), (20)
+
+country IR: DFS-JP
+	(2402 - 2482 @ 40), (20)
+	(5735 - 5835 @ 80), (30)
+
+country IS: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country IT: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country JM: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country JO: DFS-JP
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (23)
+	(5735 - 5835 @ 80), (23)
+
+country JP: DFS-JP
+	(2402 - 2482 @ 40), (20)
+	(2474 - 2494 @ 20), (20), NO-OFDM
+	(4910 - 4990 @ 40), (23)
+	(5030 - 5090 @ 40), (23)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (23), DFS
+
+country KE: DFS-JP
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (23)
+	(5490 - 5570 @ 80), (30), DFS
+	(5735 - 5775 @ 40), (23)
+
+country KH: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+# Source
+# http://ntrc.kn/?page_id=7
+country KN: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (30), DFS
+	(5735 - 5815 @ 80), (30)
+
+country KP: DFS-JP
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5630 @ 80), (30), DFS
+	(5735 - 5815 @ 80), (30)
+
+country KR: DFS-JP
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (30), DFS
+	(5735 - 5835 @ 80), (30)
+
+country KW: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+
+country KY: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (24), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country KZ:
+	(2402 - 2482 @ 40), (20)
+
+country LB: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+# Source:
+# http://www.ntrc.org.lc/operational_structures.htm
+country LC: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (30), DFS
+	(5735 - 5815 @ 80), (30)
+
+country LI: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+country LK: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17)
+	(5250 - 5330 @ 80), (24), DFS
+	(5490 - 5730 @ 80), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+# Source:
+# http://lca.org.ls/images/documents/lesotho_national_frequency_allocation_plan.pdf
+country LS: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+country LT: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country LU: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country LV: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country MA: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+
+country MC: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+# Source:
+# http://www.cnfr.md/index.php?pag=sec&id=117&l=en
+country MD: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+# Source:
+# http://www.cept.org/files/1050/Tools%20and%20Services/EFIS%20-%20ECO%20Frequency%20Information%20System/National%20frequency%20tables/Montenegro%20NAFT%20-%202010.pdf
+country ME: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+country MF: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+country MH: DFS-FCC
+	(2402 - 2472 @ 40), (30)
+	(5170 - 5250 @ 80), (24), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country MK: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country MN: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (24), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country MO:
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 40), (23)
+	(5250 - 5330 @ 40), (23), DFS
+	(5735 - 5835 @ 40), (30)
+
+country MP: DFS-FCC
+	(2402 - 2472 @ 40), (30)
+	(5170 - 5250 @ 80), (24), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country MQ: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+# Source:
+# http://www.are.mr/pdfs/telec_freq_TNAbf_2010.pdf
+country MR: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+country MT: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country MU: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (24), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country MW: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+country MX: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country MY: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (23), DFS, AUTO-BW
+	(5735 - 5835 @ 80), (30)
+
+country NI: DFS-FCC
+	(2402 - 2472 @ 40), (30)
+	(5170 - 5250 @ 80), (24), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country NL: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), NO-OUTDOOR, AUTO-BW
+	(5250 - 5330 @ 80), (20), NO-OUTDOOR, DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+# Data from http://www.lovdata.no/dokument/SF/forskrift/2012-01-19-77
+# Power at 5250 - 5350 MHz, 5470 - 5725 MHz and 5815 – 5850 MHz can
+# be doubled if TPC is implemented.
+# Up to 2W (or 4W with TPC) is allowed in the 5725 – 5795 MHz band
+# which has been merged with 5470 - 5725 MHz to allow wide channels
+country NO: DFS-ETSI
+	(2400 - 2483.5 @ 40), (100 mW)
+	(5150 - 5250 @ 80), (200 mW), AUTO-BW
+	(5250 - 5350 @ 80), (100 mW), DFS, AUTO-BW
+	(5470 - 5795 @ 160), (500 mW), DFS
+	(5815 - 5850 @ 35), (2000 mW), DFS
+	(17100 - 17300 @ 200), (100 mW)
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country NP: DFS-JP
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5735 - 5835 @ 80), (20)
+
+country NZ: DFS-FCC
+	(2402 - 2482 @ 40), (30)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country OM: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+country PA: DFS-FCC
+	(2402 - 2472 @ 40), (30)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (23), DFS, AUTO-BW
+	(5735 - 5835 @ 80), (30)
+
+country PE: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country PF: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+country PG: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country PH: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country PK: DFS-JP
+	(2402 - 2482 @ 40), (20)
+	(5735 - 5835 @ 80), (30)
+
+country PL: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country PM: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+country PR: DFS-FCC
+	(2402 - 2472 @ 40), (30)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country PT: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country PW: DFS-FCC
+	(2402 - 2472 @ 40), (30)
+	(5170 - 5250 @ 80), (24), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country PY: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (24), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country QA: DFS-JP
+	(2402 - 2482 @ 40), (20)
+	(5735 - 5835 @ 80), (30)
+
+country RE: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+country RO: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+
+# Source:
+# http://www.ratel.rs/upload/documents/Plan_namene/Plan_namene-sl_glasnik.pdf
+country RS: DFS-ETSI
+	(2400 - 2483.5 @ 40), (100 mW)
+	(5150 - 5350 @ 40), (200 mW), NO-OUTDOOR
+	(5470 - 5725 @ 20), (1000 mW), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country RU: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20)
+	(5250 - 5330 @ 80), (20), DFS
+	(5650 - 5730 @ 80), (30), DFS
+	(5735 - 5835 @ 80), (30)
+
+country RW: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country SA: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+country SE: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country SG: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country SI: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country SK: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+# Source:
+# Regulation N° 2004-005 ART/DG/DRC/D.Rég
+country SN: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country SR: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+country SV: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17)
+	(5250 - 5330 @ 80), (23), DFS
+	(5735 - 5835 @ 80), (30)
+
+country SY:
+	(2402 - 2482 @ 40), (20)
+
+# Source:
+# http://www.telecommission.tc/Spectrum-plan20110324-101210.html
+country TC: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (24), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country TD: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+country TG: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 40), (20)
+	(5250 - 5330 @ 40), (20), DFS
+	(5490 - 5710 @ 40), (27), DFS
+
+country TH: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country TN: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+
+country TR: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country TT: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country TW: DFS-JP
+	(2402 - 2472 @ 40), (30)
+	(5270 - 5330 @ 40), (17), DFS
+	(5490 - 5590 @ 80), (30), DFS
+	(5650 - 5710 @ 40), (30), DFS
+	(5735 - 5835 @ 80), (30)
+ 
+# Source:
+# #914 / 06 Sep 2007: http://www.ucrf.gov.ua/uk/doc/nkrz/1196068874
+# #1174 / 23 Oct 2008: http://www.nkrz.gov.ua/uk/activities/ruling/1225269361
+# (appendix 8)
+# Listed 5GHz range is a lowest common denominator for all related
+# rules in the referenced laws. Such a range is used because of
+# disputable definitions there.
+country UA: DFS-ETSI
+	(2400 - 2483.5 @ 40), (20), NO-OUTDOOR
+	(5150 - 5350 @ 40), (20), NO-OUTDOOR
+	(5490 - 5670 @ 80), (20), DFS
+	(5735 - 5835 @ 80), (20)
+	# 60 gHz band channels 1-4, ref: Etsi En 302 567
+	(57000 - 66000 @ 2160), (40)
+
+country UG: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (24), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country US: DFS-FCC
+	(2402 - 2472 @ 40), (30)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (23), DFS, AUTO-BW
+	(5735 - 5835 @ 80), (30)
+	# 60g band
+	# reference: http://cfr.regstoday.com/47cfr15.aspx#47_CFR_15p255
+	# channels 1,2,3, EIRP=40dBm(43dBm peak)
+	(57240 - 63720 @ 2160), (40)
+
+country UY: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+# Source:
+# http://cemc.uz/article/1976/
+country UZ: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+
+# Source:
+# http://www.ntrc.vc/regulations/Jun_2006_Spectrum_Managment_Regulations.pdf
+country VC: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+# Source:
+# Official Gazette (Gaceta Oficial) concerning Unlicensed transmitter use
+# (10 June 2013)
+# http://www.conatel.gob.ve/
+country VE: DFS-FCC
+	(2402 - 2482 @ 40), (30)
+	(5170 - 5250 @ 80), (23), AUTO-BW
+	(5250 - 5330 @ 80), (23), DFS, AUTO-BW
+	(5735 - 5835 @ 80), (30)
+
+country VI: DFS-FCC
+	(2402 - 2472 @ 40), (30)
+	(5170 - 5250 @ 80), (24), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country VN: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17)
+	(5250 - 5330 @ 80), (24), DFS
+	(5490 - 5730 @ 80), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+# Source:
+# http://www.trr.vu/attachments/category/130/GURL_for_Short-range_Radiocommunication_Devices2.pdf
+country VU: DFS-FCC
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (17), AUTO-BW
+	(5250 - 5330 @ 80), (24), DFS, AUTO-BW
+	(5490 - 5730 @ 160), (24), DFS
+	(5735 - 5835 @ 80), (30)
+
+country WF: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+country YE:
+	(2402 - 2482 @ 40), (20)
+
+country YT: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+country ZA: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
+country ZW: DFS-ETSI
+	(2402 - 2482 @ 40), (20)
+	(5170 - 5250 @ 80), (20), AUTO-BW
+	(5250 - 5330 @ 80), (20), DFS, AUTO-BW
+	(5490 - 5710 @ 160), (27), DFS
+
diff --git a/net/xfrm/xfrm_output.c b/net/xfrm/xfrm_output.c
index 73ad8c8ef344..80b8b36e3e7e 100644
--- a/net/xfrm/xfrm_output.c
+++ b/net/xfrm/xfrm_output.c
@@ -119,6 +119,9 @@ static int xfrm_output_one(struct sk_buff *skb, int err)
 			goto error_nolock;
 		}
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+next_dst:
+#endif
 		dst = skb_dst_pop(skb);
 		if (!dst) {
 			XFRM_INC_STATS(net, LINUX_MIB_XFRMOUTERROR);
@@ -128,12 +131,43 @@ static int xfrm_output_one(struct sk_buff *skb, int err)
 		skb_dst_set(skb, dst);
 		x = dst->xfrm;
 	} while (x && !(x->outer_mode->flags & XFRM_MODE_FLAG_TUNNEL));
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	if (!skb->sp || atomic_read(&skb->sp->refcnt) != 1) {
+		struct sec_path *sp;
+
+		sp = secpath_dup(skb->sp);
+		if (!sp)
+			goto error_nolock;
+		if (skb->sp)
+			secpath_put(skb->sp);
+		skb->sp = sp;
+	}
+
+	/* Hub and spoke changes: Resetting the POLICY_IN SA and setting only the 
+	POLICY_OUT SA */
+	if (skb->ipsec_xfrm_dir & ( 1 << XFRM_POLICY_IN))
+	{
+		skb->sp->len = 0;
+		skb->ipsec_xfrm_dir &= ~ ( 1 << XFRM_POLICY_IN);
+	}
+
+	if (xfrm_nr + skb->sp->len > XFRM_MAX_DEPTH)
+		goto error_nolock;
+
+	memcpy(skb->sp->xvec + skb->sp->len, xfrm_vec,
+	       xfrm_nr * sizeof(xfrm_vec[0]));
+	skb->sp->len += xfrm_nr;
+#endif
 
 	return 0;
 
 error:
 	spin_unlock_bh(&x->lock);
 error_nolock:
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	for (i = 0; i < xfrm_nr; i++)
+		xfrm_state_put(xfrm_vec[i]);
+#endif
 	kfree_skb(skb);
 out:
 	return err;
diff --git a/net/xfrm/xfrm_policy.c b/net/xfrm/xfrm_policy.c
index 688ed34f0671..cca441dbeb0e 100644
--- a/net/xfrm/xfrm_policy.c
+++ b/net/xfrm/xfrm_policy.c
@@ -54,6 +54,11 @@ static struct xfrm_policy_afinfo const __rcu *xfrm_policy_afinfo[AF_INET6 + 1]
 static struct kmem_cache *xfrm_dst_cache __read_mostly;
 static __read_mostly seqcount_t xfrm_policy_hash_generation;
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+extern int ipsec_nlkey_flow(u16 xfrm_nr, u16 *xfrm_handle,
+                const struct flowi *fl, u16 family, u16 dir, u16 ignore_neigh);
+#endif
+
 static void xfrm_init_pmtu(struct dst_entry *dst);
 static int stale_bundle(struct dst_entry *dst);
 static int xfrm_bundle_ok(struct xfrm_dst *xdst);
@@ -170,6 +175,9 @@ static inline struct dst_entry *xfrm_dst_lookup(struct xfrm_state *x,
 
 	return dst;
 }
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+EXPORT_SYMBOL(xfrm_dst_lookup);
+#endif
 
 static inline unsigned long make_jiffies(long secs)
 {
@@ -1532,6 +1540,9 @@ static inline int xfrm_fill_dst(struct xfrm_dst *xdst, struct net_device *dev,
 
 	return err;
 }
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+EXPORT_SYMBOL(xfrm_get_tos);
+#endif
 
 
 /* Allocate chain of dst_entry's, attach known xfrm's, calculate
@@ -2127,6 +2138,9 @@ struct dst_entry *xfrm_lookup(struct net *net, struct dst_entry *dst_orig,
 	u16 family = dst_orig->ops->family;
 	u8 dir = XFRM_POLICY_OUT;
 	int i, err, num_pols, num_xfrms = 0, drop_pols = 0;
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	u8 new_flow = 0;
+#endif
 
 	dst = NULL;
 	xdst = NULL;
@@ -2238,6 +2252,33 @@ struct dst_entry *xfrm_lookup(struct net *net, struct dst_entry *dst_orig,
 		dst_release(dst);
 		dst = dst_orig;
 	}
+
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	if (new_flow) {
+		struct dst_entry *dst1 = dst;
+		struct xfrm_state *x; 
+		u16	xfrm_handle[XFRM_POLICY_TYPE_MAX];
+		u16	ignore_neigh = 0;
+
+		num_xfrms = 0;
+		memset(xfrm_handle, 0, XFRM_POLICY_TYPE_MAX*sizeof(u16));
+		while((x = dst1->xfrm) != NULL) {
+			if (!x->offloaded)
+				goto ok;
+			xfrm_handle[num_xfrms++] = x->handle;
+			if(x->props.mode == XFRM_MODE_TUNNEL)
+				ignore_neigh = 1;
+			dst1 = dst1->child;
+			if (dst1 == NULL) {
+				err = -EHOSTUNREACH;
+				goto error;
+			}
+		}
+		// sent flow notification to cmm with sa_handle
+		ipsec_nlkey_flow(num_xfrms, xfrm_handle, fl, family, (unsigned short)dir, ignore_neigh);
+	}
+#endif
+
 ok:
 	xfrm_pols_put(pols, drop_pols);
 	if (dst && dst->xfrm &&
@@ -2382,6 +2423,9 @@ int __xfrm_policy_check(struct sock *sk, int dir, struct sk_buff *skb,
 	int xfrm_nr;
 	int pi;
 	int reverse;
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	u8 new_flow = 0;
+#endif
 	struct flowi fl;
 	int xerr_idx = -1;
 
@@ -2508,6 +2552,32 @@ int __xfrm_policy_check(struct sock *sk, int dir, struct sk_buff *skb,
 			goto reject;
 		}
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+		if (new_flow) {
+			struct xfrm_state *x;
+			u16	xfrm_handle[XFRM_POLICY_TYPE_MAX];
+
+			xfrm_nr = 0;
+			memset(xfrm_handle, 0, XFRM_POLICY_TYPE_MAX*sizeof(u16));
+			for (i=sp->len-1; i>=0; i--) 
+			{
+				x = sp->xvec[i];
+
+				if (!x->offloaded)
+					goto std_path;
+
+				xfrm_handle[xfrm_nr++] = x->handle;
+			}
+			// sent flow notification to cmm with sa_handle
+			if (xfrm_nr)
+				ipsec_nlkey_flow(xfrm_nr, xfrm_handle, (const struct flowi *)&fl, family, fl_dir, 0);
+		}
+
+		/* Hub and spoke changes : Setting the POLICY_IN direction in the packet*/
+		skb->ipsec_xfrm_dir |= (1 << XFRM_POLICY_IN); 
+
+std_path:
+#endif
 		xfrm_pols_put(pols, npols);
 		return 1;
 	}
diff --git a/net/xfrm/xfrm_state.c b/net/xfrm/xfrm_state.c
index 1f5cee2269af..3fcaf4206d80 100644
--- a/net/xfrm/xfrm_state.c
+++ b/net/xfrm/xfrm_state.c
@@ -51,6 +51,9 @@ static inline bool xfrm_state_hold_rcu(struct xfrm_state __rcu *x)
 	return refcount_inc_not_zero(&x->refcnt);
 }
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+static unsigned short xfrm_state_handle;
+#endif
 static inline unsigned int xfrm_dst_hash(struct net *net,
 					 const xfrm_address_t *daddr,
 					 const xfrm_address_t *saddr,
@@ -75,11 +78,20 @@ xfrm_spi_hash(struct net *net, const xfrm_address_t *daddr,
 	return __xfrm_spi_hash(daddr, spi, proto, family, net->xfrm.state_hmask);
 }
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+static void xfrm_hash_transfer(struct hlist_head *list,
+			       struct hlist_head *ndsttable,
+			       struct hlist_head *nsrctable,
+			       struct hlist_head *nspitable,
+			       struct hlist_head *nhtable,
+			       unsigned int nhashmask)
+#else
 static void xfrm_hash_transfer(struct hlist_head *list,
 			       struct hlist_head *ndsttable,
 			       struct hlist_head *nsrctable,
 			       struct hlist_head *nspitable,
 			       unsigned int nhashmask)
+#endif
 {
 	struct hlist_node *tmp;
 	struct xfrm_state *x;
@@ -103,6 +115,12 @@ static void xfrm_hash_transfer(struct hlist_head *list,
 					    nhashmask);
 			hlist_add_head_rcu(&x->byspi, nspitable + h);
 		}
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+		if (x->handle && x->in_byh_hash) {
+			h = (x->handle & nhashmask);
+			hlist_add_head_rcu(&x->byh, nhtable + h);
+		}
+#endif
 	}
 }
 
@@ -115,6 +133,9 @@ static void xfrm_hash_resize(struct work_struct *work)
 {
 	struct net *net = container_of(work, struct net, xfrm.state_hash_work);
 	struct hlist_head *ndst, *nsrc, *nspi, *odst, *osrc, *ospi;
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	struct hlist_head *nh, *oh;
+#endif
 	unsigned long nsize, osize;
 	unsigned int nhashmask, ohashmask;
 	int i;
@@ -134,6 +155,15 @@ static void xfrm_hash_resize(struct work_struct *work)
 		xfrm_hash_free(nsrc, nsize);
 		return;
 	}
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	nh = xfrm_hash_alloc(nsize);
+	if (!nh) {
+		xfrm_hash_free(ndst, nsize);
+		xfrm_hash_free(nsrc, nsize);
+		xfrm_hash_free(nspi, nsize);
+		return;
+	}
+#endif
 
 	spin_lock_bh(&net->xfrm.xfrm_state_lock);
 	write_seqcount_begin(&xfrm_state_hash_generation);
@@ -141,15 +171,25 @@ static void xfrm_hash_resize(struct work_struct *work)
 	nhashmask = (nsize / sizeof(struct hlist_head)) - 1U;
 	odst = xfrm_state_deref_prot(net->xfrm.state_bydst, net);
 	for (i = net->xfrm.state_hmask; i >= 0; i--)
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)		
+		xfrm_hash_transfer(odst + i, ndst, nsrc, nspi, nh, nhashmask);
+#else
 		xfrm_hash_transfer(odst + i, ndst, nsrc, nspi, nhashmask);
+#endif
 
 	osrc = xfrm_state_deref_prot(net->xfrm.state_bysrc, net);
 	ospi = xfrm_state_deref_prot(net->xfrm.state_byspi, net);
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	oh   = xfrm_state_deref_prot(net->xfrm.state_byh, net);
+#endif
 	ohashmask = net->xfrm.state_hmask;
 
 	rcu_assign_pointer(net->xfrm.state_bydst, ndst);
 	rcu_assign_pointer(net->xfrm.state_bysrc, nsrc);
 	rcu_assign_pointer(net->xfrm.state_byspi, nspi);
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	rcu_assign_pointer(net->xfrm.state_byh, nh);
+#endif
 	net->xfrm.state_hmask = nhashmask;
 
 	write_seqcount_end(&xfrm_state_hash_generation);
@@ -162,6 +202,9 @@ static void xfrm_hash_resize(struct work_struct *work)
 	xfrm_hash_free(odst, osize);
 	xfrm_hash_free(osrc, osize);
 	xfrm_hash_free(ospi, osize);
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	xfrm_hash_free(oh,   osize);
+#endif
 }
 
 static DEFINE_SPINLOCK(xfrm_state_afinfo_lock);
@@ -572,6 +615,10 @@ struct xfrm_state *xfrm_state_alloc(struct net *net)
 		INIT_HLIST_NODE(&x->bydst);
 		INIT_HLIST_NODE(&x->bysrc);
 		INIT_HLIST_NODE(&x->byspi);
+
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+		INIT_HLIST_NODE(&x->byh);
+#endif
 		tasklet_hrtimer_init(&x->mtimer, xfrm_timer_handler,
 					CLOCK_BOOTTIME, HRTIMER_MODE_ABS);
 		setup_timer(&x->rtimer, xfrm_replay_timer_handler,
@@ -583,6 +630,12 @@ struct xfrm_state *xfrm_state_alloc(struct net *net)
 		x->lft.hard_packet_limit = XFRM_INF;
 		x->replay_maxage = 0;
 		x->replay_maxdiff = 0;
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+		do {
+			x->handle = xfrm_state_handle++;
+		} while (x->handle == 0);
+		x->in_byh_hash = 0;
+#endif
 		x->inner_mode = NULL;
 		x->inner_mode_iaf = NULL;
 		spin_lock_init(&x->lock);
@@ -615,6 +668,17 @@ int __xfrm_state_delete(struct xfrm_state *x)
 		hlist_del_rcu(&x->bysrc);
 		if (x->id.spi)
 			hlist_del_rcu(&x->byspi);
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+		/*
+		 * if 'handle' value is assigned and xfrm_state is inserted
+		 * into 'byh' hash table, remove it now and reset 'in_byh_hash'
+		 * to zero.  
+		 */
+		if (x->handle && x->in_byh_hash) {
+			hlist_del_rcu(&x->byh);
+			x->in_byh_hash = 0;
+		}
+#endif
 		net->xfrm.state_num--;
 		spin_unlock(&net->xfrm.xfrm_state_lock);
 
@@ -1029,6 +1093,19 @@ xfrm_state_find(const xfrm_address_t *daddr, const xfrm_address_t *saddr,
 				h = xfrm_spi_hash(net, &x->id.daddr, x->id.spi, x->id.proto, encap_family);
 				hlist_add_head_rcu(&x->byspi, net->xfrm.state_byspi + h);
 			}
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+			/*
+			 * at this point, xfrm_state is activated because it
+			 * has been inserted into other linux original hash
+			 * tables.  it must be inserted into 'byh' hash table
+			 * too if it is not yet inserted.
+			 */
+			if (x->handle && !x->in_byh_hash) {
+				h = (x->handle & net->xfrm.state_hmask);
+				hlist_add_head_rcu(&x->byh, net->xfrm.state_byh+h);
+				x->in_byh_hash = 1;
+			}
+#endif
 			x->lft.hard_add_expires_seconds = net->xfrm.sysctl_acq_expires;
 			tasklet_hrtimer_start(&x->mtimer, ktime_set(net->xfrm.sysctl_acq_expires, 0), HRTIMER_MODE_REL);
 			net->xfrm.state_num++;
@@ -1140,6 +1217,18 @@ static void __xfrm_state_insert(struct xfrm_state *x)
 
 		hlist_add_head_rcu(&x->byspi, net->xfrm.state_byspi + h);
 	}
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	/*
+	 * at this point, xfrm_state is activated because it has been inserted
+	 * into other linux original hash tables.  it must also be inserted
+	 * into 'byh' hash table if it is not yet inserted.
+	 */
+	if (x->handle && !x->in_byh_hash) {
+		h = (x->handle & net->xfrm.state_hmask);
+		hlist_add_head_rcu(&x->byh, net->xfrm.state_byh+h);
+		x->in_byh_hash = 1;
+	}
+#endif
 
 	tasklet_hrtimer_start(&x->mtimer, ktime_set(1, 0), HRTIMER_MODE_REL);
 	if (x->replay_maxage)
@@ -1250,6 +1339,19 @@ static struct xfrm_state *__find_acq_core(struct net *net,
 		hlist_add_head_rcu(&x->bydst, net->xfrm.state_bydst + h);
 		h = xfrm_src_hash(net, daddr, saddr, family);
 		hlist_add_head_rcu(&x->bysrc, net->xfrm.state_bysrc + h);
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+		/*
+		 * at this point, xfrm_state is activated because it has been
+		 * inserted into other linux original hash tables.  it must
+		 * also be inserted into 'byh' hash table if it is not yet
+		 * inserted.
+		 */
+		if (x->handle && !x->in_byh_hash) {
+			h = (x->handle & net->xfrm.state_hmask);
+			hlist_add_head_rcu(&x->byh, net->xfrm.state_byh+h);
+			x->in_byh_hash = 1;
+		}
+#endif
 
 		net->xfrm.state_num++;
 
@@ -1609,6 +1711,38 @@ xfrm_state_lookup_byaddr(struct net *net, u32 mark,
 }
 EXPORT_SYMBOL(xfrm_state_lookup_byaddr);
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+struct xfrm_state *__xfrm_state_lookup_byhandle(struct net *net, u16 handle)
+{
+	unsigned int h = (handle & net->xfrm.state_hmask);
+	struct xfrm_state *x;
+	struct hlist_node *entry;
+
+	//hlist_for_each_entry(x, entry, net->xfrm.state_byh+h, byh) { // FIXME
+	hlist_for_each_entry(x, net->xfrm.state_byh+h, byh) {
+		if (x->handle != handle)
+			continue;
+	
+		xfrm_state_hold(x);
+		return x;
+	}
+
+	return NULL;
+}
+
+struct xfrm_state *
+xfrm_state_lookup_byhandle(struct net *net, u16 handle)
+{
+	struct xfrm_state *x;
+
+	spin_lock_bh(&net->xfrm.xfrm_state_lock);
+	x = __xfrm_state_lookup_byhandle(net, handle);
+	spin_unlock_bh(&net->xfrm.xfrm_state_lock);
+	return x;
+}
+EXPORT_SYMBOL(xfrm_state_lookup_byhandle);
+#endif
+
 struct xfrm_state *
 xfrm_find_acq(struct net *net, const struct xfrm_mark *mark, u8 mode, u32 reqid,
 	      u8 proto, const xfrm_address_t *daddr,
@@ -1784,6 +1918,20 @@ int xfrm_alloc_spi(struct xfrm_state *x, u32 low, u32 high)
 		spin_lock_bh(&net->xfrm.xfrm_state_lock);
 		h = xfrm_spi_hash(net, &x->id.daddr, x->id.spi, x->id.proto, x->props.family);
 		hlist_add_head_rcu(&x->byspi, net->xfrm.state_byspi + h);
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+		/*
+		 * at this point, xfrm_state is inserted into 'byspi' hash
+		 * table.  this may be an additional step to make the entry
+		 * searchable by SPI.  however, it is a time to consider
+		 * whether the entry is also inserted into 'byh' hash talbe
+		 * or not.  if it still not be inserted, insert it now.
+		 */
+		if (x->handle && !x->in_byh_hash) {
+			h = (x->handle & net->xfrm.state_hmask);
+			hlist_add_head_rcu(&x->byh, net->xfrm.state_byh+h);
+			x->in_byh_hash = 1;
+		}
+#endif
 		spin_unlock_bh(&net->xfrm.xfrm_state_lock);
 
 		err = 0;
@@ -2297,6 +2445,12 @@ int __net_init xfrm_state_init(struct net *net)
 	net->xfrm.state_byspi = xfrm_hash_alloc(sz);
 	if (!net->xfrm.state_byspi)
 		goto out_byspi;
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	net->xfrm.state_byh = xfrm_hash_alloc(sz);
+	if (!net->xfrm.state_byh)
+		goto out_byh;
+	get_random_bytes(&xfrm_state_handle, sizeof(xfrm_state_handle));
+#endif
 	net->xfrm.state_hmask = ((sz / sizeof(struct hlist_head)) - 1);
 
 	net->xfrm.state_num = 0;
@@ -2304,6 +2458,10 @@ int __net_init xfrm_state_init(struct net *net)
 	spin_lock_init(&net->xfrm.xfrm_state_lock);
 	return 0;
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+out_byh:
+	xfrm_hash_free(net->xfrm.state_byspi, sz);
+#endif
 out_byspi:
 	xfrm_hash_free(net->xfrm.state_bysrc, sz);
 out_bysrc:
@@ -2329,6 +2487,10 @@ void xfrm_state_fini(struct net *net)
 	xfrm_hash_free(net->xfrm.state_bysrc, sz);
 	WARN_ON(!hlist_empty(net->xfrm.state_bydst));
 	xfrm_hash_free(net->xfrm.state_bydst, sz);
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	WARN_ON(!hlist_empty(net->xfrm.state_byh));
+	xfrm_hash_free(net->xfrm.state_byh, sz);
+#endif
 }
 
 #ifdef CONFIG_AUDITSYSCALL
-- 
2.17.1

